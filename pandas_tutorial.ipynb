{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# introduction to data structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pandas' from '/home/ultron/Desktop/Python/myenv/lib/python3.12/site-packages/pandas/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({'A': [1, 2, 3]})\n",
    "pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series\n",
    "\n",
    "Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. The basic method to create a Series is to call:\n",
    "\n",
    "s = pd.Series(data, index=index)\n",
    "Here, data can be many different things:\n",
    "\n",
    "- a Python dict\n",
    "\n",
    "- an ndarray\n",
    "\n",
    "- a scalar value (like 5)\n",
    "\n",
    "The passed index is a list of axis labels. Thus, this separates into a few cases depending on what data is:\n",
    "\n",
    "From ndarray\n",
    "\n",
    "If data is an ndarray, index must be the same length as data. If no index is passed, one will be created having values [0, ..., len(data) - 1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas.Series\n",
    "\n",
    "class pandas.Series(data=None, index=None, dtype=None, name=None, copy=None, fastpath=<no_default>)\n",
    "\n",
    "One-dimensional ndarray with axis labels (including time series).\n",
    "\n",
    "Labels need not be unique but must be a hashable type. The object supports both integer- and label-based indexing and provides a host of methods for performing operations involving the index. Statistical methods from ndarray have been overridden to automatically exclude missing data (currently represented as NaN).\n",
    "\n",
    "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their associated index values– they need not be the same length. The result index will be the sorted union of the two indexes.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "data:\n",
    "\n",
    "array-like, Iterable, dict, or scalar value\n",
    "Contains data stored in Series. If data is a dict, argument order is maintained.\n",
    "\n",
    "index:\n",
    "\n",
    "array-like or Index (1d)\n",
    "\n",
    "Values must be hashable and have the same length as data. Non-unique index values are allowed. Will default to RangeIndex (0, 1, 2, …, n) if not provided. If data is dict-like and index is None, then the keys in the data are used as the index. If the index is not None, the resulting Series is reindexed with the index values.\n",
    "\n",
    "dtype:\n",
    "\n",
    "str, numpy.dtype, or ExtensionDtype, optional\n",
    "Data type for the output Series. If not specified, this will be inferred from data. See the user guide for more usages.\n",
    "\n",
    "name:\n",
    "\n",
    "Hashable, default None\n",
    "The name to give to the Series.\n",
    "\n",
    "copy:\n",
    "\n",
    "bool, default False\n",
    "Copy input data. Only affects Series or 1d ndarray input. See examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "ser = pd.Series(data=d, index=['a', 'b', 'c'])\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    999\n",
       "1      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [1, 2]\n",
    "ser = pd.Series(r, copy=False)\n",
    "ser.iloc[0] = 999\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([999,   2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.array([1, 2])\n",
    "ser = pd.Series(r, copy=False)\n",
    "ser.iloc[0] = 999\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to input data type the Series has a view on the original data, so the data is changed as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series`** is a one-dimensional labeled array that can hold data of any type (integers, floats, strings, Python objects, etc.). It is one of the core data structures in the Pandas library and is widely used for data manipulation and analysis in Python. Below is a detailed explanation of the **`pandas.Series`** class, including its parameters, attributes, methods, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Overview of `pandas.Series`**\n",
    "\n",
    "A `Series` is similar to a column in a spreadsheet or a single column in a SQL table. It has:\n",
    "\n",
    "- **Data**: The actual values stored in the Series.\n",
    "- **Index**: Labels associated with each value in the Series.\n",
    "- **dtype**: The data type of the values in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Parameters of `pandas.Series`**\n",
    "\n",
    "The `pandas.Series` constructor has the following parameters:\n",
    "\n",
    "```python\n",
    "pandas.Series(data=None, index=None, dtype=None, name=None, copy=None, fastpath=<no_default>)\n",
    "```\n",
    "\n",
    "#### **Parameters:**\n",
    "\n",
    "1. **`data`**:\n",
    "\n",
    "   - Input data for the Series. Can be:\n",
    "     - A list, tuple, or NumPy array.\n",
    "     - A dictionary.\n",
    "     - A scalar value (e.g., `5`).\n",
    "   - If `data` is a dictionary, the keys are used as the index unless an `index` is explicitly provided.\n",
    "\n",
    "2. **`index`**:\n",
    "\n",
    "   - Index labels for the Series. Must be the same length as `data`.\n",
    "   - If not provided, it defaults to `RangeIndex(0, 1, 2, ..., n-1)`.\n",
    "\n",
    "3. **`dtype`**:\n",
    "\n",
    "   - Data type for the Series (e.g., `int`, `float`, `str`).\n",
    "   - If not specified, Pandas infers the data type from the input data.\n",
    "\n",
    "4. **`name`**:\n",
    "\n",
    "   - Name of the Series. Useful when combining multiple Series into a DataFrame.\n",
    "\n",
    "5. **`copy`**:\n",
    "   - If `True`, copies the input data. Default is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Creating a Series**\n",
    "\n",
    "#### **3.1 From a List**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series from a list\n",
    "data = [10, 20, 30, 40, 50]\n",
    "s = pd.Series(data)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    10\n",
    "1    20\n",
    "2    30\n",
    "3    40\n",
    "4    50\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### **3.2 From a Dictionary**\n",
    "\n",
    "```python\n",
    "# Create a Series from a dictionary\n",
    "data = {'a': 10, 'b': 20, 'c': 30}\n",
    "s = pd.Series(data)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    10\n",
    "b    20\n",
    "c    30\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### **3.3 From a NumPy Array**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create a Series from a NumPy array\n",
    "arr = np.array([1.5, 2.5, 3.5, 4.5])\n",
    "s = pd.Series(arr)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1.5\n",
    "1    2.5\n",
    "2    3.5\n",
    "3    4.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### **3.4 From a Scalar Value**\n",
    "\n",
    "```python\n",
    "# Create a Series from a scalar value\n",
    "s = pd.Series(5, index=[0, 1, 2, 3])\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    5\n",
    "1    5\n",
    "2    5\n",
    "3    5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Attributes of a Series**\n",
    "\n",
    "#### **4.1 `index`**\n",
    "\n",
    "- Returns the index of the Series.\n",
    "\n",
    "```python\n",
    "print(s.index)  # Output: Index([0, 1, 2, 3], dtype='int64')\n",
    "```\n",
    "\n",
    "#### **4.2 `values`**\n",
    "\n",
    "- Returns the data in the Series as a NumPy array.\n",
    "\n",
    "```python\n",
    "print(s.values)  # Output: [5 5 5 5]\n",
    "```\n",
    "\n",
    "#### **4.3 `dtype`**\n",
    "\n",
    "- Returns the data type of the Series.\n",
    "\n",
    "```python\n",
    "print(s.dtype)  # Output: int64\n",
    "```\n",
    "\n",
    "#### **4.4 `shape`**\n",
    "\n",
    "- Returns the shape of the Series.\n",
    "\n",
    "```python\n",
    "print(s.shape)  # Output: (4,)\n",
    "```\n",
    "\n",
    "#### **4.5 `name`**\n",
    "\n",
    "- Returns or sets the name of the Series.\n",
    "\n",
    "```python\n",
    "s.name = \"My Series\"\n",
    "print(s.name)  # Output: My Series\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Methods of a Series**\n",
    "\n",
    "#### **5.1 `head()` and `tail()`**\n",
    "\n",
    "- `head(n)` returns the first `n` elements.\n",
    "- `tail(n)` returns the last `n` elements.\n",
    "\n",
    "```python\n",
    "print(s.head(2))  # Output: First 2 elements\n",
    "print(s.tail(2))  # Output: Last 2 elements\n",
    "```\n",
    "\n",
    "#### **5.2 `describe()`**\n",
    "\n",
    "- Provides summary statistics.\n",
    "\n",
    "```python\n",
    "print(s.describe())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "count    4.0\n",
    "mean     5.0\n",
    "std      0.0\n",
    "min      5.0\n",
    "25%      5.0\n",
    "50%      5.0\n",
    "75%      5.0\n",
    "max      5.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### **5.3 `isnull()` and `notnull()`**\n",
    "\n",
    "- Check for missing values.\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4])\n",
    "print(s.isnull())  # Output: Boolean Series indicating missing values\n",
    "print(s.notnull())  # Output: Boolean Series indicating non-missing values\n",
    "```\n",
    "\n",
    "#### **5.4 `dropna()`**\n",
    "\n",
    "- Drops missing values.\n",
    "\n",
    "```python\n",
    "s_cleaned = s.dropna()\n",
    "print(s_cleaned)\n",
    "```\n",
    "\n",
    "#### **5.5 `fillna()`**\n",
    "\n",
    "- Fills missing values with a specified value.\n",
    "\n",
    "```python\n",
    "s_filled = s.fillna(0)\n",
    "print(s_filled)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Operations on Series**\n",
    "\n",
    "#### **6.1 Arithmetic Operations**\n",
    "\n",
    "```python\n",
    "s1 = pd.Series([1, 2, 3, 4])\n",
    "s2 = pd.Series([10, 20, 30, 40])\n",
    "\n",
    "# Addition\n",
    "print(s1 + s2)\n",
    "\n",
    "# Multiplication\n",
    "print(s1 * s2)\n",
    "```\n",
    "\n",
    "#### **6.2 Logical Operations**\n",
    "\n",
    "```python\n",
    "# Filter elements greater than 2\n",
    "print(s1[s1 > 2])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Advanced Topics**\n",
    "\n",
    "#### **7.1 Reindexing**\n",
    "\n",
    "Reindexing allows you to change the index of a Series.\n",
    "\n",
    "```python\n",
    "s = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "s_reindexed = s.reindex(['c', 'b', 'a', 'd'])\n",
    "print(s_reindexed)\n",
    "```\n",
    "\n",
    "#### **7.2 Sorting**\n",
    "\n",
    "- Sort by index or values.\n",
    "\n",
    "```python\n",
    "# Sort by index\n",
    "print(s.sort_index())\n",
    "\n",
    "# Sort by values\n",
    "print(s.sort_values())\n",
    "```\n",
    "\n",
    "#### **7.3 Applying Functions**\n",
    "\n",
    "You can apply a function to each element in the Series.\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "print(s.apply(lambda x: x**2))\n",
    "```\n",
    "\n",
    "#### **7.4 Vectorized Operations**\n",
    "\n",
    "Pandas Series supports vectorized operations with NumPy functions.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "print(np.sqrt(s))  # Square root of each element\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Practical Applications**\n",
    "\n",
    "- **Data Cleaning**: Handle missing values, filter data, etc.\n",
    "- **Data Analysis**: Perform statistical operations.\n",
    "- **Feature Engineering**: Create new features from existing data.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Summary**\n",
    "\n",
    "- A `pandas.Series` is a one-dimensional labeled array.\n",
    "- It can be created from lists, NumPy arrays, dictionaries, or scalar values.\n",
    "- You can access elements using labels or positions.\n",
    "- Series supports various operations, including arithmetic, logical, and vectorized operations.\n",
    "- Advanced features include reindexing, sorting, and applying functions.\n",
    "\n",
    "By mastering `pandas.Series`, you'll have a strong foundation for working with tabular data in Python. Let me know if you'd like further clarification or additional examples!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **transpose** of a matrix is an operation that flips the matrix over its diagonal, swapping its rows and columns. If you have a matrix \\( A \\), its **transpose**, denoted as \\( A^T \\), is obtained by switching the element at position \\( (i, j) \\) with the element at \\( (j, i) \\).\n",
    "\n",
    "## **Definition**\n",
    "\n",
    "If a matrix \\( A \\) is given by:\n",
    "\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "a*{11} & a*{12} & \\dots & a*{1n} \\\\\n",
    "a*{21} & a*{22} & \\dots & a*{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a*{m1} & a*{m2} & \\dots & a\\_{mn}\n",
    "\\end{bmatrix}\n",
    "\n",
    "Then its transpose \\( A^T \\) is:\n",
    "\n",
    "A^T =\n",
    "\\begin{bmatrix}\n",
    "a*{11} & a*{21} & \\dots & a*{m1} \\\\\n",
    "a*{12} & a*{22} & \\dots & a*{m2} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a*{1n} & a*{2n} & \\dots & a\\_{mn}\n",
    "\\end{bmatrix}\n",
    "\n",
    "This means the rows of \\( A \\) become the columns of \\( A^T \\) and vice versa.\n",
    "\n",
    "## **Properties of the Transpose**\n",
    "\n",
    "1. **Double Transpose Property**:\n",
    "\n",
    "   (A^T)^T = A\n",
    "\n",
    "   Taking the transpose twice returns the original matrix.\n",
    "\n",
    "2. **Addition Property**:\n",
    "\n",
    "   (A + B)^T = A^T + B^T\n",
    "\n",
    "   The transpose of a sum is the sum of the transposes.\n",
    "\n",
    "3. **Scalar Multiplication**:\n",
    "\n",
    "   (cA)^T = cA^T\n",
    "\n",
    "   The transpose of a scalar multiple is the scalar times the transpose.\n",
    "\n",
    "4. **Multiplication Property**:\n",
    "\n",
    "   (AB)^T = B^T A^T\n",
    "\n",
    "   The transpose of a product reverses the order of multiplication.\n",
    "\n",
    "5. **Inverse Property (for invertible matrices)**:\n",
    "\n",
    "   (A^{-1})^T = (A^T)^{-1}\n",
    "\n",
    "   The transpose of the inverse is the inverse of the transpose.\n",
    "\n",
    "6. **Symmetric Matrices**:  \n",
    "   A matrix is **symmetric** if:\n",
    "\n",
    "   A^T = A\n",
    "\n",
    "   That means it is equal to its transpose.\n",
    "\n",
    "7. **Orthogonal Matrices**:  \n",
    "   A matrix \\( Q \\) is **orthogonal** if:\n",
    "\n",
    "   Q^T Q = Q Q^T = I\n",
    "\n",
    "   Its transpose is also its inverse.\n",
    "\n",
    "## **Special Cases**\n",
    "\n",
    "- **Square Matrices**: For a square matrix (same number of rows and columns), the transpose maintains its square shape.\n",
    "- **Column and Row Vectors**:\n",
    "  - A **column vector** (single column) becomes a **row vector** when transposed.\n",
    "  - A **row vector** (single row) becomes a **column vector** when transposed.\n",
    "\n",
    "## **Example**\n",
    "\n",
    "Consider the matrix:\n",
    "\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix}\n",
    "\n",
    "Its transpose is:\n",
    "\n",
    "A^T =\n",
    "\\begin{bmatrix}\n",
    "1 & 4 \\\\\n",
    "2 & 5 \\\\\n",
    "3 & 6\n",
    "\\end{bmatrix}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Pandas.Series.index\n",
    "\n",
    "Series.index\n",
    "\n",
    "The index (axis labels) of the Series.\n",
    "\n",
    "The index of a Series is used to label and identify each element of the underlying data. The index can be thought of as an immutable ordered set (technically a multi-set, as it may contain duplicate labels), and is used to index and align data in pandas.\n",
    "\n",
    "Returns :\n",
    "Index\n",
    "The index labels of the Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Kolkata', 'Chicago', 'Toronto', 'Lisbon'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = ['Kolkata', 'Chicago', 'Toronto', 'Lisbon']\n",
    "populations = [14.85, 2.71, 2.93, 0.51]\n",
    "city_series = pd.Series(populations, index=cities)\n",
    "city_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KOL', 'CHI', 'TOR', 'LIS'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_series.index = ['KOL', 'CHI', 'TOR', 'LIS']\n",
    "city_series.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas.Series.index\n",
    "\n",
    "The `Series.index` attribute in **pandas** is used to access and manipulate the **index labels** of a Series. It is an **immutable ordered set** (technically a multi-set, as duplicate labels are allowed). The index helps **identify and align data** in pandas.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Basic Usage: Accessing Index**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "cities = ['Kolkata', 'Chicago', 'Toronto', 'Lisbon']\n",
    "populations = [14.85, 2.71, 2.93, 0.51]\n",
    "\n",
    "city_series = pd.Series(populations, index=cities)\n",
    "print(city_series.index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Index(['Kolkata', 'Chicago', 'Toronto', 'Lisbon'], dtype='object')\n",
    "```\n",
    "\n",
    "- This returns the **index labels** of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Changing the Index**\n",
    "\n",
    "You can change the index labels of an existing Series.\n",
    "\n",
    "```python\n",
    "city_series.index = ['KOL', 'CHI', 'TOR', 'LIS']\n",
    "print(city_series.index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Index(['KOL', 'CHI', 'TOR', 'LIS'], dtype='object')\n",
    "```\n",
    "\n",
    "- Directly replaces the existing index.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Getting Index Values**\n",
    "\n",
    "You can get the index values as a **NumPy array**.\n",
    "\n",
    "```python\n",
    "print(city_series.index.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "['KOL' 'CHI' 'TOR' 'LIS']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Checking Index Data Type**\n",
    "\n",
    "```python\n",
    "print(city_series.index.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "object\n",
    "```\n",
    "\n",
    "- Shows the **data type** of the index elements.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Checking if an Index Contains a Value**\n",
    "\n",
    "```python\n",
    "print('KOL' in city_series.index)  # True\n",
    "print('NYC' in city_series.index)  # False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Resetting the Index (Convert Index to Column)**\n",
    "\n",
    "```python\n",
    "city_reset = city_series.reset_index()\n",
    "print(city_reset)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "  index      0\n",
    "0   KOL  14.85\n",
    "1   CHI   2.71\n",
    "2   TOR   2.93\n",
    "3   LIS   0.51\n",
    "```\n",
    "\n",
    "- Converts the index into a column.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Setting a Column as Index**\n",
    "\n",
    "```python\n",
    "city_new = city_reset.set_index(\"index\")\n",
    "print(city_new)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        0\n",
    "index\n",
    "KOL  14.85\n",
    "CHI   2.71\n",
    "TOR   2.93\n",
    "LIS   0.51\n",
    "```\n",
    "\n",
    "- Uses the `\"index\"` column as the new index.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Renaming the Index**\n",
    "\n",
    "```python\n",
    "city_series.index.name = \"City Code\"\n",
    "print(city_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "City Code\n",
    "KOL    14.85\n",
    "CHI     2.71\n",
    "TOR     2.93\n",
    "LIS     0.51\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Sorting the Index**\n",
    "\n",
    "```python\n",
    "sorted_series = city_series.sort_index()\n",
    "print(sorted_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "CHI     2.71\n",
    "KOL    14.85\n",
    "LIS     0.51\n",
    "TOR     2.93\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- Sorts the Series **by index labels**.\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Reindexing (Changing Index & Adding Missing Values)**\n",
    "\n",
    "```python\n",
    "new_index = [\"KOL\", \"CHI\", \"TOR\", \"LIS\", \"NYC\"]\n",
    "reindexed_series = city_series.reindex(new_index, fill_value=0)\n",
    "print(reindexed_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "KOL    14.85\n",
    "CHI     2.71\n",
    "TOR     2.93\n",
    "LIS     0.51\n",
    "NYC     0.00\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- Adds missing index labels with a **default value**.\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Getting Index Position**\n",
    "\n",
    "```python\n",
    "print(city_series.index.get_loc(\"TOR\"))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2\n",
    "```\n",
    "\n",
    "- Returns the **position** of the label `\"TOR\"` in the index.\n",
    "\n",
    "---\n",
    "\n",
    "## **12. Converting Index to List**\n",
    "\n",
    "```python\n",
    "print(city_series.index.tolist())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "['KOL', 'CHI', 'TOR', 'LIS']\n",
    "```\n",
    "\n",
    "- Converts index to a **Python list**.\n",
    "\n",
    "---\n",
    "\n",
    "## **13. Checking If Index Is Unique**\n",
    "\n",
    "```python\n",
    "print(city_series.index.is_unique)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "- Returns `True` if **all index labels are unique**.\n",
    "\n",
    "---\n",
    "\n",
    "## **14. Checking Index Length**\n",
    "\n",
    "```python\n",
    "print(len(city_series.index))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "4\n",
    "```\n",
    "\n",
    "- Returns the **number of index elements**.\n",
    "\n",
    "---\n",
    "\n",
    "## **15. Getting Index Item by Position**\n",
    "\n",
    "```python\n",
    "print(city_series.index[1])  # 'CHI'\n",
    "```\n",
    "\n",
    "- Access **specific index labels** by position.\n",
    "\n",
    "---\n",
    "\n",
    "## **16. Getting a Slice of Index**\n",
    "\n",
    "```python\n",
    "print(city_series.index[:2])\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Index(['KOL', 'CHI'], dtype='object')\n",
    "```\n",
    "\n",
    "- Retrieves a **subset** of the index.\n",
    "\n",
    "---\n",
    "\n",
    "## **17. Finding Index of a Specific Label**\n",
    "\n",
    "```python\n",
    "print(city_series.index.get_indexer([\"TOR\", \"NYC\"]))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "[2 -1]\n",
    "```\n",
    "\n",
    "- Returns the **position** of labels (`-1` means not found).\n",
    "\n",
    "---\n",
    "\n",
    "## **18. Changing Index Type (e.g., Numeric)**\n",
    "\n",
    "```python\n",
    "city_series.index = [101, 102, 103, 104]\n",
    "print(city_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "101    14.85\n",
    "102     2.71\n",
    "103     2.93\n",
    "104     0.51\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- Replaces **string index** with numbers.\n",
    "\n",
    "---\n",
    "\n",
    "## **19. Checking Index Memory Usage**\n",
    "\n",
    "```python\n",
    "print(city_series.index.memory_usage())\n",
    "```\n",
    "\n",
    "- Shows the **memory usage** of the index.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary Table**\n",
    "\n",
    "| Syntax                     | Description                          |\n",
    "| -------------------------- | ------------------------------------ |\n",
    "| `s.index`                  | Get the index of a Series            |\n",
    "| `s.index = [...]`          | Set a new index                      |\n",
    "| `s.index.values`           | Get index values as NumPy array      |\n",
    "| `s.index.dtype`            | Get index data type                  |\n",
    "| `\"x\" in s.index`           | Check if a value exists in the index |\n",
    "| `s.reset_index()`          | Reset index to default numeric       |\n",
    "| `s.set_index(\"col\")`       | Set a column as an index             |\n",
    "| `s.index.name = \"NewName\"` | Name the index                       |\n",
    "| `s.sort_index()`           | Sort the Series by index             |\n",
    "| `s.reindex([...])`         | Change index, add missing values     |\n",
    "| `s.index.get_loc(\"x\")`     | Get position of an index label       |\n",
    "| `s.index.tolist()`         | Convert index to list                |\n",
    "| `s.index.is_unique`        | Check if index is unique             |\n",
    "| `s.index.memory_usage()`   | Get memory usage of index            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas.Series.array\n",
    "\n",
    "The **`.array`** property in **pandas.Series** returns the **ExtensionArray** that holds the underlying data. It is different from `.values`, which may convert the data into a **NumPy array**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Basic Usage: Accessing `.array`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.array)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<NumpyExtensionArray>\n",
    "[1, 2, 3]\n",
    "Length: 3, dtype: int64\n",
    "```\n",
    "\n",
    "- This returns a **pandas NumpyExtensionArray**, which wraps around a NumPy array.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Difference Between `.array` and `.values`**\n",
    "\n",
    "```python\n",
    "print(s.array)   # Returns an ExtensionArray\n",
    "print(s.values)  # Returns a NumPy array\n",
    "```\n",
    "\n",
    "- `.array` returns an **ExtensionArray**.\n",
    "- `.values` returns a **NumPy array** (or an object array if mixed types).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Working with Extension Types**\n",
    "\n",
    "For pandas **ExtensionArrays**, `.array` returns the **actual array**.\n",
    "\n",
    "### **Categorical Example**\n",
    "\n",
    "```python\n",
    "ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
    "print(ser.array)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "['a', 'b', 'a']\n",
    "Categories (2, object): ['a', 'b']\n",
    "```\n",
    "\n",
    "- Here, `.array` returns a **CategoricalArray** instead of a NumPy array.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Boolean ExtensionArray**\n",
    "\n",
    "```python\n",
    "ser = pd.Series([True, False, None], dtype=\"boolean\")\n",
    "print(ser.array)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<BooleanArray>\n",
    "[True, False, <NA>]\n",
    "Length: 3, dtype: boolean\n",
    "```\n",
    "\n",
    "- It returns a **BooleanArray** instead of a NumPy array.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. String ExtensionArray**\n",
    "\n",
    "```python\n",
    "ser = pd.Series([\"apple\", \"banana\", None], dtype=\"string\")\n",
    "print(ser.array)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<StringArray>\n",
    "['apple', 'banana', <NA>]\n",
    "Length: 3, dtype: string\n",
    "```\n",
    "\n",
    "- If the dtype is `\"string\"`, it returns a **StringArray**.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Integer ExtensionArray**\n",
    "\n",
    "```python\n",
    "ser = pd.Series([1, 2, None], dtype=\"Int64\")\n",
    "print(ser.array)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<IntegerArray>\n",
    "[1, 2, <NA>]\n",
    "Length: 3, dtype: Int64\n",
    "```\n",
    "\n",
    "- If the dtype is `\"Int64\"`, it returns an **IntegerArray** that supports `NaN` values.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. PeriodArray for Datetime-Like Data**\n",
    "\n",
    "```python\n",
    "ser = pd.Series(pd.period_range('2023-01', periods=3, freq='M'))\n",
    "print(ser.array)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<PeriodArray>\n",
    "['2023-01', '2023-02', '2023-03']\n",
    "Length: 3, dtype: period[M]\n",
    "```\n",
    "\n",
    "- `.array` returns a **PeriodArray** when working with period data.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. IntervalArray for Ranges**\n",
    "\n",
    "```python\n",
    "ser = pd.Series(pd.interval_range(start=0, periods=3))\n",
    "print(ser.array)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<IntervalArray>\n",
    "[(0, 1], (1, 2], (2, 3]]\n",
    "Length: 3, dtype: interval[int64, right]\n",
    "```\n",
    "\n",
    "- Returns an **IntervalArray**.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. DatetimeArray with Timezones**\n",
    "\n",
    "```python\n",
    "ser = pd.Series(pd.date_range(\"2024-01-01\", periods=3, tz=\"UTC\"))\n",
    "print(ser.array)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<DatetimeArray>\n",
    "['2024-01-01 00:00:00+00:00', '2024-01-02 00:00:00+00:00', '2024-01-03 00:00:00+00:00']\n",
    "Length: 3, dtype: datetime64[ns, UTC]\n",
    "```\n",
    "\n",
    "- `.array` returns a **DatetimeArray** when timezones are included.\n",
    "\n",
    "---\n",
    "\n",
    "### **10. Getting the Length of `.array`**\n",
    "\n",
    "```python\n",
    "print(len(s.array))\n",
    "```\n",
    "\n",
    "- Returns the **length** of the underlying array.\n",
    "\n",
    "---\n",
    "\n",
    "### **11. Checking Type of `.array`**\n",
    "\n",
    "```python\n",
    "print(type(s.array))\n",
    "```\n",
    "\n",
    "- Returns the **type** of the underlying array (usually `NumpyExtensionArray` or a pandas ExtensionArray).\n",
    "\n",
    "---\n",
    "\n",
    "## **12. Converting `.array` to a List**\n",
    "\n",
    "```python\n",
    "print(s.array.tolist())\n",
    "```\n",
    "\n",
    "- Converts the `.array` to a **Python list**.\n",
    "\n",
    "---\n",
    "\n",
    "## **13. Converting `.array` to a NumPy Array**\n",
    "\n",
    "```python\n",
    "print(s.array.to_numpy())\n",
    "```\n",
    "\n",
    "- This explicitly converts it to a **NumPy array**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Comparison Table: `.array` vs `.values` vs `.to_numpy()`**\n",
    "\n",
    "| Syntax         | Returns                         | Notes                                        |\n",
    "| -------------- | ------------------------------- | -------------------------------------------- |\n",
    "| `s.array`      | **ExtensionArray**              | Wraps actual data (may not be a NumPy array) |\n",
    "| `s.values`     | **NumPy array** or object array | Converts data if necessary                   |\n",
    "| `s.to_numpy()` | **NumPy array**                 | Explicit NumPy conversion                    |\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary Table of Extension Arrays**\n",
    "\n",
    "| Data Type                    | `.array` Type         |\n",
    "| ---------------------------- | --------------------- |\n",
    "| `category`                   | `CategoricalArray`    |\n",
    "| `boolean`                    | `BooleanArray`        |\n",
    "| `string`                     | `StringArray`         |\n",
    "| `Int64`, `UInt32` (nullable) | `IntegerArray`        |\n",
    "| `datetime64[ns, tz]`         | `DatetimeArray`       |\n",
    "| `period[M]`, `period[D]`     | `PeriodArray`         |\n",
    "| `interval[int64]`            | `IntervalArray`       |\n",
    "| Other dtypes                 | `NumpyExtensionArray` |\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "- `.array` **does not always return a NumPy array**. It returns an **ExtensionArray** when using pandas-specific data types.\n",
    "- If you want a **NumPy array**, use `.to_numpy()`.\n",
    "- If you work with pandas **categoricals, nullable integers, or periods**, `.array` helps maintain the original dtype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NumpyExtensionArray>\n",
       "[np.int64(1), np.int64(2), np.int64(3)]\n",
       "Length: 3, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1, 2, 3]).array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'a']\n",
       "Categories (2, object): ['a', 'b']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
    "ser.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.values – All Syntaxes & Details**\n",
    "\n",
    "The **`.values`** attribute in **pandas.Series** returns the underlying data as a **NumPy array or an ndarray-like object**, depending on the dtype.\n",
    "\n",
    "> **⚠️ Warning:**\n",
    ">\n",
    "> - **`Series.values` is NOT recommended**.\n",
    "> - Use **`.array`** if you need a reference to the underlying data (ExtensionArray).\n",
    "> - Use **`.to_numpy()`** if you need a NumPy array.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Basic Usage: Accessing `.values`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([1, 2, 3])\n",
    "```\n",
    "\n",
    "- Returns a **NumPy array** (`numpy.ndarray`).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Difference Between `.values`, `.array`, and `.to_numpy()`**\n",
    "\n",
    "```python\n",
    "print(s.values)       # NumPy array\n",
    "print(s.array)        # ExtensionArray\n",
    "print(s.to_numpy())   # NumPy array\n",
    "```\n",
    "\n",
    "- `.values` **returns a NumPy array or an ndarray-like object**.\n",
    "- `.array` **returns an ExtensionArray**.\n",
    "- `.to_numpy()` is **explicitly meant to return a NumPy array**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Using `.values` with String Data**\n",
    "\n",
    "```python\n",
    "s = pd.Series(list('aabc'))\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array(['a', 'a', 'b', 'c'], dtype=object)\n",
    "```\n",
    "\n",
    "- Returns an **object dtype NumPy array**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Using `.values` with Categorical Data**\n",
    "\n",
    "```python\n",
    "s = pd.Series(list('aabc')).astype('category')\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "['a', 'a', 'b', 'c']\n",
    "Categories (3, object): ['a', 'b', 'c']\n",
    "```\n",
    "\n",
    "- Returns a **Categorical array** instead of a NumPy array.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Using `.values` with Datetime and Timezone Data**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.date_range('20130101', periods=3, tz='US/Eastern'))\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array(['2013-01-01T05:00:00.000000000',\n",
    "       '2013-01-02T05:00:00.000000000',\n",
    "       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
    "```\n",
    "\n",
    "- Converts **timezone-aware** datetime to **UTC**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Using `.values` with Boolean Data**\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False, True])\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([ True, False,  True])\n",
    "```\n",
    "\n",
    "- Returns a **boolean NumPy array**.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Using `.values` with Mixed Data Types**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, \"apple\", 3.5])\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([1, 'apple', 3.5], dtype=object)\n",
    "```\n",
    "\n",
    "- Returns a **NumPy object array** due to mixed types.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Using `.values` with IntegerNA Dtype**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None], dtype=\"Int64\")\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([1, 2, <NA>], dtype=object)\n",
    "```\n",
    "\n",
    "- Returns an **object array** instead of a NumPy array.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Using `.values` with Period Data**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.period_range(\"2023-01\", periods=3, freq=\"M\"))\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([Period('2023-01', 'M'), Period('2023-02', 'M'), Period('2023-03', 'M')],\n",
    "      dtype=object)\n",
    "```\n",
    "\n",
    "- Returns an **object array of Period elements**.\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Using `.values` with Interval Data**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.interval_range(start=0, periods=3))\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([Interval(0, 1, closed='right'),\n",
    "       Interval(1, 2, closed='right'),\n",
    "       Interval(2, 3, closed='right')], dtype=object)\n",
    "```\n",
    "\n",
    "- Returns an **object array of Interval elements**.\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Using `.values` with Float Data**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.1, 2.2, 3.3])\n",
    "print(s.values)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([1.1, 2.2, 3.3])\n",
    "```\n",
    "\n",
    "- Returns a **NumPy float64 array**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Comparison Table: `.values` vs `.array` vs `.to_numpy()`**\n",
    "\n",
    "| Syntax         | Returns                     | Notes                                        |\n",
    "| -------------- | --------------------------- | -------------------------------------------- |\n",
    "| `s.values`     | NumPy array or ndarray-like | May return **object dtype** for complex data |\n",
    "| `s.array`      | ExtensionArray              | Preserves pandas-specific types              |\n",
    "| `s.to_numpy()` | NumPy array                 | Explicit conversion to NumPy                 |\n",
    "\n",
    "---\n",
    "\n",
    "## **Best Practices**\n",
    "\n",
    "✅ **Use `.array`** if you need a reference to the underlying data (ExtensionArray).  \n",
    "✅ **Use `.to_numpy()`** if you need a NumPy array.  \n",
    "⚠️ **Avoid `.values`** since it may behave unexpectedly with extension types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1, 2, 3]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'a', 'b', 'c'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(list('aabc')).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'b', 'c']\n",
       "Categories (3, object): ['a', 'b', 'c']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(list('aabc')).astype('category').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2013-01-01T05:00:00.000000000', '2013-01-02T05:00:00.000000000',\n",
       "       '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Timezone aware datetime data is converted to UTC:\n",
    "pd.Series(pd.date_range('20130101', periods=3,\n",
    "                        tz='US/Eastern')).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.dtype – All Syntaxes & Details**\n",
    "\n",
    "The **`.dtype`** property in **pandas.Series** returns the **data type (dtype)** of the underlying data.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Basic Usage: Checking `.dtype`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "int64\n",
    "```\n",
    "\n",
    "- Returns the **dtype** (`int64`) of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. `.dtype` with Different Data Types**\n",
    "\n",
    "### **2.1 Integer Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2.2 Floating-Point Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.1, 2.2, 3.3])\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2.3 String Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"apple\", \"banana\", \"cherry\"])\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "object\n",
    "```\n",
    "\n",
    "- Default string dtype is **\"object\"**, unless explicitly set to **\"string\"**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.4 Boolean Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False, True])\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "bool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2.5 Mixed Data Types**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, \"apple\", 3.5])\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "object\n",
    "```\n",
    "\n",
    "- When elements have different types, pandas assigns **\"object\" dtype**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.6 Categorical Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"a\", \"b\", \"a\"], dtype=\"category\")\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "category\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2.7 DateTime Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.date_range(\"2024-01-01\", periods=3))\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "datetime64[ns]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2.8 Timezone-Aware DateTime**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.date_range(\"2024-01-01\", periods=3, tz=\"UTC\"))\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "datetime64[ns, UTC]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2.9 Timedelta Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.to_timedelta([\"1 days\", \"2 days\", \"3 days\"]))\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "timedelta64[ns]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2.10 Integer Nullable (IntegerNA)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None], dtype=\"Int64\")\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Int64\n",
    "```\n",
    "\n",
    "- Allows `NaN` values in integer Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.11 Boolean Nullable**\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False, None], dtype=\"boolean\")\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "boolean\n",
    "```\n",
    "\n",
    "- **Supports `None` as missing values**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.12 String (Pandas StringArray)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"apple\", \"banana\", None], dtype=\"string\")\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "string\n",
    "```\n",
    "\n",
    "- **\"string\" dtype is different from \"object\" dtype**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.13 Period Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.period_range(\"2023-01\", periods=3, freq=\"M\"))\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "period[M]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2.14 Interval Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.interval_range(start=0, periods=3))\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "interval[int64]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Checking Data Type (`isinstance`)**\n",
    "\n",
    "```python\n",
    "if s.dtype == \"int64\":\n",
    "    print(\"Series contains integers\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Convert `.dtype` to String**\n",
    "\n",
    "```python\n",
    "print(str(s.dtype))\n",
    "```\n",
    "\n",
    "- Useful when comparing dtype as a string.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Changing Data Type (`astype`)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "s = s.astype(\"float64\")\n",
    "print(s.dtype)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "float64\n",
    "```\n",
    "\n",
    "- Converts **int64** to **float64**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Getting Data Type Name**\n",
    "\n",
    "```python\n",
    "print(s.dtype.name)\n",
    "```\n",
    "\n",
    "- Returns dtype **as a string**.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Summary Table of `.dtype` Outputs**\n",
    "\n",
    "| Data Type               | `.dtype` Output       |\n",
    "| ----------------------- | --------------------- |\n",
    "| Integer                 | `int64`               |\n",
    "| Float                   | `float64`             |\n",
    "| String (default)        | `object`              |\n",
    "| String (Pandas)         | `string`              |\n",
    "| Boolean                 | `bool`                |\n",
    "| Boolean (nullable)      | `boolean`             |\n",
    "| Categorical             | `category`            |\n",
    "| DateTime                | `datetime64[ns]`      |\n",
    "| Timezone-Aware DateTime | `datetime64[ns, UTC]` |\n",
    "| Timedelta               | `timedelta64[ns]`     |\n",
    "| Period                  | `period[M]`           |\n",
    "| Interval                | `interval[int64]`     |\n",
    "| Integer (nullable)      | `Int64`               |\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Practices**\n",
    "\n",
    "✅ Use `.dtype` to check the type of data in a Series.  \n",
    "✅ Use `.astype()` to convert types when needed.  \n",
    "✅ Use `s.dtype.name` if you need the dtype as a string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a tuple of the shape of the underlying data. \n",
    "s = pd.Series([1, 2, 3])\n",
    "s.shape\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.nbytes – All Syntaxes & Details**\n",
    "\n",
    "The **`.nbytes`** property in **pandas.Series** returns the **total number of bytes consumed by the data in memory**. This includes the size of the data stored in the **underlying NumPy array or ExtensionArray**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Basic Usage: Checking `.nbytes`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- Each **int64** element takes **8 bytes**.\n",
    "- `3 elements × 8 bytes = 24 bytes`.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Using `.nbytes` with Different Data Types**\n",
    "\n",
    "### **2.1 Integer Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3], dtype=\"int64\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- **Each int64 element takes 8 bytes** (`3 × 8 = 24 bytes`).\n",
    "\n",
    "---\n",
    "\n",
    "### **2.2 Float Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.1, 2.2, 3.3], dtype=\"float64\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- **Each float64 element takes 8 bytes** (`3 × 8 = 24 bytes`).\n",
    "\n",
    "---\n",
    "\n",
    "### **2.3 Boolean Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False, True])\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "- **Each boolean element takes 1 byte** (`3 × 1 = 3 bytes`).\n",
    "\n",
    "---\n",
    "\n",
    "### **2.4 String (Object) Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"Ant\", \"Bear\", \"Cow\"])\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- **String data is stored as Python objects**, so `.nbytes` reflects only the pointers (not actual string sizes).\n",
    "\n",
    "---\n",
    "\n",
    "### **2.5 String (Pandas StringArray)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"Ant\", \"Bear\", \"Cow\"], dtype=\"string\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Variable (depends on the string lengths)\n",
    "```\n",
    "\n",
    "- The **Pandas \"string\" dtype** is more memory-efficient than \"object\".\n",
    "\n",
    "---\n",
    "\n",
    "### **2.6 Categorical Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"a\", \"b\", \"a\"], dtype=\"category\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "- Categories are stored as **integer codes**, making it memory-efficient.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.7 DateTime Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.date_range(\"2024-01-01\", periods=3))\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- Each **datetime64[ns]** element takes **8 bytes**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.8 Timezone-Aware DateTime**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.date_range(\"2024-01-01\", periods=3, tz=\"UTC\"))\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- **Same as datetime64[ns]** since timezone-aware timestamps are stored as UTC.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.9 Timedelta Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.to_timedelta([\"1 days\", \"2 days\", \"3 days\"]))\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- Each **timedelta64[ns]** element takes **8 bytes**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.10 Integer Nullable (IntegerNA)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None], dtype=\"Int64\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Variable (depends on storage format)\n",
    "```\n",
    "\n",
    "- The **\"Int64\" nullable type** stores additional metadata.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.11 Boolean Nullable**\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False, None], dtype=\"boolean\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Variable (depends on storage format)\n",
    "```\n",
    "\n",
    "- Similar to `\"Int64\"`, the `\"boolean\"` dtype requires additional metadata.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Using `.nbytes` with Index**\n",
    "\n",
    "```python\n",
    "idx = pd.Index([1, 2, 3])\n",
    "print(idx.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- Works the same way as **Series.nbytes**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Using `.nbytes` with MultiIndex**\n",
    "\n",
    "```python\n",
    "arrays = [\n",
    "    [\"A\", \"A\", \"B\", \"B\"],\n",
    "    [1, 2, 1, 2]\n",
    "]\n",
    "idx = pd.MultiIndex.from_arrays(arrays)\n",
    "print(idx.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Variable (depends on number of levels)\n",
    "```\n",
    "\n",
    "- **MultiIndex** takes up more memory due to hierarchical indexing.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `.nbytes` vs `.memory_usage()`**\n",
    "\n",
    "- `.nbytes` **only includes the data storage**.\n",
    "- `.memory_usage()` **includes index memory too**.\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.nbytes)           # 24 bytes (data only)\n",
    "print(s.memory_usage())   # 112 bytes (data + index)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Summary Table: `.nbytes` for Different Dtypes**\n",
    "\n",
    "| Data Type                | `.nbytes` (per element)           |\n",
    "| ------------------------ | --------------------------------- |\n",
    "| `int64`                  | 8 bytes                           |\n",
    "| `float64`                | 8 bytes                           |\n",
    "| `bool`                   | 1 byte                            |\n",
    "| `object` (string)        | 8 bytes (pointer only)            |\n",
    "| `\"string\"` (StringArray) | Varies (depends on string length) |\n",
    "| `category`               | 1-4 bytes (integer codes)         |\n",
    "| `datetime64[ns]`         | 8 bytes                           |\n",
    "| `timedelta64[ns]`        | 8 bytes                           |\n",
    "| `Int64` (nullable int)   | Varies                            |\n",
    "| `boolean` (nullable)     | Varies                            |\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Best Practices**\n",
    "\n",
    "✅ **Use `.nbytes`** to check how much memory **data alone** takes.  \n",
    "✅ **Use `.memory_usage()`** if you want the **total memory usage (including index)**.  \n",
    "✅ **Convert `object` dtype to `string` or `category`** to save memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Ant\n",
       "1    Bear\n",
       "2     Cow\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1, 2, 3], dtype='int64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.Index([1, 2, 3])\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.nbytes – All Syntaxes & Details**\n",
    "\n",
    "The **`.nbytes`** property in **pandas.Series** returns the **total number of bytes consumed by the data in memory**. This includes the size of the data stored in the **underlying NumPy array or ExtensionArray**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Basic Usage: Checking `.nbytes`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- Each **int64** element takes **8 bytes**.\n",
    "- `3 elements × 8 bytes = 24 bytes`.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Using `.nbytes` with Different Data Types**\n",
    "\n",
    "### **2.1 Integer Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3], dtype=\"int64\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- **Each int64 element takes 8 bytes** (`3 × 8 = 24 bytes`).\n",
    "\n",
    "---\n",
    "\n",
    "### **2.2 Float Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.1, 2.2, 3.3], dtype=\"float64\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- **Each float64 element takes 8 bytes** (`3 × 8 = 24 bytes`).\n",
    "\n",
    "---\n",
    "\n",
    "### **2.3 Boolean Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False, True])\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "- **Each boolean element takes 1 byte** (`3 × 1 = 3 bytes`).\n",
    "\n",
    "---\n",
    "\n",
    "### **2.4 String (Object) Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"Ant\", \"Bear\", \"Cow\"])\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- **String data is stored as Python objects**, so `.nbytes` reflects only the pointers (not actual string sizes).\n",
    "\n",
    "---\n",
    "\n",
    "### **2.5 String (Pandas StringArray)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"Ant\", \"Bear\", \"Cow\"], dtype=\"string\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Variable (depends on the string lengths)\n",
    "```\n",
    "\n",
    "- The **Pandas \"string\" dtype** is more memory-efficient than \"object\".\n",
    "\n",
    "---\n",
    "\n",
    "### **2.6 Categorical Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"a\", \"b\", \"a\"], dtype=\"category\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "- Categories are stored as **integer codes**, making it memory-efficient.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.7 DateTime Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.date_range(\"2024-01-01\", periods=3))\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- Each **datetime64[ns]** element takes **8 bytes**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.8 Timezone-Aware DateTime**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.date_range(\"2024-01-01\", periods=3, tz=\"UTC\"))\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- **Same as datetime64[ns]** since timezone-aware timestamps are stored as UTC.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.9 Timedelta Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.to_timedelta([\"1 days\", \"2 days\", \"3 days\"]))\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- Each **timedelta64[ns]** element takes **8 bytes**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.10 Integer Nullable (IntegerNA)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None], dtype=\"Int64\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Variable (depends on storage format)\n",
    "```\n",
    "\n",
    "- The **\"Int64\" nullable type** stores additional metadata.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.11 Boolean Nullable**\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False, None], dtype=\"boolean\")\n",
    "print(s.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Variable (depends on storage format)\n",
    "```\n",
    "\n",
    "- Similar to `\"Int64\"`, the `\"boolean\"` dtype requires additional metadata.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Using `.nbytes` with Index**\n",
    "\n",
    "```python\n",
    "idx = pd.Index([1, 2, 3])\n",
    "print(idx.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- Works the same way as **Series.nbytes**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Using `.nbytes` with MultiIndex**\n",
    "\n",
    "```python\n",
    "arrays = [\n",
    "    [\"A\", \"A\", \"B\", \"B\"],\n",
    "    [1, 2, 1, 2]\n",
    "]\n",
    "idx = pd.MultiIndex.from_arrays(arrays)\n",
    "print(idx.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Variable (depends on number of levels)\n",
    "```\n",
    "\n",
    "- **MultiIndex** takes up more memory due to hierarchical indexing.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `.nbytes` vs `.memory_usage()`**\n",
    "\n",
    "- `.nbytes` **only includes the data storage**.\n",
    "- `.memory_usage()` **includes index memory too**.\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.nbytes)           # 24 bytes (data only)\n",
    "print(s.memory_usage())   # 112 bytes (data + index)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Summary Table: `.nbytes` for Different Dtypes**\n",
    "\n",
    "| Data Type                | `.nbytes` (per element)           |\n",
    "| ------------------------ | --------------------------------- |\n",
    "| `int64`                  | 8 bytes                           |\n",
    "| `float64`                | 8 bytes                           |\n",
    "| `bool`                   | 1 byte                            |\n",
    "| `object` (string)        | 8 bytes (pointer only)            |\n",
    "| `\"string\"` (StringArray) | Varies (depends on string length) |\n",
    "| `category`               | 1-4 bytes (integer codes)         |\n",
    "| `datetime64[ns]`         | 8 bytes                           |\n",
    "| `timedelta64[ns]`        | 8 bytes                           |\n",
    "| `Int64` (nullable int)   | Varies                            |\n",
    "| `boolean` (nullable)     | Varies                            |\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Best Practices**\n",
    "\n",
    "✅ **Use `.nbytes`** to check how much memory **data alone** takes.  \n",
    "✅ **Use `.memory_usage()`** if you want the **total memory usage (including index)**.  \n",
    "✅ **Convert `object` dtype to `string` or `category`** to save memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Ant\n",
       "1    Bear\n",
       "2     Cow\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1, 2, 3], dtype='int64')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.Index([1, 2, 3])\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.ndim – All Syntaxes & Details**\n",
    "\n",
    "The **`.ndim`** property in **pandas.Series** and **pandas.Index** returns the **number of dimensions** of the underlying data. It is used to understand the dimensionality of the object. For a **Series** or an **Index**, which are one-dimensional structures, this will always return `1`.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.ndim\n",
    "Index.ndim\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Explanation**\n",
    "\n",
    "- **Series**: A **Series** is always **one-dimensional**, so `.ndim` will return `1`.\n",
    "- **Index**: Similarly, an **Index** is also **one-dimensional**, so `.ndim` will also return `1`.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Series**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
    "print(s)\n",
    "print(s.ndim)  # The number of dimensions of a Series\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     Ant\n",
    "1    Bear\n",
    "2     Cow\n",
    "dtype: object\n",
    "\n",
    "1\n",
    "```\n",
    "\n",
    "- **`.ndim`** returns `1` because a Series is a one-dimensional object.\n",
    "\n",
    "### **3.2 Index**\n",
    "\n",
    "```python\n",
    "idx = pd.Index([1, 2, 3])\n",
    "print(idx)\n",
    "print(idx.ndim)  # The number of dimensions of an Index\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Index([1, 2, 3], dtype='int64')\n",
    "\n",
    "1\n",
    "```\n",
    "\n",
    "- **`.ndim`** returns `1` because an Index is also a one-dimensional object.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. `.ndim` in Two-Dimensional Objects (for Contrast)**\n",
    "\n",
    "For objects that have more than one dimension, such as **pandas.DataFrame**, `.ndim` returns the total number of dimensions.\n",
    "\n",
    "### **4.1 DataFrame Example**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
    "print(df)\n",
    "print(df.ndim)  # The number of dimensions of a DataFrame\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C\n",
    "0  1  2  3\n",
    "1  4  5  6\n",
    "\n",
    "2\n",
    "```\n",
    "\n",
    "- **DataFrame** has two dimensions (rows and columns), so `.ndim` returns `2`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Summary Table**\n",
    "\n",
    "| Object Type   | `.ndim` Output |\n",
    "| ------------- | -------------- |\n",
    "| **Series**    | `1`            |\n",
    "| **Index**     | `1`            |\n",
    "| **DataFrame** | `2`            |\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Best Practices**\n",
    "\n",
    "- Use **`.ndim`** to quickly determine if the object is **one-dimensional** (like Series or Index) or **two-dimensional** (like DataFrame).\n",
    "- For multi-dimensional structures, `.ndim` helps identify the number of axes (dimensions).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Ant\n",
       "1    Bear\n",
       "2     Cow\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1, 2, 3], dtype='int64')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.Index([1, 2, 3])\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.size – All Syntaxes & Details**\n",
    "\n",
    "The **`.size`** property in **pandas.Series** returns the **total number of elements** (i.e., the length of the Series).\n",
    "\n",
    "It **always returns the number of elements, including NaN values**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Basic Usage: Checking `.size`**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([\"Ant\", \"Bear\", \"Cow\"])\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "- The Series has **3 elements**, so `.size` returns `3`.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. `.size` vs `.shape` vs `.count()`**\n",
    "\n",
    "| Attribute  | Description                     | Includes NaN? |\n",
    "| ---------- | ------------------------------- | ------------- |\n",
    "| `.size`    | Total number of elements        | ✅ Yes        |\n",
    "| `.shape`   | Tuple of dimensions (`(rows,)`) | ✅ Yes        |\n",
    "| `.count()` | Number of **non-null** elements | ❌ No         |\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"Ant\", \"Bear\", \"Cow\", None])\n",
    "\n",
    "print(s.size)    # 4 (total elements)\n",
    "print(s.shape)   # (4,) (tuple representation)\n",
    "print(s.count()) # 3 (non-null elements)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "4\n",
    "(4,)\n",
    "3\n",
    "```\n",
    "\n",
    "- **`.size` counts all elements**, even if they are `None` or `NaN`.\n",
    "- **`.count()` excludes NaN values**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. `.size` with Different Data Types**\n",
    "\n",
    "### **3.1 Integer Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "5\n",
    "```\n",
    "\n",
    "- 5 elements, so `.size = 5`.\n",
    "\n",
    "---\n",
    "\n",
    "### **3.2 Float Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.1, 2.2, 3.3])\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3.3 Boolean Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False, True, False])\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3.4 String Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"apple\", \"banana\", \"cherry\"])\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3.5 Series with NaN Values**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1, 2, np.nan, 4, None])\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "5\n",
    "```\n",
    "\n",
    "- NaN and None **are included in `.size`**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3.6 Categorical Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"A\", \"B\", \"A\"], dtype=\"category\")\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "- **Categorical dtype does not affect `.size`**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3.7 DateTime Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.date_range(\"2024-01-01\", periods=10))\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "10\n",
    "```\n",
    "\n",
    "- **Datetime series counts each timestamp as one element**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. `.size` with Index**\n",
    "\n",
    "```python\n",
    "idx = pd.Index([1, 2, 3])\n",
    "print(idx.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "- Works the same way as **Series.size**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. `.size` with MultiIndex**\n",
    "\n",
    "```python\n",
    "arrays = [\n",
    "    [\"A\", \"A\", \"B\", \"B\"],\n",
    "    [1, 2, 1, 2]\n",
    "]\n",
    "idx = pd.MultiIndex.from_arrays(arrays)\n",
    "print(idx.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "4\n",
    "```\n",
    "\n",
    "- **Counts all levels in MultiIndex**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. `.size` for an Empty Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series([])\n",
    "print(s.size)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0\n",
    "```\n",
    "\n",
    "- **Empty Series has `.size = 0`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Summary Table**\n",
    "\n",
    "| Series Data                      | `.size` Output     |\n",
    "| -------------------------------- | ------------------ |\n",
    "| `[1, 2, 3]`                      | `3`                |\n",
    "| `[1.1, 2.2, 3.3]`                | `3`                |\n",
    "| `[True, False, True]`            | `3`                |\n",
    "| `[\"a\", \"b\", \"c\"]`                | `3`                |\n",
    "| `[1, 2, np.nan]`                 | `3` (includes NaN) |\n",
    "| `pd.Series([], dtype=\"float64\")` | `0` (empty Series) |\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Best Practices**\n",
    "\n",
    "✅ Use `.size` to get the **total number of elements**.  \n",
    "✅ Use `.count()` if you only want **non-null values**.  \n",
    "✅ Use `.shape[0]` if you prefer a **tuple-like format**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Ant\n",
       "1    Bear\n",
       "2     Cow\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1, 2, 3], dtype='int64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.Index([1, 2, 3])\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.T – All Syntaxes & Details**\n",
    "\n",
    "The **`.T`** property is used to **transpose** a **pandas.Series** or **pandas.Index**. However, since both **Series** and **Index** are **one-dimensional** objects, transposing them doesn't change their structure or content. It effectively results in the same object.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.T\n",
    "Index.T\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Explanation**\n",
    "\n",
    "- **Series**: A **Series** is inherently **one-dimensional**, so transposing it does **not** modify the object. It will remain the same after the transpose.\n",
    "- **Index**: Similarly, for an **Index**, which is also one-dimensional, transposing it will result in the same Index without any changes.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Transposing a Series**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
    "print(s)\n",
    "print(s.T)  # Transpose does not alter the Series\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     Ant\n",
    "1    Bear\n",
    "2     Cow\n",
    "dtype: object\n",
    "\n",
    "0     Ant\n",
    "1    Bear\n",
    "2     Cow\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "- **`s.T`** will return the **same Series** as **`s`** because a Series is a one-dimensional object, and transposing it doesn't change its structure.\n",
    "\n",
    "### **3.2 Transposing an Index**\n",
    "\n",
    "```python\n",
    "idx = pd.Index([1, 2, 3])\n",
    "print(idx)\n",
    "print(idx.T)  # Transpose does not alter the Index\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Index([1, 2, 3], dtype='int64')\n",
    "\n",
    "Index([1, 2, 3], dtype='int64')\n",
    "```\n",
    "\n",
    "- **`idx.T`** will return the **same Index** as **`idx`**, as the Index is also one-dimensional, so transposing doesn't change it.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Transposing DataFrame (for Contrast)**\n",
    "\n",
    "For a **DataFrame**, which is a two-dimensional object (rows and columns), the `.T` property swaps the rows and columns.\n",
    "\n",
    "### **4.1 Example with DataFrame Transpose**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
    "print(df)\n",
    "print(df.T)  # Transpose swaps rows and columns\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C\n",
    "0  1  2  3\n",
    "1  4  5  6\n",
    "\n",
    "   0  1\n",
    "A  1  4\n",
    "B  2  5\n",
    "C  3  6\n",
    "```\n",
    "\n",
    "- **In a DataFrame**, transposing swaps the rows and columns.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Summary**\n",
    "\n",
    "| Object Type   | `.T` Effect                         |\n",
    "| ------------- | ----------------------------------- |\n",
    "| **Series**    | No effect (returns the same Series) |\n",
    "| **Index**     | No effect (returns the same Index)  |\n",
    "| **DataFrame** | Swaps rows and columns              |\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Best Practices**\n",
    "\n",
    "- **For Series and Index**, the `.T` property is essentially a **no-op** and does not modify the object.\n",
    "- **For DataFrame**, use `.T` when you want to swap the rows and columns.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Ant\n",
       "1    Bear\n",
       "2     Cow\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Ant\n",
       "1    Bear\n",
       "2     Cow\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1, 2, 3], dtype='int64')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.Index([1, 2, 3])\n",
    "idx.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.memory_usage – All Syntaxes & Details**\n",
    "\n",
    "The **`.memory_usage()`** function in **pandas.Series** returns the amount of **memory** consumed by the **Series**. This includes options to account for the **index** and, for objects, the **deep introspection** of object dtypes for more precise memory calculations.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.memory_usage(index=True, deep=False)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **`index`** (`bool`, default `True`):  \n",
    "  Specifies whether to include the memory usage of the **Series index**.\n",
    "\n",
    "  - If `True`, the index memory usage is included.\n",
    "  - If `False`, the memory usage of the index is excluded, focusing only on the data itself.\n",
    "\n",
    "- **`deep`** (`bool`, default `False`):  \n",
    "  If set to `True`, **deep introspection** is done on the data. Specifically, for **object dtypes**, the system-level memory consumption of each object element is measured and included in the result.\n",
    "  - If `True`, the memory usage of each element of **object** dtype will be deeply calculated, including the object-level memory consumption (such as strings).\n",
    "  - If `False`, the memory usage of object elements is ignored (less accurate but faster).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Returns**\n",
    "\n",
    "- **`int`**: The number of **bytes** consumed by the Series, which can be influenced by the inclusion of index memory and the deep introspection of object elements.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Basic Memory Usage**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(range(3))\n",
    "print(s.memory_usage())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "152\n",
    "```\n",
    "\n",
    "- The total memory usage includes the memory of both the **data** and the **index**.\n",
    "\n",
    "### **3.2 Memory Usage Without Index**\n",
    "\n",
    "```python\n",
    "s = pd.Series(range(3))\n",
    "print(s.memory_usage(index=False))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- When **`index=False`**, only the memory consumed by the **data** (not the index) is returned.\n",
    "\n",
    "### **3.3 Memory Usage with Object Data Type (default)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"a\", \"b\"])\n",
    "print(s.memory_usage())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "144\n",
    "```\n",
    "\n",
    "- For **object dtypes**, the default memory usage does not include the system-level memory of each object element, like strings. It only considers the overall memory of the object dtype.\n",
    "\n",
    "### **3.4 Memory Usage with Deep Introspection**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"a\", \"b\"])\n",
    "print(s.memory_usage(deep=True))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "244\n",
    "```\n",
    "\n",
    "- **`deep=True`** introspects the memory usage of each object element, and **calculates** the system-level memory used by the individual string objects.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Comparison with `numpy.ndarray.nbytes`**\n",
    "\n",
    "If you are working with **numpy arrays**, the `.nbytes` property gives the total number of bytes consumed by the elements of the array.\n",
    "\n",
    "### **Example with `numpy.ndarray.nbytes`**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "arr = np.array([1, 2, 3])\n",
    "print(arr.nbytes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- This is the total **bytes** consumed by the elements of the **numpy.ndarray**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Best Practices**\n",
    "\n",
    "- Use **`.memory_usage()`** to get a sense of the memory consumption of the **Series**, especially when dealing with large datasets.\n",
    "- When working with object dtypes (e.g., strings), use **`deep=True`** to get a more accurate representation of memory consumption.\n",
    "- **Excluding the index** (`index=False`) can be useful when you're only interested in the memory used by the data itself.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Summary Table**\n",
    "\n",
    "| Parameter  | Default Value | Description                                                                         |\n",
    "| ---------- | ------------- | ----------------------------------------------------------------------------------- |\n",
    "| **index**  | `True`        | Whether to include memory usage of the index.                                       |\n",
    "| **deep**   | `False`       | Whether to introspect object dtypes deeply to include memory of individual objects. |\n",
    "| **Return** | `int`         | Memory usage in bytes.                                                              |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "pandas.Series.memory_usage\n",
    "\n",
    "Series.memory_usage(index=True, deep=False)\n",
    "\n",
    "Return the memory usage of the Series.\n",
    "\n",
    "The memory usage can optionally include the contribution of the index and of elements of object dtype.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "index:\n",
    "bool, default True\n",
    "Specifies whether to include the memory usage of the Series index.\n",
    "\n",
    "deep:\n",
    "bool, default False\n",
    "If True, introspect the data deeply by interrogating object dtypes for system-level memory consumption, and include it in the returned value.\n",
    "\n",
    "Returns:\n",
    "\n",
    "int\n",
    "\n",
    "Bytes of memory consumed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(range(3))\n",
    "s.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.memory_usage(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([\"a\", \"b\"])\n",
    "s.values\n",
    "s.memory_usage()\n",
    "s.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.hasnans – All Syntaxes & Details**\n",
    "\n",
    "The **`.hasnans`** property in **pandas.Series** checks whether the **Series** contains any **NaN** (Not a Number) values. This property is useful for quickly determining the presence of missing or undefined values in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.hasnans\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Explanation**\n",
    "\n",
    "- **`.hasnans`** returns a **boolean value (`True` or `False`)**:\n",
    "  - **`True`**: Indicates that there is at least one **NaN** value in the **Series**.\n",
    "  - **`False`**: Indicates that there are no **NaN** values in the **Series**.\n",
    "- This property enables certain performance optimizations in pandas when working with missing data.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Series with NaN Value**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3, None])\n",
    "print(s)\n",
    "print(s.hasnans)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    3.0\n",
    "3    NaN\n",
    "dtype: float64\n",
    "\n",
    "True\n",
    "```\n",
    "\n",
    "- **`s.hasnans`** returns **`True`** because the Series contains a **NaN** value.\n",
    "\n",
    "### **3.2 Series Without NaN Values**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s)\n",
    "print(s.hasnans)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "dtype: int64\n",
    "\n",
    "False\n",
    "```\n",
    "\n",
    "- **`s.hasnans`** returns **`False`** because there are no **NaN** values in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Best Practices**\n",
    "\n",
    "- Use **`.hasnans`** when you want to **quickly check** for the presence of missing data in a Series.\n",
    "- This can be helpful before performing operations like **filling** (`fillna`) or **dropping** missing values (`dropna`), as it gives you an efficient check to decide if those operations are necessary.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Summary**\n",
    "\n",
    "| Property    | Return Type | Description                                                |\n",
    "| ----------- | ----------- | ---------------------------------------------------------- |\n",
    "| **hasnans** | `bool`      | Returns `True` if there are NaN values, `False` otherwise. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.Series.hasnans\n",
    "\n",
    "property Series.hasnans:\n",
    "Return True if there are any NaNs.\n",
    "\n",
    "Enables various performance speedups.\n",
    "\n",
    "Returns:\n",
    "bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, None])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.hasnans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.empty – All Syntaxes & Details**\n",
    "\n",
    "The **`.empty`** property in **pandas.Series** checks whether the **Series** is **empty**, meaning it contains no elements. It is useful for determining whether a Series has any data or not, regardless of its index or any missing (NaN) values.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.empty\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Explanation**\n",
    "\n",
    "- **`.empty`** returns a **boolean value (`True` or `False`)**:\n",
    "  - **`True`**: If the **Series** is entirely empty, meaning it has no elements, it returns **`True`**.\n",
    "  - **`False`**: If the **Series** has any elements, it returns **`False`**.\n",
    "- An important note: A **Series** containing only **NaN** values is **not considered empty** by `.empty`. It still contains elements, even though they are missing values.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Series with No Elements (Empty Series)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "ser_empty = pd.Series()\n",
    "print(ser_empty.empty)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "- The Series is completely empty, so **`ser_empty.empty`** returns **`True`**.\n",
    "\n",
    "### **3.2 Series with NaN Values (Not Empty)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ser = pd.Series([np.nan])\n",
    "print(ser.empty)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "- The Series has an element, even though it's NaN, so **`ser.empty`** returns **`False`**.\n",
    "\n",
    "### **3.3 Series with Actual Data (Not Empty)**\n",
    "\n",
    "```python\n",
    "ser = pd.Series([1, 2, 3])\n",
    "print(ser.empty)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "- The Series contains actual data, so **`ser.empty`** returns **`False`**.\n",
    "\n",
    "### **3.4 DataFrame Example (Empty DataFrame)**\n",
    "\n",
    "```python\n",
    "df_empty = pd.DataFrame({'A': []})\n",
    "print(df_empty.empty)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "- An **empty DataFrame** with no rows or columns is considered **empty**, so **`df_empty.empty`** returns **`True`**.\n",
    "\n",
    "### **3.5 DataFrame with NaN Values (Not Empty)**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [np.nan]})\n",
    "print(df.empty)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "- A **DataFrame** with NaN values is **not considered empty**, so **`df.empty`** returns **`False`**.\n",
    "\n",
    "### **3.6 Dropping NaN to Make DataFrame Empty**\n",
    "\n",
    "```python\n",
    "df.dropna().empty\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "- If we drop the **NaN** values from the DataFrame using **`dropna()`**, the DataFrame is considered empty, and **`df.dropna().empty`** returns **`True`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Notes**\n",
    "\n",
    "- **Series with NaN values**: Even if a Series contains only **NaN** values, it is **not empty**. It still has data, but that data is missing (NaN).\n",
    "- Use `.dropna()` if you want to remove **NaN** values and check whether a Series or DataFrame becomes empty after removing them.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Summary**\n",
    "\n",
    "| Property  | Return Type | Description                                                                       |\n",
    "| --------- | ----------- | --------------------------------------------------------------------------------- |\n",
    "| **empty** | `bool`      | Returns `True` if the Series/DataFrame is empty (no elements), otherwise `False`. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [A]\n",
       "Index: []"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_empty = pd.DataFrame({'A': []})\n",
    "df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_empty.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A\n",
       "0 NaN"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A' : [np.nan]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna().empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    []\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_empty = pd.Series({'A' : []})\n",
    "ser_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_empty.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_empty = pd.Series()\n",
    "ser_empty.empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.dtypes – All Syntaxes & Details**\n",
    "\n",
    "The **`.dtypes`** property of a **pandas.Series** returns the **data type** of the elements in the Series. This can be useful for understanding the type of data you're working with, especially when the Series contains multiple types (e.g., numbers, strings, dates).\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.dtypes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Explanation**\n",
    "\n",
    "- **`.dtypes`** returns the **data type** (`dtype`) of the elements in the **Series**.\n",
    "- The **`dtype`** will indicate whether the Series contains:\n",
    "  - **Integers**: `dtype('int64')`\n",
    "  - **Floating point numbers**: `dtype('float64')`\n",
    "  - **Strings**: `dtype('object')`\n",
    "  - **Categoricals**, **Datetime**, or other specialized types.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Series with Integer Values**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "int64\n",
    "```\n",
    "\n",
    "- The **Series** contains integers, so the `dtype` is **`int64`**.\n",
    "\n",
    "### **3.2 Series with Float Values**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.1, 2.2, 3.3])\n",
    "print(s.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "float64\n",
    "```\n",
    "\n",
    "- The **Series** contains floats, so the `dtype` is **`float64`**.\n",
    "\n",
    "### **3.3 Series with Object Values (Strings)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"apple\", \"banana\", \"cherry\"])\n",
    "print(s.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "object\n",
    "```\n",
    "\n",
    "- The **Series** contains strings (objects), so the `dtype` is **`object`**.\n",
    "\n",
    "### **3.4 Series with Datetime Values**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.to_datetime([\"2022-01-01\", \"2022-02-01\", \"2022-03-01\"]))\n",
    "print(s.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "datetime64[ns]\n",
    "```\n",
    "\n",
    "- The **Series** contains datetime values, so the `dtype` is **`datetime64[ns]`**.\n",
    "\n",
    "### **3.5 Series with Categorical Values**\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.Categorical([\"apple\", \"banana\", \"apple\"]))\n",
    "print(s.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "category\n",
    "```\n",
    "\n",
    "- The **Series** contains categorical data, so the `dtype` is **`category`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Notes**\n",
    "\n",
    "- The **`.dtypes`** property is especially useful when working with data that could be of mixed types. Understanding the **dtype** helps you decide which operations can be safely performed on the data.\n",
    "- If the Series contains objects, like strings or lists, the `dtype` will often be **`object`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Summary**\n",
    "\n",
    "| Property   | Return Type | Description                                          |\n",
    "| ---------- | ----------- | ---------------------------------------------------- |\n",
    "| **dtypes** | `dtype`     | Returns the data type of the elements in the Series. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.name – All Syntaxes & Details**\n",
    "\n",
    "The **`.name`** property in **pandas.Series** is used to retrieve or set the name of a **Series**. This name becomes important when the Series is used as part of a **DataFrame** because it serves as the column name.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.name\n",
    "```\n",
    "\n",
    "To set the name of the Series:\n",
    "\n",
    "```python\n",
    "Series.name = 'NewName'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Explanation**\n",
    "\n",
    "- The **`name`** of a **Series** is a label that is associated with the Series, and this label is used when displaying the Series or if it is part of a **DataFrame** (becoming the column name).\n",
    "- It is **hashable** (can be a string, number, or other hashable type).\n",
    "- If the **Series** is part of a **DataFrame**, the **`name`** is also used as the **column name**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Setting the Series Name at Initialization**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')\n",
    "print(s)\n",
    "print(s.name)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "Name: Numbers, dtype: int64\n",
    "Numbers\n",
    "```\n",
    "\n",
    "- The **`name`** of the Series is set to `'Numbers'` during initialization, and it is printed when accessing **`s.name`**.\n",
    "\n",
    "### **3.2 Changing the Name of the Series**\n",
    "\n",
    "```python\n",
    "s.name = 'Integers'\n",
    "print(s)\n",
    "print(s.name)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "Name: Integers, dtype: int64\n",
    "Integers\n",
    "```\n",
    "\n",
    "- The **`name`** is changed from `'Numbers'` to `'Integers'`, and this is reflected both in the Series output and when accessing **`s.name`**.\n",
    "\n",
    "### **3.3 Series Name as Column Name in DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame([[1, 2], [3, 4], [5, 6]], columns=[\"Odd Numbers\", \"Even Numbers\"])\n",
    "print(df)\n",
    "print(df[\"Even Numbers\"].name)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   Odd Numbers  Even Numbers\n",
    "0            1             2\n",
    "1            3             4\n",
    "2            5             6\n",
    "Even Numbers\n",
    "```\n",
    "\n",
    "- The **`name`** of the Series **`df[\"Even Numbers\"]`** corresponds to the column name in the **DataFrame**, which is `'Even Numbers'`.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Notes**\n",
    "\n",
    "- **Setting the name** of a Series is optional, but it helps in organizing and identifying the data, especially when the Series is part of a **DataFrame**.\n",
    "- The **name** can be any hashable object, including strings or numbers.\n",
    "- If the Series is not part of a **DataFrame**, its **name** is still useful for display and accessing its contents.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Summary**\n",
    "\n",
    "| Property | Return Type | Description                                                          |\n",
    "| -------- | ----------- | -------------------------------------------------------------------- |\n",
    "| **name** | `label`     | Returns or sets the name of the Series (column name in a DataFrame). |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.Series.name\n",
    "\n",
    "property Series.name\n",
    "\n",
    "Return the name of the Series.\n",
    "\n",
    "The name of a Series becomes its index or column name if it is used to form a DataFrame. It is also used whenever displaying the Series using the interpreter.\n",
    "\n",
    "Returns:\n",
    "label (hashable object)\n",
    "The name of the Series, also the column name if part of a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "Name: Numbers, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "Name: Integers, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.name = \"Integers\"\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Odd Numbers</th>\n",
       "      <th>Even Numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Odd Numbers  Even Numbers\n",
       "0            1             2\n",
       "1            3             4\n",
       "2            5             6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],\n",
    "                  columns=[\"Odd Numbers\", \"Even Numbers\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Even Numbers'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Even Numbers\"].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.flags – All Syntaxes & Details**\n",
    "\n",
    "The **`.flags`** property in **pandas.Series** provides access to the set of properties (flags) associated with the **Series**. These flags reflect attributes of the Series, such as whether it allows duplicate labels or not.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.flags\n",
    "```\n",
    "\n",
    "To access a specific flag:\n",
    "\n",
    "```python\n",
    "Series.flags.<flag_name>\n",
    "```\n",
    "\n",
    "To set a flag:\n",
    "\n",
    "```python\n",
    "Series.flags.<flag_name> = <new_value>\n",
    "```\n",
    "\n",
    "You can also access flags through slicing:\n",
    "\n",
    "```python\n",
    "Series.flags[\"<flag_name>\"]\n",
    "Series.flags[\"<flag_name>\"] = <new_value>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Explanation**\n",
    "\n",
    "- **`.flags`** provides access to **Flags** associated with the Series.\n",
    "- Flags are special properties that describe the behavior of the Series (or DataFrame).\n",
    "- The primary flag currently available for **Series** is:\n",
    "  - **`allows_duplicate_labels`**: Indicates whether the Series allows duplicate labels in its index. The default is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Accessing Flags**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'a'])\n",
    "\n",
    "print(s.flags)\n",
    "print(s.flags.allows_duplicate_labels)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<Flags(allows_duplicate_labels=True)>\n",
    "True\n",
    "```\n",
    "\n",
    "- The **`flags`** of the **Series** indicate that it **allows duplicate labels** in the index.\n",
    "\n",
    "### **3.2 Setting Flags**\n",
    "\n",
    "```python\n",
    "s.flags.allows_duplicate_labels = False\n",
    "print(s.flags.allows_duplicate_labels)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "- The **`allows_duplicate_labels`** flag has been set to `False`, so duplicate labels are not allowed in the index anymore.\n",
    "\n",
    "### **3.3 Accessing Flags with Slicing**\n",
    "\n",
    "```python\n",
    "print(s.flags[\"allows_duplicate_labels\"])\n",
    "s.flags[\"allows_duplicate_labels\"] = True\n",
    "print(s.flags[\"allows_duplicate_labels\"])\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "False\n",
    "True\n",
    "```\n",
    "\n",
    "- The **flag** was accessed and updated using slicing syntax.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Notes**\n",
    "\n",
    "- Flags provide information about the behavior of the pandas object (e.g., Series, DataFrame). They should not be confused with **metadata**, which describes the data itself.\n",
    "- **`.flags`** is a read-write property, so it is possible to change the flags of a Series.\n",
    "- **`allows_duplicate_labels`** flag controls whether or not the Series can have duplicate labels in the index. The default is typically `True`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Summary**\n",
    "\n",
    "| Property                    | Return Type | Description                                                  |\n",
    "| --------------------------- | ----------- | ------------------------------------------------------------ |\n",
    "| **flags**                   | `Flags`     | Access the flags that describe properties of the Series.     |\n",
    "| **allows_duplicate_labels** | `bool`      | Indicates whether duplicate labels are allowed in the index. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Flags(allows_duplicate_labels=True)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas.Series.flags\n",
    "# property Series.flags[source]\n",
    "# Get the properties associated with this pandas object.\n",
    "\n",
    "# The available flags are\n",
    "\n",
    "# Flags.allows_duplicate_labels\n",
    "df = pd.DataFrame({\"A\": [1, 2]})\n",
    "df.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flags.allows_duplicate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.flags.allows_duplicate_labels = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flags[\"allows_duplicate_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.flags[\"allows_duplicate_labels\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas.Series.set_flags\n",
    "# Series.set_flags(*, copy=False, allows_duplicate_labels=None)[source]\n",
    "# Return a new object with updated flags.\n",
    "# Parameters:\n",
    "# copy : bool, default False\n",
    "# Specify if a copy of the object should be made.\n",
    "# allows_duplicate_labelsbool, optional\n",
    "# Whether the returned object allows duplicate labels.\n",
    "# Returns:\n",
    "# Series or DataFrame\n",
    "# The same type as the caller\n",
    "df = pd.DataFrame({\"A\": [1, 2]})\n",
    "df.flags.allows_duplicate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.set_flags(allows_duplicate_labels=False)\n",
    "df2.flags.allows_duplicate_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.set_flags – All Syntaxes & Details**\n",
    "\n",
    "The **`set_flags()`** method allows you to create a new **Series** (or **DataFrame**) with updated flags, particularly useful when working with chained operations. This is the method to update certain flags like whether duplicate labels are allowed in the Series or DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.set_flags(*, copy=False, allows_duplicate_labels=None)\n",
    "```\n",
    "\n",
    "### **Parameters:**\n",
    "\n",
    "- **`copy`**: `bool`, default `False`\n",
    "  - If `True`, a copy of the object is made.\n",
    "  - **Note**: In future versions of pandas (3.0), **copy-on-write** will be the default behavior, meaning this parameter will be deprecated.\n",
    "- **`allows_duplicate_labels`**: `bool`, optional\n",
    "  - **True** or **False** to specify whether the object should allow duplicate labels. If `None`, the flag remains unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Return Value**\n",
    "\n",
    "- Returns the same type as the caller: **Series** or **DataFrame** with the updated flags.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Explanation**\n",
    "\n",
    "- **`set_flags()`** is used to update the flags of a pandas object (Series or DataFrame).\n",
    "- It’s especially useful when you want to change flags in method chains without directly modifying the original Series or DataFrame.\n",
    "- By default, the flag changes are applied to a copy of the object unless specified otherwise.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Examples**\n",
    "\n",
    "### **4.1 Updating Flags on a DataFrame**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\"A\": [1, 2]})\n",
    "\n",
    "# Checking the current flag for duplicate labels\n",
    "print(df.flags.allows_duplicate_labels)  # Output: True\n",
    "\n",
    "# Creating a new DataFrame with the updated flag\n",
    "df2 = df.set_flags(allows_duplicate_labels=False)\n",
    "\n",
    "# Checking the updated flag in the new DataFrame\n",
    "print(df2.flags.allows_duplicate_labels)  # Output: False\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- In the above example, the **`set_flags()`** method was used to create a new DataFrame `df2`, which does not allow duplicate labels, while the original DataFrame `df` remains unchanged.\n",
    "\n",
    "### **4.2 Using `set_flags()` in a Chain of Methods**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\"A\": [1, 2]})\n",
    "\n",
    "# Chaining methods and updating flags\n",
    "df3 = df.set_flags(allows_duplicate_labels=False).rename(columns={'A': 'B'})\n",
    "\n",
    "print(df3.flags.allows_duplicate_labels)  # Output: False\n",
    "print(df3.columns)  # Output: Index(['B'], dtype='object')\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- Here, `set_flags()` is part of a method chain, and the flag is updated in the same line while renaming the column.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Notes**\n",
    "\n",
    "- **`set_flags()`** returns a new object (copy or view) with updated flags. The original Series or DataFrame is not modified unless a new reference is assigned.\n",
    "- The **`copy`** parameter's behavior will change in **pandas 3.0**, with **copy-on-write** being enabled by default. This means methods like **`set_flags()`** will perform a lazy copy and not always copy the object unless necessary.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Summary of Parameters**\n",
    "\n",
    "| Parameter                   | Type   | Description                                               |\n",
    "| --------------------------- | ------ | --------------------------------------------------------- |\n",
    "| **copy**                    | `bool` | Whether to create a copy of the object. Default: `False`. |\n",
    "| **allows_duplicate_labels** | `bool` | Whether to allow duplicate labels in the index.           |\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Summary of Output**\n",
    "\n",
    "The method returns a **Series** or **DataFrame** with updated flags. The key flags you can modify include:\n",
    "\n",
    "- **`allows_duplicate_labels`**: Controls whether the object allows duplicate labels in the index.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    int64\n",
       "col2    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"pandas.Series.astype\n",
    "Series.astype(dtype, copy=None, errors='raise')[source]\n",
    "Cast a pandas object to a specified dtype dtype.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "dtype: str, data type, Series or Mapping of column name -> data type\n",
    "\n",
    "\n",
    "Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to cast entire pandas object to the same type. Alternatively, use a mapping, e.g. {col: dtype, …}, where col is a column label and dtype is a numpy.dtype or Python type to cast one or more of the DataFrame’s columns to column-specific types.\n",
    "\n",
    "copy: bool, default True\n",
    "\n",
    "\n",
    "Return a copy when copy=True (be very careful setting copy=False as changes to values then may propagate to other pandas objects). \n",
    "\n",
    "errors : {‘raise’, ‘ignore’}, default ‘raise’\n",
    "Control raising of exceptions on invalid data for provided dtype.\n",
    "\n",
    "raise : allow exceptions to be raised\n",
    "\n",
    "ignore : suppress exceptions. On error return original object.\n",
    "\n",
    "Returns:\n",
    "        same type as caller\n",
    "\"\"\"\n",
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    int32\n",
       "col2    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.astype('int32').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    int32\n",
       "col2    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.astype({'col1': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "dtype: int32"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ser = pd.Series([1, 2], dtype='int32')\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "dtype: category\n",
       "Categories (2, int32): [1, 2]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "dtype: category\n",
       "Categories (2, int64): [2 < 1]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to ordered categorical type with custom ordering:\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_dtype = CategoricalDtype(\n",
    "    categories=[2, 1], ordered=True)\n",
    "ser.astype(cat_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01\n",
       "1   2020-01-02\n",
       "2   2020-01-03\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a series of dates:\n",
    "ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
    "ser_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "pandas.Series.convert_dtypes\n",
    "Series.convert_dtypes(infer_objects=True, convert_string=True, convert_integer=True, convert_boolean=True, convert_floating=True, dtype_backend='numpy_nullable')[source]\n",
    "Convert columns to the best possible dtypes using dtypes supporting pd.NA.\n",
    "\n",
    "Parameters:\n",
    "infer_objectsbool, default True\n",
    "Whether object dtypes should be converted to the best possible types.\n",
    "\n",
    "convert_stringbool, default True\n",
    "Whether object dtypes should be converted to StringDtype().\n",
    "\n",
    "convert_integerbool, default True\n",
    "Whether, if possible, conversion can be done to integer extension types.\n",
    "\n",
    "convert_booleanbool, defaults True\n",
    "Whether object dtypes should be converted to BooleanDtypes().\n",
    "\n",
    "convert_floatingbool, defaults True\n",
    "Whether, if possible, conversion can be done to floating extension types. If convert_integer is also True, preference will be give to integer dtypes if the floats can be faithfully casted to integers.\n",
    "\n",
    "dtype_backend{‘numpy_nullable’, ‘pyarrow’}, default ‘numpy_nullable’\n",
    "Back-end data type applied to the resultant DataFrame (still experimental). Behaviour is as follows:\n",
    "\n",
    "\"numpy_nullable\": returns nullable-dtype-backed DataFrame (default).\n",
    "\n",
    "\"pyarrow\": returns pyarrow-backed nullable ArrowDtype DataFrame.\n",
    "\n",
    "Added in version 2.0.\n",
    "\n",
    "Returns:\n",
    "Series or DataFrame\n",
    "Copy of input object with new dtype.\n",
    "\n",
    " \"\"\"\n",
    " \n",
    "df = pd.DataFrame(\n",
    "     {\n",
    "        \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
    "         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
    "         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
    "         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
    "         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
    "         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
    "     }\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>h</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b      c    d     e      f\n",
       "0  1  x   True    h  10.0    NaN\n",
       "1  2  y  False    i   NaN  100.5\n",
       "2  3  z    NaN  NaN  20.0  200.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with a DataFrame with default dtypes:\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      int32\n",
       "b     object\n",
       "c     object\n",
       "d     object\n",
       "e    float64\n",
       "f    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>h</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>i</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>100.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>z</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b      c     d     e      f\n",
       "0  1  x   True     h    10   <NA>\n",
       "1  2  y  False     i  <NA>  100.5\n",
       "2  3  z   <NA>  <NA>    20  200.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the DataFrame to the best possible dtypes:\n",
    "dfn = df.convert_dtypes()\n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a             Int32\n",
       "b    string[python]\n",
       "c           boolean\n",
       "d    string[python]\n",
       "e             Int64\n",
       "f           Float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      a\n",
       "1      b\n",
       "2    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with a Series of strings and missing data represented by np.nan .\n",
    "s=pd.Series([\"a\", \"b\", np.nan])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       a\n",
       "1       b\n",
       "2    <NA>\n",
       "dtype: string"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain a series with dtype StringDtype:\n",
    "s.convert_dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.convert_dtypes – All Syntaxes & Details**\n",
    "\n",
    "The **`convert_dtypes()`** method is a powerful function used to convert the columns or elements in a **Series** or **DataFrame** to the best possible dtypes that support **`pd.NA`** (pandas' missing value indicator).\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.convert_dtypes(infer_objects=True, convert_string=True, convert_integer=True, convert_boolean=True, convert_floating=True, dtype_backend='numpy_nullable')\n",
    "```\n",
    "\n",
    "### **Parameters:**\n",
    "\n",
    "- **`infer_objects`** (`bool`, default `True`):\n",
    "  - Whether object dtypes (typically `dtype('O')`) should be inferred and converted to the best possible types.\n",
    "- **`convert_string`** (`bool`, default `True`):\n",
    "  - Whether object dtypes should be converted to `StringDtype()` (nullable string type).\n",
    "- **`convert_integer`** (`bool`, default `True`):\n",
    "  - Whether object dtypes should be converted to integer extension types if possible.\n",
    "- **`convert_boolean`** (`bool`, default `True`):\n",
    "  - Whether object dtypes should be converted to `BooleanDtype()` (nullable boolean type).\n",
    "- **`convert_floating`** (`bool`, default `True`):\n",
    "  - Whether object dtypes should be converted to floating extension types (nullable floats). If `convert_integer` is also `True`, preference will be given to integer dtypes if possible.\n",
    "- **`dtype_backend`** (`{'numpy_nullable', 'pyarrow'}`, default `numpy_nullable`):\n",
    "  - Defines the backend data type used for conversion.\n",
    "    - **`numpy_nullable`**: Uses pandas' nullable types based on NumPy.\n",
    "    - **`pyarrow`**: Uses PyArrow nullable types (experimental feature).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Return Value**\n",
    "\n",
    "- Returns the **Series** or **DataFrame** with converted dtypes based on the above parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Explanation**\n",
    "\n",
    "- **`convert_dtypes()`** analyzes each column or element of a **Series** or **DataFrame** and converts them to their most appropriate dtype.\n",
    "- It is especially useful for handling object types (`dtype('O')`) and ensuring that the data uses the most efficient nullable types like `StringDtype`, `Int64`, `Float64`, `BooleanDtype`, etc.\n",
    "- It supports `pd.NA` for missing values, offering better handling of missing data compared to the traditional `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Examples**\n",
    "\n",
    "### **4.1 Convert a DataFrame to Best Possible Dtypes**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
    "    \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
    "    \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
    "    \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
    "    \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
    "    \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\"))\n",
    "})\n",
    "\n",
    "# Show the DataFrame before conversion\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert to the best possible dtypes\n",
    "dfn = df.convert_dtypes()\n",
    "print(dfn)\n",
    "print(dfn.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "Before conversion:\n",
    "\n",
    "```\n",
    "a      int32\n",
    "b     object\n",
    "c     object\n",
    "d     object\n",
    "e    float64\n",
    "f    float64\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "After conversion:\n",
    "\n",
    "```\n",
    "   a  b      c     d     e      f\n",
    "0  1  x   True     h    10   <NA>\n",
    "1  2  y  False     i  <NA>  100.5\n",
    "2  3  z   <NA>  <NA>    20  200.0\n",
    "```\n",
    "\n",
    "New dtypes:\n",
    "\n",
    "```\n",
    "a             Int32\n",
    "b    string[python]\n",
    "c           boolean\n",
    "d    string[python]\n",
    "e             Int64\n",
    "f           Float64\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The `convert_dtypes()` method automatically converts the columns to their best types, such as:\n",
    "  - `int32` to `Int32` (nullable integer),\n",
    "  - `object` to `string[python]` (nullable string),\n",
    "  - `object` to `boolean` (nullable boolean),\n",
    "  - `float64` to `Float64` (nullable float).\n",
    "\n",
    "### **4.2 Convert a Series with Strings and Missing Data**\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"a\", \"b\", np.nan])\n",
    "print(s)\n",
    "\n",
    "# Convert the Series to StringDtype\n",
    "s_converted = s.convert_dtypes()\n",
    "print(s_converted)\n",
    "print(s_converted.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0      a\n",
    "1      b\n",
    "2    NaN\n",
    "dtype: object\n",
    "\n",
    "0       a\n",
    "1       b\n",
    "2    <NA>\n",
    "dtype: string\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The Series, initially of `object` dtype, is converted to a nullable string type (`StringDtype`), with missing values represented as `<NA>`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Notes**\n",
    "\n",
    "- **`convert_dtypes()`** aims to convert object dtype columns to better types like nullable integers (`Int64`), strings (`StringDtype`), booleans (`BooleanDtype`), and floats (`Float64`), where applicable.\n",
    "- If **`infer_objects`** is `True`, it will attempt to convert object-dtype columns to the most suitable type based on their values.\n",
    "- It is particularly useful for ensuring consistent, efficient, and more memory-efficient handling of data in **Series** or **DataFrames**, especially when dealing with missing values (using `pd.NA`).\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Summary of Parameters**\n",
    "\n",
    "| Parameter            | Type                                                      | Description                                                                     |\n",
    "| -------------------- | --------------------------------------------------------- | ------------------------------------------------------------------------------- |\n",
    "| **infer_objects**    | `bool`, default `True`                                    | Whether to convert object dtypes to the best possible types.                    |\n",
    "| **convert_string**   | `bool`, default `True`                                    | Whether to convert object dtypes to `StringDtype()`.                            |\n",
    "| **convert_integer**  | `bool`, default `True`                                    | Whether to convert object dtypes to integer extension types (e.g., `Int64`).    |\n",
    "| **convert_boolean**  | `bool`, default `True`                                    | Whether to convert object dtypes to `BooleanDtype()`.                           |\n",
    "| **convert_floating** | `bool`, default `True`                                    | Whether to convert object dtypes to floating extension types (e.g., `Float64`). |\n",
    "| **dtype_backend**    | `{‘numpy_nullable’, ‘pyarrow’}`, default `numpy_nullable` | Defines the backend dtype used for conversion. (experimental).                  |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A\n",
       "1  1\n",
       "2  2\n",
       "3  3"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pandas.Series.infer_objects\n",
    "\n",
    "Series.infer_objects(copy=None)\n",
    "\n",
    "Attempt to infer better dtypes for object columns.\n",
    "\n",
    "Attempts soft conversion of object-dtyped columns, leaving non-object and unconvertible columns unchanged. The inference rules are the same as during normal Series/DataFrame construction.\n",
    "\n",
    "Parameters:\n",
    "copy: bool, default True\n",
    "Whether to make a copy for non-object or non-inferable columns or Series. \n",
    "\n",
    "Returns:\n",
    "same type as input object\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
    "df = df.iloc[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.infer_objects().dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.infer_objects – All Syntaxes & Details**\n",
    "\n",
    "The **`infer_objects()`** method attempts to infer better, more specific dtypes for columns with **`object`** dtype, essentially trying to \"soft convert\" those columns into their most appropriate types. It is particularly useful for automatically converting columns of mixed types (e.g., strings and integers) into a more appropriate type (like `int64`, `float64`, `datetime`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.infer_objects(copy=True)\n",
    "```\n",
    "\n",
    "### **Parameters:**\n",
    "\n",
    "- **`copy`** (`bool`, default `True`):\n",
    "  - Whether to make a copy of the Series or DataFrame for columns that are not of object type or not inferable. If `False`, it modifies the original object in place.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Return Value**\n",
    "\n",
    "- The **`infer_objects()`** method returns the **Series** or **DataFrame** with inferred types for columns that are of `object` dtype.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Explanation**\n",
    "\n",
    "- **`infer_objects()`** is typically used to improve the dtype of object columns in **Series** or **DataFrame**.\n",
    "- For instance, a column that consists of integers stored as strings will be converted to an integer dtype (`int64`).\n",
    "- It only attempts to convert columns with `object` dtype and leaves other dtypes (like `int64`, `float64`, etc.) unchanged.\n",
    "- If the column contains mixed types that cannot be directly converted (e.g., integers and strings), it will remain as `object` dtype.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Examples**\n",
    "\n",
    "### **4.1 Infer dtypes for a Series**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with object dtype column\n",
    "df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
    "df = df.iloc[1:]  # Slice to remove the first row\n",
    "\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Infer better dtypes for object columns\n",
    "df_inferred = df.infer_objects()\n",
    "print(df_inferred)\n",
    "print(df_inferred.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "Before inference:\n",
    "\n",
    "```\n",
    "   A\n",
    "1  1\n",
    "2  2\n",
    "3  3\n",
    "A    object\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "After inference:\n",
    "\n",
    "```\n",
    "   A\n",
    "1  1\n",
    "2  2\n",
    "3  3\n",
    "A    int64\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- Initially, column **A** has an **`object`** dtype, as it contains both strings and integers.\n",
    "- After calling **`infer_objects()`**, pandas infers that the values in the column are all integers, and therefore converts the column to **`int64`**.\n",
    "\n",
    "### **4.2 Behavior with Mixed-Type Column**\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with mixed types in a column\n",
    "df2 = pd.DataFrame({\"B\": [\"1\", \"2\", \"three\", \"4\"]})\n",
    "print(df2)\n",
    "print(df2.dtypes)\n",
    "\n",
    "# Infer better dtypes for object columns\n",
    "df2_inferred = df2.infer_objects()\n",
    "print(df2_inferred)\n",
    "print(df2_inferred.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "Before inference:\n",
    "\n",
    "```\n",
    "       B\n",
    "0      1\n",
    "1      2\n",
    "2  three\n",
    "3      4\n",
    "B    object\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "After inference:\n",
    "\n",
    "```\n",
    "       B\n",
    "0      1\n",
    "1      2\n",
    "2  three\n",
    "3      4\n",
    "B    object\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- Even though the column has some integer-like strings, there is also a non-numeric value (`\"three\"`).\n",
    "- **`infer_objects()`** does not convert the column to `int64` because the non-numeric value makes the column incompatible for conversion. The dtype remains **`object`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Notes**\n",
    "\n",
    "- **`infer_objects()`** is particularly useful when you're working with mixed types in columns and you want pandas to automatically infer a better dtype for those columns.\n",
    "- The method doesn't make any changes to columns that are already of a suitable dtype (e.g., `int64`, `float64`, `datetime`).\n",
    "- The **`copy`** parameter allows you to control whether you want to modify the original DataFrame or Series in place or return a new one with inferred types.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Summary of Parameters**\n",
    "\n",
    "| Parameter  | Type                   | Description                                                                       |\n",
    "| ---------- | ---------------------- | --------------------------------------------------------------------------------- |\n",
    "| **`copy`** | `bool`, default `True` | Whether to return a copy of the Series/DataFrame or modify the original in place. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19760\\2406818618.py:17: FutureWarning: Series.bool is now deprecated and will be removed in future version of pandas\n",
      "  pd.Series([True]).bool()\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19760\\2406818618.py:18: FutureWarning: Series.bool is now deprecated and will be removed in future version of pandas\n",
      "  pd.Series([False]).bool()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pandas.Series.bool\n",
    "\n",
    "\n",
    "Series.bool()\n",
    "\n",
    "Return the bool of a single element Series or DataFrame.\n",
    "\n",
    "Deprecated since version 2.1.0: bool is deprecated and will be removed in future version of pandas. For Series use pandas.Series.item.\n",
    "\n",
    "This must be a boolean scalar value, either True or False. It will raise a ValueError if the Series or DataFrame does not have exactly 1 element, or that element is not boolean (integer values 0 and 1 will also raise an exception).\n",
    "\n",
    "Returns:\n",
    "    bool\n",
    "        The value in the Series or DataFrame. \"\"\"\n",
    "\n",
    "\n",
    "pd.Series([True]).bool()  \n",
    "pd.Series([False]).bool()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([True]).item() \n",
    "pd.Series([False]).item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.bool – Deprecated Method for Extracting Boolean Value**\n",
    "\n",
    "The **`bool()`** method in pandas was used to extract the boolean value from a **single-element** Series or DataFrame. However, it has been deprecated as of **pandas version 2.1.0** and will be removed in future versions. Instead, **`pandas.Series.item()`** should be used for this purpose.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.bool()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Parameters**\n",
    "\n",
    "The **`bool()`** method does not take any parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Return Value**\n",
    "\n",
    "The method returns a **boolean value** (`True` or `False`).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Explanation**\n",
    "\n",
    "- **`bool()`** was used to extract the boolean value of a **single-element** Series or DataFrame.\n",
    "- If the Series or DataFrame contains more than one element, or if the element is not a boolean value (e.g., `True` or `False`), it raises a **ValueError**.\n",
    "- As mentioned, this method is deprecated and will be removed in future versions of pandas, so **`item()`** is the recommended method to use instead.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Examples**\n",
    "\n",
    "### **5.1 Example with a Single Element Series**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Series with a single boolean element\n",
    "s = pd.Series([True])\n",
    "print(s.bool())  # Output: True\n",
    "\n",
    "# Series with a single boolean element (False)\n",
    "s = pd.Series([False])\n",
    "print(s.bool())  # Output: False\n",
    "```\n",
    "\n",
    "### **5.2 Example with DataFrame**\n",
    "\n",
    "```python\n",
    "# DataFrame with a single boolean element\n",
    "df = pd.DataFrame({'col': [True]})\n",
    "print(df.bool())  # Output: True\n",
    "\n",
    "# DataFrame with a single boolean element (False)\n",
    "df = pd.DataFrame({'col': [False]})\n",
    "print(df.bool())  # Output: False\n",
    "```\n",
    "\n",
    "### **5.3 Using `item()` Instead of `bool()`**\n",
    "\n",
    "Since **`bool()`** is deprecated, **`item()`** is the preferred alternative:\n",
    "\n",
    "```python\n",
    "# Using item() method on a single-element Series\n",
    "s = pd.Series([True])\n",
    "print(s.item())  # Output: True\n",
    "\n",
    "# Using item() method on a single-element Series (False)\n",
    "s = pd.Series([False])\n",
    "print(s.item())  # Output: False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Notes**\n",
    "\n",
    "- The **`bool()`** method is only useful for single-element Series or DataFrames containing boolean values.\n",
    "- If you try to use **`bool()`** on a multi-element Series/DataFrame or on an element that is not a boolean, you will get a **ValueError**.\n",
    "\n",
    "For instance:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "# This will raise an error:\n",
    "s.bool()  # ValueError: The truth value of a Series is ambiguous.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Summary of Deprecated Method**\n",
    "\n",
    "| Method              | Description                                                                                                                    |\n",
    "| ------------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **`Series.bool()`** | Extracts a boolean value from a single-element Series/DataFrame. Deprecated in version 2.1.0, use **`Series.item()`** instead. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'a'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pandas.Series.to_numpy\n",
    "Series.to_numpy(dtype=None, copy=False, na_value=<no_default>, **kwargs)[source]\n",
    "A NumPy ndarray representing the values in this Series or Index.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "dtype\n",
    "str or numpy.dtype, optional\n",
    "The dtype to pass to numpy.asarray().\n",
    "\n",
    "copy: \n",
    "   bool, default False\n",
    "Whether to ensure that the returned value is not a view on another array. Note that copy=False does not ensure that to_numpy() is no-copy. Rather, copy=True ensure that a copy is made, even if not strictly necessary.\n",
    "\n",
    "na_value: \n",
    "   Any, optional\n",
    "The value to use for missing values. The default value depends on dtype and the type of the array.\n",
    "\n",
    "**kwargs\n",
    "Additional keywords passed through to the to_numpy method of the underlying array (for extension arrays).\n",
    "\n",
    "Returns:\n",
    "\n",
    "numpy.ndarray \"\"\"\n",
    "\n",
    "ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
    "ser.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n",
       "       Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
    "ser.to_numpy(dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.to_numpy(dtype=\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.to_numpy – Convert Series to NumPy Array**\n",
    "\n",
    "The **`to_numpy()`** method in pandas allows you to convert a **Series** (or **Index**) to a **NumPy ndarray**, representing the underlying values. This method provides an easy way to access the Series data as a NumPy array, while retaining the original values.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.to_numpy(dtype=None, copy=False, na_value=<no_default>, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Parameters**\n",
    "\n",
    "- **`dtype`** _(str or numpy.dtype, optional)_: Specifies the data type for the returned NumPy array. If not provided, it will infer the appropriate dtype.\n",
    "- **`copy`** _(bool, default False)_: If `True`, ensures that a copy of the data is returned (even if not strictly necessary). If `False`, it may return a reference to the data if possible (no copy).\n",
    "- **`na_value`** _(any, optional)_: Defines the value to use for missing values (e.g., `NaN`). This can be used to customize the representation of missing data.\n",
    "- **`**kwargs`**: Additional keyword arguments are passed to the `to_numpy()` method of the underlying array (for extension arrays).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Return Value**\n",
    "\n",
    "- **`numpy.ndarray`**: The method returns a NumPy array representing the Series data.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Notes**\n",
    "\n",
    "- **Extension Arrays**: If the Series contains an extension array (like `category`, `period`, `interval`, or `datetime`), `to_numpy()` may require copying data and coercing the result to a NumPy type, which could be expensive.\n",
    "- **Category Type**: If a Series is of `category` dtype, the `to_numpy()` method will lose the category information and return an array of objects.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Examples**\n",
    "\n",
    "### **5.1 Basic Example (Conversion to NumPy Array)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Series with integer values\n",
    "ser = pd.Series([1, 2, 3])\n",
    "arr = ser.to_numpy()\n",
    "print(arr)  # Output: [1 2 3]\n",
    "```\n",
    "\n",
    "### **5.2 Example with Categorical Data**\n",
    "\n",
    "```python\n",
    "# Series with categorical data\n",
    "ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
    "arr = ser.to_numpy()\n",
    "print(arr)  # Output: ['a' 'b' 'a']\n",
    "```\n",
    "\n",
    "### **5.3 Specifying dtype for Datetime Series**\n",
    "\n",
    "```python\n",
    "# Series with datetime data\n",
    "ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
    "arr = ser.to_numpy(dtype=object)\n",
    "print(arr)\n",
    "# Output: [Timestamp('2000-01-01 00:00:00+0100', tz='CET')\n",
    "#          Timestamp('2000-01-02 00:00:00+0100', tz='CET')]\n",
    "```\n",
    "\n",
    "### **5.4 Specifying dtype as datetime64**\n",
    "\n",
    "```python\n",
    "# Converting to native datetime64\n",
    "arr = ser.to_numpy(dtype=\"datetime64[ns]\")\n",
    "print(arr)\n",
    "# Output: ['1999-12-31T23:00:00.000000000' '2000-01-01T23:00:00.000000000']\n",
    "```\n",
    "\n",
    "### **5.5 Handling Missing Values**\n",
    "\n",
    "```python\n",
    "# Series with missing values\n",
    "ser = pd.Series([1, 2, None, 4])\n",
    "arr = ser.to_numpy(na_value=-1)\n",
    "print(arr)  # Output: [ 1.  2. -1.  4.]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Comparison to `Series.array`**\n",
    "\n",
    "- **`Series.to_numpy()`**: Returns a NumPy array, but it may not preserve the exact dtype for extension arrays like `category` or `datetime`.\n",
    "- **`Series.array()`**: Provides access to the raw data stored in the Series, retaining the extension type (e.g., `DatetimeArray`, `Categorical`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Summary Table**\n",
    "\n",
    "| dtype                | array type                       |\n",
    "| -------------------- | -------------------------------- |\n",
    "| `category[T]`        | ndarray[T] (same dtype as input) |\n",
    "| `period`             | ndarray[object] (Periods)        |\n",
    "| `interval`           | ndarray[object] (Intervals)      |\n",
    "| `IntegerNA`          | ndarray[object]                  |\n",
    "| `datetime64[ns]`     | datetime64[ns]                   |\n",
    "| `datetime64[ns, tz]` | ndarray[object] (Timestamps)     |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023    1\n",
       "2024    2\n",
       "2025    3\n",
       "Freq: Y-DEC, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pandas.Series.to_period\n",
    "Series.to_period(freq=None, copy=None)[source]\n",
    "Convert Series from DatetimeIndex to PeriodIndex.\n",
    "\n",
    "Parameters:\n",
    "freq: str, default None\n",
    "Frequency associated with the PeriodIndex.\n",
    "\n",
    "copy: bool, default True\n",
    "Whether or not to return a copy.\n",
    "\n",
    "\n",
    "\n",
    "Returns:\n",
    "      Series\n",
    "        Series with index converted to PeriodIndex. \"\"\"\n",
    "        \n",
    "idx = pd.DatetimeIndex(['2023', '2024', '2025'])\n",
    "s = pd.Series([1, 2, 3], index=idx)\n",
    "s = s.to_period()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2023', '2024', '2025'], dtype='period[Y-DEC]')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.to_period – Convert Series from DatetimeIndex to PeriodIndex**\n",
    "\n",
    "The **`to_period()`** method in pandas is used to convert a Series with a **DatetimeIndex** to a Series with a **PeriodIndex**. This can be useful when working with time-based data that you want to handle in terms of specific time periods (such as years, months, or quarters).\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.to_period(freq=None, copy=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Parameters**\n",
    "\n",
    "- **`freq`** _(str, optional)_: Specifies the frequency for the resulting **PeriodIndex**. If not provided, the frequency will be inferred from the data.\n",
    "- **`copy`** _(bool, default True)_: Whether or not to return a copy of the data. In future versions of pandas (pandas 3.0), the behavior of copy will change to **Copy-on-Write** by default.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Return Value**\n",
    "\n",
    "- **`Series`**: The method returns a new **Series** where the index is now a **PeriodIndex**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Notes**\n",
    "\n",
    "- If the **`freq`** is not provided, pandas will infer it from the **DatetimeIndex**.\n",
    "- The resulting **PeriodIndex** will represent the same points in time but will be shown as periods based on the specified frequency.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Examples**\n",
    "\n",
    "### **5.1 Basic Example (Conversion from DatetimeIndex to PeriodIndex)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DatetimeIndex\n",
    "idx = pd.DatetimeIndex(['2023', '2024', '2025'])\n",
    "\n",
    "# Creating a Series with DatetimeIndex\n",
    "s = pd.Series([1, 2, 3], index=idx)\n",
    "\n",
    "# Converting the Series to PeriodIndex\n",
    "s_period = s.to_period()\n",
    "\n",
    "print(s_period)\n",
    "# Output:\n",
    "# 2023    1\n",
    "# 2024    2\n",
    "# 2025    3\n",
    "# Freq: Y-DEC, dtype: int64\n",
    "```\n",
    "\n",
    "### **5.2 Viewing the PeriodIndex**\n",
    "\n",
    "```python\n",
    "# Viewing the index\n",
    "print(s_period.index)\n",
    "# Output:\n",
    "# PeriodIndex(['2023', '2024', '2025'], dtype='period[Y-DEC]')\n",
    "```\n",
    "\n",
    "### **5.3 Converting with a Specified Frequency**\n",
    "\n",
    "```python\n",
    "# Converting with a specified frequency (monthly frequency)\n",
    "s_monthly = s.to_period(freq='M')\n",
    "\n",
    "print(s_monthly)\n",
    "# Output:\n",
    "# 2023-01    1\n",
    "# 2024-01    2\n",
    "# 2025-01    3\n",
    "# Freq: M, dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Summary**\n",
    "\n",
    "- **`to_period()`** is great for transforming time-based data (like **DatetimeIndex**) into period-based data (like **PeriodIndex**).\n",
    "- It can be helpful when analyzing data that involves discrete time periods (such as yearly, monthly, etc.).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023    1\n",
       "2024    2\n",
       "2025    3\n",
       "Freq: Y-DEC, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pandas.Series.to_timestamp\n",
    "Series.to_timestamp(freq=None, how='start', copy=None)[source]\n",
    "Cast to DatetimeIndex of Timestamps, at beginning of period.\n",
    "\n",
    "Parameters:\n",
    "freq : str, default frequency of PeriodIndex\n",
    "Desired frequency.\n",
    "\n",
    "how : {‘s’, ‘e’, ‘start’, ‘end’}\n",
    "Convention for converting period to timestamp; start of period vs. end.\n",
    "\n",
    "copy : bool, default True\n",
    "Whether or not to return a copy. \n",
    "\n",
    "Returns:\n",
    "     Series with DatetimeIndex\n",
    "     \n",
    "\"\"\"\n",
    "idx = pd.PeriodIndex(['2023', '2024', '2025'], freq='Y')\n",
    "s1 = pd.Series([1, 2, 3], index=idx)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023-01-01    1\n",
       "2024-01-01    2\n",
       "2025-01-01    3\n",
       "Freq: YS-JAN, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = s1.to_timestamp()\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023-01-31    1\n",
       "2024-01-31    2\n",
       "2025-01-31    3\n",
       "Freq: YE-JAN, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = pd.Series([1, 2, 3], index=idx)\n",
    "s2 = s2.to_timestamp(freq='M')\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.to_timestamp – Convert PeriodIndex to DatetimeIndex**\n",
    "\n",
    "The **`to_timestamp()`** method in pandas is used to convert a **PeriodIndex** to a **DatetimeIndex**. The method provides flexibility in defining the exact timestamp to represent each period, such as the start or end of a given period.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.to_timestamp(freq=None, how='start', copy=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Parameters**\n",
    "\n",
    "- **`freq`** _(str, optional)_: The frequency of the resulting **DatetimeIndex**. By default, it uses the frequency of the **PeriodIndex**.\n",
    "- **`how`** _({'s', 'e', 'start', 'end'}, default 'start')_: Defines whether the timestamp represents the start or the end of the period.\n",
    "\n",
    "  - 's' or 'start' refers to the beginning of the period.\n",
    "  - 'e' or 'end' refers to the end of the period.\n",
    "\n",
    "- **`copy`** _(bool, default True)_: Whether to return a copy of the data. In pandas 3.0, **Copy-on-Write** will be enabled by default.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Return Value**\n",
    "\n",
    "- **`Series`**: The method returns a **Series** with **DatetimeIndex** as the index.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Notes**\n",
    "\n",
    "- If you specify **`freq`**, it will override the frequency of the original **PeriodIndex**.\n",
    "- The **`how`** parameter allows you to control whether the **DatetimeIndex** will represent the start or end of the period.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Examples**\n",
    "\n",
    "### **5.1 Basic Example (Convert PeriodIndex to DatetimeIndex at the Start of Period)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a PeriodIndex with yearly frequency\n",
    "idx = pd.PeriodIndex(['2023', '2024', '2025'], freq='Y')\n",
    "\n",
    "# Create a Series with PeriodIndex\n",
    "s1 = pd.Series([1, 2, 3], index=idx)\n",
    "\n",
    "# Convert the PeriodIndex to a DatetimeIndex (start of each period)\n",
    "s1_timestamp = s1.to_timestamp()\n",
    "\n",
    "print(s1_timestamp)\n",
    "# Output:\n",
    "# 2023-01-01    1\n",
    "# 2024-01-01    2\n",
    "# 2025-01-01    3\n",
    "# Freq: YS-JAN, dtype: int64\n",
    "```\n",
    "\n",
    "### **5.2 Using the `freq` Parameter**\n",
    "\n",
    "```python\n",
    "# Convert with a different frequency (monthly frequency)\n",
    "s2 = s1.to_timestamp(freq='M')\n",
    "\n",
    "print(s2)\n",
    "# Output:\n",
    "# 2023-01-31    1\n",
    "# 2024-01-31    2\n",
    "# 2025-01-31    3\n",
    "# Freq: YE-JAN, dtype: int64\n",
    "```\n",
    "\n",
    "### **5.3 Specifying the `how` Parameter (End of Period)**\n",
    "\n",
    "```python\n",
    "# Convert to DatetimeIndex, using the end of each period\n",
    "s3 = s1.to_timestamp(how='end')\n",
    "\n",
    "print(s3)\n",
    "# Output:\n",
    "# 2023-12-31    1\n",
    "# 2024-12-31    2\n",
    "# 2025-12-31    3\n",
    "# Freq: YE-DEC, dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Summary**\n",
    "\n",
    "- The **`to_timestamp()`** method is useful when converting a **PeriodIndex** to a **DatetimeIndex**.\n",
    "- The **`freq`** parameter allows you to control the frequency of the resulting **DatetimeIndex**.\n",
    "- The **`how`** parameter allows you to specify whether the timestamp should be at the start or the end of each period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pandas.Series.to_list\n",
    "\n",
    "\n",
    "Series.to_list()\n",
    "Return a list of the values.\n",
    "\n",
    "These are each a scalar type, which is a Python scalar (for str, int, float) or a pandas scalar (for Timestamp/Timedelta/Interval/Period)\n",
    "\n",
    "Returns:\n",
    "list \n",
    "\n",
    "\"\"\"\n",
    "# for Series\n",
    "s = pd.Series([1, 2, 3])\n",
    "s.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1, 2, 3], dtype='int64')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for Index\n",
    "idx = pd.Index([1, 2, 3])\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.to_list – Convert Series to a Python List**\n",
    "\n",
    "The **`to_list()`** method in pandas is used to convert a **Series** (or **Index**) into a plain Python list.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.to_list()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Return Value**\n",
    "\n",
    "- **`list`**: A Python list containing the values of the **Series** or **Index**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Examples**\n",
    "\n",
    "### **3.1 Convert a Series to a List**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a simple Series\n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# Convert the Series to a list\n",
    "list_values = s.to_list()\n",
    "\n",
    "print(list_values)\n",
    "# Output: [1, 2, 3]\n",
    "```\n",
    "\n",
    "### **3.2 Convert an Index to a List**\n",
    "\n",
    "```python\n",
    "# Create a simple Index\n",
    "idx = pd.Index([1, 2, 3])\n",
    "\n",
    "# Convert the Index to a list\n",
    "list_idx = idx.to_list()\n",
    "\n",
    "print(list_idx)\n",
    "# Output: [1, 2, 3]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Notes**\n",
    "\n",
    "- The **`to_list()`** method returns a regular Python list, not a pandas-specific object.\n",
    "- The list will contain Python scalars, such as **int**, **float**, **str**, or **pandas** scalars like **Timestamp**, **Timedelta**, etc.\n",
    "- This method is convenient when you need to work with data outside of pandas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pandas.Series.__array__\n",
    "Series.__array__(dtype=None, copy=None)[source]\n",
    "Return the values as a NumPy array.\n",
    "\n",
    "Users should not call this directly. Rather, it is invoked by numpy.array() and numpy.asarray().\n",
    "\n",
    "Parameters:\n",
    "\n",
    "\n",
    "dtype : \n",
    "        str or numpy.dtype, optional\n",
    "The dtype to use for the resulting NumPy array. By default, the dtype is inferred from the data.\n",
    "\n",
    "copy : \n",
    "bool or None, optional\n",
    "Unused.\n",
    "\n",
    "Returns :\n",
    "    numpy.ndarray\n",
    "The values in the series converted to a numpy.ndarray with the specified dtype. \n",
    "\n",
    "\"\"\"\n",
    "ser = pd.Series([1, 2, 3])\n",
    "np.asarray(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n",
       "       Timestamp('2000-01-02 00:00:00+0100', tz='CET')], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For timezone-aware data, the timezones may be retained with dtype='object'\n",
    "tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
    "np.asarray(tzser, dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or the values may be localized to UTC and the tzinfo discarded with dtype='datetime64[ns]'\n",
    "np.asarray(tzser, dtype=\"datetime64[ns]\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.**array** – Convert Series to a NumPy Array**\n",
    "\n",
    "The **`__array__()`** method is an internal method used by **NumPy** to convert a **pandas Series** into a **NumPy ndarray**. It is invoked when using functions like **`numpy.array()`** or **`numpy.asarray()`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.__array__(dtype=None, copy=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Parameters**\n",
    "\n",
    "- **`dtype`**: `str` or `numpy.dtype`, optional  \n",
    "  Specifies the desired data type for the resulting NumPy array. If not provided, the dtype is inferred from the Series.\n",
    "- **`copy`**: `bool` or `None`, optional  \n",
    "  This parameter is not used in this method.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Return Value**\n",
    "\n",
    "- **`numpy.ndarray`**: A **NumPy array** containing the values from the Series, optionally with the specified dtype.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Usage Examples**\n",
    "\n",
    "### **4.1 Converting a Simple Series to a NumPy Array**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a Series\n",
    "ser = pd.Series([1, 2, 3])\n",
    "\n",
    "# Convert Series to NumPy array\n",
    "np_array = np.asarray(ser)\n",
    "\n",
    "print(np_array)\n",
    "# Output: [1 2 3]\n",
    "```\n",
    "\n",
    "### **4.2 Converting Timezone-Aware Data**\n",
    "\n",
    "```python\n",
    "# Create a Series with timezone-aware datetime data\n",
    "tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
    "\n",
    "# Convert the timezone-aware Series to a NumPy array (dtype='object')\n",
    "np_array_tz = np.asarray(tzser, dtype=\"object\")\n",
    "\n",
    "print(np_array_tz)\n",
    "# Output: [Timestamp('2000-01-01 00:00:00+0100', tz='CET') Timestamp('2000-01-02 00:00:00+0100', tz='CET')]\n",
    "```\n",
    "\n",
    "### **4.3 Converting Timezone-Aware Data to UTC**\n",
    "\n",
    "```python\n",
    "# Convert the timezone-aware Series to NumPy array with dtype='datetime64[ns]'\n",
    "np_array_utc = np.asarray(tzser, dtype=\"datetime64[ns]\")\n",
    "\n",
    "print(np_array_utc)\n",
    "# Output: ['1999-12-31T23:00:00.000000000' '2000-01-01T23:00:00.000000000']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Notes**\n",
    "\n",
    "- **`__array__()`** is not meant to be directly called. Instead, it is invoked when you use **`numpy.array()`** or **`numpy.asarray()`** to convert a pandas Series to a NumPy array.\n",
    "- If you want a zero-copy view of the underlying array data in the Series, you can use **`Series.array`**.\n",
    "- **`Series.to_numpy()`** provides a similar function but is recommended for user-facing code.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.get\n",
    "\n",
    "Series.get(key, default=None)\n",
    "\n",
    "Get item from object for given key (ex: DataFrame column).\n",
    "\n",
    "Returns default value if not found.\n",
    "\n",
    "Parameters:\n",
    "  key : \n",
    "    object\n",
    "    \n",
    "Returns\n",
    ":\n",
    "same type as items contained in object\n",
    "\"\"\"\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [24.3, 75.7, \"high\"],\n",
    "        [31, 87.8, \"high\"],\n",
    "        [22, 71.6, \"medium\"],\n",
    "        [35, 95, \"medium\"],\n",
    "    ],\n",
    "    columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n",
    "    index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_celsius</th>\n",
       "      <th>temp_fahrenheit</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-02-12</th>\n",
       "      <td>24.3</td>\n",
       "      <td>75.7</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-13</th>\n",
       "      <td>31.0</td>\n",
       "      <td>87.8</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-14</th>\n",
       "      <td>22.0</td>\n",
       "      <td>71.6</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-15</th>\n",
       "      <td>35.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temp_celsius  temp_fahrenheit windspeed\n",
       "2014-02-12          24.3             75.7      high\n",
       "2014-02-13          31.0             87.8      high\n",
       "2014-02-14          22.0             71.6    medium\n",
       "2014-02-15          35.0             95.0    medium"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_celsius</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-02-12</th>\n",
       "      <td>24.3</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-13</th>\n",
       "      <td>31.0</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-14</th>\n",
       "      <td>22.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-15</th>\n",
       "      <td>35.0</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temp_celsius windspeed\n",
       "2014-02-12          24.3      high\n",
       "2014-02-13          31.0      high\n",
       "2014-02-14          22.0    medium\n",
       "2014-02-15          35.0    medium"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get([\"temp_celsius\", \"windspeed\"]  , default=\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'high'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = df['windspeed']\n",
    "ser.get('2014-02-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default_value'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get([\"temp_celsius\", \"temp_kelvin\"], default=\"default_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[unknown]'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.get('2014-02-10', '[unknown]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **pandas.Series.get – Retrieve an Item from a Series**\n",
    "\n",
    "The **`get()`** method is used to retrieve an item from a **pandas Series** (or **DataFrame** column) for a given key (index label). If the key is not found, it returns a default value instead of raising an error.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.get(key, default=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Parameters**\n",
    "\n",
    "- **`key`**: `object`  \n",
    "  The key (index label) you want to retrieve the value for.\n",
    "\n",
    "- **`default`**: `any`, optional  \n",
    "  The value to return if the key is not found. The default value is `None`.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Return Value**\n",
    "\n",
    "- The method returns the value associated with the given key in the Series. If the key is not found, it returns the `default` value.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Usage Examples**\n",
    "\n",
    "### **4.1 Accessing Multiple Columns in a DataFrame**\n",
    "\n",
    "You can use the `get()` method to access multiple columns at once in a **DataFrame**.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [24.3, 75.7, \"high\"],\n",
    "        [31, 87.8, \"high\"],\n",
    "        [22, 71.6, \"medium\"],\n",
    "        [35, 95, \"medium\"],\n",
    "    ],\n",
    "    columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n",
    "    index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n",
    ")\n",
    "\n",
    "# Get multiple columns\n",
    "result = df.get([\"temp_celsius\", \"windspeed\"])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "            temp_celsius windspeed\n",
    "2014-02-12          24.3      high\n",
    "2014-02-13          31.0      high\n",
    "2014-02-14          22.0    medium\n",
    "2014-02-15          35.0    medium\n",
    "```\n",
    "\n",
    "### **4.2 Accessing a Single Element from a Series**\n",
    "\n",
    "You can use `get()` on a Series to retrieve a single element using an index label.\n",
    "\n",
    "```python\n",
    "# Access a single element\n",
    "ser = df['windspeed']\n",
    "value = ser.get('2014-02-13')\n",
    "print(value)\n",
    "# Output: high\n",
    "```\n",
    "\n",
    "### **4.3 Providing a Default Value When Key is Not Found**\n",
    "\n",
    "If the key is not present, the `get()` method will return the default value you specify.\n",
    "\n",
    "```python\n",
    "# Access a key that doesn't exist, with a default value\n",
    "default_value = df.get([\"temp_celsius\", \"temp_kelvin\"], default=\"default_value\")\n",
    "print(default_value)\n",
    "# Output: default_value\n",
    "```\n",
    "\n",
    "### **4.4 Handling Missing Data in a Series**\n",
    "\n",
    "You can use `get()` to handle missing data in a **Series** by returning a default value when the key is not found.\n",
    "\n",
    "```python\n",
    "# Access a key that doesn't exist in the Series\n",
    "missing_value = ser.get('2014-02-10', '[unknown]')\n",
    "print(missing_value)\n",
    "# Output: [unknown]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Notes**\n",
    "\n",
    "- If the key exists in the Series or DataFrame, `get()` returns the corresponding value.\n",
    "- If the key is not found, the specified default value will be returned instead of throwing a `KeyError`.\n",
    "- This method is useful when you want to avoid errors for missing keys and provide fallback/default values.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.at\n",
    "\n",
    "\n",
    "property Series.at[source]\n",
    "Access a single value for a row/column label pair.\n",
    "\n",
    "Similar to loc, in that both provide label-based lookups. Use at if you only need to get or set a single value in a DataFrame or Series.\n",
    "\n",
    "Raises:\n",
    "\n",
    "KeyError\n",
    "\n",
    "If getting a value and ‘label’ does not exist in a DataFrame or Series.\n",
    "\n",
    "ValueError\n",
    "\n",
    "If row/column label pair is not a tuple or if any label from the pair is not a scalar for DataFrame. If label is list-like (excluding NamedTuple) for Series. \"\"\"\n",
    "df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
    "                  index=[4, 5, 6], columns=['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C\n",
       "4   0   2   3\n",
       "5   0   4   1\n",
       "6  10  20  30"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get value at specified row/column pair\n",
    "df.at[4, 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set value at specified row/column pair\n",
    "df.at[4, 'B'] = 10\n",
    "df.at[4, 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get value within a Series\n",
    "df.loc[5].at['B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.at – Access a Single Value for a Row/Column Label Pair**\n",
    "\n",
    "The **`Series.at`** property provides an efficient way to access a single value within a **pandas Series** or **DataFrame** using a specific label (row/column pair).\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.at[label]\n",
    "```\n",
    "\n",
    "- **`label`**: The row label in a Series or DataFrame, and optionally the column label for DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Usage**\n",
    "\n",
    "- **Accessing values**: You can access a specific element from a Series or DataFrame using a row/column label.\n",
    "- **Efficient for scalars**: `at` is designed for accessing a single value, making it faster than other methods such as `loc` or `iloc` when you are only retrieving a single value.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Parameters**\n",
    "\n",
    "- **`label`**: The label of the row (and optionally column, for DataFrame) you want to access.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Return Value**\n",
    "\n",
    "- **`Series`** or **`scalar`**: Returns the value at the specified label in the Series (or DataFrame).\n",
    "- If the label is not found, a **`KeyError`** is raised.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Common Use Cases**\n",
    "\n",
    "- **Accessing Single Values in Series**\n",
    "- **Modifying Single Values in Series**\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Examples**\n",
    "\n",
    "#### **6.1 Accessing a Single Value in a DataFrame**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
    "                  index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Access value at specific row/column pair\n",
    "print(df.at[4, 'B'])  # Output: 2\n",
    "\n",
    "# Set a new value at the same location\n",
    "df.at[4, 'B'] = 10\n",
    "print(df.at[4, 'B'])  # Output: 10\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    A   B   C\n",
    "4   0   2   3\n",
    "5   0   4   1\n",
    "6  10  20  30\n",
    "```\n",
    "\n",
    "#### **6.2 Accessing a Single Value in a Series**\n",
    "\n",
    "You can also use **`at`** within a Series after using `.loc` to select a specific row.\n",
    "\n",
    "```python\n",
    "# Access a value from a Series\n",
    "series = df.loc[5]  # Select row 5 from DataFrame\n",
    "print(series.at['B'])  # Output: 4\n",
    "```\n",
    "\n",
    "#### **6.3 Modifying a Single Value in a Series**\n",
    "\n",
    "```python\n",
    "# Modifying a value in a Series\n",
    "df.loc[6].at['A'] = 100\n",
    "print(df.at[6, 'A'])  # Output: 100\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Notes**\n",
    "\n",
    "- **Efficient Access**: `at` is faster than `loc` for accessing single values because it is optimized for scalar retrieval.\n",
    "- **Error Handling**: If the label is not present, it raises a **`KeyError`**.\n",
    "- **Not for Lists**: Unlike `loc`, **`at`** cannot handle list-like labels. It expects a single label, not a list or array.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. See Also**\n",
    "\n",
    "- **`DataFrame.at`** – Access a single value in a DataFrame.\n",
    "- **`Series.loc`** – Access a group of rows by labels.\n",
    "- **`Series.iat`** – Access a single value by integer position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' DataFrame.at\\n      \\nAccess a single value for a row/column label pair.\\n\\nDataFrame.loc\\nAccess a group of rows and columns by label(s).\\n\\nDataFrame.iloc\\nAccess a group of rows and columns by integer position(s). '"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "pandas.Series.iat\n",
    "\n",
    "property Series.iat[source]\n",
    "Access a single value for a row/column pair by integer position.\n",
    "\n",
    "Similar to iloc, in that both provide integer-based lookups. Use iat if you only need to get or set a single value in a DataFrame or Series.\n",
    "\n",
    "Raises :\n",
    "    IndexError\n",
    "      When integer position is out of bounds. \"\"\"\n",
    "      \n",
    "      \n",
    "\"\"\" DataFrame.at\n",
    "      \n",
    "Access a single value for a row/column label pair.\n",
    "\n",
    "DataFrame.loc\n",
    "Access a group of rows and columns by label(s).\n",
    "\n",
    "DataFrame.iloc\n",
    "Access a group of rows and columns by integer position(s). \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C\n",
       "0   0   2   3\n",
       "1   0   4   1\n",
       "2  10  20  30"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get value at specified row/column pair\n",
    "df.iat[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set value at specified row/column pair\n",
    "df.iat[1, 2] = 10\n",
    "df.iat[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get value within a series\n",
    "df.loc[0].iat[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.iat – Access a Single Value for a Row/Column Pair by Integer Position**\n",
    "\n",
    "The **`Series.iat`** property provides an efficient way to access or modify a single value in a **pandas Series** or **DataFrame** using integer-based indexing.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.iat[row_index, col_index]\n",
    "```\n",
    "\n",
    "- **`row_index`**: Integer position of the row.\n",
    "- **`col_index`**: Integer position of the column.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Usage**\n",
    "\n",
    "- **Efficient for single-value access**: Similar to **`iloc`**, but more efficient for getting or setting a single value, as it is optimized for scalar operations.\n",
    "- **Integer-based**: Uses integers for both row and column positions, rather than labels.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Parameters**\n",
    "\n",
    "- **`row_index`**: Integer position of the row.\n",
    "- **`col_index`**: Integer position of the column.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Return Value**\n",
    "\n",
    "- **`Series`** or **`scalar`**: Returns the value at the specified row and column (position).\n",
    "- If the indices are out of bounds, an **`IndexError`** is raised.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Common Use Cases**\n",
    "\n",
    "- **Accessing single values by integer position**\n",
    "- **Modifying values by integer position**\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Examples**\n",
    "\n",
    "#### **6.1 Accessing a Single Value in a DataFrame**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Access value at specific row/column position\n",
    "print(df.iat[1, 2])  # Output: 1\n",
    "\n",
    "# Set a new value at the same location\n",
    "df.iat[1, 2] = 10\n",
    "print(df.iat[1, 2])  # Output: 10\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    A   B   C\n",
    "0   0   2   3\n",
    "1   0   4   1\n",
    "2  10  20  30\n",
    "```\n",
    "\n",
    "#### **6.2 Accessing a Single Value in a Series**\n",
    "\n",
    "You can also use **`iat`** after selecting a specific row from a **DataFrame** using **`loc`**.\n",
    "\n",
    "```python\n",
    "# Access a value from a Series within a DataFrame\n",
    "series = df.loc[0]  # Select row 0 from DataFrame\n",
    "print(series.iat[1])  # Output: 2\n",
    "```\n",
    "\n",
    "#### **6.3 Modifying a Single Value in a Series**\n",
    "\n",
    "```python\n",
    "# Modifying a value in a Series\n",
    "df.loc[2].iat[0] = 100\n",
    "print(df.iat[2, 0])  # Output: 100\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Notes**\n",
    "\n",
    "- **Efficient for Scalar Access**: **`iat`** is faster than **`iloc`** when dealing with a single value, as it is optimized for scalar operations.\n",
    "- **Indexing with Integers**: You must use integer positions, not labels (which **`loc`** and **`at`** support).\n",
    "- **Error Handling**: If the indices are out of bounds, an **`IndexError`** is raised, so always ensure valid positions are provided.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. See Also**\n",
    "\n",
    "- **`DataFrame.at`** – Access a single value for a row/column label pair.\n",
    "- **`DataFrame.loc`** – Access a group of rows and columns by labels.\n",
    "- **`Series.loc`** – Access a group of rows by label.\n",
    "- **`Series.iloc`** – Access a group of rows by integer position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra               1       2\n",
       "viper               4       5\n",
       "sidewinder          7       8"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pandas.Series.loc\n",
    "property Series.loc[source]\n",
    "Access a group of rows and columns by label(s) or a boolean array.\n",
    "\n",
    ".loc[] is primarily label based, but may also be used with a boolean array.\n",
    "\n",
    "Allowed inputs are:\n",
    "\n",
    "A single label, e.g. 5 or 'a', (note that 5 is interpreted as a label of the index, and never as an integer position along the index).\n",
    "\n",
    "A list or array of labels, e.g. ['a', 'b', 'c'].\n",
    "\n",
    "A slice object with labels, e.g. 'a':'f'.\n",
    "\n",
    "Warning\n",
    "\n",
    "Note that contrary to usual python slices, both the start and the stop are included\n",
    "\n",
    "A boolean array of the same length as the axis being sliced, e.g. [True, False, True].\n",
    "\n",
    "An alignable boolean Series. The index of the key will be aligned before masking.\n",
    "\n",
    "An alignable Index. The Index of the returned selection will be the input.\n",
    "\n",
    "A callable function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above)\n",
    "\n",
    "See more at Selection by Label.\n",
    "\n",
    "Raises\n",
    ":\n",
    "KeyError\n",
    "If any items are not found.\n",
    "\n",
    "IndexingError\n",
    "If an indexed key is passed and its index is unalignable to the frame index.\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.at\n",
    "Access a single value for a row/column label pair.\n",
    "\n",
    "DataFrame.iloc\n",
    "Access group of rows and columns by integer position(s).\n",
    "\n",
    "DataFrame.xs\n",
    "Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.\n",
    "\n",
    "Series.loc\n",
    "Access group of values using labels. \"\"\"\n",
    "\n",
    "df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
    "                  index=['cobra', 'viper', 'sidewinder'],\n",
    "                  columns=['max_speed', 'shield'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_speed    4\n",
       "shield       5\n",
       "Name: viper, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single label. Note this returns the row as a Series.\n",
    "df.loc['viper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "viper               4       5\n",
       "sidewinder          7       8"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of labels. Note using [[]] returns a DataFrame.\n",
    "df.loc[['viper', 'sidewinder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cobra    1\n",
       "viper    4\n",
       "Name: max_speed, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice wit hlabels for row and single label for column.\n",
    "df.loc['cobra':'viper', 'max_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "sidewinder          7       8"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean list with the same length as the row axis\n",
    "df.loc[[False, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "sidewinder          7       8"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alignable boolean Series:\n",
    "df.loc[pd.Series([False, True, False],\n",
    "                 index=['viper', 'sidewinder', 'cobra'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       max_speed  shield\n",
       "foo                     \n",
       "cobra          1       2\n",
       "viper          4       5"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index (same behavior as df.reindex)\n",
    "df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "sidewinder          7       8"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditional that returns a boolean Series\n",
    "df.loc[df['shield'] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed\n",
       "sidewinder          7"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditional that returns a boolean Series with column labels specified\n",
    "df.loc[df['shield'] > 6, ['max_speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       max_speed  shield\n",
       "viper          4       5"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple conditional using & that returns a boolean Series\n",
    "df.loc[(df['max_speed'] > 1) & (df['shield'] < 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra               1       2\n",
       "sidewinder          7       8"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple conditional using | that returns a boolean Series\n",
    "df.loc[(df['max_speed'] > 4) | (df['shield'] < 5)]\n",
    "# Please ensure that each condition is wrapped in parentheses ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "sidewinder          7       8"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callable that returns a boolean Series\n",
    "\n",
    "df.loc[lambda df: df['shield'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra               1       2\n",
       "viper               4      50\n",
       "sidewinder          7      50"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting values\n",
    "\n",
    "# Set value for all items matching the list of labels\n",
    "\n",
    "df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra              10      10\n",
       "viper               4      50\n",
       "sidewinder          7      50"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set value for an entire row\n",
    "\n",
    "df.loc['cobra'] = 10\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra              30      10\n",
       "viper              30      50\n",
       "sidewinder         30      50"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set value for an entire column\n",
    "\n",
    "df.loc[:, 'max_speed'] = 30\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra              30      10\n",
       "viper               0       0\n",
       "sidewinder          0       0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set value for rows matching callable condition\n",
    "\n",
    "df.loc[df['shield'] > 35] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra              30      10\n",
       "viper               0       5\n",
       "sidewinder          0       0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add value matching location\n",
    "\n",
    "df.loc[\"viper\", \"shield\"] += 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sidewinder</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_speed  shield\n",
       "cobra              60      20\n",
       "viper               0      10\n",
       "sidewinder          0       0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting using a Series or a DataFrame sets the values matching the index labels, not the index positions.\n",
    "\n",
    "shuffled_df = df.loc[[\"viper\", \"cobra\", \"sidewinder\"]]\n",
    "df.loc[:] += shuffled_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_speed  shield\n",
       "7          1       2\n",
       "8          4       5\n",
       "9          7       8"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting values on a DataFrame with an index that has integer labels\n",
    "\n",
    "# Another example using integers for the index\n",
    "\n",
    "df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
    "                  index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_speed  shield\n",
       "7          1       2\n",
       "8          4       5\n",
       "9          7       8"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice with integer labels for rows. As mentioned above, note that both the start and stop of the slice are included.\n",
    "\n",
    "df.loc[7:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cobra</th>\n",
       "      <th>mark i</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark ii</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sidewinder</th>\n",
       "      <th>mark i</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark ii</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">viper</th>\n",
       "      <th>mark ii</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark iii</th>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     max_speed  shield\n",
       "cobra      mark i           12       2\n",
       "           mark ii           0       4\n",
       "sidewinder mark i           10      20\n",
       "           mark ii           1       4\n",
       "viper      mark ii           7       1\n",
       "           mark iii         16      36"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting values with a MultiIndex\n",
    "\n",
    "# A number of examples using a DataFrame with a MultiIndex\n",
    "\n",
    "tuples = [\n",
    "    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
    "    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
    "    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
    "]\n",
    "index = pd.MultiIndex.from_tuples(tuples)\n",
    "values = [[12, 2], [0, 4], [10, 20],\n",
    "          [1, 4], [7, 1], [16, 36]]\n",
    "df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mark i</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark ii</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         max_speed  shield\n",
       "mark i          12       2\n",
       "mark ii          0       4"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single label. Note this returns a DataFrame with a single index.\n",
    "\n",
    "df.loc['cobra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_speed    0\n",
       "shield       4\n",
       "Name: (cobra, mark ii), dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single index tuple. Note this returns a Series.\n",
    "\n",
    "df.loc[('cobra', 'mark ii')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_speed    12\n",
       "shield        2\n",
       "Name: (cobra, mark i), dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single label for row and column. Similar to passing in a tuple, this returns a Series.\n",
    "\n",
    "df.loc['cobra', 'mark i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobra</th>\n",
       "      <th>mark ii</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               max_speed  shield\n",
       "cobra mark ii          0       4"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single tuple. Note using [[]] returns a DataFrame.\n",
    "\n",
    "df.loc[[('cobra', 'mark ii')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single tuple for the index with a single label for the column\n",
    "\n",
    "df.loc[('cobra', 'mark i'), 'shield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cobra</th>\n",
       "      <th>mark i</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark ii</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sidewinder</th>\n",
       "      <th>mark i</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark ii</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">viper</th>\n",
       "      <th>mark ii</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark iii</th>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     max_speed  shield\n",
       "cobra      mark i           12       2\n",
       "           mark ii           0       4\n",
       "sidewinder mark i           10      20\n",
       "           mark ii           1       4\n",
       "viper      mark ii           7       1\n",
       "           mark iii         16      36"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice from index tuple to single label\n",
    "\n",
    "df.loc[('cobra', 'mark i'):'viper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max_speed</th>\n",
       "      <th>shield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cobra</th>\n",
       "      <th>mark i</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark ii</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sidewinder</th>\n",
       "      <th>mark i</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark ii</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viper</th>\n",
       "      <th>mark ii</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    max_speed  shield\n",
       "cobra      mark i          12       2\n",
       "           mark ii          0       4\n",
       "sidewinder mark i          10      20\n",
       "           mark ii          1       4\n",
       "viper      mark ii          7       1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice from index tuple to index tuple\n",
    "\n",
    "df.loc[('cobra', 'mark i'):('viper', 'mark ii')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.loc – Access a Group of Rows and Columns by Label(s)**\n",
    "\n",
    "The **`Series.loc[]`** property is used to access rows and columns in a **pandas DataFrame** or **Series** by label. It allows for more flexible and readable indexing compared to integer-based access (like `iloc`).\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.loc[row_indexer, column_indexer]\n",
    "```\n",
    "\n",
    "- **`row_indexer`**: This can be a single label, list/array of labels, slice, or boolean array.\n",
    "- **`column_indexer`**: This can also be a label, list of labels, or a slice for columns.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Allowed Inputs for `row_indexer`**\n",
    "\n",
    "- **Single label**: e.g., `'viper'` or `5` (treated as a label, not an integer position).\n",
    "- **List/array of labels**: e.g., `['viper', 'sidewinder']`.\n",
    "- **Slice object with labels**: e.g., `'cobra':'viper'` (inclusive of both start and stop).\n",
    "- **Boolean array**: Array of `True`/`False` values corresponding to rows.\n",
    "- **Boolean Series**: A Series with boolean values that align with the DataFrame's index.\n",
    "- **Callable function**: A function that returns valid output (like the above).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Allowed Inputs for `column_indexer`**\n",
    "\n",
    "- **Single label**: e.g., `'shield'`.\n",
    "- **List/array of labels**: e.g., `['shield', 'max_speed']`.\n",
    "- **Slice object**: e.g., `'shield':'max_speed'`.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Return Values**\n",
    "\n",
    "- **Series**: When selecting a single row or column.\n",
    "- **DataFrame**: When selecting multiple rows or columns.\n",
    "- **Error**: If a label doesn’t exist, a `KeyError` is raised. If there is an issue with alignment, an `IndexingError` may be raised.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Common Use Cases**\n",
    "\n",
    "- **Label-based row and column selection**\n",
    "- **Slicing rows or columns**\n",
    "- **Boolean indexing**\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Examples**\n",
    "\n",
    "#### **6.1 Accessing a Single Row**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
    "                  index=['cobra', 'viper', 'sidewinder'],\n",
    "                  columns=['max_speed', 'shield'])\n",
    "\n",
    "# Access a single row by label\n",
    "print(df.loc['viper'])\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "max_speed    4\n",
    "shield       5\n",
    "Name: viper, dtype: int64\n",
    "```\n",
    "\n",
    "#### **6.2 Accessing Multiple Rows**\n",
    "\n",
    "```python\n",
    "# Access multiple rows by labels\n",
    "print(df.loc[['viper', 'sidewinder']])\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "            max_speed  shield\n",
    "viper               4       5\n",
    "sidewinder          7       8\n",
    "```\n",
    "\n",
    "#### **6.3 Slicing Rows**\n",
    "\n",
    "```python\n",
    "# Slicing rows by labels\n",
    "print(df.loc['cobra':'viper', 'max_speed'])\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "cobra    1\n",
    "viper    4\n",
    "Name: max_speed, dtype: int64\n",
    "```\n",
    "\n",
    "#### **6.4 Boolean Indexing**\n",
    "\n",
    "```python\n",
    "# Boolean indexing for rows\n",
    "print(df.loc[[False, False, True]])\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "            max_speed  shield\n",
    "sidewinder          7       8\n",
    "```\n",
    "\n",
    "#### **6.5 Conditional Filtering**\n",
    "\n",
    "```python\n",
    "# Conditional filtering on column values\n",
    "print(df.loc[df['shield'] > 6])\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "            max_speed  shield\n",
    "sidewinder          7       8\n",
    "```\n",
    "\n",
    "#### **6.6 Setting Values**\n",
    "\n",
    "```python\n",
    "# Setting values for multiple rows\n",
    "df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "            max_speed  shield\n",
    "cobra               1       2\n",
    "viper               4      50\n",
    "sidewinder          7      50\n",
    "```\n",
    "\n",
    "#### **6.7 Setting Entire Row**\n",
    "\n",
    "```python\n",
    "# Setting an entire row\n",
    "df.loc['cobra'] = 10\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "            max_speed  shield\n",
    "cobra              10      10\n",
    "viper               4      50\n",
    "sidewinder          7      50\n",
    "```\n",
    "\n",
    "#### **6.8 Conditional Row Modification**\n",
    "\n",
    "```python\n",
    "# Conditional modification of values\n",
    "df.loc[df['shield'] > 35] = 0\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "            max_speed  shield\n",
    "cobra              10      10\n",
    "viper               0       0\n",
    "sidewinder          0       0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Notes**\n",
    "\n",
    "- **Inclusive Slicing**: Unlike regular Python slicing, both the start and stop are included in **`loc[]`** slices.\n",
    "- **Boolean Indexing**: When using boolean indexing, ensure the boolean array or Series matches the axis length.\n",
    "- **Advanced Indexing**: If you have multiple conditions or complex indexing, consider using more advanced indexing techniques.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. See Also**\n",
    "\n",
    "- **`DataFrame.at`** – Access a single value by label.\n",
    "- **`DataFrame.iloc`** – Access rows/columns by integer position.\n",
    "- **`DataFrame.xs`** – Return cross-sections from the DataFrame.\n",
    "- **`Series.iat`** – Access a single value by integer position.\n",
    "- **`Series.loc`** – Access group of values using labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>3000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a     b     c     d\n",
       "0     1     2     3     4\n",
       "1   100   200   300   400\n",
       "2  1000  2000  3000  4000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "pandas.Series.iloc\n",
    "\n",
    "\n",
    "property Series.iloc\n",
    "\n",
    "Purely integer-location based indexing for selection by position.\n",
    "\n",
    "Deprecated since version 2.2.0: Returning a tuple from a callable is deprecated.\n",
    "\n",
    ".iloc[] is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array.\n",
    "\n",
    "Allowed inputs are:\n",
    "\n",
    "An integer, e.g. 5.\n",
    "\n",
    "A list or array of integers, e.g. [4, 3, 0].\n",
    "\n",
    "A slice object with ints, e.g. 1:7.\n",
    "\n",
    "A boolean array.\n",
    "\n",
    "A callable function with one argument (the calling Series or DataFrame) and that returns valid output for indexing (one of the above). This is useful in method chains, when you don’t have a reference to the calling object, but would like to base your selection on some value.\n",
    "\n",
    "A tuple of row and column indexes. The tuple elements consist of one of the above inputs, e.g. (0, 1).\n",
    "\n",
    ".iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing (this conforms with python/numpy slice semantics).\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.iat\n",
    "Fast integer location scalar accessor.\n",
    "\n",
    "DataFrame.loc\n",
    "Purely label-location based indexer for selection by label.\n",
    "\n",
    "Series.iloc\n",
    "Purely integer-location based indexing for selection by position. \"\"\"\n",
    "\n",
    "mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
    "          {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
    "          {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000}]\n",
    "df = pd.DataFrame(mydict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (136484933.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[145], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    <class 'pandas.core.series.Series'>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Indexing just the rows\n",
    "\n",
    "# With a scalar integer.\n",
    "\n",
    "type(df.iloc[0])\n",
    "<class 'pandas.core.series.Series'>\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a list of integers.\n",
    "\n",
    "df.iloc[[0]]#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a slice object.\n",
    "\n",
    "df.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a boolean mask the same length as the index.\n",
    "\n",
    "df.iloc[[True, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a callable, useful in method chains. The x passed to the lambda is the DataFrame being sliced. This selects the rows whose index label even.\n",
    "\n",
    "df.iloc[lambda x: x.index % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing both axes\n",
    "\n",
    "# You can mix the indexer types for the index and columns. Use : to select the entire axis.\n",
    "\n",
    "# With scalar integers.\n",
    "\n",
    "df.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With lists of integers.\n",
    "\n",
    "df.iloc[[0, 2], [1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With slice objects.\n",
    "\n",
    "df.iloc[1:3, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a boolean array whose length matches the columns.\n",
    "\n",
    "df.iloc[:, [True, False, True, False]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a callable function that expects the Series or DataFrame.\n",
    "\n",
    "df.iloc[:, lambda df: [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.iloc – Integer-Location Based Indexing**\n",
    "\n",
    "The **`Series.iloc[]`** property provides integer-location based indexing for selecting values from **pandas DataFrame** or **Series** by position rather than by label. This is especially useful when you're dealing with index labels that are non-numeric or when you need to access rows and columns based on their integer positions.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Syntax**\n",
    "\n",
    "```python\n",
    "Series.iloc[row_indexer, column_indexer]\n",
    "```\n",
    "\n",
    "- **`row_indexer`**: Integer index, list/array of integers, slice, boolean array, callable function, or tuple.\n",
    "- **`column_indexer`**: Integer index, list of integers, slice, or boolean array for column selection.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Allowed Inputs for `row_indexer`**\n",
    "\n",
    "- **Integer**: e.g., `0`, `1`, etc. (for single row).\n",
    "- **List/array of integers**: e.g., `[0, 1, 2]` (for multiple rows).\n",
    "- **Slice object**: e.g., `1:5` (slicing rows between positions 1 and 5).\n",
    "- **Boolean array**: e.g., `[True, False, True]` (matching the index length).\n",
    "- **Callable function**: A function that returns a valid indexer (like a lambda) that operates on the DataFrame/Series.\n",
    "- **Tuple of row and column indexers**: e.g., `(0, 1)` for selecting a specific value.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Allowed Inputs for `column_indexer`**\n",
    "\n",
    "- **Integer**: Single column by its integer position.\n",
    "- **List/array of integers**: Select multiple columns by their integer positions.\n",
    "- **Slice object**: Select a range of columns.\n",
    "- **Boolean array**: Select columns based on a boolean mask.\n",
    "- **Callable function**: Apply a function to the columns to determine which to select.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Return Values**\n",
    "\n",
    "- **Series**: When selecting a single row or column.\n",
    "- **DataFrame**: When selecting multiple rows and/or columns.\n",
    "- **Scalar value**: When selecting a specific value.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Examples**\n",
    "\n",
    "#### **5.1 Indexing Rows**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
    "          {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
    "          {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000}]\n",
    "df = pd.DataFrame(mydict)\n",
    "\n",
    "# Access a single row by position\n",
    "print(df.iloc[0])  # First row\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     1\n",
    "b     2\n",
    "c     3\n",
    "d     4\n",
    "Name: 0, dtype: int64\n",
    "```\n",
    "\n",
    "#### **5.2 Indexing Multiple Rows**\n",
    "\n",
    "```python\n",
    "# Access multiple rows\n",
    "print(df.iloc[[0, 1]])  # First and second rows\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     a    b    c    d\n",
    "0    1    2    3    4\n",
    "1  100  200  300  400\n",
    "```\n",
    "\n",
    "#### **5.3 Slicing Rows**\n",
    "\n",
    "```python\n",
    "# Access a slice of rows (first three rows)\n",
    "print(df.iloc[:3])\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     a     b     c     d\n",
    "0    1     2     3     4\n",
    "1  100   200   300   400\n",
    "2  1000  2000  3000  4000\n",
    "```\n",
    "\n",
    "#### **5.4 Boolean Masking**\n",
    "\n",
    "```python\n",
    "# Use boolean array to filter rows\n",
    "print(df.iloc[[True, False, True]])  # Selects first and third rows\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     a     b     c     d\n",
    "0    1     2     3     4\n",
    "2  1000  2000  3000  4000\n",
    "```\n",
    "\n",
    "#### **5.5 Using Callable Function**\n",
    "\n",
    "```python\n",
    "# Select rows whose index is even using a lambda function\n",
    "print(df.iloc[lambda x: x.index % 2 == 0])\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     a     b     c     d\n",
    "0    1     2     3     4\n",
    "2  1000  2000  3000  4000\n",
    "```\n",
    "\n",
    "#### **5.6 Indexing Both Rows and Columns**\n",
    "\n",
    "```python\n",
    "# Select specific row and column (row 0, column 1)\n",
    "print(df.iloc[0, 1])  # First row, second column\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "2\n",
    "```\n",
    "\n",
    "#### **5.7 Indexing Multiple Rows and Columns**\n",
    "\n",
    "```python\n",
    "# Select multiple rows and columns\n",
    "print(df.iloc[[0, 2], [1, 3]])  # First and third rows, second and fourth columns\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     b     d\n",
    "0    2     4\n",
    "2  2000  4000\n",
    "```\n",
    "\n",
    "#### **5.8 Slicing Rows and Columns**\n",
    "\n",
    "```python\n",
    "# Slice rows and columns\n",
    "print(df.iloc[1:3, 0:3])  # Rows 1-2 and columns 0-2\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     a     b     c\n",
    "1  100   200   300\n",
    "2  1000  2000  3000\n",
    "```\n",
    "\n",
    "#### **5.9 Using Boolean Mask for Columns**\n",
    "\n",
    "```python\n",
    "# Boolean indexing for columns\n",
    "print(df.iloc[:, [True, False, True, False]])  # Selects columns 0 and 2\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     a     c\n",
    "0    1     3\n",
    "1  100   300\n",
    "2  1000  3000\n",
    "```\n",
    "\n",
    "#### **5.10 Callable Function for Column Selection**\n",
    "\n",
    "```python\n",
    "# Use callable function to select columns based on function result\n",
    "print(df.iloc[:, lambda df: [0, 2]])  # Select first and third columns\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     a     c\n",
    "0    1     3\n",
    "1  100   300\n",
    "2  1000  3000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Notes**\n",
    "\n",
    "- **Out-of-bounds Handling**: Using out-of-bounds indices (like `df.iloc[5]` on a DataFrame with 5 rows) will raise an **IndexError**. However, slicing allows for out-of-bounds indices and will not throw an error.\n",
    "- **Boolean Indexing**: For boolean indexing, ensure the boolean array or Series matches the length of the axis you're indexing.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. See Also**\n",
    "\n",
    "- **`DataFrame.iat`** – Fast scalar integer location access.\n",
    "- **`DataFrame.loc`** – Label-based indexer for rows and columns.\n",
    "- **`Series.loc`** – Access group of values using labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.__iter__\n",
    "\n",
    "Series.__iter__()\n",
    "\n",
    "Return an iterator of the values.\n",
    "\n",
    "These are each a scalar type, which is a Python scalar (for str, int, float) or a pandas scalar (for Timestamp/Timedelta/Interval/Period)\n",
    "\n",
    "Returns :\n",
    "iterator \n",
    "\"\"\"\n",
    "s = pd.Series([1, 2, 3])\n",
    "for x in s:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.**iter** – Iterator for Values**\n",
    "\n",
    "The **`Series.__iter__()`** method allows iteration over the values of a **pandas Series**. This function returns an iterator that allows you to loop over the Series in a for loop or other iterative constructs. Each value returned by the iterator is a scalar, either a standard Python scalar (such as `int`, `float`, or `str`) or a **pandas scalar** (e.g., `Timestamp`, `Timedelta`, `Period`, or `Interval`).\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.__iter__()\n",
    "```\n",
    "\n",
    "- This method doesn't take any arguments and returns an iterator that can be used to loop through the values of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Simple Iteration over a Series**\n",
    "\n",
    "You can loop through the values of the Series just like you would with any iterable object in Python.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# Iterate over the Series\n",
    "for x in s:\n",
    "    print(x)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1\n",
    "2\n",
    "3\n",
    "```\n",
    "\n",
    "#### **2. Iterating over a Series of Strings**\n",
    "\n",
    "```python\n",
    "# Create a Series of strings\n",
    "s = pd.Series(['apple', 'banana', 'cherry'])\n",
    "\n",
    "# Iterate over the Series\n",
    "for x in s:\n",
    "    print(x)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "apple\n",
    "banana\n",
    "cherry\n",
    "```\n",
    "\n",
    "#### **3. Iterating over a Series of Timestamps**\n",
    "\n",
    "```python\n",
    "# Create a Series of Timestamps\n",
    "s = pd.Series(pd.date_range('2023-01-01', periods=3))\n",
    "\n",
    "# Iterate over the Series\n",
    "for x in s:\n",
    "    print(x)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "2023-01-01 00:00:00\n",
    "2023-01-02 00:00:00\n",
    "2023-01-03 00:00:00\n",
    "```\n",
    "\n",
    "#### **4. Iterating over a Series with Mixed Data Types**\n",
    "\n",
    "```python\n",
    "# Create a Series with mixed data types\n",
    "s = pd.Series([1, 'banana', 3.14, pd.Timestamp('2023-01-01')])\n",
    "\n",
    "# Iterate over the Series\n",
    "for x in s:\n",
    "    print(x)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1\n",
    "banana\n",
    "3.14\n",
    "2023-01-01 00:00:00\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Notes**\n",
    "\n",
    "- **Python Scalars**: Scalars like `int`, `float`, and `str` are returned during iteration.\n",
    "- **Pandas Scalars**: Types like `Timestamp`, `Timedelta`, `Period`, and `Interval` are also returned for datetime or time-related Series.\n",
    "- The **`Series.__iter__()`** method is automatically invoked when using a `for` loop directly on the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. See Also**\n",
    "\n",
    "- **`pandas.Series.iteritems()`**: Another iteration method, returns an iterator yielding pairs of index and value.\n",
    "- **`pandas.Series.values`**: Returns an array of the values in the Series, useful when needing to use the values outside of iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pandas in c:\\users\\user\\onedrive\\desktop\\python\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\onedrive\\desktop\\python\\.venv\\lib\\site-packages (from Pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\onedrive\\desktop\\python\\.venv\\lib\\site-packages (from Pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\onedrive\\desktop\\python\\.venv\\lib\\site-packages (from Pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\onedrive\\desktop\\python\\.venv\\lib\\site-packages (from Pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\onedrive\\desktop\\python\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->Pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\onedrive\\desktop\\python\\.venv\\lib\\site-packages (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install Pandas\n",
    "! pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.items\n",
    "\n",
    "\n",
    "Series.items()\n",
    "\n",
    "Lazily iterate over (index, value) tuples.\n",
    "\n",
    "This method returns an iterable tuple (index, value). This is convenient if you want to create a lazy iterator.\n",
    "\n",
    "Returns :\n",
    "      iterable\n",
    "      Iterable of tuples containing the (index, value) pairs from a Series.\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.items\n",
    "Iterate over (column name, Series) pairs.\n",
    "\n",
    "DataFrame.iterrows\n",
    "Iterate over DataFrame rows as (index, Series) pairs. \n",
    "\n",
    "\"\"\"\n",
    "! pip install pandas\n",
    "import pandas as pd\n",
    "s = pd.Series(['A', 'B', 'C'])\n",
    "for index, value in s.items():\n",
    "    print(f\"Index : {index}, Value : {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.items – Lazily Iterate Over (Index, Value) Pairs**\n",
    "\n",
    "The **`Series.items()`** method in **pandas** allows you to lazily iterate over a **Series** by returning an iterable of `(index, value)` tuples. This method is useful when you want both the **index** and the **value** of each element in the Series, and it's efficient in cases where you don't want to load the entire Series into memory at once.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.items()\n",
    "```\n",
    "\n",
    "- This method returns an **iterable** of tuples where each tuple contains:\n",
    "  - The **index** of the element.\n",
    "  - The **value** at that index in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Simple Iteration Over Index and Value**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series(['A', 'B', 'C'])\n",
    "\n",
    "# Iterate over the Series using items()\n",
    "for index, value in s.items():\n",
    "    print(f\"Index : {index}, Value : {value}\")\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Index : 0, Value : A\n",
    "Index : 1, Value : B\n",
    "Index : 2, Value : C\n",
    "```\n",
    "\n",
    "#### **2. Iterating Over a Series of Integers**\n",
    "\n",
    "```python\n",
    "# Create a Series of integers\n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# Iterate over the Series using items()\n",
    "for index, value in s.items():\n",
    "    print(f\"Index : {index}, Value : {value}\")\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Index : 0, Value : 1\n",
    "Index : 1, Value : 2\n",
    "Index : 2, Value : 3\n",
    "```\n",
    "\n",
    "#### **3. Iterating Over a Series with Mixed Data Types**\n",
    "\n",
    "```python\n",
    "# Create a Series with mixed types\n",
    "s = pd.Series([100, 'apple', 3.14])\n",
    "\n",
    "# Iterate over the Series using items()\n",
    "for index, value in s.items():\n",
    "    print(f\"Index : {index}, Value : {value}\")\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Index : 0, Value : 100\n",
    "Index : 1, Value : apple\n",
    "Index : 2, Value : 3.14\n",
    "```\n",
    "\n",
    "#### **4. Using items() with a Custom Index**\n",
    "\n",
    "```python\n",
    "# Create a Series with a custom index\n",
    "s = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "\n",
    "# Iterate over the Series using items()\n",
    "for index, value in s.items():\n",
    "    print(f\"Index : {index}, Value : {value}\")\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Index : a, Value : 10\n",
    "Index : b, Value : 20\n",
    "Index : c, Value : 30\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Notes**\n",
    "\n",
    "- The **`items()`** method returns an iterator, making it **memory efficient** compared to converting the entire Series into a list or array.\n",
    "- This is especially useful in cases where you need both **index** and **value** for operations like transformation or conditional processing.\n",
    "\n",
    "### **6. See Also**\n",
    "\n",
    "- **`Series.iteritems()`**: Similar to **`items()`**, but **`items()`** is the preferred method for iterating over index-value pairs.\n",
    "- **`DataFrame.items()`**: Allows iteration over a DataFrame's column name and its corresponding Series.\n",
    "- **`DataFrame.iterrows()`**: Iterates over DataFrame rows, returning a pair of index and Series for each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2], dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "pandas.Series.keys\n",
    "\n",
    "Series.keys()\n",
    "\n",
    "Return alias for index.\n",
    "\n",
    "Returns :\n",
    "      Index\n",
    "      \n",
    "Index of the Series. \"\"\"\n",
    "s = pd.Series([1, 2, 3], index=[0, 1, 2])\n",
    "s.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.keys – Alias for Index**\n",
    "\n",
    "The **`Series.keys()`** method is an alias for the **`index`** of a **pandas Series**. It returns the **Index** of the Series, which essentially gives you the labels or positions of the elements.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.keys()\n",
    "```\n",
    "\n",
    "- This method returns the **Index** object of the Series, which contains the labels for the Series elements.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Example with Default Integer Index**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series with default integer index\n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# Get the keys (index) of the Series\n",
    "print(s.keys())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "RangeIndex(start=0, stop=3, step=1)\n",
    "```\n",
    "\n",
    "#### **2. Example with Custom Index**\n",
    "\n",
    "```python\n",
    "# Create a Series with a custom index\n",
    "s = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "\n",
    "# Get the keys (index) of the Series\n",
    "print(s.keys())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Index(['a', 'b', 'c'], dtype='object')\n",
    "```\n",
    "\n",
    "#### **3. Example with Mixed Data Types**\n",
    "\n",
    "```python\n",
    "# Create a Series with mixed data types\n",
    "s = pd.Series([100, 'apple', 3.14], index=[1, 2, 3])\n",
    "\n",
    "# Get the keys (index) of the Series\n",
    "print(s.keys())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Index([1, 2, 3], dtype='int64')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Notes**\n",
    "\n",
    "- The **`keys()`** method is functionally identical to **`index`** in terms of the output. It's a shorthand alias for accessing the index.\n",
    "- It can be particularly useful in situations where you want to access the index in a more semantic or intuitive way.\n",
    "\n",
    "### **5. See Also**\n",
    "\n",
    "- **`Series.index`**: Direct access to the index of the Series, same as **`keys()`**.\n",
    "- **`DataFrame.keys()`**: Iterates over the column names of a DataFrame, similarly to how **`keys()`** works for a Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.pop\n",
    "\n",
    "\n",
    "Series.pop(item)\n",
    "\n",
    "\n",
    "Return item and drops from series. Raise KeyError if not found.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "item:   label\n",
    "Index of the element that needs to be removed.\n",
    "\n",
    "Returns :\n",
    "Value that is popped from series. \n",
    "\"\"\"\n",
    "ser = pd.Series([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "pandas.Series.item\n",
    "\n",
    "Series.item() \n",
    "\n",
    "Return the first element of the underlying data as a Python scalar.\n",
    "\n",
    "Returns :\n",
    "\n",
    "    scalar\n",
    "    The first element of Series or Index.\n",
    "\n",
    "Raises :\n",
    "        ValueError\n",
    "If the data is not length = 1.  \n",
    "\"\"\"\n",
    "s = pd.Series([1])\n",
    "s.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1], index=['a'])\n",
    "s.index.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "pandas.Series.xs\n",
    "\n",
    "Series.xs(key, axis=0, level=None, drop_level=True)[source]\n",
    "Return cross-section from the Series/DataFrame.\n",
    "\n",
    "This method takes a key argument to select data at a particular level of a MultiIndex.\n",
    "\n",
    "Parameters :\n",
    "      key:\n",
    "      label or tuple of label\n",
    "      Label contained in the index, or partially in a MultiIndex.\n",
    "\n",
    "axis :\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Axis to retrieve cross-section on.\n",
    "\n",
    "level :\n",
    "object, defaults to first n levels (n=1 or len(key))\n",
    "In case of a key partially contained in a MultiIndex, indicate which levels are used. Levels can be referred by label or position.\n",
    "\n",
    "drop_level: \n",
    "bool, default True\n",
    "If False, returns object with same levels as self.\n",
    "\n",
    "Returns :\n",
    "\n",
    "Series or DataFrame: \n",
    "      Cross-section from the original Series or DataFrame corresponding to the selected index levels.\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.loc\n",
    "Access a group of rows and columns by label(s) or a boolean array.\n",
    "\n",
    "DataFrame.iloc\n",
    "Purely integer-location based indexing for selection by position. \"\"\"\n",
    "\n",
    "d = {'num_legs': [4, 4, 2, 2],\n",
    "     'num_wings': [0, 0, 2, 2],\n",
    "     'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
    "     'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
    "     'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.set_index(['class', 'animal', 'locomotion'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.xs – Cross-section from a Series**\n",
    "\n",
    "The **`Series.xs()`** method is used to extract a cross-section from a Series or DataFrame. It is particularly useful when working with **MultiIndex** data, as it allows you to select data from specific levels of the index.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.xs(key, axis=0, level=None, drop_level=True)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **key**: `label` or `tuple of labels`\n",
    "\n",
    "  - The label or tuple of labels to select the data at the corresponding level(s) of the index. This is the value you want to cross-section at.\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "  - The axis to retrieve the cross-section on:\n",
    "    - `0` (or `'index'`): Works on the row index.\n",
    "    - `1` (or `'columns'`): Works on the columns (for DataFrames).\n",
    "\n",
    "- **level**: `object`, default `None`\n",
    "\n",
    "  - Specifies which level(s) of the index to use if `key` is only partially contained in a **MultiIndex**. You can refer to levels by name or position.\n",
    "\n",
    "- **drop_level**: `bool`, default `True`\n",
    "  - Whether to drop the level(s) of the index that are selected. If `True`, the resulting DataFrame or Series will have one fewer level. If `False`, it retains all levels.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series** or **DataFrame**: A Series or DataFrame corresponding to the selected index levels, depending on whether the **axis** is `0` or `1`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Example with MultiIndex**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with MultiIndex\n",
    "data = {\n",
    "    'num_legs': [4, 4, 2, 2],\n",
    "    'num_wings': [0, 0, 2, 2],\n",
    "    'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
    "    'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
    "    'locomotion': ['walks', 'walks', 'flies', 'walks']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index(['class', 'animal', 'locomotion'])\n",
    "\n",
    "# View the DataFrame\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "                           num_legs  num_wings\n",
    "class  animal  locomotion\n",
    "mammal cat     walks              4          0\n",
    "       dog     walks              4          0\n",
    "       bat     flies              2          2\n",
    "bird   penguin walks              2          2\n",
    "```\n",
    "\n",
    "#### **2. Get Values at a Specific Index (Single Level)**\n",
    "\n",
    "```python\n",
    "# Get all rows where the class is 'mammal'\n",
    "mammal_data = df.xs('mammal')\n",
    "print(mammal_data)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "                   num_legs  num_wings\n",
    "animal locomotion\n",
    "cat    walks              4          0\n",
    "dog    walks              4          0\n",
    "bat    flies              2          2\n",
    "```\n",
    "\n",
    "#### **3. Get Values at Multiple Index Levels (Tuple)**\n",
    "\n",
    "```python\n",
    "# Get values for 'mammal', 'dog', and 'walks'\n",
    "specific_data = df.xs(('mammal', 'dog', 'walks'))\n",
    "print(specific_data)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "num_legs     4\n",
    "num_wings    0\n",
    "Name: (mammal, dog, walks), dtype: int64\n",
    "```\n",
    "\n",
    "#### **4. Get Values at a Specific Level**\n",
    "\n",
    "```python\n",
    "# Get values for the 'cat' at level 1 (animal)\n",
    "cat_data = df.xs('cat', level=1)\n",
    "print(cat_data)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "                   num_legs  num_wings\n",
    "class  locomotion\n",
    "mammal walks              4          0\n",
    "```\n",
    "\n",
    "#### **5. Get Values at Multiple Levels**\n",
    "\n",
    "```python\n",
    "# Get values for 'bird' and 'walks' at levels 0 and 'locomotion'\n",
    "bird_walks_data = df.xs(('bird', 'walks'), level=[0, 'locomotion'])\n",
    "print(bird_walks_data)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "num_legs  num_wings\n",
    "animal\n",
    "penguin         2          2\n",
    "```\n",
    "\n",
    "#### **6. Get Values at a Specific Column (axis=1)**\n",
    "\n",
    "```python\n",
    "# Get values for 'num_wings' column across all rows\n",
    "num_wings_data = df.xs('num_wings', axis=1)\n",
    "print(num_wings_data)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "class   animal   locomotion\n",
    "mammal  cat      walks         0\n",
    "        dog      walks         0\n",
    "        bat      flies         2\n",
    "bird    penguin  walks         2\n",
    "Name: num_wings, dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`DataFrame.loc`**: Select rows and columns by label(s) or boolean array.\n",
    "- **`DataFrame.iloc`**: Purely integer-location based indexing for selection by position.\n",
    "\n",
    "This method is especially powerful when working with **MultiIndex** data, providing a flexible way to select cross-sections of your dataset based on different index levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values at specified index\n",
    "\n",
    "df.xs('mammal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values at several indexes\n",
    "\n",
    "df.xs(('mammal', 'dog', 'walks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values at specified index and level\n",
    "\n",
    "df.xs('cat', level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values at several indexes and levels\n",
    "\n",
    "df.xs(('bird', 'walks'),\n",
    "      level=[0, 'locomotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values at specified column and axis\n",
    "\n",
    "df.xs('num_wings', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "pandas.Series.add\n",
    "\n",
    "\n",
    "Series.add(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Addition of series and other, element-wise (binary operator add).\n",
    "\n",
    "Equivalent to series + other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Paramaters :\n",
    "\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "\n",
    "level :\n",
    "int or name\n",
    "\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value :\n",
    "\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "Series.radd\n",
    "Reverse of the Addition operator, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.add – Addition of Series and Other**\n",
    "\n",
    "The **`Series.add()`** method is used to add two Series or a Series and a scalar element-wise. It is essentially the same as using the `+` operator but with additional support for handling missing values (`NaN`) through the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.add(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The other Series or scalar value to add to the calling Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Used to broadcast across a level in a MultiIndex. If the Series have MultiIndexes, the operation aligns the data along the specified level.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - This value will replace missing values (`NaN`) in either the calling Series or the `other` Series before performing the addition. If both Series have missing values at the same location, the result will also be missing unless a `fill_value` is provided.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but kept for compatibility with DataFrame operations.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of adding the two Series element-wise.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Example**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating two Series with some NaN values\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "\n",
    "# Adding two Series with a fill_value for missing data\n",
    "result = a.add(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    2.0\n",
    "b    1.0\n",
    "c    1.0\n",
    "d    1.0\n",
    "e    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this example, `NaN` values are replaced with `0` during the addition, resulting in the sum of `1 + 1 = 2` for index `'a'`, and so on.\n",
    "\n",
    "#### **2. Handling Missing Values with `fill_value`**\n",
    "\n",
    "```python\n",
    "# Another example with NaN values in both Series\n",
    "a = pd.Series([np.nan, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([1, np.nan, 4], index=['a', 'b', 'c'])\n",
    "\n",
    "# Add them with fill_value for NaNs\n",
    "result = a.add(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    1.0\n",
    "b    2.0\n",
    "c    7.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this case, `NaN` in `a` and `b` are treated as `0`, so the result is the sum of `0 + 1 = 1` for `'a'`, `2 + 0 = 2` for `'b'`, and `3 + 4 = 7` for `'c'`.\n",
    "\n",
    "#### **3. Addition with Scalar**\n",
    "\n",
    "```python\n",
    "# Adding a scalar value to a Series\n",
    "a = pd.Series([1, 2, 3])\n",
    "result = a.add(5)  # Adding 5 to each element\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    6\n",
    "1    7\n",
    "2    8\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here, each element of the Series is added to the scalar value `5`, producing the result `[6, 7, 8]`.\n",
    "\n",
    "#### **4. Addition with MultiIndex**\n",
    "\n",
    "```python\n",
    "# Creating MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "\n",
    "index2 = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 4)], names=['letter', 'number'])\n",
    "b = pd.Series([4, 5, 6], index=index2)\n",
    "\n",
    "# Add them with fill_value for unmatched indexes\n",
    "result = a.add(b, level='number', fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         5.0\n",
    "b       2         7.0\n",
    "c       3         3.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "The addition is performed at the `'number'` level of the index, with missing values filled by `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.radd()`**: Reverse of the addition operator, useful for implementing custom addition behavior.\n",
    "\n",
    "This method is a powerful tool when performing element-wise addition between Series, especially with missing values or when using a **MultiIndex**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.sub\n",
    "\n",
    "\n",
    "Series.sub(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Subtraction of series and other, element-wise (binary operator sub).\n",
    "\n",
    "Equivalent to series - other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "level:\n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value:\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "\n",
    "Series.rsub\n",
    "Reverse of the Subtraction operator, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.subtract(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.sub – Subtraction of Series (Element-wise)**\n",
    "\n",
    "The **`Series.sub()`** method performs element-wise subtraction between a **pandas Series** and another **Series** or a scalar value. It is equivalent to using the **`-`** (minus) operator, but it provides extra functionality, such as filling missing values with a specified value during the operation.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.sub(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or scalar value\n",
    "  - The other Series or scalar value to subtract from the current Series.\n",
    "- **level**: `int` or `str`, default `None`\n",
    "\n",
    "  - Used when the Series has a MultiIndex. If specified, the operation will broadcast across the level and match the index values at that level.\n",
    "\n",
    "- **fill_value**: `None` or `float`, default `None`\n",
    "\n",
    "  - A value to substitute for missing (NaN) data during the subtraction. If missing data is encountered in one or both Series, this value will be used instead of NaN during the computation.\n",
    "  - If **both** Series have missing data for the corresponding index, the result will be NaN.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, default `0`\n",
    "  - Unused, but kept for compatibility with DataFrame operations.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A new Series containing the result of the subtraction.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Example of Subtraction**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create two Series\n",
    "a = pd.Series([5, 10, 15], index=['x', 'y', 'z'])\n",
    "b = pd.Series([1, 2, 3], index=['x', 'y', 'z'])\n",
    "\n",
    "# Subtract Series b from Series a\n",
    "result = a.sub(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "x    4\n",
    "y    8\n",
    "z    12\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### **2. Using `fill_value` for Missing Data**\n",
    "\n",
    "```python\n",
    "# Create two Series with missing values\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "\n",
    "# Subtract b from a, filling missing values with 0\n",
    "result = a.sub(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    0.0\n",
    "b    1.0\n",
    "c    1.0\n",
    "d   -1.0\n",
    "e    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this case:\n",
    "\n",
    "- The missing value in **`a`** (at index `'d'`) is filled with `0`, and the result becomes **`-1.0`**.\n",
    "- The missing value in **`b`** (at index `'b'`) is also filled with `0`, and the result becomes **`1.0`**.\n",
    "\n",
    "#### **3. Using `level` with MultiIndex**\n",
    "\n",
    "```python\n",
    "# Create Series with MultiIndex\n",
    "index = pd.MultiIndex.from_tuples([('A', 1), ('A', 2), ('B', 1)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "b = pd.Series([0, 1, 4], index=index)\n",
    "\n",
    "# Subtract b from a across a specific level (e.g., 'letter')\n",
    "result = a.sub(b, level='letter')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "A       1         1\n",
    "        2         1\n",
    "B       1        -1\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "The operation is performed across the 'letter' level of the MultiIndex, and the values are aligned and subtracted accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. See Also**\n",
    "\n",
    "- **`Series.rsub()`**: The reverse of subtraction (`other - series`).\n",
    "- **`DataFrame.sub()`**: Subtraction between DataFrames, handling missing values and broadcasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.mul\n",
    "\n",
    "\n",
    "Series.mul(other, level=None, fill_value=None, axis=0)\n",
    "\n",
    "\n",
    "Return Multiplication of series and other, element-wise (binary operator mul).\n",
    "\n",
    "Equivalent to series * other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "\n",
    "other: \n",
    "\n",
    "Series or scalar value\n",
    "\n",
    "level: \n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value: \n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "Series\n",
    "The result of the operation. \"\"\"\n",
    "\n",
    "\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.multiply(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.mul – Element-wise Multiplication of Series and Other**\n",
    "\n",
    "The **`Series.mul()`** method is used for element-wise multiplication of two Series (or a Series and a scalar). It operates like the `*` operator but adds functionality to handle missing values (`NaN`) using the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.mul(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The other Series or scalar value to multiply with the calling Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Used to broadcast the operation across a specific level in a MultiIndex, ensuring the multiplication aligns along the given index.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - This value replaces missing values (`NaN`) in either Series before performing the multiplication. If both Series have `NaN` at the same position, the result will be `NaN` unless a `fill_value` is provided.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but included for DataFrame compatibility.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of multiplying the Series element-wise.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Example**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating two Series with NaN values\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "\n",
    "# Multiply two Series with fill_value for missing data\n",
    "result = a.mul(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    1.0\n",
    "b    0.0\n",
    "c    0.0\n",
    "d    0.0\n",
    "e    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here, missing values (`NaN`) are replaced with `0` during the multiplication, resulting in `1 * 1 = 1` for `'a'`, `1 * NaN = 0` for `'b'`, and so on.\n",
    "\n",
    "#### **2. Handling Missing Values with `fill_value`**\n",
    "\n",
    "```python\n",
    "# Another example with missing values in both Series\n",
    "a = pd.Series([np.nan, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([1, np.nan, 4], index=['a', 'b', 'c'])\n",
    "\n",
    "# Multiply them with a fill_value for NaNs\n",
    "result = a.mul(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    0.0\n",
    "b    0.0\n",
    "c    12.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "The missing value at index `'a'` in `a` is replaced by `0`, and similarly, `b`'s missing value at `'b'` is replaced by `0`, so the multiplication results in `0 * 1 = 0` and `2 * 0 = 0`. For `'c'`, both values are present, so the result is `3 * 4 = 12`.\n",
    "\n",
    "#### **3. Multiplication with Scalar**\n",
    "\n",
    "```python\n",
    "# Multiplying a Series by a scalar value\n",
    "a = pd.Series([1, 2, 3])\n",
    "result = a.mul(3)  # Multiplying each element by 3\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0     3\n",
    "1     6\n",
    "2     9\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Each element of the Series is multiplied by `3`, resulting in `[3, 6, 9]`.\n",
    "\n",
    "#### **4. Multiplying with MultiIndex**\n",
    "\n",
    "```python\n",
    "# Creating MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "\n",
    "index2 = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 4)], names=['letter', 'number'])\n",
    "b = pd.Series([4, 5, 6], index=index2)\n",
    "\n",
    "# Multiply Series with a MultiIndex using fill_value\n",
    "result = a.mul(b, level='number', fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         4.0\n",
    "b       2        10.0\n",
    "c       3         0.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "The multiplication is performed based on the `'number'` level of the MultiIndex, filling missing values with `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.rmul()`**: Reverse of the multiplication operator, used when you want the multiplication order to be swapped.\n",
    "\n",
    "This method allows for flexible element-wise multiplication, with powerful handling for missing data. You can perform multiplication with both scalar values and Series, including those with MultiIndex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.div\n",
    "\n",
    "Series.div(other, level=None, fill_value=None, axis=0)\n",
    "\n",
    "Return Floating division of series and other, element-wise (binary operator truediv).\n",
    "\n",
    "Equivalent to series / other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "level: \n",
    "\n",
    "int or name\n",
    "\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value: \n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "      Series\n",
    "The result of the operation. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.divide(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.truediv\n",
    "Series.truediv(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Floating division of series and other, element-wise (binary operator truediv).\n",
    "\n",
    "Equivalent to series / other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "\n",
    "other: \n",
    "Series or scalar value\n",
    "\n",
    "level: \n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value : \n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "\n",
    "Series.rtruediv\n",
    "Reverse of the Floating division operator, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.divide(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.truediv – Element-wise Floating Division of Series and Other**\n",
    "\n",
    "The **`Series.truediv()`** method is used for element-wise division of two Series (or a Series and a scalar). It operates like the `/` operator but adds functionality to handle missing values (`NaN`) using the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.truediv(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The other Series or scalar value to divide the calling Series by.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Used to broadcast the division across a specific level in a MultiIndex.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - This value replaces missing values (`NaN`) in either Series before performing the division. If both Series have `NaN` at the same position, the result will be `NaN` unless a `fill_value` is provided.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but included for DataFrame compatibility.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of dividing the Series element-wise.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Example**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating two Series with NaN values\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "\n",
    "# Perform floating division of the two Series with fill_value for missing data\n",
    "result = a.truediv(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    1.0\n",
    "b    0.0\n",
    "c    1.0\n",
    "d    NaN\n",
    "e    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here, missing values (`NaN`) are replaced with `0` before the division. So, `1 / 1 = 1`, `1 / NaN = 0`, and `1 / 0 = infinity` for the appropriate cases.\n",
    "\n",
    "#### **2. Division with Scalar**\n",
    "\n",
    "```python\n",
    "# Dividing a Series by a scalar value\n",
    "a = pd.Series([1, 2, 3])\n",
    "result = a.truediv(3)  # Dividing each element by 3\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    0.333333\n",
    "1    0.666667\n",
    "2    1.000000\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Each element of the Series is divided by `3`, resulting in `[1/3, 2/3, 3/3]`.\n",
    "\n",
    "#### **3. Handling Missing Values with `fill_value`**\n",
    "\n",
    "```python\n",
    "# Example with missing values in both Series\n",
    "a = pd.Series([np.nan, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([1, np.nan, 4], index=['a', 'b', 'c'])\n",
    "\n",
    "# Perform division with a fill_value\n",
    "result = a.truediv(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    0.0\n",
    "b    0.0\n",
    "c    0.75\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "The missing value at index `'a'` in `a` is replaced by `0`, and similarly, `b`'s missing value at `'b'` is replaced by `0`, so the division results in `NaN / 1 = 0`, `2 / NaN = 0`, and `3 / 4 = 0.75`.\n",
    "\n",
    "#### **4. Division with MultiIndex**\n",
    "\n",
    "```python\n",
    "# Creating MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "\n",
    "index2 = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 4)], names=['letter', 'number'])\n",
    "b = pd.Series([4, 5, 6], index=index2)\n",
    "\n",
    "# Divide Series with a MultiIndex using fill_value\n",
    "result = a.truediv(b, level='number', fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         0.25\n",
    "b       2         0.40\n",
    "c       3         NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "The division is performed based on the `'number'` level of the MultiIndex, filling missing values with `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.rtruediv()`**: Reverse of the floating division operator.\n",
    "\n",
    "The `truediv()` method is useful for handling element-wise division while accounting for missing values and supporting MultiIndex operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.floordiv\n",
    "\n",
    "Series.floordiv(other, level=None, fill_value=None, axis=0)\n",
    "\n",
    "\n",
    "Return Integer division of series and other, element-wise (binary operator floordiv).\n",
    "\n",
    "Equivalent to series // other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "level:\n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value: \n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns:\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "\n",
    "Series.rfloordiv\n",
    "Reverse of the Integer division operator, see Python documentation for more details \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.floordiv(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.floordiv – Element-wise Integer Division of Series and Other**\n",
    "\n",
    "The **`Series.floordiv()`** method is used for element-wise integer division between two Series (or a Series and a scalar). It behaves similarly to the `//` operator in Python, and it supports the **`fill_value`** parameter to handle missing (`NaN`) values in the Series.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.floordiv(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The other Series or scalar value to divide the calling Series by.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Specifies which level of a MultiIndex to use when broadcasting the division.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Used to replace missing values (`NaN`) before performing the division. If both Series contain `NaN` values at the same location, the result will be `NaN` unless a `fill_value` is provided.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but included for DataFrame compatibility.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the integer division (floored).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Example**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating two Series with NaN values\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "\n",
    "# Perform integer division with fill_value for missing data\n",
    "result = a.floordiv(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    1.0\n",
    "b    inf\n",
    "c    inf\n",
    "d    0.0\n",
    "e    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this case:\n",
    "\n",
    "- `1 // 1 = 1`\n",
    "- `1 // NaN = inf` (infinity) because the second series has a missing value.\n",
    "- `1 // 0 = inf` because division by zero returns infinity.\n",
    "- For `NaN // NaN`, the result is `NaN`.\n",
    "\n",
    "#### **2. Integer Division with Scalar**\n",
    "\n",
    "```python\n",
    "# Dividing a Series by a scalar value using floor division\n",
    "a = pd.Series([10, 20, 30])\n",
    "result = a.floordiv(3)  # Floor division by 3\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0     3\n",
    "1     6\n",
    "2    10\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Each element of the Series is divided by `3` and floored (rounded down to the nearest integer).\n",
    "\n",
    "#### **3. Handling Missing Values with `fill_value`**\n",
    "\n",
    "```python\n",
    "# Example with missing values\n",
    "a = pd.Series([np.nan, 20, 30], index=['a', 'b', 'c'])\n",
    "b = pd.Series([1, np.nan, 4], index=['a', 'b', 'c'])\n",
    "\n",
    "# Perform floor division with a fill_value\n",
    "result = a.floordiv(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    0.0\n",
    "b    inf\n",
    "c    7.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `NaN // 1 = 0` because `fill_value` is `0` for the missing value in `a`.\n",
    "- `20 // NaN = inf` because `b` has a missing value.\n",
    "- `30 // 4 = 7`.\n",
    "\n",
    "#### **4. Integer Division with MultiIndex**\n",
    "\n",
    "```python\n",
    "# Creating MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([10, 20, 30], index=index)\n",
    "\n",
    "index2 = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 4)], names=['letter', 'number'])\n",
    "b = pd.Series([1, 5, 6], index=index2)\n",
    "\n",
    "# Perform floor division with MultiIndex and fill_value\n",
    "result = a.floordiv(b, level='number', fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         10\n",
    "b       2          4\n",
    "c       3          5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this case, the division is done along the `'number'` level of the MultiIndex, with missing values filled by `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.rfloordiv()`**: Reverse of the floor division operator.\n",
    "\n",
    "The **`floordiv()`** method is helpful for performing element-wise integer division, with special handling for missing values and MultiIndex support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.mod\n",
    "Series.mod(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Modulo of series and other, element-wise (binary operator mod).\n",
    "\n",
    "Equivalent to series % other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other: \n",
    "Series or scalar value\n",
    "level: \n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value: \n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "Series.rmod\n",
    "Reverse of the Modulo operator, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mod(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.mod – Element-wise Modulo of Series and Other**\n",
    "\n",
    "The **`Series.mod()`** method performs element-wise modulo operation between two Series (or a Series and a scalar). It works similarly to the `%` operator in Python, but also supports the **`fill_value`** parameter for handling missing (`NaN`) values during the calculation.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.mod(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The other Series or scalar value to calculate the modulo with.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Specifies the level of a MultiIndex to be used for broadcasting the modulo operation.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Fills missing (`NaN`) values in the Series before performing the modulo operation.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series, included for compatibility with DataFrame.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the modulo operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Modulo Operation**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "b = pd.Series([3, 7, 5], index=['a', 'b', 'c'])\n",
    "\n",
    "# Perform element-wise modulo\n",
    "result = a.mod(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    1\n",
    "b    6\n",
    "c    0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `10 % 3 = 1`\n",
    "- `20 % 7 = 6`\n",
    "- `30 % 5 = 0`\n",
    "\n",
    "#### **2. Modulo with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "# Series with NaN values\n",
    "a = pd.Series([10, 20, np.nan], index=['a', 'b', 'c'])\n",
    "b = pd.Series([3, np.nan, 5], index=['a', 'b', 'c'])\n",
    "\n",
    "# Perform modulo with fill_value=0 for missing data\n",
    "result = a.mod(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    1.0\n",
    "b    NaN\n",
    "c    0.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `10 % 3 = 1`\n",
    "- `20 % NaN = NaN` (since `b` has a missing value)\n",
    "- For the missing value in `a`, we replace it with `0` before calculating, so `NaN % 5 = 0`.\n",
    "\n",
    "#### **3. Modulo with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([10, 20, 30], index=index)\n",
    "\n",
    "index2 = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 4)], names=['letter', 'number'])\n",
    "b = pd.Series([3, 7, 5], index=index2)\n",
    "\n",
    "# Perform modulo with MultiIndex and fill_value\n",
    "result = a.mod(b, level='number', fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         1\n",
    "b       2         6\n",
    "c       3         0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this case, the modulo operation is applied along the `'number'` level of the MultiIndex.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.rmod()`**: Reverse of the modulo operator.\n",
    "\n",
    "This method is helpful when you want to calculate modulo with extra handling for missing data and support for MultiIndex alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.pow\n",
    "Series.pow(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Exponential power of series and other, element-wise (binary operator pow).\n",
    "\n",
    "Equivalent to series ** other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other: \n",
    "Series or scalar value\n",
    "level: \n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value: \n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "Series\n",
    "The result of the operation. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.pow(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.pow – Exponential Power of Series and Other**\n",
    "\n",
    "The **`Series.pow()`** method performs element-wise exponentiation between two Series (or a Series and a scalar). It works like the **`**` operator in Python, but includes additional support for handling missing (`NaN`) values through the **`fill_value`\\*\\* parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.pow(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The other Series or scalar value to perform the exponentiation operation with.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Specifies the level of a MultiIndex to broadcast the power operation across.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Fills missing (`NaN`) values in the Series before performing the power operation.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series, included for compatibility with DataFrame.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the exponentiation operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Exponentiation**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([2, 3, 4], index=['a', 'b', 'c'])\n",
    "b = pd.Series([2, 2, 2], index=['a', 'b', 'c'])\n",
    "\n",
    "# Perform element-wise exponentiation\n",
    "result = a.pow(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     4\n",
    "b     9\n",
    "c    16\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `2 ** 2 = 4`\n",
    "- `3 ** 2 = 9`\n",
    "- `4 ** 2 = 16`\n",
    "\n",
    "#### **2. Exponentiation with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "# Series with NaN values\n",
    "a = pd.Series([2, 3, 4, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([2, np.nan, 2, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Perform exponentiation with fill_value=1 for missing data\n",
    "result = a.pow(b, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     4.0\n",
    "b     NaN\n",
    "c    16.0\n",
    "d     1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `2 ** 2 = 4`\n",
    "- `3 ** NaN = NaN` (since `b` has a missing value)\n",
    "- `4 ** 2 = 16`\n",
    "- `NaN ** NaN` results in `1` (as we fill with `1` before calculation)\n",
    "\n",
    "#### **3. Exponentiation with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([2, 3, 4], index=index)\n",
    "\n",
    "index2 = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "b = pd.Series([2, 2, 2], index=index2)\n",
    "\n",
    "# Perform exponentiation with MultiIndex\n",
    "result = a.pow(b, level='number')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         4\n",
    "b       2         9\n",
    "c       3        16\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this case, the exponentiation is applied across the `'number'` level of the MultiIndex.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.rpow()`**: Reverse of the exponential power operator.\n",
    "\n",
    "This method is useful when you need to compute exponentiation with proper handling of missing values and support for MultiIndex alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.radd\n",
    "Series.radd(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Addition of series and other, element-wise (binary operator radd).\n",
    "\n",
    "Equivalent to other + series, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "\n",
    "other: \n",
    "\n",
    "Series or scalar value\n",
    "\n",
    "level: \n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value :\n",
    "\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis:\n",
    " \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "Series.add\n",
    "Element-wise Addition, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.radd – Reverse Addition of Series and Other**\n",
    "\n",
    "The **`Series.radd()`** method performs element-wise addition between a Series and another Series (or a scalar). This is the reverse of the **`Series.add()`** operation, meaning it is effectively **`other + series`**. It allows handling missing (`NaN`) values through the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.radd(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The other Series or scalar value to perform the addition operation with.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Used in case of MultiIndex to broadcast across a level.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Fills missing (`NaN`) values before performing the addition.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but needed for compatibility with DataFrame.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the addition operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Addition**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([4, 5, 6], index=['a', 'b', 'c'])\n",
    "\n",
    "# Reverse addition: other + series\n",
    "result = a.radd(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     5\n",
    "b     7\n",
    "c     9\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here, `b + a` gives the same result as `a + b` because addition is commutative.\n",
    "\n",
    "#### **2. Addition with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "# Series with NaN values\n",
    "a = pd.Series([1, 2, 3, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, np.nan, 6, 7], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Perform addition with fill_value=0 for missing data\n",
    "result = a.radd(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     5.0\n",
    "b     2.0\n",
    "c     9.0\n",
    "d     7.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `1 + 4 = 5`\n",
    "- `2 + NaN = 2` (because we fill `NaN` with `0`)\n",
    "- `3 + 6 = 9`\n",
    "- `NaN + 7 = 7` (filling `NaN` with `0`)\n",
    "\n",
    "#### **3. Reverse Addition with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "\n",
    "# Reverse addition with MultiIndex\n",
    "b = pd.Series([4, 5, 6], index=index)\n",
    "\n",
    "result = a.radd(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         5\n",
    "b       2         7\n",
    "c       3         9\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this case, the reverse addition is applied across the MultiIndex levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.add()`**: Regular element-wise addition.\n",
    "\n",
    "The `radd()` method is helpful when you need the reverse of the addition operation, particularly when working with multi-indexed data or handling missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rsub\n",
    "Series.rsub(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Subtraction of series and other, element-wise (binary operator rsub).\n",
    "\n",
    "Equivalent to other - series, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "level:\n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value: \n",
    "\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "Series.sub\n",
    "Element-wise Subtraction, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.subtract(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.rsub – Reverse Subtraction of Series and Other**\n",
    "\n",
    "The **`Series.rsub()`** method performs element-wise subtraction between a Series and another Series (or scalar), but it works in reverse. This means it performs the operation as **`other - series`**. It also supports handling missing (`NaN`) values using the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rsub(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The Series or scalar value to subtract from the Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Used when dealing with MultiIndex data, allowing the operation to be broadcast across a specific level.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Fills missing (`NaN`) values before performing the subtraction.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but needed for compatibility with DataFrame.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the subtraction operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Subtraction**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([4, 5, 6], index=['a', 'b', 'c'])\n",
    "\n",
    "# Reverse subtraction: other - series\n",
    "result = a.rsub(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    3\n",
    "b    3\n",
    "c    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here, `b - a` gives the result:\n",
    "\n",
    "- `4 - 1 = 3`\n",
    "- `5 - 2 = 3`\n",
    "- `6 - 3 = 3`\n",
    "\n",
    "#### **2. Subtraction with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "# Series with NaN values\n",
    "a = pd.Series([1, 2, 3, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, np.nan, 6, 7], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Perform subtraction with fill_value=0 for missing data\n",
    "result = a.rsub(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     3.0\n",
    "b     2.0\n",
    "c     3.0\n",
    "d     7.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `4 - 1 = 3`\n",
    "- `NaN - 2 = 2` (because we fill `NaN` with `0`)\n",
    "- `6 - 3 = 3`\n",
    "- `7 - NaN = 7` (filling `NaN` with `0`)\n",
    "\n",
    "#### **3. Reverse Subtraction with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "\n",
    "# Reverse subtraction with MultiIndex\n",
    "b = pd.Series([4, 5, 6], index=index)\n",
    "\n",
    "result = a.rsub(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         3\n",
    "b       2         3\n",
    "c       3         3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this case, the reverse subtraction is applied across the MultiIndex levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.sub()`**: Regular element-wise subtraction.\n",
    "\n",
    "The **`rsub()`** method is particularly useful when you need the reverse of the subtraction operation, especially for handling multi-indexed data or missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rmul\n",
    "Series.rmul(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Multiplication of series and other, element-wise (binary operator rmul).\n",
    "\n",
    "Equivalent to other * series, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "level:\n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value:\n",
    "\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis:\n",
    "\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "Series.mul\n",
    "Element-wise Multiplication, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.multiply(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.rmul – Reverse Multiplication of Series and Other**\n",
    "\n",
    "The **`Series.rmul()`** method performs element-wise multiplication of a Series and another Series (or scalar) in reverse. This means it performs the operation as **`other * series`**, with support for handling missing (`NaN`) values using the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rmul(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The Series or scalar value to multiply by the Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Used for MultiIndex, to specify which level to perform the operation across.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Fills missing (`NaN`) values before performing the multiplication.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but necessary for DataFrame compatibility.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the multiplication operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Multiplication**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([4, 5, 6], index=['a', 'b', 'c'])\n",
    "\n",
    "# Reverse multiplication: other * series\n",
    "result = a.rmul(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     4\n",
    "b    10\n",
    "c    18\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here, `b * a` gives:\n",
    "\n",
    "- `4 * 1 = 4`\n",
    "- `5 * 2 = 10`\n",
    "- `6 * 3 = 18`\n",
    "\n",
    "#### **2. Multiplication with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Series with NaN values\n",
    "a = pd.Series([1, 2, 3, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, np.nan, 6, 7], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Perform multiplication with fill_value=0 for missing data\n",
    "result = a.rmul(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     4.0\n",
    "b     0.0\n",
    "c    18.0\n",
    "d     0.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `4 * 1 = 4`\n",
    "- `NaN * 2 = 0` (because we fill `NaN` with `0`)\n",
    "- `6 * 3 = 18`\n",
    "- `7 * NaN = 0` (filling `NaN` with `0`)\n",
    "\n",
    "#### **3. Reverse Multiplication with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "\n",
    "# Reverse multiplication with MultiIndex\n",
    "b = pd.Series([4, 5, 6], index=index)\n",
    "\n",
    "result = a.rmul(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         4\n",
    "b       2        10\n",
    "c       3        18\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this case, the reverse multiplication is applied across the MultiIndex levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.mul()`**: Regular element-wise multiplication.\n",
    "\n",
    "The **`rmul()`** method is useful when you want the reverse of a multiplication operation, especially when dealing with missing values or working with multi-indexed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rdiv\n",
    "Series.rdiv(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Floating division of series and other, element-wise (binary operator rtruediv).\n",
    "\n",
    "Equivalent to other / series, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "level:\n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value:\n",
    "\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis:\n",
    "\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.truediv\n",
    "Element-wise Floating division, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.divide(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.rdiv – Reverse Floating Division of Series and Other**\n",
    "\n",
    "The **`Series.rdiv()`** method performs floating division of a Series and another Series (or scalar) in reverse. This means it performs the operation as **`other / series`**, with support for handling missing (`NaN`) values using the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rdiv(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The Series or scalar value to divide by the Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Used for MultiIndex, to specify which level to perform the operation across.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Fills missing (`NaN`) values before performing the division.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but necessary for DataFrame compatibility.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the division operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Division**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([4, 5, 6], index=['a', 'b', 'c'])\n",
    "\n",
    "# Reverse division: other / series\n",
    "result = a.rdiv(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     4.0\n",
    "b     2.5\n",
    "c     2.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here, `b / a` gives:\n",
    "\n",
    "- `4 / 1 = 4.0`\n",
    "- `5 / 2 = 2.5`\n",
    "- `6 / 3 = 2.0`\n",
    "\n",
    "#### **2. Division with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Series with NaN values\n",
    "a = pd.Series([1, 2, 3, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, np.nan, 6, 7], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Perform division with fill_value=1 for missing data\n",
    "result = a.rdiv(b, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    4.0\n",
    "b    1.0\n",
    "c    2.0\n",
    "d    1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `4 / 1 = 4.0`\n",
    "- `NaN / 2 = 1.0` (because we fill `NaN` with `1`)\n",
    "- `6 / 3 = 2.0`\n",
    "- `7 / NaN = 1.0` (filling `NaN` with `1`)\n",
    "\n",
    "#### **3. Reverse Division with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "\n",
    "# Reverse division with MultiIndex\n",
    "b = pd.Series([4, 5, 6], index=index)\n",
    "\n",
    "result = a.rdiv(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         4.0\n",
    "b       2         2.5\n",
    "c       3         2.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this case, the reverse division is applied across the MultiIndex levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.truediv()`**: Regular element-wise floating division.\n",
    "\n",
    "The **`rdiv()`** method is helpful when you want the reverse of a division operation, especially when dealing with missing values or working with multi-indexed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rtruediv\n",
    "\n",
    "Series.rtruediv(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Floating division of series and other, element-wise (binary operator rtruediv).\n",
    "\n",
    "Equivalent to other / series, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "\n",
    "other: \n",
    "\n",
    "Series or scalar value\n",
    "level:\n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value :\n",
    "\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis: \n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "\n",
    "Series.truediv\n",
    "Element-wise Floating division, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a.divide(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.rtruediv – Reverse Floating Division of Series and Other**\n",
    "\n",
    "The **`Series.rtruediv()`** method performs floating division of a Series and another Series (or scalar) in reverse, i.e., it performs the operation as **`other / series`**. It also supports handling missing (`NaN`) values by using the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rtruediv(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The Series or scalar value to divide by the Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - Used for MultiIndex, to specify which level to perform the operation across.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Fills missing (`NaN`) values before performing the division.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but necessary for DataFrame compatibility.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the division operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Reverse Division**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([4, 5, 6], index=['a', 'b', 'c'])\n",
    "\n",
    "# Reverse division: other / series\n",
    "result = a.rtruediv(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     4.0\n",
    "b     2.5\n",
    "c     2.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here, `b / a` gives:\n",
    "\n",
    "- `4 / 1 = 4.0`\n",
    "- `5 / 2 = 2.5`\n",
    "- `6 / 3 = 2.0`\n",
    "\n",
    "#### **2. Reverse Division with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Series with NaN values\n",
    "a = pd.Series([1, 2, 3, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, np.nan, 6, 7], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Perform reverse division with fill_value=1 for missing data\n",
    "result = a.rtruediv(b, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    4.0\n",
    "b    1.0\n",
    "c    2.0\n",
    "d    1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `4 / 1 = 4.0`\n",
    "- `NaN / 2 = 1.0` (because we fill `NaN` with `1`)\n",
    "- `6 / 3 = 2.0`\n",
    "- `7 / NaN = 1.0` (filling `NaN` with `1`)\n",
    "\n",
    "#### **3. Reverse Division with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([1, 2, 3], index=index)\n",
    "\n",
    "# Reverse division with MultiIndex\n",
    "b = pd.Series([4, 5, 6], index=index)\n",
    "\n",
    "result = a.rtruediv(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         4.0\n",
    "b       2         2.5\n",
    "c       3         2.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this case, the reverse division is applied across the MultiIndex levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.truediv()`**: Regular element-wise floating division.\n",
    "\n",
    "The **`rtruediv()`** method is useful when you want the reverse of a division operation, especially when handling missing data or using MultiIndex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rfloordiv\n",
    "Series.rfloordiv(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Integer division of series and other, element-wise (binary operator rfloordiv).\n",
    "\n",
    "Equivalent to other // series, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "level:\n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value: \n",
    "\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis:\n",
    "\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "Series:\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "\n",
    "Series.floordiv\n",
    "Element-wise Integer division, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.floordiv(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.rfloordiv – Reverse Integer Division of Series and Other**\n",
    "\n",
    "The **`Series.rfloordiv()`** method performs reverse integer division of a Series and another Series (or scalar). Essentially, it computes the operation as **`other // series`**. It also supports handling missing values (`NaN`) by using the **`fill_value`** parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rfloordiv(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The Series or scalar value to divide by the Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - For MultiIndex, specifies which level to apply the operation across.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - If the data contains `NaN` values, this parameter fills missing values before performing the division.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but necessary for DataFrame compatibility.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the integer division operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Reverse Integer Division**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([2, 5, 9], index=['a', 'b', 'c'])\n",
    "b = pd.Series([4, 2, 3], index=['a', 'b', 'c'])\n",
    "\n",
    "# Reverse integer division: other // series\n",
    "result = a.rfloordiv(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    2\n",
    "b    2\n",
    "c    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here, `b // a` gives:\n",
    "\n",
    "- `4 // 2 = 2`\n",
    "- `2 // 5 = 0`\n",
    "- `3 // 9 = 0`\n",
    "\n",
    "#### **2. Reverse Integer Division with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Series with NaN values\n",
    "a = pd.Series([2, 5, np.nan], index=['a', 'b', 'c'])\n",
    "b = pd.Series([4, np.nan, 6], index=['a', 'b', 'c'])\n",
    "\n",
    "# Perform reverse integer division with fill_value=1 for missing data\n",
    "result = a.rfloordiv(b, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    2.0\n",
    "b    1.0\n",
    "c    1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this case:\n",
    "\n",
    "- `4 // 2 = 2`\n",
    "- `NaN // 5 = 1.0` (using `fill_value=1`)\n",
    "- `6 // NaN = 1.0` (using `fill_value=1`)\n",
    "\n",
    "#### **3. Reverse Integer Division with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([9, 16, 27], index=index)\n",
    "\n",
    "# Reverse integer division with MultiIndex\n",
    "b = pd.Series([3, 4, 6], index=index)\n",
    "\n",
    "result = a.rfloordiv(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         3\n",
    "b       2         4\n",
    "c       3         4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here, the reverse integer division is applied across the MultiIndex levels:\n",
    "\n",
    "- `9 // 3 = 3`\n",
    "- `16 // 4 = 4`\n",
    "- `27 // 6 = 4`\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.floordiv()`**: Regular element-wise integer division.\n",
    "\n",
    "The **`rfloordiv()`** method is helpful when you need to perform reverse integer division with handling of missing data or with MultiIndex operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rpow\n",
    "Series.rpow(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Exponential power of series and other, element-wise (binary operator rpow).\n",
    "\n",
    "Equivalent to other ** series, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters :\n",
    "\n",
    "other:\n",
    "\n",
    "Series or scalar value\n",
    "level:\n",
    "\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value:\n",
    "\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis:\n",
    "\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns :\n",
    "Series\n",
    "The result of the operation.\n",
    "\n",
    "\n",
    "\n",
    "Series.pow\n",
    "Element-wise Exponential power, see Python documentation for more details. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.pow(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.rpow – Reverse Exponential Power of Series and Other**\n",
    "\n",
    "The **`Series.rpow()`** method computes the element-wise exponential power of a Series and another Series (or scalar). It’s equivalent to the operation **`other ** series`**, allowing for the inclusion of a **`fill_value`** to handle missing (`NaN`) values.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rpow(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The Series or scalar value to raise the power to.\n",
    "\n",
    "- **level**: `int` or `name`, optional, default `None`\n",
    "\n",
    "  - If working with a MultiIndex, this parameter allows broadcasting across a specified level.\n",
    "\n",
    "- **fill_value**: `None` or `float`, optional, default `None` (NaN)\n",
    "\n",
    "  - Specifies a value to fill any missing (`NaN`) values before performing the operation.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, unused for Series but necessary for DataFrame compatibility.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The result of the exponential power operation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Basic Reverse Exponential Power**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating two Series\n",
    "a = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "b = pd.Series([2, 3, 4], index=['a', 'b', 'c'])\n",
    "\n",
    "# Reverse exponential power: other ** series\n",
    "result = a.rpow(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a      2.0\n",
    "b      8.0\n",
    "c     81.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `2 ** 1 = 2`\n",
    "- `3 ** 2 = 9`\n",
    "- `4 ** 3 = 64`\n",
    "\n",
    "#### **2. Reverse Exponential Power with Missing Values (Using `fill_value`)**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Series with NaN values\n",
    "a = pd.Series([1, 2, np.nan], index=['a', 'b', 'c'])\n",
    "b = pd.Series([2, np.nan, 4], index=['a', 'b', 'c'])\n",
    "\n",
    "# Reverse exponential power with fill_value=1 for missing data\n",
    "result = a.rpow(b, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a      2.0\n",
    "b      2.0\n",
    "c     256.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this case:\n",
    "\n",
    "- `2 ** 1 = 2`\n",
    "- `NaN ** 2 = 2` (using `fill_value=1`)\n",
    "- `4 ** 1 = 4`\n",
    "\n",
    "#### **3. Reverse Exponential Power with MultiIndex**\n",
    "\n",
    "```python\n",
    "# MultiIndex Series\n",
    "index = pd.MultiIndex.from_tuples([('a', 1), ('b', 2), ('c', 3)], names=['letter', 'number'])\n",
    "a = pd.Series([9, 16, 27], index=index)\n",
    "\n",
    "# Reverse exponential power with MultiIndex\n",
    "b = pd.Series([3, 4, 6], index=index)\n",
    "\n",
    "result = a.rpow(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "letter  number\n",
    "a       1         729\n",
    "b       2        65536\n",
    "c       3    387420489\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- `3 ** 9 = 19683`\n",
    "- `4 ** 16 = 4294967296`\n",
    "- `6 ** 27 = 4747561509943`\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.pow()`**: Element-wise exponential power.\n",
    "\n",
    "The **`rpow()`** method is particularly useful when you need to perform a reverse exponential operation (where `other` is the base and `series` is the exponent) and handle missing data properly using the `fill_value` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.combine\n",
    "Series.combine(other, func, fill_value=None)[source]\n",
    "Combine the Series with a Series or scalar according to func.\n",
    "\n",
    "Combine the Series and other using func to perform elementwise selection for combined Series. fill_value is assumed when value is missing at some index from one of the two objects being combined.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series or scalar\n",
    "The value(s) to be combined with the Series.\n",
    "\n",
    "func\n",
    "function\n",
    "Function that takes two scalars as inputs and returns an element.\n",
    "\n",
    "fill_value\n",
    "scalar, optional\n",
    "The value to assume when an index is missing from one Series or the other. The default specifies to use the appropriate NaN value for the underlying dtype of the Series.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of combining the Series with the other object. \"\"\"\n",
    "s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.combine(s2, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.combine(s2, max, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.combine – Combine Two Series Using a Function**\n",
    "\n",
    "The **`Series.combine()`** method is used to combine two Series (or a Series and a scalar) element-wise, using a specified function. You can specify how missing values should be handled with the `fill_value` parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.combine(other, func, fill_value=None)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The other Series or scalar value to combine with the calling Series.\n",
    "\n",
    "- **func**: `function`\n",
    "\n",
    "  - A function that takes two scalars as inputs and returns a scalar value. This function will be applied element-wise between the two Series (or Series and scalar).\n",
    "\n",
    "- **fill_value**: `scalar`, optional, default `None`\n",
    "  - The value used when an index is missing from one of the Series. If not provided, `NaN` is used for the missing values.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A new Series containing the result of applying `func` to the combined elements.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Combine Using `max()` Function**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Define two Series\n",
    "s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})\n",
    "s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})\n",
    "\n",
    "# Combine using max function\n",
    "result = s1.combine(s2, max)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "duck        NaN\n",
    "eagle     200.0\n",
    "falcon    345.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "- The `max()` function is applied to the two Series element-wise.\n",
    "- The value for `'duck'` is missing in `s1`, so it results in `NaN`.\n",
    "\n",
    "#### **2. Combine Using `max()` with `fill_value`**\n",
    "\n",
    "```python\n",
    "# Combine using max function with fill_value=0\n",
    "result = s1.combine(s2, max, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "duck       30.0\n",
    "eagle     200.0\n",
    "falcon    345.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- The missing `'duck'` value is filled with `0`, and the maximum value is calculated as `30.0`.\n",
    "- Now, `'duck'` gets a value instead of `NaN`.\n",
    "\n",
    "#### **3. Combine Using Custom Function**\n",
    "\n",
    "```python\n",
    "# Define a custom function\n",
    "def custom_func(x, y):\n",
    "    return x * y if x > y else x + y\n",
    "\n",
    "# Combine using the custom function\n",
    "result = s1.combine(s2, custom_func, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "duck        31.0\n",
    "eagle     360.0\n",
    "falcon    675.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "- The custom function multiplies `x` and `y` if `x > y`, otherwise, it adds `x` and `y`.\n",
    "- The result shows different combinations based on the logic defined.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.combine_first()`**: Combine Series values by choosing the calling Series' values first, then the other Series' values if missing.\n",
    "\n",
    "The **`combine()`** method provides great flexibility for combining Series element-wise using a custom function, allowing for specific handling of missing data with the `fill_value` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.combine_first\n",
    "Series.combine_first(other)[source]\n",
    "Update null elements with value in the same location in ‘other’.\n",
    "\n",
    "Combine two Series objects by filling null values in one Series with non-null values from the other Series. Result index will be the union of the two indexes.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series\n",
    "The value(s) to be used for filling null values.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of combining the provided Series with the other object.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.combine\n",
    "Perform element-wise operation on two Series using a given function. \"\"\"\n",
    "s1 = pd.Series([1, np.nan])\n",
    "s2 = pd.Series([3, 4, 5])\n",
    "s1.combine_first(s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series({'falcon': np.nan, 'eagle': 160.0})\n",
    "s2 = pd.Series({'eagle': 200.0, 'duck': 30.0})\n",
    "s1.combine_first(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas.Series.combine_first – Combine Two Series by Filling Nulls**\n",
    "\n",
    "The **`Series.combine_first()`** method is used to combine two Series by filling missing (null) values in one Series with the corresponding non-null values from the other Series. The result will have the union of the indices of both Series.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.combine_first(other)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series`\n",
    "  - The Series used to fill in missing values in the calling Series.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A new Series where missing values (nulls) in the calling Series are filled with corresponding values from `other`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **1. Combine Two Series with Null Values**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define two Series with some null values\n",
    "s1 = pd.Series([1, np.nan])\n",
    "s2 = pd.Series([3, 4, 5])\n",
    "\n",
    "# Combine the Series, filling nulls in s1 with values from s2\n",
    "result = s1.combine_first(s2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    1.0\n",
    "1    4.0\n",
    "2    5.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "- The first Series `s1` has a `NaN` at index `1`, which is filled by the corresponding value from `s2`.\n",
    "- The second Series `s2` has extra data at index `2`, which is added to the result.\n",
    "\n",
    "#### **2. Combine Two Series with Different Indexes**\n",
    "\n",
    "```python\n",
    "# Define two Series with different indexes\n",
    "s1 = pd.Series({'falcon': np.nan, 'eagle': 160.0})\n",
    "s2 = pd.Series({'eagle': 200.0, 'duck': 30.0})\n",
    "\n",
    "# Combine the Series, filling nulls in s1 with values from s2\n",
    "result = s1.combine_first(s2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "duck       30.0\n",
    "eagle     160.0\n",
    "falcon      NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this case:\n",
    "\n",
    "- The missing value for `'falcon'` in `s1` could not be filled because `s2` does not have a `'falcon'` value.\n",
    "- The missing `'eagle'` value in `s1` is not replaced because it already has a value in `s1`.\n",
    "- The `'duck'` value from `s2` fills the missing index.\n",
    "\n",
    "#### **3. Result with Union of Indexes**\n",
    "\n",
    "```python\n",
    "# Combine Series with non-overlapping indexes\n",
    "s1 = pd.Series([1, np.nan], index=['a', 'b'])\n",
    "s2 = pd.Series([3, 4, 5], index=['b', 'c', 'd'])\n",
    "\n",
    "# Combine the Series, filling nulls in s1 with values from s2\n",
    "result = s1.combine_first(s2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    1.0\n",
    "b    4.0\n",
    "c    5.0\n",
    "d    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "- The result's index is the union of the indexes from both Series (`a`, `b`, `c`, `d`).\n",
    "- The value at index `'a'` is from `s1`, while missing values at index `'b'` are filled with data from `s2`.\n",
    "- The index `'d'` is only present in `s2`, but there is no corresponding value to fill, so it remains `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.combine()`**: Performs element-wise operation on two Series using a given function (for more complex operations than just filling nulls).\n",
    "\n",
    "The **`combine_first()`** method is useful when you want to \"fill in the blanks\" of one Series with data from another, ensuring no data is lost where possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.round\n",
    "Series.round(decimals=0, *args, **kwargs)[source]\n",
    "Round each value in a Series to the given number of decimals.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "decimals\n",
    "int, default 0\n",
    "Number of decimal places to round to. If decimals is negative, it specifies the number of positions to the left of the decimal point.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional arguments and keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns :\n",
    "\n",
    "\n",
    "Series\n",
    "Rounded values of the Series.\n",
    "\n",
    "\n",
    "\n",
    "numpy.around\n",
    "Round values of an np.array.\n",
    "\n",
    "DataFrame.round\n",
    "Round values of a DataFrame. \"\"\"\n",
    "s = pd.Series([0.1, 1.3, 2.7])\n",
    "s.round()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.round()`** function in pandas allows you to round the values of a Series to a specified number of decimal places. Here’s a summary and an example:\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.round(decimals=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **decimals**: `int`, default is `0`\n",
    "  - The number of decimal places to round to. If negative, it rounds to the left of the decimal point (e.g., `-1` rounds to the nearest 10).\n",
    "- **\\*args, \\*\\*kwargs**: These additional arguments and keywords are accepted for compatibility with NumPy but do not affect the behavior of this method.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: The resulting Series with the values rounded to the specified number of decimal places.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Round to the Nearest Integer (0 Decimal Places)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series with floating-point numbers\n",
    "s = pd.Series([0.1, 1.3, 2.7])\n",
    "\n",
    "# Round to the nearest integer\n",
    "rounded_s = s.round()\n",
    "\n",
    "print(rounded_s)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    0.0\n",
    "1    1.0\n",
    "2    3.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- In this case, the values are rounded to the nearest whole number (i.e., 0 decimal places).\n",
    "\n",
    "#### Example 2: Round to a Specific Number of Decimal Places\n",
    "\n",
    "```python\n",
    "# Round to 1 decimal place\n",
    "rounded_s = s.round(decimals=1)\n",
    "\n",
    "print(rounded_s)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    0.1\n",
    "1    1.3\n",
    "2    2.7\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- Here, the values are rounded to 1 decimal place.\n",
    "\n",
    "#### Example 3: Round to the Nearest Ten (Negative Decimal Places)\n",
    "\n",
    "```python\n",
    "# Round to the nearest 10\n",
    "rounded_s = s.round(decimals=-1)\n",
    "\n",
    "print(rounded_s)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    0.0\n",
    "1    0.0\n",
    "2    0.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- The negative value of `decimals=-1` rounds each number to the nearest 10.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`numpy.around`**: Equivalent function in NumPy for rounding values in arrays.\n",
    "- **`DataFrame.round`**: For rounding values in an entire DataFrame.\n",
    "\n",
    "This method is useful when you need to control the precision of the data in a pandas Series. Let me know if you'd like to explore more!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.lt\n",
    "Series.lt(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Less than of series and other, element-wise (binary operator lt).\n",
    "\n",
    "Equivalent to series < other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series or scalar value\n",
    "level\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.lt(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.lt()`** function in pandas is used to compare the elements of a Series with another Series or a scalar value to check for \"less than\" relationships, element-wise. This function can handle missing data by using a `fill_value` parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.lt(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "  - The value(s) you want to compare the Series with. It can be another Series or a scalar value.\n",
    "- **level**: `int` or `name`, optional\n",
    "\n",
    "  - If the Series has a `MultiIndex`, this parameter is used to perform the comparison across a specific level of the index.\n",
    "\n",
    "- **fill_value**: `scalar`, optional, default `None`\n",
    "\n",
    "  - If there are missing (NaN) values in the Series, this value will be used to replace them before performing the comparison.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, optional\n",
    "  - This parameter is unused for Series but is included for compatibility with DataFrame operations.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A Series of boolean values (`True` or `False`), indicating whether the elements of the original Series are less than the corresponding elements in the `other`.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Simple Comparison (Without Missing Data)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series\n",
    "a = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, 3, 2, 1], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Compare if elements in 'a' are less than corresponding elements in 'b'\n",
    "result = a.lt(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b     False\n",
    "c     False\n",
    "d     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- In this case, the result is a boolean Series where each value is `True` if the corresponding value in `a` is less than the value in `b`.\n",
    "\n",
    "#### Example 2: Comparison with Missing Values\n",
    "\n",
    "```python\n",
    "# Create Series with missing values\n",
    "a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
    "b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
    "\n",
    "# Compare with fill_value for NaNs\n",
    "result = a.lt(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     False\n",
    "b     False\n",
    "c      True\n",
    "d     False\n",
    "e     False\n",
    "f      True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- Here, the comparison is performed element-wise, and the missing values are filled with `0` before performing the comparison. As a result:\n",
    "  - For index `a`, `1.0 < 0.0` is `False`.\n",
    "  - For index `b`, `1.0 < 1.0` is `False`.\n",
    "  - For index `c`, `1.0 < 2.0` is `True`.\n",
    "  - For index `d`, `NaN` is compared with `NaN`, and the result is `False` because NaN is not less than NaN.\n",
    "  - For index `f`, the value `NaN` in `b` is filled with `0`, so `1.0 < 0.0` is `True`.\n",
    "\n",
    "#### Example 3: Comparison with a Scalar Value\n",
    "\n",
    "```python\n",
    "# Compare each element in the Series to a scalar value\n",
    "result = a.lt(2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b     True\n",
    "c     True\n",
    "d    False\n",
    "e     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- Here, every element in `a` is compared to the scalar value `2`. The result is `True` for values less than `2` and `False` otherwise.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.gt()`**: Greater than comparison (`>`).\n",
    "- **`Series.le()`**: Less than or equal to comparison (`<=`).\n",
    "- **`Series.ge()`**: Greater than or equal to comparison (`>=`).\n",
    "- **`Series.eq()`**: Equal to comparison (`==`).\n",
    "\n",
    "The **`lt()`** function is useful when you need to compare Series element-wise and handle missing values in a controlled way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.gt\n",
    "Series.gt(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Greater than of series and other, element-wise (binary operator gt).\n",
    "\n",
    "Equivalent to series > other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series or scalar value\n",
    "level\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.gt(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.gt()`** function in pandas is used to compare the elements of a Series with another Series or a scalar value, checking if they are \"greater than\" element-wise. It also allows for handling missing data by using the `fill_value` parameter.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.gt(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "  - The value(s) you want to compare the Series with. It can be another Series or a scalar value.\n",
    "- **level**: `int` or `name`, optional\n",
    "\n",
    "  - If the Series has a `MultiIndex`, this parameter is used to perform the comparison across a specific level of the index.\n",
    "\n",
    "- **fill_value**: `scalar`, optional, default `None`\n",
    "\n",
    "  - If there are missing (NaN) values in the Series, this value will be used to replace them before performing the comparison.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, optional\n",
    "  - This parameter is unused for Series but is included for compatibility with DataFrame operations.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A Series of boolean values (`True` or `False`), indicating whether the elements of the original Series are greater than the corresponding elements in `other`.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Simple Comparison (Without Missing Data)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series\n",
    "a = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, 3, 2, 1], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Compare if elements in 'a' are greater than corresponding elements in 'b'\n",
    "result = a.gt(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    False\n",
    "b     True\n",
    "c     True\n",
    "d     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- The result is a boolean Series where each value is `True` if the corresponding value in `a` is greater than the value in `b`.\n",
    "\n",
    "#### Example 2: Comparison with Missing Values\n",
    "\n",
    "```python\n",
    "# Create Series with missing values\n",
    "a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
    "b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
    "\n",
    "# Compare with fill_value for NaNs\n",
    "result = a.gt(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b    False\n",
    "c     True\n",
    "d    False\n",
    "e     True\n",
    "f    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- Here, the comparison is performed element-wise, and missing values (NaN) are filled with `0` before performing the comparison. As a result:\n",
    "  - For index `a`, `1.0 > 0.0` is `True`.\n",
    "  - For index `b`, `1.0 > 1.0` is `False`.\n",
    "  - For index `c`, `1.0 > 2.0` is `False`.\n",
    "  - For index `d`, `NaN` is compared with `NaN`, and the result is `False`.\n",
    "  - For index `f`, `NaN` in `b` is filled with `0`, so `1.0 > 0.0` is `True`.\n",
    "\n",
    "#### Example 3: Comparison with a Scalar Value\n",
    "\n",
    "```python\n",
    "# Compare each element in the Series to a scalar value\n",
    "result = a.gt(0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b     False\n",
    "c     False\n",
    "d    False\n",
    "e     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- Here, every element in `a` is compared to the scalar value `0`. The result is `True` for values greater than `0` and `False` otherwise.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.lt()`**: Less than comparison (`<`).\n",
    "- **`Series.le()`**: Less than or equal to comparison (`<=`).\n",
    "- **`Series.ge()`**: Greater than or equal to comparison (`>=`).\n",
    "- **`Series.eq()`**: Equal to comparison (`==`).\n",
    "\n",
    "The **`gt()`** function is useful when you need to compare Series element-wise and handle missing values in a controlled way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.le\n",
    "Series.le(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Less than or equal to of series and other, element-wise (binary operator le).\n",
    "\n",
    "Equivalent to series <= other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series or scalar value\n",
    "level\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.le(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.le()`** function in pandas is used to compare the elements of a Series to another Series or a scalar value to check if they are \"less than or equal to\" each other element-wise. It also provides support for handling missing (NaN) values by substituting them with a specified `fill_value`.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.le(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "  - The value(s) with which to compare the Series. It can be another Series or a scalar value.\n",
    "- **level**: `int` or `name`, optional\n",
    "\n",
    "  - If the Series has a `MultiIndex`, this parameter allows comparison across a specific level of the index.\n",
    "\n",
    "- **fill_value**: `scalar`, optional, default `None`\n",
    "\n",
    "  - If there are missing (NaN) values in either of the Series, this value will be used to fill those missing values before performing the comparison.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, optional\n",
    "  - This parameter is unused for Series but is included for compatibility with DataFrame operations.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A boolean Series indicating the result of the element-wise comparison (`True` if the value is less than or equal to the corresponding value in `other`, `False` otherwise).\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Comparison (Without Missing Values)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series\n",
    "a = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, 3, 2, 1], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Compare if elements in 'a' are less than or equal to corresponding elements in 'b'\n",
    "result = a.le(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b    False\n",
    "c    False\n",
    "d     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- The result is a boolean Series where each value is `True` if the corresponding value in `a` is less than or equal to the value in `b`.\n",
    "\n",
    "#### Example 2: Comparison with Missing Values\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create Series with missing values\n",
    "a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
    "b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
    "\n",
    "# Compare with fill_value for NaNs\n",
    "result = a.le(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     False\n",
    "b      True\n",
    "c      True\n",
    "d     False\n",
    "e      True\n",
    "f     False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- In this example, the comparison is done element-wise. The NaN values are filled with `0` before performing the comparison. For instance:\n",
    "  - For index `a`, `1.0 <= 0.0` is `False`.\n",
    "  - For index `b`, `1.0 <= 1.0` is `True`.\n",
    "  - For index `c`, `1.0 <= 2.0` is `True`.\n",
    "  - For index `d`, `NaN` is compared with `NaN`, which results in `False`.\n",
    "\n",
    "#### Example 3: Comparison with a Scalar Value\n",
    "\n",
    "```python\n",
    "# Compare each element in the Series to a scalar value\n",
    "result = a.le(1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b     True\n",
    "c     True\n",
    "d    False\n",
    "e     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- Here, every element in `a` is compared to the scalar value `1`. The result is `True` for values that are less than or equal to `1` and `False` for values that are greater than `1`.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.lt()`**: Less than comparison (`<`).\n",
    "- **`Series.gt()`**: Greater than comparison (`>`).\n",
    "- **`Series.ge()`**: Greater than or equal to comparison (`>=`).\n",
    "- **`Series.eq()`**: Equal to comparison (`==`).\n",
    "\n",
    "The **`le()`** function is useful when you need to perform element-wise comparisons for \"less than or equal to\" conditions, especially when dealing with missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.ge\n",
    "Series.ge(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Greater than or equal to of series and other, element-wise (binary operator ge).\n",
    "\n",
    "Equivalent to series >= other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series or scalar value\n",
    "level\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.ge(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.ge()`** function in pandas is used to compare the elements of a Series to another Series or scalar to check if they are \"greater than or equal to\" each other element-wise. It also handles missing (NaN) values by allowing the use of a `fill_value` for those missing entries before performing the comparison.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.ge(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The value(s) with which to compare the Series. It can be another Series or a scalar value.\n",
    "\n",
    "- **level**: `int` or `name`, optional\n",
    "\n",
    "  - If the Series has a `MultiIndex`, this parameter allows comparison across a specific level of the index.\n",
    "\n",
    "- **fill_value**: `scalar`, optional, default `None`\n",
    "\n",
    "  - If there are missing (NaN) values in either of the Series, this value will be used to fill those missing values before performing the comparison.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, optional\n",
    "  - This parameter is unused for Series but is included for compatibility with DataFrame operations.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A boolean Series indicating the result of the element-wise comparison (`True` if the value is greater than or equal to the corresponding value in `other`, `False` otherwise).\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Comparison (Without Missing Values)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series\n",
    "a = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, 3, 2, 1], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Compare if elements in 'a' are greater than or equal to corresponding elements in 'b'\n",
    "result = a.ge(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    False\n",
    "b     True\n",
    "c     True\n",
    "d     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- The result is a boolean Series where each value is `True` if the corresponding value in `a` is greater than or equal to the value in `b`.\n",
    "\n",
    "#### Example 2: Comparison with Missing Values\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create Series with missing values\n",
    "a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
    "b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
    "\n",
    "# Compare with fill_value for NaNs\n",
    "result = a.ge(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b     True\n",
    "c    False\n",
    "d    False\n",
    "e     True\n",
    "f    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- In this example, the comparison is done element-wise. The NaN values are filled with `0` before performing the comparison. For instance:\n",
    "  - For index `a`, `1.0 >= 0.0` is `True`.\n",
    "  - For index `b`, `1.0 >= 1.0` is `True`.\n",
    "  - For index `c`, `1.0 >= 2.0` is `False`.\n",
    "  - For index `d`, `NaN` is compared with `NaN`, which results in `False`.\n",
    "\n",
    "#### Example 3: Comparison with a Scalar Value\n",
    "\n",
    "```python\n",
    "# Compare each element in the Series to a scalar value\n",
    "result = a.ge(1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b     True\n",
    "c     True\n",
    "d    False\n",
    "e     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- Here, every element in `a` is compared to the scalar value `1`. The result is `True` for values that are greater than or equal to `1` and `False` for values that are less than `1`.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.lt()`**: Less than comparison (`<`).\n",
    "- **`Series.gt()`**: Greater than comparison (`>`).\n",
    "- **`Series.le()`**: Less than or equal to comparison (`<=`).\n",
    "- **`Series.eq()`**: Equal to comparison (`==`).\n",
    "\n",
    "The **`ge()`** function is useful when you need to perform element-wise comparisons for \"greater than or equal to\" conditions, especially when dealing with missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.ne\n",
    "Series.ne(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Not equal to of series and other, element-wise (binary operator ne).\n",
    "\n",
    "Equivalent to series != other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series or scalar value\n",
    "level\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.ne(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.ne()`** function in pandas is used to compare whether the elements in a Series are \"not equal to\" another Series or a scalar. This is an element-wise comparison and supports handling missing (NaN) values by allowing the use of a `fill_value` before performing the comparison.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.ne(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The Series or scalar value with which to compare each element in the original Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional\n",
    "\n",
    "  - This parameter is used if the Series has a `MultiIndex`. It allows comparison across a specific level of the index.\n",
    "\n",
    "- **fill_value**: `scalar`, optional, default `None`\n",
    "\n",
    "  - If the Series or `other` contains missing (NaN) values, this value will be used to fill those NaNs before the comparison.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, optional\n",
    "  - This parameter is unused for Series but is kept for compatibility with DataFrame operations.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A boolean Series indicating the result of the element-wise \"not equal to\" comparison (`True` if the values are not equal, `False` otherwise).\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Comparison (Without Missing Values)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series\n",
    "a = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, 3, 2, 1], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Compare if elements in 'a' are not equal to corresponding elements in 'b'\n",
    "result = a.ne(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b     True\n",
    "c     True\n",
    "d     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- The result is a boolean Series where each value is `True` if the corresponding values in `a` and `b` are not equal.\n",
    "\n",
    "#### Example 2: Comparison with Missing Values\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create Series with missing values\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "\n",
    "# Compare with fill_value for NaNs\n",
    "result = a.ne(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    False\n",
    "b     True\n",
    "c     True\n",
    "d     True\n",
    "e     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- In this example, missing values are filled with `0` before performing the comparison. For instance:\n",
    "  - For index `a`, `1.0 != 1.0` is `False`.\n",
    "  - For index `b`, `1.0 != NaN` is `True` (after filling NaN with `0`).\n",
    "  - For index `d`, `NaN != NaN` is `True` (after filling NaN with `0`).\n",
    "\n",
    "#### Example 3: Comparison with a Scalar Value\n",
    "\n",
    "```python\n",
    "# Compare each element in the Series to a scalar value\n",
    "result = a.ne(1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    False\n",
    "b    False\n",
    "c    False\n",
    "d     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- Here, each element of `a` is compared to the scalar value `1`. The result is `False` where the value is `1` and `True` where it is not.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.eq()`**: Equal to comparison (`==`).\n",
    "- **`Series.lt()`**: Less than comparison (`<`).\n",
    "- **`Series.le()`**: Less than or equal to comparison (`<=`).\n",
    "- **`Series.gt()`**: Greater than comparison (`>`).\n",
    "- **`Series.ge()`**: Greater than or equal to comparison (`>=`).\n",
    "\n",
    "The **`ne()`** function is useful for performing element-wise \"not equal to\" comparisons, especially when working with missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.eq\n",
    "Series.eq(other, level=None, fill_value=None, axis=0)[source]\n",
    "Return Equal to of series and other, element-wise (binary operator eq).\n",
    "\n",
    "Equivalent to series == other, but with support to substitute a fill_value for missing data in either one of the inputs.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series or scalar value\n",
    "level\n",
    "int or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "None or float value, default None (NaN)\n",
    "Fill existing missing (NaN) values, and any new element needed for successful Series alignment, with this value before computation. If data in both corresponding Series locations is missing the result of filling (at that location) will be missing.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The result of the operation. \"\"\"\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.eq(b, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.eq()`** function in pandas is used to compare if each element in a Series is equal to the corresponding element in another Series or a scalar. It is an element-wise comparison with support for handling missing values (NaN), using a `fill_value` before performing the comparison.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.eq(other, level=None, fill_value=None, axis=0)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: `Series` or `scalar`\n",
    "\n",
    "  - The Series or scalar value to compare against each element in the original Series.\n",
    "\n",
    "- **level**: `int` or `name`, optional\n",
    "\n",
    "  - Used if the Series has a `MultiIndex`. It specifies the level on which to perform the comparison.\n",
    "\n",
    "- **fill_value**: `scalar`, optional, default `None`\n",
    "\n",
    "  - If either Series contains missing (NaN) values, this value will be used to fill them before the comparison.\n",
    "\n",
    "- **axis**: `{0 or 'index'}`, optional\n",
    "  - This parameter is not used for Series but is kept for compatibility with DataFrame operations.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A boolean Series indicating the result of the element-wise equality comparison (`True` if the values are equal, `False` otherwise).\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Comparison (Without Missing Values)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series\n",
    "a = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([4, 3, 2, 1], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Compare if elements in 'a' are equal to corresponding elements in 'b'\n",
    "result = a.eq(b)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    False\n",
    "b    False\n",
    "c    False\n",
    "d    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- The result is `False` for all indices because the corresponding values in `a` and `b` are not equal.\n",
    "\n",
    "#### Example 2: Comparison with Missing Values\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create Series with missing values\n",
    "a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
    "b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
    "\n",
    "# Compare with fill_value for NaNs\n",
    "result = a.eq(b, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b    False\n",
    "c     True\n",
    "d    False\n",
    "e    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- In this example, missing values (NaNs) are replaced with `0` before the comparison. For instance:\n",
    "  - For index `a`, `1.0 == 1.0` is `True`.\n",
    "  - For index `b`, `1.0 == NaN` is `False` (since NaN is filled with `0`).\n",
    "  - For index `d`, `NaN == NaN` is `False` (since NaN is filled with `0`).\n",
    "\n",
    "#### Example 3: Comparison with a Scalar Value\n",
    "\n",
    "```python\n",
    "# Compare each element in the Series to a scalar value\n",
    "result = a.eq(1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a     True\n",
    "b     True\n",
    "c     True\n",
    "d    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- Here, each element of `a` is compared to the scalar value `1`. The result is `True` for the elements that are equal to `1` and `False` where they are not.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.ne()`**: Not equal to comparison (`!=`).\n",
    "- **`Series.lt()`**: Less than comparison (`<`).\n",
    "- **`Series.le()`**: Less than or equal to comparison (`<=`).\n",
    "- **`Series.gt()`**: Greater than comparison (`>`).\n",
    "- **`Series.ge()`**: Greater than or equal to comparison (`>=`).\n",
    "\n",
    "The **`eq()`** function is useful for performing element-wise equality comparisons and can handle missing values efficiently by filling them before the comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.product\n",
    "Series.product(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)[source]\n",
    "Return the product of the values over the requested axis.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Warning\n",
    "\n",
    "The behavior of DataFrame.prod with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar To retain the old behavior, pass axis=0 (or do not pass axis).\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "min_countint, default 0\n",
    "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar\n",
    "See also\n",
    "\n",
    "Series.sum\n",
    "Return the sum.\n",
    "\n",
    "Series.min\n",
    "Return the minimum.\n",
    "\n",
    "Series.max\n",
    "Return the maximum.\n",
    "\n",
    "Series.idxmin\n",
    "Return the index of the minimum.\n",
    "\n",
    "Series.idxmax\n",
    "Return the index of the maximum.\n",
    "\n",
    "DataFrame.sum\n",
    "Return the sum over the requested axis.\n",
    "\n",
    "DataFrame.min\n",
    "Return the minimum over the requested axis.\n",
    "\n",
    "DataFrame.max\n",
    "Return the maximum over the requested axis.\n",
    "\n",
    "DataFrame.idxmin\n",
    "Return the index of the minimum over the requested axis.\n",
    "\n",
    "DataFrame.idxmax\n",
    "Return the index of the maximum over the requested axis. \"\"\"\n",
    "\n",
    "pd.Series([], dtype=\"float64\").prod()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([], dtype=\"float64\").prod(min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([np.nan]).prod()\n",
    "pd.Series([np.nan]).prod(min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.product()`** function in pandas calculates the product of the values in a Series along a specified axis (in this case, it is primarily used with a single axis, i.e., the Series itself). It multiplies the elements together and can handle missing data based on specific parameters.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.product(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **axis**: `{index (0)}`, optional, default `None`\n",
    "\n",
    "  - This parameter is unused for Series (since Series is 1D), and the default behavior is to compute the product along the only axis (axis 0).\n",
    "\n",
    "- **skipna**: `bool`, default `True`\n",
    "  - Excludes missing (NA) values when performing the calculation. If set to `False`, the presence of NaN will result in the entire product being NaN.\n",
    "- **numeric_only**: `bool`, default `False`\n",
    "\n",
    "  - If set to `True`, it will include only numeric (int, float, or boolean) data. This parameter is not implemented for Series but is available for DataFrame.\n",
    "\n",
    "- **min_count**: `int`, default `0`\n",
    "\n",
    "  - Specifies the minimum number of non-null values required to perform the operation. If there are fewer than `min_count` non-null values, the result will be NaN.\n",
    "\n",
    "- **kwargs**: Additional arguments to be passed to the function.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- A scalar value representing the product of the values in the Series.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Default Behavior (Product of All Values)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([2, 3, 4])\n",
    "\n",
    "# Calculate the product of the values in the Series\n",
    "result = s.prod()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "- The product of `2 * 3 * 4` is `24`.\n",
    "\n",
    "#### Example 2: Handling Missing Values (`skipna=True`)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Series with a NaN value\n",
    "s = pd.Series([2, np.nan, 4])\n",
    "\n",
    "# Calculate the product, skipping NaN values\n",
    "result = s.prod()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "8.0\n",
    "```\n",
    "\n",
    "- By default, `skipna=True`, so the NaN value is excluded from the product calculation, and `2 * 4 = 8`.\n",
    "\n",
    "#### Example 3: Handling Missing Values with `skipna=False`\n",
    "\n",
    "```python\n",
    "# Calculate the product, without skipping NaN values\n",
    "result = s.prod(skipna=False)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "- Since there is a NaN value and `skipna=False`, the product is `NaN`.\n",
    "\n",
    "#### Example 4: Empty Series with `min_count`\n",
    "\n",
    "```python\n",
    "# Create an empty Series\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "\n",
    "# Calculate the product of an empty Series\n",
    "result = s.prod()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1.0\n",
    "```\n",
    "\n",
    "- By default, the product of an empty Series is `1`.\n",
    "\n",
    "#### Example 5: Empty Series with `min_count=1`\n",
    "\n",
    "```python\n",
    "# Calculate the product, requiring at least 1 valid value\n",
    "result = s.prod(min_count=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "- When `min_count=1`, the product is `NaN` because the Series is empty, and there are no valid values to multiply.\n",
    "\n",
    "#### Example 6: Series with NaN and `min_count=1`\n",
    "\n",
    "```python\n",
    "# Series with a NaN value\n",
    "s = pd.Series([np.nan])\n",
    "\n",
    "# Calculate the product with min_count=1\n",
    "result = s.prod(min_count=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "- Even though there is a single element (which is NaN), with `min_count=1`, the product is `NaN` because there are no valid numeric values.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.sum()`**: To calculate the sum of the values in a Series.\n",
    "- **`Series.min()`**: To calculate the minimum value of the Series.\n",
    "- **`Series.max()`**: To calculate the maximum value of the Series.\n",
    "- **`Series.idxmin()`**: To get the index of the minimum value in the Series.\n",
    "- **`Series.idxmax()`**: To get the index of the maximum value in the Series.\n",
    "\n",
    "The **`Series.product()`** function is a simple but powerful method to calculate the product of all values in a Series, with support for handling missing data and specifying minimum valid values required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "pandas.Series.dot\n",
    "\n",
    "\n",
    "Series.dot(other)\n",
    "\n",
    "\n",
    "\n",
    "Compute the dot product between the Series and the columns of other.\n",
    "\n",
    "This method computes the dot product between the Series and another one, or the Series and each columns of a DataFrame, or the Series and each columns of an array.\n",
    "\n",
    "It can also be called using self @ other.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series, DataFrame or array-like\n",
    "The other object to compute the dot product with its columns.\n",
    "\n",
    "Returns\n",
    ":\n",
    "scalar, Series or numpy.ndarray\n",
    "Return the dot product of the Series and other if other is a Series, the Series of the dot product of Series and each rows of other if other is a DataFrame or a numpy.ndarray between the Series and each columns of the numpy array.\n",
    "\n",
    "\n",
    "DataFrame.dot\n",
    "Compute the matrix product with the DataFrame.\n",
    "\n",
    "Series.mul\n",
    "Multiplication of series and other, element-wise. \"\"\"\n",
    "\n",
    "s = pd.Series([0, 1, 2, 3])\n",
    "other = pd.Series([-1, 2, -3, 4])\n",
    "s.dot(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s @ other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
    "s.dot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
    "s.dot(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.dot()`** method in pandas computes the dot product between the Series and another object (Series, DataFrame, or array-like). It's a vectorized operation for calculating the sum of the element-wise product between two series or matrices.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.dot(other)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **other**: Series, DataFrame, or array-like\n",
    "  - The object with which you want to compute the dot product. If `other` is a Series, the result will be a scalar (a single value).\n",
    "  - If `other` is a DataFrame or an array, the method computes the dot product with each column (if a DataFrame) or each column (if a NumPy array).\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **scalar**: If `other` is a Series, returns a scalar value representing the dot product.\n",
    "- **Series**: If `other` is a DataFrame, returns a Series where each element is the dot product between the Series and each column of the DataFrame.\n",
    "- **numpy.ndarray**: If `other` is a NumPy array, returns an ndarray with the dot product between the Series and each column of the array.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Dot Product of Two Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([0, 1, 2, 3])\n",
    "other = pd.Series([-1, 2, -3, 4])\n",
    "\n",
    "result = s.dot(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "8\n",
    "```\n",
    "\n",
    "- The dot product is calculated as `0*(-1) + 1*2 + 2*(-3) + 3*4 = 8`.\n",
    "\n",
    "You can also use the `@` operator, which is equivalent to `dot()`:\n",
    "\n",
    "```python\n",
    "result = s @ other\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "8\n",
    "```\n",
    "\n",
    "#### Example 2: Dot Product with a DataFrame\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "result = s.dot(df)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    24\n",
    "1    14\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The dot product is computed between the Series and each column of the DataFrame:\n",
    "  - For column 0: `1*0 + 2*(-2) + 3*4 + 4*6 = 24`\n",
    "  - For column 1: `1*1 + 2*3 + 3*(-5) + 4*7 = 14`\n",
    "\n",
    "#### Example 3: Dot Product with a NumPy Array\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "result = s.dot(arr)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "[24 14]\n",
    "```\n",
    "\n",
    "- The dot product is computed between the Series and each column of the NumPy array.\n",
    "\n",
    "#### Notes:\n",
    "\n",
    "- **Index Alignment**: When `other` is a Series or a DataFrame, it is important that the indices of the two Series align. If the indices do not match, pandas will align them by index before performing the dot product, which might result in `NaN` values for mismatched indices.\n",
    "- **Matrix Multiplication**: The dot product for DataFrames is equivalent to matrix multiplication if the number of rows in the Series and the number of columns in the DataFrame match.\n",
    "- **NumPy Compatibility**: This method also works with NumPy arrays, providing flexibility in numerical computations.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`DataFrame.dot()`**: To compute the matrix product of a DataFrame with another DataFrame or array.\n",
    "- **`Series.mul()`**: Element-wise multiplication between two Series.\n",
    "- **`numpy.dot()`**: Direct dot product computation in NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.apply\n",
    "\n",
    "Series.apply(func, convert_dtype=<no_default>, args=(), *, by_row='compat', **kwargs)[source]\n",
    "Invoke function on values of Series.\n",
    "\n",
    "Can be ufunc (a NumPy function that applies to the entire Series) or a Python function that only works on single values.\n",
    "\n",
    "Parameters:\n",
    "funcfunction\n",
    "Python function or NumPy ufunc to apply.\n",
    "\n",
    "convert_dtypebool, default True\n",
    "Try to find better dtype for elementwise function results. If False, leave as dtype=object. Note that the dtype is always preserved for some extension array dtypes, such as Categorical.\n",
    "\n",
    "Deprecated since version 2.1.0: convert_dtype has been deprecated. Do ser.astype(object).apply() instead if you want convert_dtype=False.\n",
    "\n",
    "argstuple\n",
    "Positional arguments passed to func after the series value.\n",
    "\n",
    "by_rowFalse or “compat”, default “compat”\n",
    "If \"compat\" and func is a callable, func will be passed each element of the Series, like Series.map. If func is a list or dict of callables, will first try to translate each func into pandas methods. If that doesn’t work, will try call to apply again with by_row=\"compat\" and if that fails, will call apply again with by_row=False (backward compatible). If False, the func will be passed the whole Series at once.\n",
    "\n",
    "by_row has no effect when func is a string.\n",
    "\n",
    "Added in version 2.1.0.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments passed to func.\n",
    "\n",
    "Returns:\n",
    "Series or DataFrame\n",
    "If func returns a Series object the result will be a DataFrame. \"\"\"\n",
    "\n",
    "s = pd.Series([20, 21, 12],\n",
    "              index=['London', 'New York', 'Helsinki'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "s.apply(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.apply(lambda x: x ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_custom_value(x, custom_value):\n",
    "     return x - custom_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.apply(subtract_custom_value, args=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.apply()`** method allows you to apply a function along the values of a pandas Series. It is versatile and can work with NumPy ufuncs (functions that apply to entire arrays) or custom Python functions that apply to individual values in the Series.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.apply(func, convert_dtype=True, args=(), *, by_row='compat', **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **func**: function (Python or NumPy ufunc)\n",
    "  - A function or callable object that will be applied to the values in the Series.\n",
    "- **convert_dtype**: bool, default `True`\n",
    "\n",
    "  - Attempt to find the best dtype for the result of the function. If `False`, the dtype will be left as `object`.\n",
    "  - **Deprecated** since version 2.1.0. Instead, you should use `astype(object).apply()` if you want `convert_dtype=False`.\n",
    "\n",
    "- **args**: tuple\n",
    "  - Positional arguments to pass to the function after the Series values.\n",
    "- **by_row**: {'compat', False}, default 'compat'\n",
    "\n",
    "  - Controls how the function is applied:\n",
    "    - If `'compat'`, the function is applied element-wise (similar to `map()`).\n",
    "    - If `False`, the function will be applied to the whole Series.\n",
    "    - This parameter is relevant only if `func` is a list or dictionary of callables.\n",
    "\n",
    "- **kwargs**: additional keyword arguments passed to `func`.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series** or **DataFrame**\n",
    "  - If `func` returns a Series, the result will be a DataFrame.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Applying a custom function to square values\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([20, 21, 12], index=['London', 'New York', 'Helsinki'])\n",
    "\n",
    "# Define a function to square the values\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Apply the function to each element in the Series\n",
    "result = s.apply(square)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 2: Applying a lambda function\n",
    "\n",
    "```python\n",
    "# Apply a lambda function to square the values\n",
    "result = s.apply(lambda x: x ** 2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 3: Passing additional positional arguments to a function\n",
    "\n",
    "```python\n",
    "# Define a custom function that subtracts a custom value\n",
    "def subtract_custom_value(x, custom_value):\n",
    "    return x - custom_value\n",
    "\n",
    "# Apply the function with an additional argument (5)\n",
    "result = s.apply(subtract_custom_value, args=(5,))\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "London      15\n",
    "New York    16\n",
    "Helsinki     7\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 4: Passing keyword arguments to a function\n",
    "\n",
    "```python\n",
    "# Define a custom function that adds custom values for each month\n",
    "def add_custom_values(x, **kwargs):\n",
    "    for month in kwargs:\n",
    "        x += kwargs[month]\n",
    "    return x\n",
    "\n",
    "# Apply the function with keyword arguments\n",
    "result = s.apply(add_custom_values, june=30, july=20, august=25)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "London      95\n",
    "New York    96\n",
    "Helsinki    87\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 5: Applying a NumPy function\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Apply a NumPy function (logarithm) to the Series\n",
    "result = s.apply(np.log)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "London      2.995732\n",
    "New York    3.044522\n",
    "Helsinki    2.484907\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The **`apply()`** method is useful for both element-wise operations (like `map()`) and operations that require access to the entire Series (like aggregation).\n",
    "- **Performance**: While flexible, `apply()` can be slower than vectorized operations (like NumPy functions or pandas' built-in methods).\n",
    "- **Function Compatibility**: Functions that mutate the passed object might produce unexpected behavior, so they are not recommended.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.map()`**: For element-wise mapping operations, similar to `apply()`, but simpler for dictionary or function-based mappings.\n",
    "- **`Series.agg()`**: To perform aggregations (sum, mean, etc.) over the Series.\n",
    "- **`Series.transform()`**: To apply functions to a Series while preserving its shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.agg\n",
    "Series.agg(func=None, axis=0, *args, **kwargs)[source]\n",
    "Aggregate using one or more operations over the specified axis.\n",
    "\n",
    "Parameters:\n",
    "funcfunction, str, list or dict\n",
    "Function to use for aggregating the data. If a function, must either work when passed a Series or when passed to Series.apply.\n",
    "\n",
    "Accepted combinations are:\n",
    "\n",
    "function\n",
    "\n",
    "string function name\n",
    "\n",
    "list of functions and/or function names, e.g. [np.sum, 'mean']\n",
    "\n",
    "dict of axis labels -> functions, function names or list of such.\n",
    "\n",
    "axis{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "*args\n",
    "Positional arguments to pass to func.\n",
    "\n",
    "**kwargs\n",
    "Keyword arguments to pass to func.\n",
    "\n",
    "Returns:\n",
    "scalar, Series or DataFrame\n",
    "The return can be:\n",
    "\n",
    "scalar : when Series.agg is called with single function\n",
    "\n",
    "Series : when DataFrame.agg is called with a single function\n",
    "\n",
    "DataFrame : when DataFrame.agg is called with several functions\n",
    "\n",
    "\n",
    "\n",
    "Series.apply\n",
    "Invoke function on a Series.\n",
    "\n",
    "Series.transform\n",
    "Transform function producing a Series with like indexes. \"\"\"\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.agg('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.agg()`** method is used to apply one or more aggregation functions to a Series. Aggregation functions compute a summary statistic for the data in a Series, such as sum, mean, min, max, etc.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.agg(func=None, axis=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **func**: function, str, list, or dict\n",
    "\n",
    "  - **function**: A single function (e.g., `np.sum`, `mean`, `max`, etc.) to apply to the Series.\n",
    "  - **str**: A string that represents the name of a function (e.g., 'sum', 'mean').\n",
    "  - **list**: A list of functions or string names. Multiple functions can be applied at once (e.g., `['sum', 'mean']`).\n",
    "  - **dict**: A dictionary where the keys are axis labels (e.g., column names for DataFrame) and the values are functions or lists of functions. This is useful when applying different functions to different columns.\n",
    "\n",
    "- **axis**: {0 or 'index'}\n",
    "\n",
    "  - This parameter is for compatibility with DataFrame and is unused for Series.\n",
    "\n",
    "- **args**: tuple\n",
    "\n",
    "  - Positional arguments to pass to the function(s).\n",
    "\n",
    "- **kwargs**: dict\n",
    "  - Additional keyword arguments to pass to the function(s).\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **scalar**: If a single function is applied, a scalar result will be returned.\n",
    "- **Series**: If multiple functions are applied and the result is a single function, a Series will be returned.\n",
    "- **DataFrame**: If multiple functions are applied to different columns (in case of DataFrame), the result is a DataFrame.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Applying a single function (e.g., 'min')\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "# Apply the 'min' aggregation function\n",
    "result = s.agg('min')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1\n",
    "```\n",
    "\n",
    "#### Example 2: Applying multiple functions (e.g., 'min' and 'max')\n",
    "\n",
    "```python\n",
    "# Apply multiple functions to the Series\n",
    "result = s.agg(['min', 'max'])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "min    1\n",
    "max    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 3: Using a list of functions (e.g., np.sum, np.mean)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Apply a list of functions to the Series\n",
    "result = s.agg([np.sum, np.mean])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "sum      10\n",
    "mean      2.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 4: Using a dictionary to apply different functions to different columns (for a DataFrame)\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "# Apply different functions to different columns\n",
    "result = df.agg({'A': 'sum', 'B': 'mean'})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A     6\n",
    "B     5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- **Aggregation functions** are performed **over an axis** (index in the case of Series, columns in the case of DataFrame).\n",
    "- The **`agg()`** method provides a flexible way to apply one or more aggregation functions to a Series or DataFrame. It can handle a wide range of use cases, from applying single functions to applying different functions to different columns.\n",
    "- **Functions that mutate the passed object** (such as modifying values in-place) are not supported with `agg()`.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.apply()`**: For applying a custom function to each element of the Series.\n",
    "- **`Series.transform()`**: For transforming data in a Series while keeping its shape.\n",
    "- **`DataFrame.agg()`**: To apply aggregation functions on DataFrame columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.aggregate\n",
    "Series.aggregate(func=None, axis=0, *args, **kwargs)[source]\n",
    "Aggregate using one or more operations over the specified axis.\n",
    "\n",
    "Parameters:\n",
    "funcfunction, str, list or dict\n",
    "Function to use for aggregating the data. If a function, must either work when passed a Series or when passed to Series.apply.\n",
    "\n",
    "Accepted combinations are:\n",
    "\n",
    "function\n",
    "\n",
    "string function name\n",
    "\n",
    "list of functions and/or function names, e.g. [np.sum, 'mean']\n",
    "\n",
    "dict of axis labels -> functions, function names or list of such.\n",
    "\n",
    "axis{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "*args\n",
    "Positional arguments to pass to func.\n",
    "\n",
    "**kwargs\n",
    "Keyword arguments to pass to func.\n",
    "\n",
    "Returns:\n",
    "scalar, Series or DataFrame\n",
    "The return can be:\n",
    "\n",
    "scalar : when Series.agg is called with single function\n",
    "\n",
    "Series : when DataFrame.agg is called with a single function\n",
    "\n",
    "DataFrame : when DataFrame.agg is called with several functions\n",
    "\n",
    "See also\n",
    "\n",
    "Series.apply\n",
    "Invoke function on a Series.\n",
    "\n",
    "Series.transform\n",
    "Transform function producing a Series with like indexes. \"\"\"\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.agg('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.aggregate()`** method in pandas is used to apply one or more aggregation functions to a Series, which helps in obtaining summary statistics or reducing the data into a single result or multiple results based on the functions applied.\n",
    "\n",
    "The **`aggregate()`** method is an alias for the **`agg()`** method, and they are used interchangeably. Both methods allow the use of aggregation functions like `sum`, `mean`, `min`, `max`, and even user-defined functions.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.aggregate(func=None, axis=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **func**: function, str, list, or dict\n",
    "\n",
    "  - **function**: A function (e.g., `np.sum`, `mean`, `max`, etc.) to apply to the Series.\n",
    "  - **str**: A string representing a function name (e.g., 'sum', 'mean', 'min').\n",
    "  - **list**: A list of functions or string names. You can apply multiple functions at once (e.g., `['sum', 'max']`).\n",
    "  - **dict**: A dictionary where keys are axis labels (for DataFrames) and values are functions or lists of functions. This is particularly useful when applying different aggregation functions to different columns in a DataFrame.\n",
    "\n",
    "- **axis**: {0 or 'index'}\n",
    "\n",
    "  - This parameter is for compatibility with DataFrame (it’s unused for Series).\n",
    "\n",
    "- **args**: tuple\n",
    "\n",
    "  - Positional arguments to pass to the aggregation function(s).\n",
    "\n",
    "- **kwargs**: dict\n",
    "  - Additional keyword arguments to pass to the function(s).\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **scalar**: If a single function is applied, it returns a scalar.\n",
    "- **Series**: If multiple functions are applied, it returns a Series containing the results of the aggregation.\n",
    "- **DataFrame**: If different functions are applied to different columns (for DataFrames), it returns a DataFrame.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Applying a single function (e.g., 'min')\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "# Apply the 'min' aggregation function\n",
    "result = s.aggregate('min')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1\n",
    "```\n",
    "\n",
    "#### Example 2: Applying multiple functions (e.g., 'min' and 'max')\n",
    "\n",
    "```python\n",
    "# Apply multiple functions to the Series\n",
    "result = s.aggregate(['min', 'max'])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "min    1\n",
    "max    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 3: Using a list of functions (e.g., np.sum, np.mean)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Apply a list of functions to the Series\n",
    "result = s.aggregate([np.sum, np.mean])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "sum      10\n",
    "mean      2.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 4: Using a dictionary to apply different functions to different columns (for DataFrame)\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "# Apply different functions to different columns\n",
    "result = df.aggregate({'A': 'sum', 'B': 'mean'})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A     6\n",
    "B     5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- **`aggregate()` and `agg()`** are interchangeable, and both methods allow the application of one or more aggregation functions to the Series.\n",
    "- The aggregation operations are performed over an axis, which is usually the index (default for Series).\n",
    "- **Functions that mutate the passed object** (e.g., changing values in-place) are not supported when using `aggregate()`.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.apply()`**: For applying a custom function to each element of the Series.\n",
    "- **`Series.transform()`**: For transforming data and returning a Series with a similar index.\n",
    "- **`DataFrame.aggregate()`**: For applying aggregation functions across DataFrame columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.transform\n",
    "Series.transform(func, axis=0, *args, **kwargs)[source]\n",
    "Call func on self producing a Series with the same axis shape as self.\n",
    "\n",
    "Parameters:\n",
    "funcfunction, str, list-like or dict-like\n",
    "Function to use for transforming the data. If a function, must either work when passed a Series or when passed to Series.apply. If func is both list-like and dict-like, dict-like behavior takes precedence.\n",
    "\n",
    "Accepted combinations are:\n",
    "\n",
    "function\n",
    "\n",
    "string function name\n",
    "\n",
    "list-like of functions and/or function names, e.g. [np.exp, 'sqrt']\n",
    "\n",
    "dict-like of axis labels -> functions, function names or list-like of such.\n",
    "\n",
    "axis{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "*args\n",
    "Positional arguments to pass to func.\n",
    "\n",
    "**kwargs\n",
    "Keyword arguments to pass to func.\n",
    "\n",
    "Returns:\n",
    "\n",
    "Series\n",
    "A Series that must have the same length as self.\n",
    "\n",
    "Raises:\n",
    "ValueError\n",
    "If the returned Series has a different length than self.\n",
    "\n",
    "\n",
    "Series.agg\n",
    "Only perform aggregating type operations.\n",
    "\n",
    "Series.apply\n",
    "Invoke function on a Series. \"\"\"\n",
    "df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transform(lambda x: x + 1  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(range(3))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Date\": [\n",
    "        \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
    "        \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
    "    \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Date')['Data'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
    "    \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'] = df.groupby('c')['type'].transform(len)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.transform()`** method in pandas is used to apply a function (or a list of functions) to a Series while ensuring that the transformed Series has the same shape as the original. It's often used for element-wise transformations and produces a new Series with the same index and length.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.transform(func, axis=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **func**: function, str, list-like, or dict-like\n",
    "\n",
    "  - **function**: A single function that operates element-wise on the Series. This could be a numpy function or a custom Python function.\n",
    "  - **str**: A string representing a function name (e.g., 'sqrt', 'log', 'exp').\n",
    "  - **list-like**: A list of functions or function names that will be applied to the Series.\n",
    "  - **dict-like**: A dictionary with axis labels as keys and functions or lists of functions as values (typically used with DataFrames).\n",
    "\n",
    "- **axis**: {0 or ‘index’}\n",
    "\n",
    "  - This parameter is unused for Series but kept for compatibility with DataFrame.\n",
    "\n",
    "- **args**: tuple\n",
    "\n",
    "  - Positional arguments passed to the function.\n",
    "\n",
    "- **kwargs**: dict\n",
    "  - Additional keyword arguments passed to the function.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A transformed Series, which must have the same length as the original Series.\n",
    "\n",
    "### **Raises**\n",
    "\n",
    "- **ValueError**: If the returned Series has a different length than the original.\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- **`transform()`** is designed for element-wise transformations where the output should have the same shape as the input.\n",
    "- Unlike **`agg()`**, which is used for aggregation and might return a scalar, **`transform()`** is used to return a transformed Series with the same axis shape as the original.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Simple transformation with a lambda function\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
    "\n",
    "# Apply a lambda function to add 1 to each element\n",
    "result = df.transform(lambda x: x + 1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A  B\n",
    "0  1  2\n",
    "1  2  3\n",
    "2  3  4\n",
    "```\n",
    "\n",
    "#### Example 2: Applying multiple functions (e.g., `np.sqrt` and `np.exp`)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([0, 1, 2])\n",
    "\n",
    "# Apply multiple functions to the Series\n",
    "result = s.transform([np.sqrt, np.exp])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "       sqrt        exp\n",
    "0  0.000000   1.000000\n",
    "1  1.000000   2.718282\n",
    "2  1.414214   7.389056\n",
    "```\n",
    "\n",
    "#### Example 3: Using transform with GroupBy\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Date\": [\"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\", \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
    "    \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
    "})\n",
    "\n",
    "# Use transform to get the sum of 'Data' for each 'Date'\n",
    "result = df.groupby('Date')['Data'].transform('sum')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0     55\n",
    "1    108\n",
    "2     66\n",
    "3    121\n",
    "4     55\n",
    "5    108\n",
    "6     66\n",
    "7    121\n",
    "Name: Data, dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 4: Adding a new column with the size of each group\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
    "    \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
    "})\n",
    "\n",
    "# Use transform to add the size of each group to the 'size' column\n",
    "df['size'] = df.groupby('c')['type'].transform(len)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   c type  size\n",
    "0  1    m     3\n",
    "1  1    n     3\n",
    "2  1    o     3\n",
    "3  2    m     4\n",
    "4  2    m     4\n",
    "5  2    n     4\n",
    "6  2    n     4\n",
    "```\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.apply()`**: For applying a function to each element of the Series.\n",
    "- **`Series.agg()`**: For aggregation operations over a Series.\n",
    "- **`Series.map()`**: For element-wise transformation using a dictionary or a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.map\n",
    "Series.map(arg, na_action=None)[source]\n",
    "Map values of Series according to an input mapping or function.\n",
    "\n",
    "Used for substituting each value in a Series with another value, that may be derived from a function, a dict or a Series.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "arg\n",
    "function, collections.abc.Mapping subclass or Series\n",
    "Mapping correspondence.\n",
    "\n",
    "na_action\n",
    "{None, ‘ignore’}, default None\n",
    "If ‘ignore’, propagate NaN values, without passing them to the mapping correspondence.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "Same index as caller.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.apply\n",
    "For applying more complex functions on a Series.\n",
    "\n",
    "Series.replace\n",
    "Replace values given in to_replace with value.\n",
    "\n",
    "DataFrame.apply\n",
    "Apply a function row-/column-wise.\n",
    "\n",
    "DataFrame.map\n",
    "Apply a function elementwise on a whole DataFrame. \"\"\"\n",
    "s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.map({'cat': 'kitten', 'dog': 'puppy'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.map('I am a {}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.map('I am a {}'.format, na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Series.map()`** method in pandas is used to map the values of a Series based on a function, dictionary, or another Series. It allows you to substitute each value in the Series with another value derived from the input mapping or function.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.map(arg, na_action=None)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **arg**: function, `collections.abc.Mapping` subclass, or Series\n",
    "\n",
    "  - **function**: A function to apply to each element in the Series.\n",
    "  - **`Mapping` subclass**: A dictionary-like object where keys correspond to the values in the Series. The dictionary can also be a `defaultdict` to provide default values for missing keys.\n",
    "  - **Series**: Another Series to map values. If the Series contains a value not found in the calling Series, it will return `NaN` unless the `na_action` is specified as 'ignore'.\n",
    "\n",
    "- **na_action**: {None, 'ignore'}, default None\n",
    "  - **None**: This is the default behavior, which means that missing values (`NaN`) will be passed to the mapping.\n",
    "  - **'ignore'**: This will propagate `NaN` values without passing them to the mapping function.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A new Series with the same index, with values transformed according to the `arg` mapping or function.\n",
    "\n",
    "### **See also**\n",
    "\n",
    "- **`Series.apply()`**: Use this for more complex functions that involve element-wise operations.\n",
    "- **`Series.replace()`**: Replaces values in a Series based on a given mapping.\n",
    "- **`DataFrame.apply()`**: Apply a function row-wise or column-wise on a DataFrame.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Mapping with a dictionary\n",
    "\n",
    "You can map values in a Series using a dictionary where the keys are the current values and the values are the corresponding replacements.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n",
    "\n",
    "# Use a dictionary for mapping\n",
    "result = s.map({'cat': 'kitten', 'dog': 'puppy'})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    kitten\n",
    "1     puppy\n",
    "2      NaN\n",
    "3      NaN\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "In this case, 'cat' is replaced with 'kitten' and 'dog' with 'puppy'. The `NaN` values are converted to `NaN` because they are not found in the dictionary.\n",
    "\n",
    "#### Example 2: Mapping with a function\n",
    "\n",
    "You can apply a function to each element of the Series. The function can reference the value in a formatted string or any transformation logic.\n",
    "\n",
    "```python\n",
    "result = s.map('I am a {}'.format)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0       I am a cat\n",
    "1       I am a dog\n",
    "2     I am a nan\n",
    "3    I am a rabbit\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "#### Example 3: Ignoring missing values with `na_action='ignore'`\n",
    "\n",
    "To prevent `NaN` values from being transformed, use the `na_action='ignore'` option.\n",
    "\n",
    "```python\n",
    "result = s.map('I am a {}'.format, na_action='ignore')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0       I am a cat\n",
    "1       I am a dog\n",
    "2            NaN\n",
    "3    I am a rabbit\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "In this case, `NaN` values are left unchanged because of the `na_action='ignore'` parameter.\n",
    "\n",
    "### **Summary of Use Cases**\n",
    "\n",
    "- **Mapping with a dictionary**: Use when you have a set of predefined replacements.\n",
    "- **Mapping with a function**: Use for more complex transformations, such as formatting or applying mathematical operations.\n",
    "- **Handling missing values**: Use `na_action='ignore'` to skip applying the function to `NaN` values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.groupby\n",
    "Series.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, observed=<no_default>, dropna=True)[source]\n",
    "Group Series using a mapper or by a Series of columns.\n",
    "\n",
    "A groupby operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups.\n",
    "\n",
    "Parameters:\n",
    "bymapping, function, label, pd.Grouper or list of such\n",
    "Used to determine the groups for the groupby. If by is a function, it’s called on each value of the object’s index. If a dict or Series is passed, the Series or dict VALUES will be used to determine the groups (the Series’ values are first aligned; see .align() method). If a list or ndarray of length equal to the selected axis is passed (see the groupby user guide), the values are used as-is to determine the groups. A label or list of labels may be passed to group by the columns in self. Notice that a tuple is interpreted as a (single) key.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Split along rows (0) or columns (1). For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Deprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version. For axis=1, do frame.T.groupby(...) instead.\n",
    "\n",
    "levelint, level name, or sequence of such, default None\n",
    "If the axis is a MultiIndex (hierarchical), group by a particular level or levels. Do not specify both by and level.\n",
    "\n",
    "as_indexbool, default True\n",
    "Return object with group labels as the index. Only relevant for DataFrame input. as_index=False is effectively “SQL-style” grouped output. This argument has no effect on filtrations (see the filtrations in the user guide), such as head(), tail(), nth() and in transformations (see the transformations in the user guide).\n",
    "\n",
    "sortbool, default True\n",
    "Sort group keys. Get better performance by turning this off. Note this does not influence the order of observations within each group. Groupby preserves the order of rows within each group. If False, the groups will appear in the same order as they did in the original DataFrame. This argument has no effect on filtrations (see the filtrations in the user guide), such as head(), tail(), nth() and in transformations (see the transformations in the user guide).\n",
    "\n",
    "Changed in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no longer sort the values.\n",
    "\n",
    "group_keysbool, default True\n",
    "When calling apply and the by argument produces a like-indexed (i.e. a transform) result, add group keys to index to identify pieces. By default group keys are not included when the result’s index (and column) labels match the inputs, and are included otherwise.\n",
    "\n",
    "Changed in version 1.5.0: Warns that group_keys will no longer be ignored when the result from apply is a like-indexed Series or DataFrame. Specify group_keys explicitly to include the group keys or not.\n",
    "\n",
    "Changed in version 2.0.0: group_keys now defaults to True.\n",
    "\n",
    "observedbool, default False\n",
    "This only applies if any of the groupers are Categoricals. If True: only show observed values for categorical groupers. If False: show all values for categorical groupers.\n",
    "\n",
    "Deprecated since version 2.1.0: The default value will change to True in a future version of pandas.\n",
    "\n",
    "dropnabool, default True\n",
    "If True, and if group keys contain NA values, NA values together with row/column will be dropped. If False, NA values will also be treated as the key in groups.\n",
    "\n",
    "Returns:\n",
    "pandas.api.typing.SeriesGroupBy\n",
    "Returns a groupby object that contains information about the groups.\n",
    "\n",
    "resample\n",
    "Convenience method for frequency conversion and resampling of time series. \"\"\"\n",
    "ser = pd.Series([390., 350., 30., 20.],\n",
    "                index=['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "                name=\"Max Speed\")\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.groupby([\"a\", \"b\", \"a\", \"b\"]).mean()\n",
    "ser.groupby(level=0).mean()\n",
    "ser.groupby(ser > 100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by Indexes\n",
    "\n",
    "# We can groupby different levels of a hierarchical index using the level parameter:\n",
    "\n",
    "arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "          ['Captive', 'Wild', 'Captive', 'Wild']]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
    "ser = pd.Series([390., 350., 30., 20.], index=index, name=\"Max Speed\")\n",
    "ser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.groupby(level=0).mean()\n",
    "ser.groupby(level=\"Type\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also choose to include NA in group keys or not by defining dropna parameter, the default setting is True.\n",
    "\n",
    "ser = pd.Series([1, 2, 3, 3], index=[\"a\", 'a', 'b', np.nan])\n",
    "ser.groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.groupby(level=0, dropna=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = ['Falcon', 'Falcon', 'Parrot', 'Parrot']\n",
    "ser = pd.Series([390., 350., 30., 20.], index=arrays, name=\"Max Speed\")\n",
    "ser.groupby([\"a\", \"b\", \"a\", np.nan]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.groupby([\"a\", \"b\", \"a\", np.nan], dropna=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.groupby()`** method is used to group data in a `Series` object based on certain criteria and apply functions (like aggregation, transformation, etc.) to those groups. This is a powerful way to perform operations like sums, means, or custom functions across groups of data.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, observed=<no_default>, dropna=True)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **by**: mapping, function, label, `pd.Grouper`, or list of such\n",
    "\n",
    "  - Defines how to group the data.\n",
    "  - This could be a dictionary, Series, or a function applied to the values of the index.\n",
    "  - You can also group by specific labels or levels in a `MultiIndex`.\n",
    "\n",
    "- **axis**: {0 or 'index', 1 or 'columns'}, default 0\n",
    "\n",
    "  - This parameter is ignored for Series and defaults to 0.\n",
    "  - In the future, the behavior will be removed, and the method will behave like `axis=0`.\n",
    "\n",
    "- **level**: int, level name, or sequence of such, default None\n",
    "\n",
    "  - Used when grouping by a particular level or levels in a `MultiIndex`.\n",
    "\n",
    "- **as_index**: bool, default True\n",
    "\n",
    "  - Determines whether to return the group labels as the index.\n",
    "  - If False, the output behaves like a SQL-style grouped output (i.e., doesn't set the group labels as the index).\n",
    "\n",
    "- **sort**: bool, default True\n",
    "\n",
    "  - Specifies whether to sort the group labels. You can turn this off for performance if sorting isn't necessary.\n",
    "\n",
    "- **group_keys**: bool, default True\n",
    "\n",
    "  - When using `apply()`, controls whether group keys are added to the index.\n",
    "\n",
    "- **observed**: bool, default False\n",
    "\n",
    "  - Relevant when using `Categorical` types. If True, only observed categories will be shown in the result.\n",
    "\n",
    "- **dropna**: bool, default True\n",
    "  - If True, `NA` values are excluded from the grouping keys.\n",
    "  - If False, `NA` values are treated as part of the groups.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **pandas.api.typing.SeriesGroupBy**: A GroupBy object containing information about the groups formed based on the provided criteria.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic GroupBy on Series\n",
    "\n",
    "You can group data based on a certain criterion (e.g., a custom list of group labels) and then apply an aggregation function like `mean()`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series([390., 350., 30., 20.], index=['Falcon', 'Falcon', 'Parrot', 'Parrot'], name=\"Max Speed\")\n",
    "print(ser.groupby([\"a\", \"b\", \"a\", \"b\"]).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    210.0\n",
    "b    185.0\n",
    "Name: Max Speed, dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 2: Grouping by Index Level in MultiIndex\n",
    "\n",
    "You can group data by a hierarchical index (MultiIndex) level.\n",
    "\n",
    "```python\n",
    "arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'], ['Captive', 'Wild', 'Captive', 'Wild']]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
    "ser = pd.Series([390., 350., 30., 20.], index=index, name=\"Max Speed\")\n",
    "print(ser.groupby(level=0).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Animal\n",
    "Falcon    370.0\n",
    "Parrot     25.0\n",
    "Name: Max Speed, dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 3: GroupBy with NA Values\n",
    "\n",
    "When the data contains `NaN` values, the `dropna` parameter controls whether the `NaN` values are included in the group.\n",
    "\n",
    "```python\n",
    "ser = pd.Series([1, 2, 3, 3], index=[\"a\", 'a', 'b', np.nan])\n",
    "print(ser.groupby(level=0).sum())\n",
    "print(ser.groupby(level=0, dropna=False).sum())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    3\n",
    "b    3\n",
    "dtype: int64\n",
    "a    3\n",
    "b    3\n",
    "NaN  3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 4: GroupBy with Conditional Grouping\n",
    "\n",
    "You can also group by conditions, such as grouping based on whether the values are greater than a certain threshold.\n",
    "\n",
    "```python\n",
    "ser = pd.Series([390., 350., 30., 20.], index=['Falcon', 'Falcon', 'Parrot', 'Parrot'], name=\"Max Speed\")\n",
    "print(ser.groupby(ser > 100).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Max Speed\n",
    "False     25.0\n",
    "True     370.0\n",
    "Name: Max Speed, dtype: float64\n",
    "```\n",
    "\n",
    "### **Grouping with Categorical Data**\n",
    "\n",
    "When using categorical data, you can control whether to include only observed categories using the `observed` parameter.\n",
    "\n",
    "```python\n",
    "ser = pd.Series([1, 2, 3, 3], index=[\"a\", 'a', 'b', np.nan])\n",
    "print(ser.groupby(level=0, observed=True).sum())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    3\n",
    "b    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### **Summary of Use Cases**\n",
    "\n",
    "- **Basic Grouping**: Group by a list of labels or a function, and then aggregate the groups (e.g., mean, sum).\n",
    "- **Hierarchical Index**: Use the `level` parameter to group by levels in a `MultiIndex`.\n",
    "- **Handling Missing Data**: Use `dropna` to control whether to exclude or include `NaN` values in group keys.\n",
    "- **Conditional Grouping**: You can group based on a condition applied to the data itself (e.g., greater than a certain value).\n",
    "- **Categorical Grouping**: Control which categories are included in the group result using `observed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rolling\n",
    "Series.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=<no_default>, closed=None, step=None, method='single')[source]\n",
    "Provide rolling window calculations.\n",
    "\n",
    "Parameters:\n",
    "windowint, timedelta, str, offset, or BaseIndexer subclass\n",
    "Size of the moving window.\n",
    "\n",
    "If an integer, the fixed number of observations used for each window.\n",
    "\n",
    "If a timedelta, str, or offset, the time period of each window. Each window will be a variable sized based on the observations included in the time-period. This is only valid for datetimelike indexes. To learn more about the offsets & frequency strings, please see this link.\n",
    "\n",
    "If a BaseIndexer subclass, the window boundaries based on the defined get_window_bounds method. Additional rolling keyword arguments, namely min_periods, center, closed and step will be passed to get_window_bounds.\n",
    "\n",
    "min_periodsint, default None\n",
    "Minimum number of observations in window required to have a value; otherwise, result is np.nan.\n",
    "\n",
    "For a window that is specified by an offset, min_periods will default to 1.\n",
    "\n",
    "For a window that is specified by an integer, min_periods will default to the size of the window.\n",
    "\n",
    "centerbool, default False\n",
    "If False, set the window labels as the right edge of the window index.\n",
    "\n",
    "If True, set the window labels as the center of the window index.\n",
    "\n",
    "win_typestr, default None\n",
    "If None, all points are evenly weighted.\n",
    "\n",
    "If a string, it must be a valid scipy.signal window function.\n",
    "\n",
    "Certain Scipy window types require additional parameters to be passed in the aggregation function. The additional parameters must match the keywords specified in the Scipy window type method signature.\n",
    "\n",
    "onstr, optional\n",
    "For a DataFrame, a column label or Index level on which to calculate the rolling window, rather than the DataFrame’s index.\n",
    "\n",
    "Provided integer column is ignored and excluded from result since an integer index is not used to calculate the rolling window.\n",
    "\n",
    "axisint or str, default 0\n",
    "If 0 or 'index', roll across the rows.\n",
    "\n",
    "If 1 or 'columns', roll across the columns.\n",
    "\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Deprecated since version 2.1.0: The axis keyword is deprecated. For axis=1, transpose the DataFrame first instead.\n",
    "\n",
    "closedstr, default None\n",
    "If 'right', the first point in the window is excluded from calculations.\n",
    "\n",
    "If 'left', the last point in the window is excluded from calculations.\n",
    "\n",
    "If 'both', the no points in the window are excluded from calculations.\n",
    "\n",
    "If 'neither', the first and last points in the window are excluded from calculations.\n",
    "\n",
    "Default None ('right').\n",
    "\n",
    "stepint, default None\n",
    "Added in version 1.5.0.\n",
    "\n",
    "Evaluate the window at every step result, equivalent to slicing as [::step]. window must be an integer. Using a step argument other than None or 1 will produce a result with a different shape than the input.\n",
    "\n",
    "methodstr {‘single’, ‘table’}, default ‘single’\n",
    "Added in version 1.3.0.\n",
    "\n",
    "Execute the rolling operation per single column or row ('single') or over the entire object ('table').\n",
    "\n",
    "This argument is only implemented when specifying engine='numba' in the method call.\n",
    "\n",
    "Returns:\n",
    "pandas.api.typing.Window or pandas.api.typing.Rolling\n",
    "An instance of Window is returned if win_type is passed. Otherwise, an instance of Rolling is returned.\n",
    "\n",
    "See also\n",
    "\n",
    "expanding\n",
    "Provides expanding transformations.\n",
    "\n",
    "ewm\n",
    "Provides exponential weighted functions. \"\"\"\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rolling(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
    "                       index=[pd.Timestamp('20130101 09:00:00'),\n",
    "                              pd.Timestamp('20130101 09:00:02'),\n",
    "                              pd.Timestamp('20130101 09:00:03'),\n",
    "                              pd.Timestamp('20130101 09:00:05'),\n",
    "                              pd.Timestamp('20130101 09:00:06')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.rolling('2s').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
    "df.rolling(window=indexer, min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" min_periods\n",
    "\n",
    "Rolling sum with a window length of 2 observations, but only needs a minimum of 1 observation to calculate a value. \"\"\"\n",
    "\n",
    "df.rolling(2, min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" center\n",
    "\n",
    "Rolling sum with the result assigned to the center of the window index. \"\"\"\n",
    "\n",
    "df.rolling(3, min_periods=1, center=True).sum()\n",
    "df.rolling(3, min_periods=1, center=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step\n",
    "\n",
    "#  Rolling sum with a window length of 2 observations, minimum of 1 observation to calculate a value, and a step of 2.\n",
    "\n",
    "df.rolling(2, min_periods=1, step=2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" win_type\n",
    "\n",
    "Rolling sum with a window length of 2, using the Scipy 'gaussian' window type. std is required in the aggregation function. \"\"\"\n",
    "\n",
    "df.rolling(2, win_type='gaussian').sum(std=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # on\n",
    " # lling sum with a window length of 2 days.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [pd.to_datetime('2020-01-01'),\n",
    "          pd.to_datetime('2020-01-01'),\n",
    "          pd.to_datetime('2020-01-02'),],\n",
    "    'B': [1, 2, 3], },\n",
    "    index=pd.date_range('2020', periods=3))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rolling('2D', on='A').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.rolling()`** method provides rolling window calculations, which allow you to apply functions (like sum, mean, etc.) over a sliding window of a specified size. This is useful for time-series analysis or smoothing data by calculating moving averages, sums, or other aggregations over a defined window.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=<no_default>, closed=None, step=None, method='single')\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **window**: int, timedelta, str, offset, or BaseIndexer subclass\n",
    "\n",
    "  - Defines the size of the moving window.\n",
    "  - If it's an integer, it will use a fixed number of observations for each window.\n",
    "  - If it's a timedelta, string, or offset, it will use a time period for the window size (only valid for datetime-like indexes).\n",
    "  - If it's a BaseIndexer subclass, it defines window boundaries using the `get_window_bounds` method.\n",
    "\n",
    "- **min_periods**: int, default None\n",
    "\n",
    "  - Minimum number of observations in the window required for a result. If there are fewer observations than this, the result will be `np.nan`.\n",
    "  - Defaults to the window size if an integer window is specified.\n",
    "  - For time-based windows (like timedelta), it defaults to 1.\n",
    "\n",
    "- **center**: bool, default False\n",
    "\n",
    "  - If False, the window labels will be positioned at the right edge of the window.\n",
    "  - If True, the window labels will be positioned at the center of the window.\n",
    "\n",
    "- **win_type**: str, default None\n",
    "\n",
    "  - If a string, applies a specific window function from `scipy.signal` (e.g., 'hanning', 'hamming'). This is used to apply specific weights to the observations in the window.\n",
    "\n",
    "- **on**: str, optional\n",
    "\n",
    "  - For a DataFrame, this allows you to specify a column label or index level to perform the rolling calculation on, rather than using the index.\n",
    "\n",
    "- **axis**: int or str, default 0\n",
    "\n",
    "  - Defines the axis along which to roll the window. For Series, this is ignored (defaults to 0).\n",
    "  - For DataFrame, 0 means rolling along rows, and 1 means rolling along columns.\n",
    "\n",
    "- **closed**: str, default None\n",
    "\n",
    "  - Controls which side of the window is included in the calculation:\n",
    "    - 'right' (default) excludes the first point in the window.\n",
    "    - 'left' excludes the last point in the window.\n",
    "    - 'both' includes both the first and last points.\n",
    "    - 'neither' excludes both the first and last points.\n",
    "\n",
    "- **step**: int, default None\n",
    "\n",
    "  - This allows you to evaluate the window at every `step`-th result. It must be an integer. This feature is available since pandas 1.5.0.\n",
    "\n",
    "- **method**: str, {'single', 'table'}, default 'single'\n",
    "  - When set to 'single', the rolling operation is executed for each column/row individually.\n",
    "  - When set to 'table', the rolling operation is performed over the entire DataFrame or Series (for the `numba` engine).\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **pandas.api.typing.Window** or **pandas.api.typing.Rolling**\n",
    "  - If `win_type` is specified, a `Window` object is returned, which provides additional methods for weighted rolling operations.\n",
    "  - If `win_type` is not specified, a `Rolling` object is returned, allowing for standard rolling window operations (e.g., `sum()`, `mean()`, etc.).\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **expanding**: Provides expanding transformations (aggregates over an expanding window).\n",
    "- **ewm**: Provides exponential weighted functions, which are similar to rolling but apply exponentially decreasing weights.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Rolling Window\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "rolling = ser.rolling(window=3)\n",
    "print(rolling.mean())  # Moving average with a window size of 3\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    NaN\n",
    "1    NaN\n",
    "2    2.0\n",
    "3    3.0\n",
    "4    4.0\n",
    "5    5.0\n",
    "6    6.0\n",
    "7    7.0\n",
    "8    8.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 2: Rolling Window with Minimum Periods\n",
    "\n",
    "```python\n",
    "ser = pd.Series([1, 2, np.nan, 4, 5])\n",
    "rolling = ser.rolling(window=3, min_periods=2)\n",
    "print(rolling.mean())  # Requires at least 2 observations for the rolling mean\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    NaN\n",
    "1    1.5\n",
    "2    1.5\n",
    "3    3.0\n",
    "4    4.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 3: Centering the Rolling Window\n",
    "\n",
    "```python\n",
    "ser = pd.Series([1, 2, 3, 4, 5])\n",
    "rolling = ser.rolling(window=3, center=True)\n",
    "print(rolling.mean())  # The window is centered around each point\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    NaN\n",
    "1    2.0\n",
    "2    2.0\n",
    "3    3.0\n",
    "4    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 4: Applying a Rolling Window with a Custom Function\n",
    "\n",
    "```python\n",
    "ser = pd.Series([1, 2, 3, 4, 5, 6])\n",
    "rolling = ser.rolling(window=3)\n",
    "print(rolling.apply(lambda x: x.max()))  # Maximum value within each window\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    NaN\n",
    "1    NaN\n",
    "2    3.0\n",
    "3    4.0\n",
    "4    5.0\n",
    "5    6.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 5: Rolling Window with Scipy Window Type\n",
    "\n",
    "```python\n",
    "from scipy.signal import hamming\n",
    "\n",
    "ser = pd.Series([1, 2, 3, 4, 5, 6])\n",
    "rolling = ser.rolling(window=3, win_type='hamming')\n",
    "print(rolling.mean())\n",
    "```\n",
    "\n",
    "This will apply a Hamming window to the rolling calculation, giving more weight to the center of each window.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- The **`rolling()`** method in pandas is used for performing rolling calculations such as mean, sum, max, etc., over a sliding window.\n",
    "- You can control the window size, minimum observations required, window centering, and apply custom window functions such as those from `scipy.signal`.\n",
    "- It’s useful for time-series analysis or smoothing noisy data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.ewm\n",
    "Series.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=<no_default>, times=None, method='single')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Provide exponentially weighted (EW) calculations.\n",
    "\n",
    "Exactly one of com, span, halflife, or alpha must be provided if times is not provided. If times is provided, halflife and one of com, span or alpha may be provided.\n",
    "\n",
    "Parameters:\n",
    "com : float, optional\n",
    "Specify decay in terms of center of mass\n",
    "alpha =1/(1+com), for com>=0 .\n",
    "\n",
    "span: float, optional\n",
    "Specify decay in terms of span\n",
    "alpha=2/(span+1), for span>=1.\n",
    "\n",
    "\n",
    "halflife: float, str, timedelta, optional\n",
    "Specify decay in terms of half-life\n",
    "alpha=1−exp(log(0.5)/halflife), for halflife>0 .\n",
    "\n",
    "If times is specified, a timedelta convertible unit over which an observation decays to half its value. Only applicable to mean(), and halflife value will not apply to the other functions.\n",
    "\n",
    "alpha: float, optional\n",
    "Specify smoothing factor \n",
    " directly\n",
    "0<alpha<=1 .\n",
    "\n",
    "min_periods: int, default 0\n",
    "Minimum number of observations in window required to have a value; otherwise, result is np.nan.\n",
    "\n",
    "adjust: bool, default True\n",
    "Divide by decaying adjustment factor in beginning periods to account for imbalance in relative weightings (viewing EWMA as a moving average).\n",
    "\n",
    "When adjust=True (default), the EW function is calculated using weights \n",
    "y_0=x_0,\n",
    "\n",
    "y_t=alpha*x_t+(1-alpha)*y_{t-1}.\n",
    "\n",
    "\n",
    "\n",
    "ignore_na: bool, default False\n",
    "Ignore missing values when calculating weights.\n",
    "\n",
    "When ignore_na=False (default), weights are based on absolute positions. \n",
    "\n",
    "When ignore_na=True, weights are based on relative positions.\n",
    "\n",
    "axis : {0, 1}, default 0\n",
    "If 0 or 'index', calculate across the rows.\n",
    "\n",
    "If 1 or 'columns', calculate across the columns.\n",
    "\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "times : np.ndarray, Series, default None\n",
    "Only applicable to mean().\n",
    "\n",
    "Times corresponding to the observations. Must be monotonically increasing and datetime64[ns] dtype.\n",
    "\n",
    "If 1-D array like, a sequence with the same shape as the observations.\n",
    "\n",
    "method: str {‘single’, ‘table’}, default ‘single’\n",
    "Added in version 1.4.0.\n",
    "\n",
    "Execute the rolling operation per single column or row ('single') or over the entire object ('table').\n",
    "\n",
    "This argument is only implemented when specifying engine='numba' in the method call.\n",
    "\n",
    "Only applicable to mean()\n",
    "\n",
    "Returns:\n",
    "pandas.api.typing.ExponentialMovingWindow\n",
    "\n",
    "rolling\n",
    "Provides rolling window calculations.\n",
    "\n",
    "expanding\n",
    "\n",
    "Provides expanding transformations.\n",
    "\n",
    "   \"\"\"\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ewm(com=0.5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ewm(alpha=2 / 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADJUST\n",
    "df.ewm(com=0.5, adjust=True).mean()\n",
    "df.ewm(com=0.5, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore_na\n",
    "df.ewm(com=0.5, ignore_na=True).mean()\n",
    "df.ewm(com=0.5, ignore_na=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times\n",
    "\n",
    "# Exponentially weighted mean with weights calculated with a timedelta halflife relative to times.\n",
    "\n",
    "times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
    "df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.ewm()`** method computes exponentially weighted (EW) calculations, which apply exponentially decreasing weights to a series of data. This is particularly useful for smoothing time-series data, calculating exponential moving averages (EMAs), or other exponentially weighted metrics.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=<no_default>, times=None, method='single')\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **com**: float, optional\n",
    "\n",
    "  - Specifies the decay in terms of the center of mass.\n",
    "  - This parameter defines how much weight each point receives. A higher value means a faster decay of weights.\n",
    "\n",
    "- **span**: float, optional\n",
    "\n",
    "  - Specifies the decay in terms of the span (how wide the window is).\n",
    "  - The span is related to the center of mass (com) via `span = 2 * com`.\n",
    "\n",
    "- **halflife**: float, str, timedelta, optional\n",
    "\n",
    "  - Specifies the decay in terms of half-life, which is the time it takes for the weight to decay to half of its value.\n",
    "  - This is especially useful when working with time-based data. It can be a string (e.g., `'4 days'`) or a timedelta.\n",
    "\n",
    "- **alpha**: float, optional\n",
    "\n",
    "  - Specifies the smoothing factor directly. The alpha value determines the weight given to the most recent observation in the series.\n",
    "  - The formula for alpha is `alpha = 1 / (1 + span)` or `alpha = 2 / (1 + span)`.\n",
    "\n",
    "- **min_periods**: int, default 0\n",
    "\n",
    "  - Minimum number of observations required in the window for a valid result. If fewer than `min_periods` are available, the result will be `np.nan`.\n",
    "\n",
    "- **adjust**: bool, default True\n",
    "\n",
    "  - If `True`, the calculation adjusts the weights to account for earlier periods, treating the EW calculation as a moving average.\n",
    "  - If `False`, the calculation is recursive and the adjustment factor is not applied.\n",
    "\n",
    "- **ignore_na**: bool, default False\n",
    "\n",
    "  - If `True`, missing values (NaN) are ignored while calculating the weights.\n",
    "  - If `False`, NaNs are treated as part of the series, and the weight of missing values will be handled accordingly.\n",
    "\n",
    "- **axis**: {0, 1}, default 0\n",
    "\n",
    "  - Specifies the axis along which to calculate the exponentially weighted function. For a Series, this is ignored (defaults to 0).\n",
    "\n",
    "- **times**: np.ndarray, Series, optional\n",
    "\n",
    "  - For calculating exponentially weighted means over time, this provides a sequence of timestamps. The times must be monotonically increasing and in `datetime64[ns]` dtype.\n",
    "  - This parameter is relevant only for `mean()` and allows for time-based decay.\n",
    "\n",
    "- **method**: str {'single', 'table'}, default 'single'\n",
    "  - Determines whether the operation is performed per column/row ('single') or over the entire object ('table').\n",
    "  - This is only implemented when using the `numba` engine with the `mean()` function.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **pandas.api.typing.ExponentialMovingWindow**\n",
    "  - This object represents the exponentially weighted window and provides methods for various EW calculations (e.g., `mean()`, `std()`, `cov()`, etc.).\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **rolling**: Provides rolling window calculations (for fixed-sized windows).\n",
    "- **expanding**: Provides expanding transformations (for a cumulative window).\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Exponentially Weighted Mean (with `com`)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "print(df.ewm(com=0.5).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "```\n",
    "\n",
    "#### Example 2: Exponentially Weighted Mean (with `alpha`)\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "print(df.ewm(alpha=2 / 3).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "```\n",
    "\n",
    "#### Example 3: Adjusting the Exponentially Weighted Mean\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "# Adjusted calculation\n",
    "print(df.ewm(com=0.5, adjust=True).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "```\n",
    "\n",
    "#### Example 4: Exponentially Weighted Mean without Adjusting\n",
    "\n",
    "```python\n",
    "print(df.ewm(com=0.5, adjust=False).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.666667\n",
    "2  1.555556\n",
    "3  1.555556\n",
    "4  3.650794\n",
    "```\n",
    "\n",
    "#### Example 5: Ignoring NaNs during Exponentially Weighted Mean Calculation\n",
    "\n",
    "```python\n",
    "print(df.ewm(com=0.5, ignore_na=True).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.225000\n",
    "```\n",
    "\n",
    "#### Example 6: Using Time-based Exponentially Weighted Mean (with `halflife`)\n",
    "\n",
    "```python\n",
    "times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
    "df = pd.DataFrame({'B': [0, 1, 2, 3, 4]}, index=pd.DatetimeIndex(times))\n",
    "print(df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "                   B\n",
    "2020-01-01  0.000000\n",
    "2020-01-03  0.585786\n",
    "2020-01-10  1.523889\n",
    "2020-01-15  1.523889\n",
    "2020-01-17  3.233686\n",
    "```\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- The **`ewm()`** method is used for exponentially weighted calculations, such as exponential moving averages.\n",
    "- The decay of weights can be controlled through parameters like `com`, `span`, `alpha`, and `halflife`.\n",
    "- You can also adjust how weights are applied with the `adjust` and `ignore_na` parameters.\n",
    "- This method is particularly useful for time-series data where recent observations are given more weight than older ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.pipe\n",
    "Series.pipe(func, *args, **kwargs)[source]\n",
    "Apply chainable functions that expect Series or DataFrames.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "func\n",
    "function\n",
    "Function to apply to the Series/DataFrame. args, and kwargs are passed into func. Alternatively a (callable, data_keyword) tuple where data_keyword is a string indicating the keyword of callable that expects the Series/DataFrame.\n",
    "\n",
    "*args\n",
    "iterable, optional\n",
    "Positional arguments passed into func.\n",
    "\n",
    "**kwargs\n",
    "mapping, optional\n",
    "A dictionary of keyword arguments passed into func.\n",
    "\n",
    "Returns\n",
    ":\n",
    "the return type of\n",
    "func\n",
    ".\n",
    "See also\n",
    "\n",
    "DataFrame.apply\n",
    "Apply a function along input axis of DataFrame.\n",
    "\n",
    "DataFrame.map\n",
    "Apply a function elementwise on a whole DataFrame.\n",
    "\n",
    "Series.map\n",
    "Apply a mapping correspondence on a Series.\n",
    "\n",
    "Notes\n",
    "\n",
    "Use .pipe when chaining together functions that expect Series, DataFrames or GroupBy objects. \"\"\"\n",
    "\n",
    "data = [[8000, 1000], [9500, np.nan], [5000, 2000]]\n",
    "df = pd.DataFrame(data, columns=['Salary', 'Others'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_federal_tax(df):\n",
    "    return df * 0.9\n",
    "def subtract_state_tax(df, rate):\n",
    "    return df * (1 - rate)\n",
    "def subtract_national_insurance(df, rate, rate_increase):\n",
    "    new_rate = rate + rate_increase\n",
    "    return df * (1 - new_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtract_national_insurance(\n",
    "    subtract_state_tax(subtract_federal_tax(df), rate=0.12),\n",
    "    rate=0.05,\n",
    "    rate_increase=0.02)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_national_insurance(rate, df, rate_increase):\n",
    "    new_rate = rate + rate_increase\n",
    "    return df * (1 - new_rate)\n",
    "(\n",
    "    df.pipe(subtract_federal_tax)\n",
    "    .pipe(subtract_state_tax, rate=0.12)\n",
    "    .pipe(\n",
    "        (subtract_national_insurance, 'df'),\n",
    "        rate=0.05,\n",
    "        rate_increase=0.02\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.pipe()`** method is used to apply a function to a Series (or DataFrame) within a chain of operations. It allows you to apply functions in a clean, readable, and functional programming style, especially when chaining multiple functions together.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.pipe(func, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **func**: function\n",
    "  - The function to apply to the Series (or DataFrame). This function will be passed the Series or DataFrame as the first argument.\n",
    "  - You can also pass a tuple where the first element is the callable function and the second is a keyword (a string) indicating where the data should be passed (e.g., as a keyword argument).\n",
    "- **args**: iterable, optional\n",
    "\n",
    "  - Positional arguments to pass into `func`.\n",
    "\n",
    "- **kwargs**: mapping, optional\n",
    "  - Keyword arguments to pass into `func`.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- The return type of the function `func`, which could be another Series, DataFrame, or any object returned by the function.\n",
    "\n",
    "### **Use Cases**\n",
    "\n",
    "- **Chaining functions**: It is particularly useful when chaining multiple functions that expect a Series or DataFrame as their first argument. Instead of nesting function calls, `pipe` allows for cleaner, more readable code.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage of `pipe`\n",
    "\n",
    "Let's say you have a DataFrame with salary data and you want to apply a series of functions to reduce the income.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = [[8000, 1000], [9500, np.nan], [5000, 2000]]\n",
    "df = pd.DataFrame(data, columns=['Salary', 'Others'])\n",
    "\n",
    "# Functions to apply\n",
    "def subtract_federal_tax(df):\n",
    "    return df * 0.9\n",
    "\n",
    "def subtract_state_tax(df, rate):\n",
    "    return df * (1 - rate)\n",
    "\n",
    "def subtract_national_insurance(df, rate, rate_increase):\n",
    "    new_rate = rate + rate_increase\n",
    "    return df * (1 - new_rate)\n",
    "\n",
    "# Chaining with pipe\n",
    "result = (\n",
    "    df.pipe(subtract_federal_tax)\n",
    "    .pipe(subtract_state_tax, rate=0.12)\n",
    "    .pipe(subtract_national_insurance, rate=0.05, rate_increase=0.02)\n",
    ")\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   Salary   Others\n",
    "0  5892.48   736.56\n",
    "1  6997.32      NaN\n",
    "2  3682.80  1473.12\n",
    "```\n",
    "\n",
    "Here, the three tax deduction functions are applied one after the other. Using `pipe`, the result of each function is passed to the next function in the chain.\n",
    "\n",
    "#### Example 2: Using `pipe` with Keyword Arguments\n",
    "\n",
    "If a function expects the Series (or DataFrame) as a keyword argument, you can pass a tuple to `pipe` that specifies which argument to assign the Series to.\n",
    "\n",
    "```python\n",
    "def subtract_national_insurance(rate, df, rate_increase):\n",
    "    new_rate = rate + rate_increase\n",
    "    return df * (1 - new_rate)\n",
    "\n",
    "result = (\n",
    "    df.pipe(subtract_federal_tax)\n",
    "    .pipe(subtract_state_tax, rate=0.12)\n",
    "    .pipe(\n",
    "        (subtract_national_insurance, 'df'),\n",
    "        rate=0.05,\n",
    "        rate_increase=0.02\n",
    "    )\n",
    ")\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   Salary   Others\n",
    "0  5892.48   736.56\n",
    "1  6997.32      NaN\n",
    "2  3682.80  1473.12\n",
    "```\n",
    "\n",
    "In this example, `subtract_national_insurance` is modified to accept the DataFrame as a keyword argument, and we specify that `df` should receive the DataFrame inside the `pipe` call using a tuple.\n",
    "\n",
    "#### Example 3: Using `pipe` for More Complex Chains\n",
    "\n",
    "You can use `pipe` to chain more complex operations, such as adding additional columns or applying custom functions, and combine them into a single readable chain.\n",
    "\n",
    "```python\n",
    "def add_bonus(df, bonus_percentage):\n",
    "    df['Bonus'] = df['Salary'] * bonus_percentage\n",
    "    return df\n",
    "\n",
    "def apply_discount(df, discount_percentage):\n",
    "    df['Salary'] = df['Salary'] * (1 - discount_percentage)\n",
    "    return df\n",
    "\n",
    "result = (\n",
    "    df.pipe(add_bonus, bonus_percentage=0.1)\n",
    "    .pipe(apply_discount, discount_percentage=0.05)\n",
    ")\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   Salary  Others  Bonus\n",
    "0   5706.0   1000   800.0\n",
    "1   6844.5    NaN   950.0\n",
    "2   3500.0   2000   500.0\n",
    "```\n",
    "\n",
    "Here, two functions (`add_bonus` and `apply_discount`) are applied in a chain to compute the bonus and apply a salary discount.\n",
    "\n",
    "### **Advantages of Using `pipe`**\n",
    "\n",
    "- **Readability**: Avoids deeply nested function calls. Each function call is neatly aligned, improving the readability of code.\n",
    "- **Flexibility**: Allows you to chain custom functions with varying arguments.\n",
    "- **Maintainability**: Makes it easier to modify or add functions without changing the overall structure of the code.\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **`pipe()`** is great for applying a series of transformations in a readable, functional style.\n",
    "- It works by passing the Series or DataFrame to each function in the chain.\n",
    "- You can pass additional arguments and keyword arguments to functions in the chain.\n",
    "- This method is ideal when you have multiple operations to perform on a Series/DataFrame and want to avoid deeply nested function calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.abs\n",
    "\n",
    "Series.abs()\n",
    "\n",
    "Return a Series/DataFrame with absolute numeric value of each element.\n",
    "\n",
    "This function only applies to elements that are all numeric.\n",
    "\n",
    "Returns\n",
    ":\n",
    "abs\n",
    "Series/DataFrame containing the absolute value of each element.\n",
    "\n",
    "See also\n",
    "\n",
    "numpy.absolute\n",
    "Calculate the absolute value element-wise. \n",
    "\n",
    "Notes\n",
    "\n",
    "For complex inputs, 1.2 + 1j, the absolute value is square_root(a^2+b^2)\n",
    ".\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "s = pd.Series([-1.10, 2, -3.33, 4])\n",
    "s.abs()\n",
    "s = pd.Series([1.2 + 1j])\n",
    "s.abs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([pd.Timedelta('1 days')])\n",
    "s.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 6, 7],\n",
    "    'b': [10, 20, 30, 40],\n",
    "    'c': [100, 50, -30, -50]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.c - 43).abs().argsort()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.abs()`** function is used to return a Series (or DataFrame) where the numeric values are transformed into their absolute values. It applies to numerical data types and can also handle complex numbers, returning the magnitude (absolute value) for complex numbers.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.abs()\n",
    "```\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- The function returns a **Series** or **DataFrame** containing the absolute values of each element.\n",
    "  - For **numeric types**, it returns the absolute value of each number.\n",
    "  - For **complex numbers**, it computes the magnitude (Euclidean norm).\n",
    "  - For **Timedelta objects**, it returns the absolute difference in days.\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **None**: The function works on the current Series/DataFrame and doesn’t take any other arguments.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Absolute values of numeric data\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a Series with negative and positive values\n",
    "s = pd.Series([-1.10, 2, -3.33, 4])\n",
    "\n",
    "# Applying abs() to get the absolute values\n",
    "result = s.abs()\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    1.10\n",
    "1    2.00\n",
    "2    3.33\n",
    "3    4.00\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here, the negative values in the Series are converted to positive.\n",
    "\n",
    "#### Example 2: Absolute values with complex numbers\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.2 + 1j])  # Complex number\n",
    "\n",
    "# Applying abs() to get the magnitude\n",
    "result = s.abs()\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    1.56205\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "For complex numbers, the absolute value is calculated as the magnitude (Euclidean norm), which is `sqrt(real^2 + imag^2)`.\n",
    "\n",
    "#### Example 3: Absolute values with Timedelta\n",
    "\n",
    "```python\n",
    "s = pd.Series([pd.Timedelta('1 days')])\n",
    "\n",
    "# Applying abs() to Timedelta\n",
    "result = s.abs()\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0   1 days\n",
    "dtype: timedelta64[ns]\n",
    "```\n",
    "\n",
    "For **Timedelta objects**, `abs()` returns the absolute duration (in days, hours, minutes, etc.).\n",
    "\n",
    "#### Example 4: Sorting rows based on absolute difference to a value\n",
    "\n",
    "You can also use `.abs()` to filter or sort based on absolute differences from a target value.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 6, 7],\n",
    "    'b': [10, 20, 30, 40],\n",
    "    'c': [100, 50, -30, -50]\n",
    "})\n",
    "\n",
    "# Sorting rows based on the absolute difference of column 'c' to 43\n",
    "sorted_df = df.loc[(df.c - 43).abs().argsort()]\n",
    "\n",
    "print(sorted_df)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   a   b   c\n",
    "1  5  20  50\n",
    "0  4  10 100\n",
    "2  6  30 -30\n",
    "3  7  40 -50\n",
    "```\n",
    "\n",
    "Here, the `.abs()` function is used to compute the absolute difference between each element in column `c` and the target value `43`. The `argsort()` function is then used to sort the rows based on these differences.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`numpy.absolute`**: This is the underlying function from NumPy that performs element-wise absolute value calculations.\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- `Series.abs()` is a simple and effective method to convert all elements in a Series or DataFrame to their absolute values.\n",
    "- It works on **numeric**, **complex**, and **Timedelta** data types.\n",
    "- It's useful for sorting, filtering, or transforming data where negative values need to be made positive or where magnitudes are required (in case of complex numbers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.all\n",
    "Series.all(axis=0, bool_only=False, skipna=True, **kwargs)[source]\n",
    "Return whether all elements are True, potentially over an axis.\n",
    "\n",
    "Returns True unless there at least one element within a series or along a Dataframe axis that is False or equivalent (e.g. zero or empty).\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis:\n",
    "\n",
    "{0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
    "Indicate which axis or axes should be reduced. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "0 / ‘index’ : reduce the index, return a Series whose index is the original column labels.\n",
    "\n",
    "1 / ‘columns’ : reduce the columns, return a Series whose index is the original index.\n",
    "\n",
    "None : reduce all axes, return a scalar.\n",
    "\n",
    "bool_only : \n",
    "\n",
    "bool, default False\n",
    "Include only boolean columns. Not implemented for Series.\n",
    "\n",
    "skipna:\n",
    "\n",
    "bool, default True\n",
    "Exclude NA/null values. If the entire row/column is NA and skipna is True, then the result will be True, as for an empty row/column. If skipna is False, then NA are treated as True, because these are not equal to zero.\n",
    "\n",
    "**kwargs:\n",
    "\n",
    "any, default None\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns:\n",
    "\n",
    "scalar or Series\n",
    "If level is specified, then, Series is returned; otherwise, scalar is returned.\n",
    "\n",
    "Series.all\n",
    "Return True if all elements are True.\n",
    "\n",
    "DataFrame.any\n",
    "Return True if one (or more) elements are True. \"\"\"\n",
    "# Series\n",
    "\n",
    "pd.Series([True, True]).all()\n",
    "pd.Series([True, False]).all()\n",
    "pd.Series([], dtype=\"float64\").all()\n",
    "pd.Series([np.nan]).all()\n",
    "pd.Series([np.nan]).all(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames\n",
    "\n",
    "# Create a dataframe from a dictionary.\n",
    "\n",
    "df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default behaviour checks if values in each column all return True.\n",
    "\n",
    "df.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify axis='columns' to check if values in each row all return True.\n",
    "\n",
    "df.all(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or axis=None for whether every value is True.\n",
    "\n",
    "df.all(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.all()`** function is used to check if all elements in a Series or DataFrame (along a specified axis) are `True`. It returns `True` if every element is `True` (or equivalent), and `False` if any element is `False` (or equivalent).\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.all(axis=0, bool_only=False, skipna=True, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **`axis`**:\n",
    "\n",
    "  - {0, ‘index’, 1, ‘columns’, None}, default 0\n",
    "  - For a **Series**, this parameter is unused and defaults to 0.\n",
    "  - For a **DataFrame**, `axis=0` reduces along the rows (checks columns), and `axis=1` reduces along the columns (checks rows). `None` checks all elements in the DataFrame.\n",
    "\n",
    "- **`bool_only`**:\n",
    "\n",
    "  - bool, default `False`\n",
    "  - If `True`, only boolean columns will be considered. This is not implemented for Series.\n",
    "\n",
    "- **`skipna`**:\n",
    "\n",
    "  - bool, default `True`\n",
    "  - If `True`, excludes `NA/null` values. If an entire row or column contains `NA` values and `skipna=True`, the result will be `True`. If `skipna=False`, `NA` values are treated as `True`.\n",
    "\n",
    "- **`kwargs`**:\n",
    "  - Additional arguments passed for compatibility with NumPy.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **scalar or Series**:\n",
    "  - If a single axis is reduced, a **scalar** is returned.\n",
    "  - If `level` is specified, a **Series** is returned.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Series with boolean values\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Series with all True values\n",
    "s = pd.Series([True, True])\n",
    "result = s.all()\n",
    "print(result)  # Output: True\n",
    "\n",
    "# Series with one False value\n",
    "s = pd.Series([True, False])\n",
    "result = s.all()\n",
    "print(result)  # Output: False\n",
    "```\n",
    "\n",
    "#### Example 2: Empty Series\n",
    "\n",
    "```python\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "result = s.all()\n",
    "print(result)  # Output: True\n",
    "```\n",
    "\n",
    "For an empty Series, `.all()` returns `True` because there are no elements to evaluate as `False`.\n",
    "\n",
    "#### Example 3: Series with `NaN`\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Series with NaN\n",
    "s = pd.Series([np.nan])\n",
    "result = s.all()\n",
    "print(result)  # Output: True (default behavior with skipna=True)\n",
    "\n",
    "# Series with NaN and skipna=False\n",
    "result = s.all(skipna=False)\n",
    "print(result)  # Output: True (NaN is treated as True by default)\n",
    "```\n",
    "\n",
    "#### Example 4: DataFrame with boolean values\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'col1': [True, True],\n",
    "    'col2': [True, False]\n",
    "})\n",
    "\n",
    "# Check if all elements in each column are True\n",
    "result = df.all()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "col1     True\n",
    "col2    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "Here, `all()` checks if every value in each column is `True`. For `col1`, all values are `True`, but for `col2`, there's a `False` value, so it returns `False`.\n",
    "\n",
    "#### Example 5: DataFrame with axis='columns' to check row-wise\n",
    "\n",
    "```python\n",
    "result = df.all(axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "This checks if all values in each row are `True`. In row 1, the second value is `False`, so the result is `False` for that row.\n",
    "\n",
    "#### Example 6: DataFrame with axis=None to check all elements\n",
    "\n",
    "```python\n",
    "result = df.all(axis=None)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "This checks if **all** values in the entire DataFrame are `True`. Since `col2` has a `False`, the result is `False`.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`Series.any()`**: Returns `True` if at least one element is `True` (similar to `.all()` but checks for any `True` value).\n",
    "- **`DataFrame.all()`**: Performs a similar operation for DataFrames, checking if all values are `True` across rows or columns.\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **`Series.all()`** checks if **all** values in a Series are `True`.\n",
    "- For **DataFrames**, you can specify the axis to check along rows or columns, or check across the entire DataFrame.\n",
    "- **`skipna`** allows you to control how missing values (NA) are handled in the check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.any\n",
    "Series.any(*, axis=0, bool_only=False, skipna=True, **kwargs)[source]\n",
    "Return whether any element is True, potentially over an axis.\n",
    "\n",
    "Returns False unless there is at least one element within a series or along a Dataframe axis that is True or equivalent (e.g. non-zero or non-empty).\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
    "Indicate which axis or axes should be reduced. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "0 / ‘index’ : reduce the index, return a Series whose index is the original column labels.\n",
    "\n",
    "1 / ‘columns’ : reduce the columns, return a Series whose index is the original index.\n",
    "\n",
    "None : reduce all axes, return a scalar.\n",
    "\n",
    "bool_only\n",
    "bool, default False\n",
    "Include only boolean columns. Not implemented for Series.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If the entire row/column is NA and skipna is True, then the result will be False, as for an empty row/column. If skipna is False, then NA are treated as True, because these are not equal to zero.\n",
    "\n",
    "**kwargs\n",
    "any, default None\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "scalar or Series\n",
    "If level is specified, then, Series is returned; otherwise, scalar is returned.\n",
    "\n",
    "\n",
    "numpy.any\n",
    "Numpy version of this method.\n",
    "\n",
    "Series.any\n",
    "Return whether any element is True.\n",
    "\n",
    "Series.all\n",
    "Return whether all elements are True.\n",
    "\n",
    "DataFrame.any\n",
    "Return whether any element is True over requested axis.\n",
    "\n",
    "DataFrame.all\n",
    "Return whether all elements are True over requested axis. \"\"\"\n",
    "\n",
    "pd.Series([False, False]).any()\n",
    "pd.Series([True, False]).any()\n",
    "pd.Series([], dtype=\"float64\").any()\n",
    "pd.Series([np.nan]).any()\n",
    "pd.Series([np.nan]).any(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "\n",
    "# Whether each column contains at least one True element (the default).\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating over the columns.\n",
    "\n",
    "df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.any(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
    "df.any(axis='columns')\n",
    "# Aggregating over the entire DataFrame with axis=None.\n",
    "\n",
    "df.any(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any for an empty DataFrame is an empty Series.\n",
    "\n",
    "pd.DataFrame([]).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.any()`** function checks if **any element** in the Series or along a specified axis of a DataFrame is `True`. It returns `True` if at least one element is `True` (or equivalent), and `False` otherwise.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.any(axis=0, bool_only=False, skipna=True, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **`axis`**:\n",
    "\n",
    "  - {0, ‘index’, 1, ‘columns’, None}, default 0\n",
    "  - For **Series**, this parameter is unused and defaults to 0.\n",
    "  - For **DataFrames**, `axis=0` reduces along rows (checks columns), and `axis=1` reduces along columns (checks rows). `None` checks across all elements in the DataFrame.\n",
    "\n",
    "- **`bool_only`**:\n",
    "\n",
    "  - bool, default `False`\n",
    "  - If `True`, only boolean columns will be considered (this is not implemented for Series).\n",
    "\n",
    "- **`skipna`**:\n",
    "\n",
    "  - bool, default `True`\n",
    "  - If `True`, excludes `NA/null` values. If an entire row or column contains `NA` values and `skipna=True`, the result will be `False`. If `skipna=False`, `NA` values are treated as `True`.\n",
    "\n",
    "- **`kwargs`**:\n",
    "  - Additional arguments, passed for compatibility with NumPy.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **scalar or Series**:\n",
    "  - If **Series**, a scalar is returned (True or False).\n",
    "  - If **DataFrame**, a Series is returned with the result for each column or row (depending on `axis`).\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Series with boolean values\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Series with no True values\n",
    "s = pd.Series([False, False])\n",
    "result = s.any()\n",
    "print(result)  # Output: False\n",
    "\n",
    "# Series with one True value\n",
    "s = pd.Series([True, False])\n",
    "result = s.any()\n",
    "print(result)  # Output: True\n",
    "```\n",
    "\n",
    "#### Example 2: Empty Series\n",
    "\n",
    "```python\n",
    "# Empty Series\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "result = s.any()\n",
    "print(result)  # Output: False (since there are no elements)\n",
    "\n",
    "# Series with NaN values\n",
    "import numpy as np\n",
    "s = pd.Series([np.nan])\n",
    "result = s.any()\n",
    "print(result)  # Output: False (NaN is not True by default)\n",
    "\n",
    "# Series with NaN values and skipna=False\n",
    "result = s.any(skipna=False)\n",
    "print(result)  # Output: True (NaN is treated as True when skipna=False)\n",
    "```\n",
    "\n",
    "#### Example 3: DataFrame with boolean values\n",
    "\n",
    "```python\n",
    "# DataFrame with boolean values\n",
    "df = pd.DataFrame({\n",
    "    'A': [True, False],\n",
    "    'B': [0, 2],\n",
    "    'C': [0, 0]\n",
    "})\n",
    "\n",
    "# Check if any value in each column is True\n",
    "result = df.any()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A     True\n",
    "B     True\n",
    "C    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "Here, `any()` checks if at least one value in each column is `True`.\n",
    "\n",
    "#### Example 4: Aggregating over rows (axis=1)\n",
    "\n",
    "```python\n",
    "# DataFrame with numeric and boolean values\n",
    "df = pd.DataFrame({\n",
    "    'A': [True, False],\n",
    "    'B': [1, 2]\n",
    "})\n",
    "\n",
    "# Check if any value in each row is True\n",
    "result = df.any(axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0     True\n",
    "1     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "Here, `axis='columns'` checks if any value in each row is `True`.\n",
    "\n",
    "#### Example 5: Aggregating over the entire DataFrame (axis=None)\n",
    "\n",
    "```python\n",
    "# DataFrame with mixed values\n",
    "df = pd.DataFrame({\n",
    "    'A': [True, False],\n",
    "    'B': [1, 0]\n",
    "})\n",
    "\n",
    "# Check if any value in the entire DataFrame is True\n",
    "result = df.any(axis=None)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "This checks the entire DataFrame and returns `True` because there is at least one `True` value.\n",
    "\n",
    "#### Example 6: Empty DataFrame\n",
    "\n",
    "```python\n",
    "# Empty DataFrame\n",
    "df_empty = pd.DataFrame([])\n",
    "\n",
    "# Check if any value in the DataFrame is True\n",
    "result = df_empty.any()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "Series([], dtype: bool)\n",
    "```\n",
    "\n",
    "For an empty DataFrame, the result is an empty Series.\n",
    "\n",
    "### **See Also**\n",
    "\n",
    "- **`numpy.any()`**: Numpy version of this method.\n",
    "- **`Series.all()`**: Checks if all elements in a Series are `True`.\n",
    "- **`DataFrame.any()`**: Checks if any value in a DataFrame is `True`, along the requested axis.\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **`Series.any()`** returns `True` if at least one element is `True`.\n",
    "- For **DataFrames**, it checks along the specified axis (rows or columns) and can return a Series.\n",
    "- **`skipna`** determines how missing values are handled (whether they are treated as `True` or ignored).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.autocorr\n",
    "Series.autocorr(lag=1)[source]\n",
    "Compute the lag-N autocorrelation.\n",
    "\n",
    "This method computes the Pearson correlation between the Series and its shifted self.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "lag\n",
    "int, default 1\n",
    "Number of lags to apply before performing autocorrelation.\n",
    "\n",
    "Returns\n",
    ":\n",
    "float\n",
    "The Pearson correlation between self and self.shift(lag).\n",
    "\n",
    "See also\n",
    "\n",
    "Series.corr\n",
    "Compute the correlation between two Series.\n",
    "\n",
    "Series.shift\n",
    "Shift index by desired number of periods.\n",
    "\n",
    "DataFrame.corr\n",
    "Compute pairwise correlation of columns.\n",
    "\n",
    "DataFrame.corrwith\n",
    "Compute pairwise correlation between rows or columns of two DataFrame objects.\n",
    "\n",
    "Notes\n",
    "\n",
    "If the Pearson correlation is not well defined return ‘NaN’.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([0.25, 0.5, 0.2, -0.05])\n",
    "s.autocorr()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.autocorr(lag=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the Pearson correlation is not well defined, then ‘NaN’ is returned.\n",
    "\n",
    "s = pd.Series([1, 0, 0, 0])\n",
    "s.autocorr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.autocorr()`** function computes the **lag-N autocorrelation** of a Series, which is a measure of how well a time series is correlated with a lagged version of itself. It uses the **Pearson correlation** between the original Series and a shifted version of it.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.autocorr(lag=1)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **`lag`**:\n",
    "  - **int**, default `1`\n",
    "  - The number of periods to shift the Series before computing the autocorrelation.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **float**:\n",
    "  - The Pearson correlation between the Series and its shifted version. If the Pearson correlation is not well defined (e.g., due to constant values), it returns `NaN`.\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- **Pearson correlation** is used for autocorrelation, which measures the linear relationship between a Series and its lagged version.\n",
    "- If the Pearson correlation cannot be computed (e.g., if there is no variation in the data), the result will be `NaN`.\n",
    "\n",
    "### **See also**\n",
    "\n",
    "- **`Series.corr`**: Computes the correlation between two Series.\n",
    "- **`Series.shift`**: Shifts the index by a specified number of periods.\n",
    "- **`DataFrame.corr`**: Computes pairwise correlation between columns in a DataFrame.\n",
    "- **`DataFrame.corrwith`**: Computes pairwise correlation between rows or columns of two DataFrame objects.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Autocorrelation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample Series\n",
    "s = pd.Series([0.25, 0.5, 0.2, -0.05])\n",
    "\n",
    "# Autocorrelation with lag=1 (default)\n",
    "result_lag_1 = s.autocorr()\n",
    "print(result_lag_1)  # Output: 0.10355...\n",
    "\n",
    "# Autocorrelation with lag=2\n",
    "result_lag_2 = s.autocorr(lag=2)\n",
    "print(result_lag_2)  # Output: -0.99999...\n",
    "```\n",
    "\n",
    "#### Example 2: Autocorrelation for Constant Series\n",
    "\n",
    "```python\n",
    "# Constant Series\n",
    "s_constant = pd.Series([1, 0, 0, 0])\n",
    "\n",
    "# Autocorrelation (result is NaN because there's no variation)\n",
    "result_constant = s_constant.autocorr()\n",
    "print(result_constant)  # Output: nan\n",
    "```\n",
    "\n",
    "#### Example 3: Series with Positive Correlation\n",
    "\n",
    "```python\n",
    "# Positive correlation example\n",
    "s_pos = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Autocorrelation with lag=1\n",
    "result_pos = s_pos.autocorr()\n",
    "print(result_pos)  # Output: 1.0 (perfect positive correlation)\n",
    "```\n",
    "\n",
    "#### Example 4: Series with Negative Correlation\n",
    "\n",
    "```python\n",
    "# Negative correlation example\n",
    "s_neg = pd.Series([5, 4, 3, 2, 1])\n",
    "\n",
    "# Autocorrelation with lag=1\n",
    "result_neg = s_neg.autocorr()\n",
    "print(result_neg)  # Output: -1.0 (perfect negative correlation)\n",
    "```\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **`autocorr(lag=1)`** computes the Pearson correlation between a Series and its shifted self by a specified number of periods (lag).\n",
    "- It can be used to assess the linear dependence of the data with itself over time.\n",
    "- If the Series has constant values, the correlation will return `NaN`, as the correlation cannot be calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.between\n",
    "\n",
    "Series.between(left, right, inclusive='both')\n",
    "Return boolean Series equivalent to left <= series <= right.\n",
    "\n",
    "This function returns a boolean vector containing True wherever the corresponding Series element is between the boundary values left and right. NA values are treated as False.\n",
    "\n",
    "Parameters:\n",
    "left: scalar or list-like\n",
    "Left boundary.\n",
    "\n",
    "right: scalar or list-like\n",
    "Right boundary.\n",
    "\n",
    "inclusive: {“both”, “neither”, “left”, “right”}\n",
    "Include boundaries. Whether to set each bound as closed or open.\n",
    "\n",
    "Changed in version 1.3.0.\n",
    "\n",
    "Returns:\n",
    "Series\n",
    "Series representing whether each element is between left and right (inclusive). \n",
    "\n",
    "Series.gt\n",
    "Greater than of series and other.\n",
    "\n",
    "Series.lt\n",
    "Less than of series and other.\n",
    "\n",
    "\n",
    "Notes\n",
    "\n",
    "This function is equivalent to (left <= ser) & (ser <= right)\n",
    "\"\"\"\n",
    "s = pd.Series([2, 0, 4, 8, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary values are included by default:\n",
    "\n",
    "s.between(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With inclusive set to \"neither\" boundary values are excluded:\n",
    "\n",
    "s.between(1, 4, inclusive=\"neither\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left and right can be any scalar value:\n",
    "\n",
    "s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n",
    "s.between('Anna', 'Daniel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.between()`** function is used to check if the elements of a Series lie between two boundary values, `left` and `right`. It returns a boolean Series where each element is `True` if it lies between the boundaries and `False` otherwise.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.between(left, right, inclusive='both')\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **`left`**:\n",
    "  - **scalar** or **list-like**\n",
    "  - The left boundary (inclusive by default).\n",
    "- **`right`**:\n",
    "\n",
    "  - **scalar** or **list-like**\n",
    "  - The right boundary (inclusive by default).\n",
    "\n",
    "- **`inclusive`**:\n",
    "  - **{“both”, “neither”, “left”, “right”}**, default `'both'`\n",
    "  - Whether the boundary values `left` and `right` are included in the comparison:\n",
    "    - **`'both'`**: Both boundaries are included.\n",
    "    - **`'neither'`**: Excludes both boundaries.\n",
    "    - **`'left'`**: Includes the left boundary but excludes the right.\n",
    "    - **`'right'`**: Excludes the left boundary but includes the right.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A boolean Series indicating whether each element is between `left` and `right`, inclusive or exclusive based on the `inclusive` parameter.\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The function is equivalent to:\n",
    "  ```python\n",
    "  (left <= ser) & (ser <= right)\n",
    "  ```\n",
    "- `NaN` values are treated as `False`.\n",
    "\n",
    "### **See also**\n",
    "\n",
    "- **`Series.gt`**: Checks if the Series is greater than a scalar.\n",
    "- **`Series.lt`**: Checks if the Series is less than a scalar.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage with Default `inclusive='both'`\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample Series\n",
    "s = pd.Series([2, 0, 4, 8, np.nan])\n",
    "\n",
    "# Check if elements are between 1 and 4 (inclusive)\n",
    "result = s.between(1, 4)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "#### Example 2: Excluding Both Boundaries (`inclusive='neither'`)\n",
    "\n",
    "```python\n",
    "# Check if elements are between 1 and 4 (exclusive)\n",
    "result_neither = s.between(1, 4, inclusive='neither')\n",
    "print(result_neither)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "2    False\n",
    "3    False\n",
    "4    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "#### Example 3: Using String Boundaries\n",
    "\n",
    "```python\n",
    "# Sample Series of strings\n",
    "s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n",
    "\n",
    "# Check if elements are between 'Anna' and 'Daniel' (inclusive by default)\n",
    "result_str = s.between('Anna', 'Daniel')\n",
    "print(result_str)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0    False\n",
    "1     True\n",
    "2     True\n",
    "3    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "#### Example 4: Including Only Left Boundary (`inclusive='left'`)\n",
    "\n",
    "```python\n",
    "# Check if elements are between 1 and 4, including left boundary only\n",
    "result_left = s.between(1, 4, inclusive='left')\n",
    "print(result_left)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "#### Example 5: Including Only Right Boundary (`inclusive='right'`)\n",
    "\n",
    "```python\n",
    "# Check if elements are between 1 and 4, including right boundary only\n",
    "result_right = s.between(1, 4, inclusive='right')\n",
    "print(result_right)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "2    False\n",
    "3    False\n",
    "4    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **`Series.between(left, right, inclusive)`** checks whether the elements in the Series are between `left` and `right` with customizable boundary inclusivity.\n",
    "- The `inclusive` parameter controls whether to include or exclude the boundary values for `left` and `right`.\n",
    "- By default, both boundaries are included (`inclusive='both'`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.clip\n",
    "Series.clip(lower=None, upper=None, *, axis=None, inplace=False, **kwargs)[source]\n",
    "Trim values at input threshold(s).\n",
    "\n",
    "Assigns values outside boundary to boundary values. Thresholds can be singular values or array like, and in the latter case the clipping is performed element-wise in the specified axis.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "lower\n",
    "float or array-like, default None\n",
    "Minimum threshold value. All values below this threshold will be set to it. A missing threshold (e.g NA) will not clip the value.\n",
    "\n",
    "upper\n",
    "float or array-like, default None\n",
    "Maximum threshold value. All values above this threshold will be set to it. A missing threshold (e.g NA) will not clip the value.\n",
    "\n",
    "axis\n",
    "{{0 or ‘index’, 1 or ‘columns’, None}}, default None\n",
    "Align object with lower and upper along the given axis. For Series this parameter is unused and defaults to None.\n",
    "\n",
    "inplace\n",
    "bool, default False\n",
    "Whether to perform the operation in place on the data.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional keywords have no effect but might be accepted for compatibility with numpy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame or None\n",
    "Same type as calling object with the values outside the clip boundaries replaced or None if inplace=True.\n",
    "\n",
    "\n",
    "\n",
    "Series.clip\n",
    "Trim values at input threshold in series.\n",
    "\n",
    "DataFrame.clip\n",
    "Trim values at input threshold in dataframe.\n",
    "\n",
    "numpy.clip\n",
    "Clip (limit) the values in an array. \"\"\"\n",
    "data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # clips per column using lower and upper thresholds:\n",
    "\n",
    "df.clip(-4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clips using specific lower and upper thresholds per column:\n",
    "\n",
    "df.clip([-2, -1], [4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clips using specific lower and upper thresholds per column element:\n",
    "\n",
    "t = pd.Series([2, -4, -1, 6, 3])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clip(t, t + 4, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clips using specific lower threshold per column element, with missing values:\n",
    "\n",
    "t = pd.Series([2, -4, np.nan, 6, 3])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.clip(t, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.clip()`** function is used to trim values at specified threshold(s). It allows you to limit the values in a Series to a defined range by setting all values outside this range to the boundary values. The thresholds can be scalar or array-like, and if array-like, the clipping will be performed element-wise along the specified axis.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.clip(lower=None, upper=None, *, axis=None, inplace=False, **kwargs)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **`lower`**:\n",
    "\n",
    "  - **float** or **array-like**, default `None`\n",
    "  - Minimum threshold. Values below this threshold will be clipped to it.\n",
    "\n",
    "- **`upper`**:\n",
    "\n",
    "  - **float** or **array-like**, default `None`\n",
    "  - Maximum threshold. Values above this threshold will be clipped to it.\n",
    "\n",
    "- **`axis`**:\n",
    "\n",
    "  - **{0 or ‘index’, 1 or ‘columns’, None}**, default `None`\n",
    "  - Align the object with `lower` and `upper` along the specified axis. For Series, this parameter is unused.\n",
    "\n",
    "- **`inplace`**:\n",
    "\n",
    "  - **bool**, default `False`\n",
    "  - If `True`, modifies the Series in place (no new object is returned).\n",
    "\n",
    "- **`\\*args, **kwargs`\\*\\*:\n",
    "  - Additional arguments and keyword arguments for compatibility, but they have no effect.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series or DataFrame or None**:\n",
    "  - The same type as the calling object, with values clipped to the specified thresholds.\n",
    "  - If `inplace=True`, the function returns `None` (modifies the object in place).\n",
    "\n",
    "### **See also**\n",
    "\n",
    "- **`Series.clip`**: Clips values for Series.\n",
    "- **`DataFrame.clip`**: Clips values for DataFrames.\n",
    "- **`numpy.clip`**: The numpy equivalent for clipping values in an array.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Clip using scalar thresholds for both columns\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Clip values using lower=-4 and upper=6 for both columns\n",
    "clipped_df = df.clip(-4, 6)\n",
    "print(clipped_df)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   col_0  col_1\n",
    "0      9     -2\n",
    "1     -3     -7\n",
    "2      0      6\n",
    "3     -1      8\n",
    "4      5     -5\n",
    "\n",
    "   col_0  col_1\n",
    "0      6     -2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3     -1      6\n",
    "4      5     -4\n",
    "```\n",
    "\n",
    "#### Example 2: Clip using different thresholds for each column\n",
    "\n",
    "```python\n",
    "# Clip using different lower and upper thresholds per column\n",
    "clipped_df_2 = df.clip([-2, -1], [4, 5])\n",
    "print(clipped_df_2)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   col_0  col_1\n",
    "0      4     -1\n",
    "1     -2     -1\n",
    "2      0      5\n",
    "3     -1      5\n",
    "4      4     -1\n",
    "```\n",
    "\n",
    "#### Example 3: Clip using element-wise thresholds (Series)\n",
    "\n",
    "```python\n",
    "# Sample Series with different thresholds\n",
    "t = pd.Series([2, -4, -1, 6, 3])\n",
    "print(t)\n",
    "\n",
    "# Clip DataFrame using the element-wise thresholds from the Series\n",
    "clipped_df_3 = df.clip(t, t + 4, axis=0)\n",
    "print(clipped_df_3)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0    2\n",
    "1   -4\n",
    "2   -1\n",
    "3    6\n",
    "4    3\n",
    "dtype: int64\n",
    "\n",
    "   col_0  col_1\n",
    "0      6      2\n",
    "1     -3     -4\n",
    "2      0      3\n",
    "3      6      8\n",
    "4      5      3\n",
    "```\n",
    "\n",
    "#### Example 4: Clip using a Series with missing values\n",
    "\n",
    "```python\n",
    "# Sample Series with NaN\n",
    "t_with_nan = pd.Series([2, -4, np.nan, 6, 3])\n",
    "print(t_with_nan)\n",
    "\n",
    "# Clip DataFrame with the lower thresholds from the Series, ignoring NaN\n",
    "clipped_df_4 = df.clip(t_with_nan, axis=0)\n",
    "print(clipped_df_4)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1   -4.0\n",
    "2    NaN\n",
    "3    6.0\n",
    "4    3.0\n",
    "dtype: float64\n",
    "\n",
    "   col_0  col_1\n",
    "0      9      2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3      6      8\n",
    "4      5      3\n",
    "```\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **`Series.clip(lower, upper)`** is used to clip values outside the specified boundaries.\n",
    "- It can accept scalar values or array-like (e.g., Series) for element-wise clipping.\n",
    "- The `inplace` parameter controls whether the operation modifies the Series in place or returns a new one.\n",
    "- Clipping is useful for limiting the range of values in a Series or DataFrame, especially in situations where outliers need to be handled by capping the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.corr\n",
    "Series.corr(other, method='pearson', min_periods=None)[source]\n",
    "Compute correlation with other Series, excluding missing values.\n",
    "\n",
    "The two Series objects are not required to be the same length and will be aligned internally before the correlation function is applied.\n",
    "\n",
    "Parameters:\n",
    "otherSeries\n",
    "Series with which to compute the correlation.\n",
    "\n",
    "method{‘pearson’, ‘kendall’, ‘spearman’} or callable\n",
    "Method used to compute correlation:\n",
    "\n",
    "pearson : Standard correlation coefficient\n",
    "\n",
    "kendall : Kendall Tau correlation coefficient\n",
    "\n",
    "spearman : Spearman rank correlation\n",
    "\n",
    "callable: Callable with input two 1d ndarrays and returning a float.\n",
    "\n",
    "Warning\n",
    "\n",
    "Note that the returned matrix from corr will have 1 along the diagonals and will be symmetric regardless of the callable’s behavior.\n",
    "\n",
    "min_periodsint, optional\n",
    "Minimum number of observations needed to have a valid result.\n",
    "\n",
    "Returns:\n",
    "float\n",
    "Correlation with other.\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.corr\n",
    "Compute pairwise correlation between columns.\n",
    "\n",
    "DataFrame.corrwith\n",
    "Compute pairwise correlation with another DataFrame or Series. \"\"\"\n",
    "def histogram_intersection(a, b):\n",
    "    v = np.minimum(a, b).sum().round(decimals=1)\n",
    "    return v\n",
    "s1 = pd.Series([.2, .0, .6, .2])\n",
    "s2 = pd.Series([.3, .6, .0, .1])\n",
    "s1.corr(s2, method=histogram_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Pandas auto-aligns the values with matching indices\n",
    "\n",
    "s1 = pd.Series([1, 2, 3], index=[0, 1, 2])\n",
    "s2 = pd.Series([1, 2, 3], index=[2, 1, 0])\n",
    "s1.corr(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.corr()`** function computes the correlation between the calling Series and another Series, excluding any missing values. The correlation can be computed using different methods such as Pearson, Kendall, or Spearman.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.corr(other, method='pearson', min_periods=None)\n",
    "```\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "- **`other`**:\n",
    "\n",
    "  - **Series**\n",
    "  - The other Series with which to compute the correlation.\n",
    "\n",
    "- **`method`**:\n",
    "\n",
    "  - **{‘pearson’, ‘kendall’, ‘spearman’}** or **callable**, default `'pearson'`\n",
    "  - The method used to compute the correlation:\n",
    "    - `'pearson'`: Standard Pearson correlation coefficient.\n",
    "    - `'kendall'`: Kendall Tau correlation coefficient.\n",
    "    - `'spearman'`: Spearman rank correlation.\n",
    "    - **callable**: A user-defined function that takes two 1D ndarrays and returns a float. This allows for custom correlation methods.\n",
    "\n",
    "- **`min_periods`**:\n",
    "  - **int**, optional\n",
    "  - The minimum number of observations needed to have a valid result. If fewer than `min_periods` observations are available, the result will be `NaN`.\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **float**\n",
    "  - The computed correlation value between the two Series.\n",
    "\n",
    "### **See also**\n",
    "\n",
    "- **`DataFrame.corr`**: For computing pairwise correlations between columns of a DataFrame.\n",
    "- **`DataFrame.corrwith`**: For computing pairwise correlations with another DataFrame or Series.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Pearson correlation (default)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample Series\n",
    "s1 = pd.Series([1, 2, 3])\n",
    "s2 = pd.Series([1, 2, 3])\n",
    "\n",
    "# Compute Pearson correlation (default)\n",
    "correlation = s1.corr(s2)\n",
    "print(correlation)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "1.0\n",
    "```\n",
    "\n",
    "Explanation: The correlation is 1 because the Series are identical.\n",
    "\n",
    "#### Example 2: Negative correlation (Pearson)\n",
    "\n",
    "```python\n",
    "# Sample Series\n",
    "s1 = pd.Series([1, 2, 3], index=[0, 1, 2])\n",
    "s2 = pd.Series([3, 2, 1], index=[2, 1, 0])\n",
    "\n",
    "# Compute Pearson correlation\n",
    "correlation = s1.corr(s2)\n",
    "print(correlation)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "-1.0\n",
    "```\n",
    "\n",
    "Explanation: The Series have a perfect negative linear relationship.\n",
    "\n",
    "#### Example 3: Custom correlation function (Histogram intersection)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Custom correlation function (Histogram intersection)\n",
    "def histogram_intersection(a, b):\n",
    "    v = np.minimum(a, b).sum().round(decimals=1)\n",
    "    return v\n",
    "\n",
    "# Sample Series\n",
    "s1 = pd.Series([0.2, 0.0, 0.6, 0.2])\n",
    "s2 = pd.Series([0.3, 0.6, 0.0, 0.1])\n",
    "\n",
    "# Compute custom correlation using histogram intersection\n",
    "correlation = s1.corr(s2, method=histogram_intersection)\n",
    "print(correlation)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0.3\n",
    "```\n",
    "\n",
    "Explanation: The custom function computes the histogram intersection between `s1` and `s2`.\n",
    "\n",
    "#### Example 4: Kendall correlation\n",
    "\n",
    "```python\n",
    "# Sample Series\n",
    "s1 = pd.Series([1, 2, 3, 4])\n",
    "s2 = pd.Series([1, 3, 2, 4])\n",
    "\n",
    "# Compute Kendall correlation\n",
    "correlation = s1.corr(s2, method='kendall')\n",
    "print(correlation)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0.5\n",
    "```\n",
    "\n",
    "Explanation: The Kendall Tau correlation coefficient measures the ordinal association between the two Series.\n",
    "\n",
    "#### Example 5: Spearman correlation\n",
    "\n",
    "```python\n",
    "# Sample Series\n",
    "s1 = pd.Series([1, 2, 3, 4])\n",
    "s2 = pd.Series([1, 3, 2, 4])\n",
    "\n",
    "# Compute Spearman correlation\n",
    "correlation = s1.corr(s2, method='spearman')\n",
    "print(correlation)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0.5\n",
    "```\n",
    "\n",
    "Explanation: The Spearman rank correlation coefficient also measures the relationship between the ranks of the values in the Series.\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The correlation is computed after automatically aligning the Series based on their indices.\n",
    "- The available methods are:\n",
    "  - **Pearson**: Standard correlation coefficient, based on linear relationships.\n",
    "  - **Kendall**: Measures ordinal association based on the ranks of the data.\n",
    "  - **Spearman**: Based on the rank values of the data, similar to Kendall but using different mathematical formulas.\n",
    "\n",
    "This method is especially useful for measuring the relationship between two sets of data, where correlation analysis helps in determining how strongly related they are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.count\n",
    "Series.count()[source]\n",
    "Return number of non-NA/null observations in the Series.\n",
    "\n",
    "Returns\n",
    ":\n",
    "int\n",
    "Number of non-null values in the Series.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.count\n",
    "Count non-NA cells for each column or row. \"\"\"\n",
    "s = pd.Series([0.0, 1.0, np.nan])\n",
    "s.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.count()`** function is used to count the number of non-NA (non-null) values in a Series.\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.count()\n",
    "```\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **int**:\n",
    "  - The number of non-null values in the Series.\n",
    "\n",
    "### **See also**\n",
    "\n",
    "- **`DataFrame.count()`**: For counting non-NA values across rows or columns in a DataFrame.\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic count\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample Series with NaN value\n",
    "s = pd.Series([0.0, 1.0, np.nan])\n",
    "\n",
    "# Count non-NA/null values\n",
    "count = s.count()\n",
    "print(count)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "2\n",
    "```\n",
    "\n",
    "Explanation: There are 2 non-null values in the Series, and the `NaN` is excluded from the count.\n",
    "\n",
    "#### Example 2: Series without null values\n",
    "\n",
    "```python\n",
    "# Sample Series without any NaN values\n",
    "s = pd.Series([5, 10, 15])\n",
    "\n",
    "# Count non-NA/null values\n",
    "count = s.count()\n",
    "print(count)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "Explanation: All values are non-null, so the count is 3.\n",
    "\n",
    "#### Example 3: Series with all NaN values\n",
    "\n",
    "```python\n",
    "# Sample Series with all NaN values\n",
    "s = pd.Series([np.nan, np.nan, np.nan])\n",
    "\n",
    "# Count non-NA/null values\n",
    "count = s.count()\n",
    "print(count)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0\n",
    "```\n",
    "\n",
    "Explanation: Since all values are `NaN`, the count of non-null values is 0.\n",
    "\n",
    "The **`count()`** function is helpful for quickly determining how many valid data points (non-null) exist in your Series, especially when working with datasets that may contain missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.cov\n",
    "Series.cov(other, min_periods=None, ddof=1)[source]\n",
    "Compute covariance with Series, excluding missing values.\n",
    "\n",
    "The two Series objects are not required to be the same length and will be aligned internally before the covariance is calculated.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series\n",
    "Series with which to compute the covariance.\n",
    "\n",
    "min_periods\n",
    "int, optional\n",
    "Minimum number of observations needed to have a valid result.\n",
    "\n",
    "ddof\n",
    "int, default 1\n",
    "Delta degrees of freedom. The divisor used in calculations is N - ddof, where N represents the number of elements.\n",
    "\n",
    "Returns\n",
    ":\n",
    "float\n",
    "Covariance between Series and other normalized by N-1 (unbiased estimator).\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.cov\n",
    "Compute pairwise covariance of columns. \"\"\"\n",
    "s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n",
    "s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n",
    "s1.cov(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.cov()`** function computes the **covariance** between two Series, excluding missing values. Covariance measures the relationship between two datasets—whether they increase or decrease together.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.cov(other, min_periods=None, ddof=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`other`** (_Series_):\n",
    "\n",
    "  - The Series to compute covariance with.\n",
    "\n",
    "- **`min_periods`** (_int, optional_):\n",
    "\n",
    "  - Minimum number of valid observations required to perform the calculation.\n",
    "  - If fewer non-null observations exist, the result is `NaN`.\n",
    "\n",
    "- **`ddof`** (_int, default `1`_):\n",
    "  - Delta degrees of freedom.\n",
    "  - The divisor used in calculations is **N - ddof**, where **N** is the number of observations.\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- **float**:\n",
    "  - The covariance value between the two Series, normalized by **N - 1**.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`DataFrame.cov()`** → Computes pairwise covariance between DataFrame columns.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Compute Covariance**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series\n",
    "s1 = pd.Series([0.9, 0.13, 0.62])\n",
    "s2 = pd.Series([0.12, 0.26, 0.51])\n",
    "\n",
    "# Compute covariance\n",
    "covariance = s1.cov(s2)\n",
    "print(covariance)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "-0.01685...\n",
    "```\n",
    "\n",
    "🔹 A **negative covariance** means that when one Series increases, the other tends to decrease.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Series with Different Indexes**\n",
    "\n",
    "```python\n",
    "s1 = pd.Series([1, 2, 3], index=[0, 1, 2])\n",
    "s2 = pd.Series([4, 5, 6], index=[1, 2, 3])\n",
    "\n",
    "# Compute covariance\n",
    "covariance = s1.cov(s2)\n",
    "print(covariance)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "🔹 Since there are no matching index values, `cov()` returns **NaN**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Handling Missing Values**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Series with NaN values\n",
    "s1 = pd.Series([1, np.nan, 3])\n",
    "s2 = pd.Series([4, 5, np.nan])\n",
    "\n",
    "# Compute covariance\n",
    "covariance = s1.cov(s2)\n",
    "print(covariance)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "🔹 Since only one pair of valid observations exists, the result is **NaN**.  \n",
    "🔹 If you add more data, `cov()` will compute the covariance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Using `min_periods`**\n",
    "\n",
    "```python\n",
    "s1 = pd.Series([1, 2, 3, 4])\n",
    "s2 = pd.Series([4, 3, 2, 1])\n",
    "\n",
    "# Compute covariance with min_periods=3\n",
    "covariance = s1.cov(s2, min_periods=3)\n",
    "print(covariance)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "-1.666...\n",
    "```\n",
    "\n",
    "🔹 `cov()` only works if at least `min_periods` valid values exist.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 5: Changing `ddof` (Delta Degrees of Freedom)**\n",
    "\n",
    "```python\n",
    "s1 = pd.Series([10, 20, 30, 40])\n",
    "s2 = pd.Series([5, 15, 25, 35])\n",
    "\n",
    "# Default ddof=1\n",
    "print(s1.cov(s2))  # Output: 125.0\n",
    "\n",
    "# Using ddof=0\n",
    "print(s1.cov(s2, ddof=0))  # Output: 93.75\n",
    "```\n",
    "\n",
    "🔹 **`ddof=0`** gives the population covariance, dividing by **N** instead of **N-1**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ `cov()` measures the relationship between two Series.  \n",
    "✅ Automatically aligns values based on the index.  \n",
    "✅ Excludes `NaN` values from computation.  \n",
    "✅ Supports `min_periods` to control the required number of valid observations.  \n",
    "✅ Changing `ddof` affects how the covariance is normalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.cummax\n",
    "Series.cummax(axis=None, skipna=True, *args, **kwargs)[source]\n",
    "Return cumulative maximum over a DataFrame or Series axis.\n",
    "\n",
    "Returns a DataFrame or Series of the same size containing the cumulative maximum.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "The index or the name of the axis. 0 is equivalent to None or ‘index’. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "scalar or Series\n",
    "Return cumulative maximum of scalar or Series.\n",
    "\n",
    "See also\n",
    "\n",
    "core.window.expanding.Expanding.max\n",
    "Similar functionality but ignores NaN values.\n",
    "\n",
    "Series.max\n",
    "Return the maximum over Series axis.\n",
    "\n",
    "Series.cummax\n",
    "Return cumulative maximum over Series axis.\n",
    "\n",
    "Series.cummin\n",
    "Return cumulative minimum over Series axis.\n",
    "\n",
    "Series.cumsum\n",
    "Return cumulative sum over Series axis.\n",
    "\n",
    "Series.cumprod\n",
    "Return cumulative product over Series axis. \"\"\"\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, NA values are ignored.\n",
    "\n",
    "s.cummax()\n",
    "# To include NA values in the operation, use skipna=False\n",
    "\n",
    "s.cummax(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "\n",
    "df = pd.DataFrame([[2.0, 1.0],\n",
    "                   [3.0, np.nan],\n",
    "                   [1.0, 0.0]],\n",
    "                  columns=list('AB'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, iterates over rows and finds the maximum in each column. This is equivalent to axis=None or axis='index'.\n",
    "\n",
    "df.cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To iterate over columns and find the maximum in each row, use axis=1\n",
    "\n",
    "df.cummax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.cummax()`** function returns the **cumulative maximum** of a Series, meaning it keeps track of the maximum value encountered so far at each position.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.cummax(axis=None, skipna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`axis`** (_{0 or ‘index’}, default `0`_):\n",
    "\n",
    "  - This parameter is unused for a Series and always defaults to `0`.\n",
    "\n",
    "- **`skipna`** (_bool, default `True`_):\n",
    "\n",
    "  - If `True`, **ignores** `NaN` values.\n",
    "  - If `False`, `NaN` values **propagate**, making all subsequent values `NaN`.\n",
    "\n",
    "- **`\\*args, **kwargs`\\*\\*:\n",
    "  - These arguments are **ignored** but exist for compatibility with NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- **Series** → A new Series of the same size with cumulative maximum values.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`Series.cummin()`** → Cumulative minimum.\n",
    "- **`Series.cumsum()`** → Cumulative sum.\n",
    "- **`Series.cumprod()`** → Cumulative product.\n",
    "- **`Series.max()`** → Maximum value in the entire Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Basic Usage**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "print(s.cummax())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    5.0\n",
    "3    5.0\n",
    "4    5.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 The function **remembers** the highest value encountered so far.  \n",
    "🔹 The `NaN` value is **ignored** by default.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Using `skipna=False`**\n",
    "\n",
    "```python\n",
    "print(s.cummax(skipna=False))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 Since `skipna=False`, the presence of `NaN` causes all subsequent values to become `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Cumulative Max in a DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [2.0, 3.0, 1.0],\n",
    "    'B': [1.0, np.nan, 0.0]\n",
    "})\n",
    "print(df.cummax())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  3.0  NaN\n",
    "2  3.0  1.0\n",
    "```\n",
    "\n",
    "🔹 **By default, it computes the max along columns (rows are compared).**\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Cumulative Max Along Rows (`axis=1`)**\n",
    "\n",
    "```python\n",
    "print(df.cummax(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  2.0\n",
    "1  3.0  NaN\n",
    "2  1.0  1.0\n",
    "```\n",
    "\n",
    "🔹 **Each row** now stores its cumulative max across columns.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ **`cummax()`** tracks the highest value seen so far.  \n",
    "✅ By default, `NaN` values are ignored (`skipna=True`).  \n",
    "✅ Setting `skipna=False` makes all subsequent values `NaN`.  \n",
    "✅ Can be used on both **Series** and **DataFrames**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.cummin\n",
    "Series.cummin(axis=None, skipna=True, *args, **kwargs)[source]\n",
    "Return cumulative minimum over a DataFrame or Series axis.\n",
    "\n",
    "Returns a DataFrame or Series of the same size containing the cumulative minimum.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "The index or the name of the axis. 0 is equivalent to None or ‘index’. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "scalar or Series\n",
    "Return cumulative minimum of scalar or Series.\n",
    "\n",
    "\n",
    "core.window.expanding.Expanding.min\n",
    "Similar functionality but ignores NaN values.\n",
    "\n",
    "Series.min\n",
    "Return the minimum over Series axis.\n",
    "\n",
    "Series.cummax\n",
    "Return cumulative maximum over Series axis.\n",
    "\n",
    "Series.cummin\n",
    "Return cumulative minimum over Series axis.\n",
    "\n",
    "Series.cumsum\n",
    "Return cumulative sum over Series axis.\n",
    "\n",
    "Series.cumprod\n",
    "Return cumulative product over Series axis. \"\"\"\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, NA values are ignored.\n",
    "\n",
    "s.cummin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To include NA values in the operation, use skipna=False\n",
    "\n",
    "s.cummin(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "\n",
    "df = pd.DataFrame([[2.0, 1.0],\n",
    "                   [3.0, np.nan],\n",
    "                   [1.0, 0.0]],\n",
    "                  columns=list('AB'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, iterates over rows and finds the minimum in each column. This is equivalent to axis=None or axis='index'.\n",
    "\n",
    "df.cummin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To iterate over columns and find the minimum in each row, use axis=1\n",
    "\n",
    "df.cummin(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.cummin()`** function returns the **cumulative minimum** of a Series, meaning it keeps track of the smallest value encountered so far at each position.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.cummin(axis=None, skipna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`axis`** (_{0 or ‘index’}, default `0`_):\n",
    "\n",
    "  - This parameter is **unused** for a Series and always defaults to `0`.\n",
    "\n",
    "- **`skipna`** (_bool, default `True`_):\n",
    "\n",
    "  - If `True`, **ignores** `NaN` values.\n",
    "  - If `False`, `NaN` values **propagate**, making all subsequent values `NaN`.\n",
    "\n",
    "- **`\\*args, **kwargs`\\*\\*:\n",
    "  - These arguments are **ignored** but exist for compatibility with NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- **Series** → A new Series of the same size with cumulative minimum values.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`Series.cummax()`** → Cumulative maximum.\n",
    "- **`Series.cumsum()`** → Cumulative sum.\n",
    "- **`Series.cumprod()`** → Cumulative product.\n",
    "- **`Series.min()`** → Minimum value in the entire Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Basic Usage**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "print(s.cummin())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    2.0\n",
    "3   -1.0\n",
    "4   -1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 The function **remembers** the smallest value encountered so far.  \n",
    "🔹 The `NaN` value is **ignored** by default.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Using `skipna=False`**\n",
    "\n",
    "```python\n",
    "print(s.cummin(skipna=False))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 Since `skipna=False`, the presence of `NaN` causes all subsequent values to become `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Cumulative Min in a DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [2.0, 3.0, 1.0],\n",
    "    'B': [1.0, np.nan, 0.0]\n",
    "})\n",
    "print(df.cummin())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  2.0  NaN\n",
    "2  1.0  0.0\n",
    "```\n",
    "\n",
    "🔹 **By default, it computes the min along columns (rows are compared).**\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Cumulative Min Along Rows (`axis=1`)**\n",
    "\n",
    "```python\n",
    "print(df.cummin(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  3.0  NaN\n",
    "2  1.0  0.0\n",
    "```\n",
    "\n",
    "🔹 **Each row** now stores its cumulative min across columns.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ **`cummin()`** tracks the smallest value seen so far.  \n",
    "✅ By default, `NaN` values are ignored (`skipna=True`).  \n",
    "✅ Setting `skipna=False` makes all subsequent values `NaN`.  \n",
    "✅ Can be used on both **Series** and **DataFrames**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.cumprod\n",
    "Series.cumprod(axis=None, skipna=True, *args, **kwargs)[source]\n",
    "Return cumulative product over a DataFrame or Series axis.\n",
    "\n",
    "Returns a DataFrame or Series of the same size containing the cumulative product.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "The index or the name of the axis. 0 is equivalent to None or ‘index’. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "scalar or Series\n",
    "Return cumulative product of scalar or Series.\n",
    "\n",
    "\n",
    "core.window.expanding.Expanding.prod\n",
    "Similar functionality but ignores NaN values.\n",
    "\n",
    "Series.prod\n",
    "Return the product over Series axis.\n",
    "\n",
    "Series.cummax\n",
    "Return cumulative maximum over Series axis.\n",
    "\n",
    "Series.cummin\n",
    "Return cumulative minimum over Series axis.\n",
    "\n",
    "Series.cumsum\n",
    "Return cumulative sum over Series axis.\n",
    "\n",
    "Series.cumprod\n",
    "Return cumulative product over Series axis. \"\"\"\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, NA values are ignored.\n",
    "\n",
    "s.cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To include NA values in the operation, use skipna=False\n",
    "\n",
    "s.cumprod(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "\n",
    "df = pd.DataFrame([[2.0, 1.0],\n",
    "                   [3.0, np.nan],\n",
    "                   [1.0, 0.0]],\n",
    "                  columns=list('AB'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, iterates over rows and finds the product in each column. This is equivalent to axis=None or axis='index'.\n",
    "\n",
    "df.cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To iterate over columns and find the product in each row, use axis=1\n",
    "\n",
    "df.cumprod(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.cumprod()`** function computes the **cumulative product** of elements in a Series, meaning it multiplies each element by the product of all previous elements.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.cumprod(axis=None, skipna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`axis`** (_{0 or ‘index’}, default `0`_):\n",
    "\n",
    "  - This parameter is **unused** for a Series and always defaults to `0`.\n",
    "\n",
    "- **`skipna`** (_bool, default `True`_):\n",
    "\n",
    "  - If `True`, **ignores** `NaN` values (continues multiplying non-NaN values).\n",
    "  - If `False`, `NaN` values **propagate**, making all subsequent values `NaN`.\n",
    "\n",
    "- **`\\*args, **kwargs`\\*\\*:\n",
    "  - These arguments are **ignored** but exist for compatibility with NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- **Series** → A new Series of the same size containing the cumulative product.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`Series.prod()`** → Returns the product of all elements in a Series.\n",
    "- **`Series.cumsum()`** → Cumulative sum.\n",
    "- **`Series.cummin()`** → Cumulative minimum.\n",
    "- **`Series.cummax()`** → Cumulative maximum.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Basic Usage**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "print(s.cumprod())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     2.0\n",
    "1     NaN\n",
    "2    10.0\n",
    "3   -10.0\n",
    "4    -0.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 The function multiplies values progressively.  \n",
    "🔹 `NaN` is ignored by default, so it continues computing.  \n",
    "🔹 The final value is `-0.0` (negative zero, which is still `0`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Using `skipna=False`**\n",
    "\n",
    "```python\n",
    "print(s.cumprod(skipna=False))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 Since `skipna=False`, `NaN` causes all subsequent values to be `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Cumulative Product in a DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [2.0, 3.0, 1.0],\n",
    "    'B': [1.0, np.nan, 0.0]\n",
    "})\n",
    "print(df.cumprod())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  6.0  NaN\n",
    "2  6.0  0.0\n",
    "```\n",
    "\n",
    "🔹 **By default, it computes the product along columns (rows are multiplied).**\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Cumulative Product Along Rows (`axis=1`)**\n",
    "\n",
    "```python\n",
    "print(df.cumprod(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  2.0\n",
    "1  3.0  NaN\n",
    "2  1.0  0.0\n",
    "```\n",
    "\n",
    "🔹 Each row now stores its **cumulative product across columns**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ **`cumprod()`** multiplies elements progressively.  \n",
    "✅ By default, `NaN` values are ignored (`skipna=True`).  \n",
    "✅ Setting `skipna=False` makes all subsequent values `NaN`.  \n",
    "✅ Can be used on both **Series** and **DataFrames**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.cumsum\n",
    "Series.cumsum(axis=None, skipna=True, *args, **kwargs)[source]\n",
    "Return cumulative sum over a DataFrame or Series axis.\n",
    "\n",
    "Returns a DataFrame or Series of the same size containing the cumulative sum.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "The index or the name of the axis. 0 is equivalent to None or ‘index’. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "scalar or Series\n",
    "Return cumulative sum of scalar or Series.\n",
    "\n",
    "\n",
    "core.window.expanding.Expanding.sum\n",
    "Similar functionality but ignores NaN values.\n",
    "\n",
    "Series.sum\n",
    "Return the sum over Series axis.\n",
    "\n",
    "Series.cummax\n",
    "Return cumulative maximum over Series axis.\n",
    "\n",
    "Series.cummin\n",
    "Return cumulative minimum over Series axis.\n",
    "\n",
    "Series.cumsum\n",
    "Return cumulative sum over Series axis.\n",
    "\n",
    "Series.cumprod\n",
    "Return cumulative product over Series axis. \"\"\"\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, NA values are ignored.\n",
    "\n",
    "s.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To include NA values in the operation, use skipna=False\n",
    "\n",
    "s.cumsum(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame\n",
    "\n",
    "df = pd.DataFrame([[2.0, 1.0],\n",
    "                   [3.0, np.nan],\n",
    "                   [1.0, 0.0]],\n",
    "columns=list('AB'))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, iterates over rows and finds the sum in each column. This is equivalent to axis=None or axis='index'.\n",
    "\n",
    "df.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To iterate over columns and find the sum in each row, use axis=1\n",
    "\n",
    "df.cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.cumsum()`** function calculates the **cumulative sum** of a Series, meaning each value is replaced by the sum of itself and all previous values.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.cumsum(axis=None, skipna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`axis`** (_{0 or ‘index’}, default `0`_):\n",
    "\n",
    "  - This parameter is **unused** for Series and always defaults to `0`.\n",
    "\n",
    "- **`skipna`** (_bool, default `True`_):\n",
    "\n",
    "  - If `True`, **ignores** `NaN` values and continues summing non-NaN values.\n",
    "  - If `False`, `NaN` values **propagate**, making all subsequent values `NaN`.\n",
    "\n",
    "- **`\\*args, **kwargs`\\*\\*:\n",
    "  - These arguments are **ignored** but exist for compatibility with NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- **Series** → A new Series of the same size containing the cumulative sum.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`Series.sum()`** → Returns the sum of all elements in a Series.\n",
    "- **`Series.cumprod()`** → Cumulative product.\n",
    "- **`Series.cummin()`** → Cumulative minimum.\n",
    "- **`Series.cummax()`** → Cumulative maximum.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Basic Usage**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "print(s.cumsum())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    7.0\n",
    "3    6.0\n",
    "4    6.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 The function adds values progressively.  \n",
    "🔹 `NaN` is ignored by default, so it continues computing.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Using `skipna=False`**\n",
    "\n",
    "```python\n",
    "print(s.cumsum(skipna=False))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 Since `skipna=False`, `NaN` causes all subsequent values to be `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Cumulative Sum in a DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [2.0, 3.0, 1.0],\n",
    "    'B': [1.0, np.nan, 0.0]\n",
    "})\n",
    "print(df.cumsum())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  5.0  NaN\n",
    "2  6.0  1.0\n",
    "```\n",
    "\n",
    "🔹 **By default, it computes the sum along columns (rows are added up).**\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Cumulative Sum Along Rows (`axis=1`)**\n",
    "\n",
    "```python\n",
    "print(df.cumsum(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  3.0  NaN\n",
    "2  1.0  1.0\n",
    "```\n",
    "\n",
    "🔹 Each row now stores its **cumulative sum across columns**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ **`cumsum()`** adds elements progressively.  \n",
    "✅ By default, `NaN` values are ignored (`skipna=True`).  \n",
    "✅ Setting `skipna=False` makes all subsequent values `NaN`.  \n",
    "✅ Can be used on both **Series** and **DataFrames**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.diff\n",
    "Series.diff(periods=1)[source]\n",
    "First discrete difference of element.\n",
    "\n",
    "Calculates the difference of a Series element compared with another element in the Series (default is element in previous row).\n",
    "\n",
    "Parameters\n",
    ":\n",
    "periods\n",
    "int, default 1\n",
    "Periods to shift for calculating difference, accepts negative values.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "First differences of the Series.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.pct_change\n",
    "Percent change over given number of periods.\n",
    "\n",
    "Series.shift\n",
    "Shift index by desired number of periods with an optional time freq.\n",
    "\n",
    "DataFrame.diff\n",
    "First discrete difference of object.\n",
    "\n",
    "Notes\n",
    "\n",
    "For boolean dtypes, this uses operator.xor() rather than operator.sub(). The result is calculated according to current dtype in Series, however dtype of the result is always float64. \"\"\"\n",
    "s = pd.Series([1, 1, 2, 3, 5, 8])\n",
    "s.diff()\n",
    "s.diff(periods=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.diff(periods=-1)\n",
    "s = pd.Series([1, 0], dtype=np.uint8)\n",
    "s.diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.diff()`** function computes the **difference between consecutive elements** in a Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.diff(periods=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`periods`** (_int, default=1_):\n",
    "  - Specifies how many places to shift before computing the difference.\n",
    "  - Positive values → Compute difference with **previous** elements.\n",
    "  - Negative values → Compute difference with **future** elements.\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- **Series** → A new Series containing the computed differences.\n",
    "\n",
    "📌 The **first `periods` elements** will be **NaN** since they have no previous value to subtract.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`Series.pct_change()`** → Computes **percent change** over periods.\n",
    "- **`Series.shift()`** → Shifts values **without** computing differences.\n",
    "- **`DataFrame.diff()`** → Computes differences for **DataFrames**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Compute the First Difference (Default)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 1, 2, 3, 5, 8])\n",
    "print(s.diff())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    NaN\n",
    "1    0.0\n",
    "2    1.0\n",
    "3    1.0\n",
    "4    2.0\n",
    "5    3.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 The first value is **NaN** (no previous value).  \n",
    "🔹 Each value is **subtracted from the previous one**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Difference with the 3rd Previous Row (`periods=3`)**\n",
    "\n",
    "```python\n",
    "print(s.diff(periods=3))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    NaN\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    2.0\n",
    "4    4.0\n",
    "5    6.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 The difference is calculated with the **third previous value**.  \n",
    "🔹 The first **three** values are **NaN**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Difference with the Next Row (`periods=-1`)**\n",
    "\n",
    "```python\n",
    "print(s.diff(periods=-1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    0.0\n",
    "1   -1.0\n",
    "2   -1.0\n",
    "3   -2.0\n",
    "4   -3.0\n",
    "5    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 A negative `periods` shifts in the **opposite direction** (future values).  \n",
    "🔹 The last element is **NaN**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Handling Unsigned Integers (`uint8` Overflow)**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1, 0], dtype=np.uint8)\n",
    "print(s.diff())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0      NaN\n",
    "1    255.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 Since `1 - 0 = 1`, we expect `1.0`, but the **uint8 type overflows** (255 instead of -1).  \n",
    "🔹 The result is **always float64** to prevent overflow.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ **`diff()` computes the difference** between values based on a given `periods`.  \n",
    "✅ Default is **previous row (`periods=1`)**, but **can be customized**.  \n",
    "✅ **First `periods` values are `NaN`** because they have no reference.  \n",
    "✅ **Supports negative values** (`periods=-1` computes difference with future values).  \n",
    "✅ **Returns float64**, even for integer inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.factorize\n",
    "Series.factorize(sort=False, use_na_sentinel=True)[source]\n",
    "Encode the object as an enumerated type or categorical variable.\n",
    "\n",
    "This method is useful for obtaining a numeric representation of an array when all that matters is identifying distinct values. factorize is available as both a top-level function pandas.factorize(), and as a method Series.factorize() and Index.factorize().\n",
    "\n",
    "Parameters:\n",
    "sortbool, default False\n",
    "Sort uniques and shuffle codes to maintain the relationship.\n",
    "\n",
    "use_na_sentinelbool, default True\n",
    "If True, the sentinel -1 will be used for NaN values. If False, NaN values will be encoded as non-negative integers and will not drop the NaN from the uniques of the values.\n",
    "\n",
    "Added in version 1.5.0.\n",
    "\n",
    "Returns:\n",
    "codesndarray\n",
    "An integer ndarray that’s an indexer into uniques. uniques.take(codes) will have the same values as values.\n",
    "\n",
    "uniquesndarray, Index, or Categorical\n",
    "The unique valid values. When values is Categorical, uniques is a Categorical. When values is some other pandas object, an Index is returned. Otherwise, a 1-D ndarray is returned.\n",
    "\n",
    "Note\n",
    "\n",
    "Even if there’s a missing value in values, uniques will not contain an entry for it.\n",
    "\n",
    "\n",
    "cut\n",
    "Discretize continuous-valued array.\n",
    "\n",
    "unique\n",
    "Find the unique value in an array. \"\"\"\n",
    "codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=\"O\"))\n",
    "codes, uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With sort=True, the uniques will be sorted, and codes will be shuffled so that the relationship is the maintained.\n",
    "\n",
    "codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=\"O\"),\n",
    "                              sort=True)\n",
    "codes\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When use_na_sentinel=True (the default), missing values are indicated in the codes with the sentinel value -1 and missing values are not included in uniques.\n",
    "\n",
    "codes, uniques = pd.factorize(np.array(['b', None, 'a', 'c', 'b'], dtype=\"O\"))\n",
    "codes\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
    "codes, uniques = pd.factorize(cat)\n",
    "codes\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pd.Series(['a', 'a', 'c'])\n",
    "codes, uniques = pd.factorize(cat)\n",
    "codes\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If NaN is in the values, and we want to include NaN in the uniques of the values, it can be achieved by setting use_na_sentinel=False.\n",
    "\n",
    "values = np.array([1, 2, 1, np.nan])\n",
    "codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True\n",
    "codes\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(values, use_na_sentinel=False)\n",
    "codes\n",
    "uniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.factorize()`** method converts a Series into numeric labels (integer codes) representing unique values.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.factorize(sort=False, use_na_sentinel=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`sort`** (_bool, default=False_)\n",
    "\n",
    "  - If `True`, unique values are sorted before encoding.\n",
    "  - Codes are shuffled to maintain value relationships.\n",
    "\n",
    "- **`use_na_sentinel`** (_bool, default=True_)\n",
    "  - If `True`, **missing values (NaN)** are assigned **-1**.\n",
    "  - If `False`, NaNs are assigned a **numeric code** and included in `uniques`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- **`codes`** (_ndarray_) → An array of **integer labels** for the Series values.\n",
    "- **`uniques`** (_ndarray, Index, or Categorical_) → Array of **unique values** in the order of first appearance.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`pandas.factorize()`** → Top-level function for factorization.\n",
    "- **`Series.unique()`** → Finds unique values in a Series.\n",
    "- **`pandas.cut()`** → Discretizes continuous data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Basic Factorization**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series(['b', 'b', 'a', 'c', 'b'])\n",
    "codes, uniques = s.factorize()\n",
    "print(\"Codes:\", codes)\n",
    "print(\"Uniques:\", uniques)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Codes: [0 0 1 2 0]\n",
    "Uniques: ['b' 'a' 'c']\n",
    "```\n",
    "\n",
    "🔹 The first occurrence of each value gets a **unique integer code**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Sorting Unique Values (`sort=True`)**\n",
    "\n",
    "```python\n",
    "codes, uniques = s.factorize(sort=True)\n",
    "print(\"Codes:\", codes)\n",
    "print(\"Uniques:\", uniques)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Codes: [1 1 0 2 1]\n",
    "Uniques: ['a' 'b' 'c']\n",
    "```\n",
    "\n",
    "🔹 The **unique values are sorted**, and codes are reassigned accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Handling NaN Values (`use_na_sentinel=True`)**\n",
    "\n",
    "```python\n",
    "s = pd.Series(['b', None, 'a', 'c', 'b'])\n",
    "codes, uniques = s.factorize()\n",
    "print(\"Codes:\", codes)\n",
    "print(\"Uniques:\", uniques)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Codes: [ 0 -1  1  2  0]\n",
    "Uniques: ['b' 'a' 'c']\n",
    "```\n",
    "\n",
    "🔹 The **NaN value gets `-1`** and is **not** included in `uniques`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Including NaN in Unique Values (`use_na_sentinel=False`)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 1, np.nan])\n",
    "codes, uniques = s.factorize(use_na_sentinel=False)\n",
    "print(\"Codes:\", codes)\n",
    "print(\"Uniques:\", uniques)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Codes: [0 1 0 2]\n",
    "Uniques: [ 1.  2. nan]\n",
    "```\n",
    "\n",
    "🔹 **NaN gets a normal integer code** instead of `-1`.  \n",
    "🔹 NaN is now **included** in the unique values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 5: Factorizing a Pandas Categorical**\n",
    "\n",
    "```python\n",
    "cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
    "codes, uniques = pd.factorize(cat)\n",
    "print(\"Codes:\", codes)\n",
    "print(\"Uniques:\", uniques)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Codes: [0 0 1]\n",
    "Uniques: ['a', 'c']\n",
    "Categories (3, object): ['a', 'b', 'c']\n",
    "```\n",
    "\n",
    "🔹 The **category ‘b’ exists** in the categories but **doesn’t appear** in the data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 6: Factorizing a Pandas Series**\n",
    "\n",
    "```python\n",
    "s = pd.Series(['a', 'a', 'c'])\n",
    "codes, uniques = s.factorize()\n",
    "print(\"Codes:\", codes)\n",
    "print(\"Uniques:\", uniques)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Codes: [0 0 1]\n",
    "Uniques: Index(['a', 'c'], dtype='object')\n",
    "```\n",
    "\n",
    "🔹 **Returns a Pandas Index** instead of an ndarray.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ **Converts categorical data into numeric labels**.  \n",
    "✅ **Handles NaN values** differently based on `use_na_sentinel`.  \n",
    "✅ **Can sort unique values** using `sort=True`.  \n",
    "✅ **Works on NumPy arrays, Pandas Series, and Categoricals**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.kurt\n",
    "Series.kurt(axis=0, skipna=True, numeric_only=False, **kwargs)[source]\n",
    "Return unbiased kurtosis over requested axis.\n",
    "\n",
    "Kurtosis obtained using Fisher’s definition of kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "For DataFrames, specifying axis=None will apply the aggregation across both axes.\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar \"\"\"\n",
    "s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.kurt()\n",
    "'''With a DataFrame'''\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},\n",
    "                  index=['cat', 'dog', 'dog', 'mouse'])\n",
    "df\n",
    "df.kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  With axis=None\n",
    "\n",
    "df.kurt(axis=None).round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using axis=1\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},\n",
    "                  index=['cat', 'dog'])\n",
    "df.kurt(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.kurt()`** method calculates the **kurtosis** of a dataset, which measures the \"tailedness\" of the distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.kurt(axis=0, skipna=True, numeric_only=False, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`axis`** (_{0, ‘index’}, default=0_)\n",
    "\n",
    "  - This parameter is **unused** for Series and defaults to 0.\n",
    "\n",
    "- **`skipna`** (_bool, default=True_)\n",
    "\n",
    "  - If `True`, **ignores NaN values** during computation.\n",
    "  - If `False`, returns `NaN` if any missing values exist.\n",
    "\n",
    "- **`numeric_only`** (_bool, default=False_)\n",
    "\n",
    "  - Not implemented for Series.\n",
    "\n",
    "- **`**kwargs`\\*\\*\n",
    "  - Additional arguments (rarely used).\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- A **scalar (float)** representing the kurtosis of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **Definition**\n",
    "\n",
    "The **kurtosis** is computed using **Fisher’s definition**:\n",
    "\n",
    "- **Normal distribution → Kurtosis = 0.0**\n",
    "- **High kurtosis (>0)** → More outliers (heavy tails).\n",
    "- **Low kurtosis (<0)** → Fewer outliers (light tails).\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`Series.skew()`** → Computes skewness of a Series.\n",
    "- **`Series.var()`** → Computes variance.\n",
    "- **`Series.std()`** → Computes standard deviation.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Compute Kurtosis for a Series**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 2, 3])\n",
    "print(s.kurt())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "1.5\n",
    "```\n",
    "\n",
    "🔹 The dataset has **heavy tails** (kurtosis > 0).\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Compute Kurtosis with NaN Values**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 2, 3, None])\n",
    "print(s.kurt(skipna=True))  # Ignores NaN\n",
    "print(s.kurt(skipna=False)) # Returns NaN if any missing values exist\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "1.5\n",
    "nan\n",
    "```\n",
    "\n",
    "🔹 **With `skipna=False`, the result is NaN.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Kurtosis for a DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3],\n",
    "    'B': [3, 4, 4, 4]\n",
    "})\n",
    "\n",
    "print(df.kurt())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "A    1.5\n",
    "B    4.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 **Column `B` has more extreme outliers** (higher kurtosis).\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Compute Kurtosis Across All Values**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 3], 'B': [3, 4, 4, 4]})\n",
    "print(df.kurt(axis=None).round(6))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "-0.988693\n",
    "```\n",
    "\n",
    "🔹 **Negative kurtosis → Light tails** (fewer outliers).\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 5: Compute Kurtosis Along Rows**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, 2], 'B': [3, 4], 'C': [3, 4], 'D': [1, 2]},\n",
    "                  index=['cat', 'dog'])\n",
    "print(df.kurt(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "cat   -6.0\n",
    "dog   -6.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "🔹 **Negative kurtosis means a flatter distribution**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ **Measures tail extremity** of data distribution.  \n",
    "✅ **Fisher’s definition** → Normal distribution has kurtosis **0**.  \n",
    "✅ **Handles NaN values** with `skipna=True`.  \n",
    "✅ **Works on both Series & DataFrames**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.max\n",
    "Series.max(axis=0, skipna=True, numeric_only=False, **kwargs)[source]\n",
    "Return the maximum of the values over the requested axis.\n",
    "\n",
    "If you want the index of the maximum, use idxmax. This is the equivalent of the numpy.ndarray method argmax.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "For DataFrames, specifying axis=None will apply the aggregation across both axes.\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar\n",
    "\n",
    "Series.sum\n",
    "Return the sum.\n",
    "\n",
    "Series.min\n",
    "Return the minimum.\n",
    "\n",
    "Series.max\n",
    "Return the maximum.\n",
    "\n",
    "Series.idxmin\n",
    "Return the index of the minimum.\n",
    "\n",
    "Series.idxmax\n",
    "Return the index of the maximum.\n",
    "\n",
    "DataFrame.sum\n",
    "Return the sum over the requested axis.\n",
    "\n",
    "DataFrame.min\n",
    "Return the minimum over the requested axis.\n",
    "\n",
    "DataFrame.max\n",
    "Return the maximum over the requested axis.\n",
    "\n",
    "DataFrame.idxmin\n",
    "Return the index of the minimum over the requested axis.\n",
    "\n",
    "DataFrame.idxmax\n",
    "Return the index of the maximum over the requested axis. \"\"\"\n",
    "idx = pd.MultiIndex.from_arrays([\n",
    "    ['warm', 'warm', 'cold', 'cold'],\n",
    "    ['dog', 'falcon', 'fish', 'spider']],\n",
    "    names=['blooded', 'animal'])\n",
    "s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    "s\n",
    "s.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.Series.max()`** method returns the **maximum value** of a Series, ignoring NaN values by default.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "Series.max(axis=0, skipna=True, numeric_only=False, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "- **`axis`** (_{0, ‘index’}, default=0_)\n",
    "\n",
    "  - **Unused** for Series (default is 0).\n",
    "  - For DataFrames, `axis=0` finds the max for each column, `axis=1` for each row.\n",
    "\n",
    "- **`skipna`** (_bool, default=True_)\n",
    "\n",
    "  - If `True`, **ignores NaN values** while computing the max.\n",
    "  - If `False`, returns `NaN` if any missing values exist.\n",
    "\n",
    "- **`numeric_only`** (_bool, default=False_)\n",
    "\n",
    "  - **Not implemented for Series.**\n",
    "\n",
    "- **`**kwargs`\\*\\*\n",
    "  - Additional arguments (**rarely used**).\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- A **scalar** (single value) representing the maximum value of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`Series.min()`** → Finds the minimum value.\n",
    "- **`Series.idxmax()`** → Finds the **index** of the maximum value.\n",
    "- **`Series.sum()`** → Computes the sum of elements.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Find the Maximum Value in a Series**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([4, 2, 9, 1, 7])\n",
    "print(s.max())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "9\n",
    "```\n",
    "\n",
    "🔹 **`9` is the maximum value in the Series.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Handling NaN Values**\n",
    "\n",
    "```python\n",
    "s = pd.Series([4, 2, None, 9, 1])\n",
    "print(s.max(skipna=True))  # Ignores NaN\n",
    "print(s.max(skipna=False)) # Returns NaN if NaN is present\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "9\n",
    "nan\n",
    "```\n",
    "\n",
    "🔹 **With `skipna=False`, the result is `NaN` because of the missing value.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Maximum Value in a MultiIndex Series**\n",
    "\n",
    "```python\n",
    "idx = pd.MultiIndex.from_arrays([\n",
    "    ['warm', 'warm', 'cold', 'cold'],\n",
    "    ['dog', 'falcon', 'fish', 'spider']],\n",
    "    names=['blooded', 'animal'])\n",
    "\n",
    "s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    "print(s.max())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "8\n",
    "```\n",
    "\n",
    "🔹 The **maximum value in the Series is `8`** (spider's legs).\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Find the Maximum Value in a DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 5, 3],\n",
    "    'B': [4, 2, 8]\n",
    "})\n",
    "\n",
    "print(df.max())        # Column-wise max (default)\n",
    "print(df.max(axis=1))  # Row-wise max\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "A    5\n",
    "B    8\n",
    "dtype: int64\n",
    "\n",
    "0    4\n",
    "1    5\n",
    "2    8\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "🔹 **Column-wise max:** `A: 5, B: 8`  \n",
    "🔹 **Row-wise max:** `4, 5, 8`\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 5: Find the Index of the Maximum Value**\n",
    "\n",
    "```python\n",
    "s = pd.Series([10, 20, 30, 25])\n",
    "print(s.idxmax())  # Returns index of max value\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2\n",
    "```\n",
    "\n",
    "🔹 The **maximum value (`30`) is at index `2`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "\n",
    "✅ **Finds the max value** in a Series or DataFrame.  \n",
    "✅ **Ignores NaN** by default, but can be configured.  \n",
    "✅ **For DataFrames**, works column-wise (`axis=0`) or row-wise (`axis=1`).  \n",
    "✅ **Use `idxmax()`** to get the **index** of the max value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.mean\n",
    "Series.mean(axis=0, skipna=True, numeric_only=False, **kwargs)[source]\n",
    "Return the mean of the values over the requested axis.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "For DataFrames, specifying axis=None will apply the aggregation across both axes.\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar \"\"\"\n",
    "s = pd.Series([1, 2, 3])\n",
    "s.mean()\n",
    "\n",
    "#  With a DataFrame\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
    "df\n",
    "df.mean()\n",
    "#  Using axis=1\n",
    "\n",
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, numeric_only should be set to True to avoid getting an error.\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
    "                  index=['tiger', 'zebra'])\n",
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a detailed reference for the **`pandas.Series.mean()`** method, including all syntaxes and examples:\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Syntax**\n",
    "\n",
    "```python\n",
    "Series.mean(axis=0, skipna=True, numeric_only=False, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Parameters**\n",
    "\n",
    "| Parameter      | Type             | Default | Description                                                                             |\n",
    "| -------------- | ---------------- | ------- | --------------------------------------------------------------------------------------- |\n",
    "| `axis`         | `{0 or ‘index’}` | `0`     | Not used for Series. For DataFrames, it specifies the axis (0 for rows, 1 for columns). |\n",
    "| `skipna`       | `bool`           | `True`  | If `True`, ignores `NaN` values. If `False`, returns `NaN` if any missing values exist. |\n",
    "| `numeric_only` | `bool`           | `False` | For DataFrames: includes only numeric columns. For Series, this doesn't have an effect. |\n",
    "| `**kwargs`     | -                | -       | Additional arguments that might be passed (rarely needed).                              |\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Return Value**\n",
    "\n",
    "- Returns a **scalar** representing the **mean** value of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Examples**\n",
    "\n",
    "### **Series Example**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.mean())  # Output: 2.0\n",
    "```\n",
    "\n",
    "### **DataFrame Example (default axis)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
    "print(df.mean())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1.5\n",
    "b    2.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### **DataFrame Example (using axis=1)**\n",
    "\n",
    "```python\n",
    "print(df.mean(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "tiger    1.5\n",
    "zebra    2.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### **DataFrame with Mixed Data Types**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']}, index=['tiger', 'zebra'])\n",
    "print(df.mean(numeric_only=True))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Key Notes**\n",
    "\n",
    "- **NaN Handling**: The `skipna=True` argument ensures that missing values (NaN) are excluded from the mean calculation.\n",
    "- **For DataFrames**: You can specify `axis=1` to compute the mean across columns instead of rows.\n",
    "- **Mixed Data Types**: When calculating the mean of a DataFrame with non-numeric columns, set `numeric_only=True` to avoid errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" pandas.Series.median\n",
    "Series.median(axis=0, skipna=True, numeric_only=False, **kwargs)[source]\n",
    "Return the median of the values over the requested axis.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "For DataFrames, specifying axis=None will apply the aggregation across both axes.\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar \"\"\"\n",
    "s = pd.Series([1, 2, 3])\n",
    "s.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a DataFrame\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
    "df\n",
    "\n",
    "df.median()\n",
    "# Using axis=1\n",
    "\n",
    "df.median(axis=1)\n",
    "# In this case, numeric_only should be set to True to avoid getting an error.\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
    "                  index=['tiger', 'zebra'])\n",
    "df.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a detailed reference for **`pandas.Series.median()`** method, including all syntaxes and examples:\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Syntax**\n",
    "\n",
    "```python\n",
    "Series.median(axis=0, skipna=True, numeric_only=False, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Parameters**\n",
    "\n",
    "| Parameter      | Type             | Default | Description                                                                                |\n",
    "| -------------- | ---------------- | ------- | ------------------------------------------------------------------------------------------ |\n",
    "| `axis`         | `{0 or ‘index’}` | `0`     | Not used for Series. For DataFrames, it specifies the axis (0 for rows, 1 for columns).    |\n",
    "| `skipna`       | `bool`           | `True`  | If `True`, it ignores `NaN` values. If `False`, returns `NaN` if any missing values exist. |\n",
    "| `numeric_only` | `bool`           | `False` | For DataFrames: includes only numeric columns. For Series, this doesn't have an effect.    |\n",
    "| `**kwargs`     | -                | -       | Additional arguments that might be passed (rarely needed).                                 |\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Return Value**\n",
    "\n",
    "- Returns a **scalar** representing the **median** value of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Examples**\n",
    "\n",
    "### **Series Example**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.median())  # Output: 2.0\n",
    "```\n",
    "\n",
    "### **DataFrame Example (default axis)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
    "print(df.median())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1.5\n",
    "b    2.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### **DataFrame Example (using axis=1)**\n",
    "\n",
    "```python\n",
    "print(df.median(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "tiger    1.5\n",
    "zebra    2.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### **DataFrame with Mixed Data Types**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']}, index=['tiger', 'zebra'])\n",
    "print(df.median(numeric_only=True))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Key Notes**\n",
    "\n",
    "- **NaN Handling**: The `skipna=True` argument ensures that missing values (NaN) are excluded from the median calculation.\n",
    "- **For DataFrames**: You can specify `axis=1` to compute the median across columns instead of rows.\n",
    "- **Mixed Data Types**: When calculating the median of a DataFrame with non-numeric columns, set `numeric_only=True` to avoid errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.min\n",
    "Series.min(axis=0, skipna=True, numeric_only=False, **kwargs)[source]\n",
    "Return the minimum of the values over the requested axis.\n",
    "\n",
    "If you want the index of the minimum, use idxmin. This is the equivalent of the numpy.ndarray method argmin.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "For DataFrames, specifying axis=None will apply the aggregation across both axes.\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar\n",
    "\n",
    "\n",
    "Series.sum\n",
    "Return the sum.\n",
    "\n",
    "Series.min\n",
    "Return the minimum.\n",
    "\n",
    "Series.max\n",
    "Return the maximum.\n",
    "\n",
    "Series.idxmin\n",
    "Return the index of the minimum.\n",
    "\n",
    "Series.idxmax\n",
    "Return the index of the maximum.\n",
    "\n",
    "DataFrame.sum\n",
    "Return the sum over the requested axis.\n",
    "\n",
    "DataFrame.min\n",
    "Return the minimum over the requested axis.\n",
    "\n",
    "DataFrame.max\n",
    "Return the maximum over the requested axis.\n",
    "\n",
    "DataFrame.idxmin\n",
    "Return the index of the minimum over the requested axis.\n",
    "\n",
    "DataFrame.idxmax\n",
    "Return the index of the maximum over the requested axis. \"\"\"\n",
    "\n",
    "\n",
    "idx = pd.MultiIndex.from_arrays([\n",
    "    ['warm', 'warm', 'cold', 'cold'],\n",
    "    ['dog', 'falcon', 'fish', 'spider']],\n",
    "    names=['blooded', 'animal'])\n",
    "s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    "s\n",
    "s.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a detailed breakdown of the **`pandas.Series.min()`** method, including syntaxes, parameters, return values, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Syntax**\n",
    "\n",
    "```python\n",
    "Series.min(axis=0, skipna=True, numeric_only=False, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Parameters**\n",
    "\n",
    "| Parameter      | Type             | Default | Description                                                                             |\n",
    "| -------------- | ---------------- | ------- | --------------------------------------------------------------------------------------- |\n",
    "| `axis`         | `{0 or ‘index’}` | `0`     | Axis for the function to be applied on. (For Series, this is unused and defaults to 0). |\n",
    "| `skipna`       | `bool`           | `True`  | Exclude `NaN` values if `True`. If `False`, returns `NaN` if any missing values exist.  |\n",
    "| `numeric_only` | `bool`           | `False` | For DataFrames, includes only numeric columns. Not applicable for Series.               |\n",
    "| `**kwargs`     | -                | -       | Additional keyword arguments that may be passed (rarely needed).                        |\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Return Value**\n",
    "\n",
    "- Returns the **minimum** value of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Examples**\n",
    "\n",
    "### **Series Example**\n",
    "\n",
    "```python\n",
    "s = pd.Series([4, 2, 3, 1])\n",
    "print(s.min())  # Output: 1\n",
    "```\n",
    "\n",
    "### **DataFrame Example (default axis)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [5, 3], 'b': [8, 4]}, index=['cat', 'dog'])\n",
    "print(df.min())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    3\n",
    "b    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### **DataFrame Example (using axis=1)**\n",
    "\n",
    "```python\n",
    "print(df.min(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "cat    5\n",
    "dog    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### **MultiIndex Series Example**\n",
    "\n",
    "```python\n",
    "idx = pd.MultiIndex.from_arrays([\n",
    "    ['warm', 'warm', 'cold', 'cold'],\n",
    "    ['dog', 'falcon', 'fish', 'spider']],\n",
    "    names=['blooded', 'animal'])\n",
    "s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    "print(s.min())  # Output: 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Related Functions**\n",
    "\n",
    "- **`Series.idxmin()`**: Returns the index of the minimum value.\n",
    "- **`Series.max()`**: Returns the maximum value.\n",
    "- **`DataFrame.min()`**: Computes the minimum across DataFrame columns or rows (depending on `axis`).\n",
    "- **`Series.sum()`**: Computes the sum of the values.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.mode\n",
    "Series.mode(dropna=True)[source]\n",
    "Return the mode(s) of the Series.\n",
    "\n",
    "The mode is the value that appears most often. There can be multiple modes.\n",
    "\n",
    "Always returns Series even if only one value is returned.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "dropna\n",
    "bool, default True\n",
    "Don’t consider counts of NaN/NaT.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "Modes of the Series in sorted order. \"\"\"\n",
    "s = pd.Series([2, 4, 2, 2, 4, None])\n",
    "s.mode()\n",
    "s = pd.Series([2, 4, 8, 2, 4, None])\n",
    "s.mode()\n",
    "s = pd.Series([2, 4, None, None, 4, None])\n",
    "s.mode(dropna=False)\n",
    "s = pd.Series([2, 4, None, None, 4, None])\n",
    "s.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a comprehensive breakdown of the **`pandas.Series.mode()`** method:\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Syntax**\n",
    "\n",
    "```python\n",
    "Series.mode(dropna=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Parameters**\n",
    "\n",
    "| Parameter | Type   | Default | Description                                                                                                                                              |\n",
    "| --------- | ------ | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `dropna`  | `bool` | `True`  | Whether or not to ignore `NaN` values. If `True`, NaN is not considered in the mode calculation. If `False`, NaN will be treated as a mode if it occurs. |\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Return Value**\n",
    "\n",
    "- Returns a **Series** containing the mode(s) of the Series. If there are multiple modes, all of them are returned in sorted order.\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Examples**\n",
    "\n",
    "### **Single Mode Example**\n",
    "\n",
    "```python\n",
    "s = pd.Series([2, 4, 2, 2, 4, None])\n",
    "print(s.mode())  # Output: 2.0\n",
    "```\n",
    "\n",
    "### **Multiple Modes Example**\n",
    "\n",
    "```python\n",
    "s = pd.Series([2, 4, 8, 2, 4, None])\n",
    "print(s.mode())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    4.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### **Mode Including `NaN` (dropna=False)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([2, 4, None, None, 4, None])\n",
    "print(s.mode(dropna=False))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0   NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### **Mode Excluding `NaN` (dropna=True, default)**\n",
    "\n",
    "```python\n",
    "s = pd.Series([2, 4, None, None, 4, None])\n",
    "print(s.mode())  # Output: 4.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Notes**\n",
    "\n",
    "- **NaN/NaT handling**: By default, `dropna=True`, so any `NaN` values are excluded from the calculation. If `dropna=False`, `NaN` can also appear as a mode if it occurs.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.nlargest\n",
    "Series.nlargest(n=5, keep='first')[source]\n",
    "Return the largest n elements.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "n\n",
    "int, default 5\n",
    "Return this many descending sorted values.\n",
    "\n",
    "keep\n",
    "{‘first’, ‘last’, ‘all’}, default ‘first’\n",
    "When there are duplicate values that cannot all fit in a Series of n elements:\n",
    "\n",
    "first : return the first n occurrences in order of appearance.\n",
    "\n",
    "last : return the last n occurrences in reverse order of appearance.\n",
    "\n",
    "all : keep all occurrences. This can result in a Series of size larger than n.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The n largest values in the Series, sorted in decreasing order.\n",
    "\n",
    "Series.nsmallest\n",
    "Get the n smallest elements.\n",
    "\n",
    "Series.sort_values\n",
    "Sort Series by values.\n",
    "\n",
    "Series.head\n",
    "Return the first n rows. \"\"\"\n",
    "\n",
    "\"\"\" Notes\n",
    "\n",
    "Faster than .sort_values(ascending=False).head(n) for small n relative to the size of the Series object. \"\"\"\n",
    "countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
    "                        \"Malta\": 434000, \"Maldives\": 434000,\n",
    "                        \"Brunei\": 434000, \"Iceland\": 337000,\n",
    "                        \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
    "                        \"Anguilla\": 11300, \"Montserrat\": 5200}\n",
    "s = pd.Series(countries_population)\n",
    "s\n",
    "s.nlargest()\n",
    "#  The n largest elements where n=3. Default keep value is ‘first’ so Malta will be kept.\n",
    "\n",
    "s.nlargest(3)\n",
    "# The n largest elements where n=3 and keeping the last duplicates. Brunei will be kept since it is the last with value 434000 based on the index order.\n",
    "\n",
    "s.nlargest(3, keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The n largest elements where n=3 with all duplicates kept. Note that the returned Series has five elements due to the three duplicates.\n",
    "\n",
    "s.nlargest(3, keep='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a comprehensive breakdown of the **`pandas.Series.nlargest()`** method:\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Syntax**\n",
    "\n",
    "```python\n",
    "Series.nlargest(n=5, keep='first')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Parameters**\n",
    "\n",
    "| Parameter | Type                       | Default   | Description                                                          |\n",
    "| --------- | -------------------------- | --------- | -------------------------------------------------------------------- |\n",
    "| `n`       | `int`                      | `5`       | Number of largest elements to return.                                |\n",
    "| `keep`    | `{'first', 'last', 'all'}` | `'first'` | Specifies which duplicate values to retain if there are ties.        |\n",
    "| &nbsp;    | `'first'`                  | &nbsp;    | Keeps the first `n` occurrences in order of appearance.              |\n",
    "| &nbsp;    | `'last'`                   | &nbsp;    | Keeps the last `n` occurrences in reverse order of appearance.       |\n",
    "| &nbsp;    | `'all'`                    | &nbsp;    | Keeps all occurrences, which may result in a Series larger than `n`. |\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Return Value**\n",
    "\n",
    "- Returns a **Series** containing the `n` largest values in **descending order**.\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Examples**\n",
    "\n",
    "### **Example 1: Default behavior (`n=5`, `keep='first'`)**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "countries_population = {\n",
    "    \"Italy\": 59000000, \"France\": 65000000, \"Malta\": 434000,\n",
    "    \"Maldives\": 434000, \"Brunei\": 434000, \"Iceland\": 337000,\n",
    "    \"Nauru\": 11300, \"Tuvalu\": 11300, \"Anguilla\": 11300, \"Montserrat\": 5200\n",
    "}\n",
    "\n",
    "s = pd.Series(countries_population)\n",
    "\n",
    "print(s.nlargest())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "France      65000000\n",
    "Italy       59000000\n",
    "Malta         434000\n",
    "Maldives      434000\n",
    "Brunei        434000\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Get `n=3` largest values**\n",
    "\n",
    "```python\n",
    "print(s.nlargest(3))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "France    65000000\n",
    "Italy     59000000\n",
    "Malta       434000\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The function keeps only the first occurrence of `434000` (`Malta`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Keeping the last duplicates (`keep='last'`)**\n",
    "\n",
    "```python\n",
    "print(s.nlargest(3, keep='last'))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "France      65000000\n",
    "Italy       59000000\n",
    "Brunei        434000\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The function keeps the **last** occurrence of `434000` (`Brunei`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Keeping all duplicates (`keep='all'`)**\n",
    "\n",
    "```python\n",
    "print(s.nlargest(3, keep='all'))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "France      65000000\n",
    "Italy       59000000\n",
    "Malta         434000\n",
    "Maldives      434000\n",
    "Brunei        434000\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Since there are three duplicate values (`434000`), **all are kept**.\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Notes**\n",
    "\n",
    "- Faster than **`.sort_values(ascending=False).head(n)`** for small `n` relative to the Series size.\n",
    "- Works only on **numeric values**; will raise an error if the Series contains non-numeric data.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.nsmallest\n",
    "Series.nsmallest(n=5, keep='first')[source]\n",
    "Return the smallest n elements.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "n\n",
    "int, default 5\n",
    "Return this many ascending sorted values.\n",
    "\n",
    "keep\n",
    "{‘first’, ‘last’, ‘all’}, default ‘first’\n",
    "When there are duplicate values that cannot all fit in a Series of n elements:\n",
    "\n",
    "first : return the first n occurrences in order of appearance.\n",
    "\n",
    "last : return the last n occurrences in reverse order of appearance.\n",
    "\n",
    "all : keep all occurrences. This can result in a Series of size larger than n.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "The n smallest values in the Series, sorted in increasing order.\n",
    "\n",
    "\n",
    "Series.nlargest\n",
    "Get the n largest elements.\n",
    "\n",
    "Series.sort_values\n",
    "Sort Series by values.\n",
    "\n",
    "Series.head\n",
    "Return the first n rows.\n",
    "\n",
    "Notes\n",
    "\n",
    "Faster than .sort_values().head(n) for small n relative to the size of the Series object. \"\"\"\n",
    "\n",
    "countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
    "                        \"Brunei\": 434000, \"Malta\": 434000,\n",
    "                        \"Maldives\": 434000, \"Iceland\": 337000,\n",
    "                        \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
    "                        \"Anguilla\": 11300, \"Montserrat\": 5200}\n",
    "s = pd.Series(countries_population)\n",
    "s\n",
    "# The n smallest elements where n=5 by default.\n",
    "\n",
    "s.nsmallest()\n",
    "# The n smallest elements where n=3. Default keep value is ‘first’ so Nauru and Tuvalu will be kept.\n",
    "\n",
    "s.nsmallest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The n smallest elements where n=3 and keeping the last duplicates. Anguilla and Tuvalu will be kept since they are the last with value 11300 based on the index order.\n",
    "\n",
    "s.nsmallest(3, keep='last')\n",
    "# The n smallest elements where n=3 with all duplicates kept. Note that the returned Series has four elements due to the three duplicates.\n",
    "\n",
    "s.nsmallest(3, keep='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.nsmallest` method retrieves the smallest elements from a Series, with options to handle duplicate values. Here's a concise breakdown:\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **n**: Number of smallest elements to return (default: 5).\n",
    "- **keep**: Determines handling of duplicates:\n",
    "  - `'first'` (default): Includes the first occurrences in order of appearance.\n",
    "  - `'last'`: Includes the last occurrences, returned in reverse order.\n",
    "  - `'all'`: Includes all duplicates, possibly exceeding `n`.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- A Series containing the `n` smallest values, sorted in ascending order.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Efficiency**: Faster than `.sort_values().head(n)` for small `n`.\n",
    "- **Duplicates Handling**:\n",
    "  - `'first'` selects the earliest entries when duplicates exist.\n",
    "  - `'last'` selects the latest entries and reverses their order.\n",
    "  - `'all'` includes all duplicates, which may result in a larger Series.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "1. **Default (`keep='first'`)**:\n",
    "\n",
    "   ```python\n",
    "   s.nsmallest(3)\n",
    "   # Returns: Montserrat (5200), Nauru (11300), Tuvalu (11300)\n",
    "   ```\n",
    "\n",
    "2. **Using `keep='last'`**:\n",
    "\n",
    "   ```python\n",
    "   s.nsmallest(3, keep='last')\n",
    "   # Returns: Montserrat (5200), Anguilla (11300), Tuvalu (11300)\n",
    "   ```\n",
    "\n",
    "3. **Using `keep='all'`**:\n",
    "   ```python\n",
    "   s.nsmallest(3, keep='all')\n",
    "   # Returns: Montserrat (5200), Nauru, Tuvalu, Anguilla (all 11300)\n",
    "   ```\n",
    "\n",
    "This method is ideal for quickly extracting the smallest values with flexible handling of ties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.pct_change\n",
    "Series.pct_change(periods=1, fill_method=<no_default>, limit=<no_default>, freq=None, **kwargs)[source]\n",
    "Fractional change between the current and a prior element.\n",
    "\n",
    "Computes the fractional change from the immediately previous row by default. This is useful in comparing the fraction of change in a time series of elements.\n",
    "\n",
    "Note\n",
    "\n",
    "Despite the name of this method, it calculates fractional change (also known as per unit change or relative change) and not percentage change. If you need the percentage change, multiply these values by 100.\n",
    "\n",
    "Parameters:\n",
    "periodsint, default 1\n",
    "Periods to shift for forming percent change.\n",
    "\n",
    "fill_method{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default ‘pad’\n",
    "How to handle NAs before computing percent changes.\n",
    "\n",
    "Deprecated since version 2.1: All options of fill_method are deprecated except fill_method=None.\n",
    "\n",
    "limitint, default None\n",
    "The number of consecutive NAs to fill before stopping.\n",
    "\n",
    "Deprecated since version 2.1.\n",
    "\n",
    "freqDateOffset, timedelta, or str, optional\n",
    "Increment to use from time series API (e.g. ‘ME’ or BDay()).\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments are passed into DataFrame.shift or Series.shift.\n",
    "\n",
    "Returns:\n",
    "Series or DataFrame\n",
    "The same type as the calling object.\n",
    "\n",
    "\n",
    "Series.diff\n",
    "Compute the difference of two elements in a Series.\n",
    "\n",
    "DataFrame.diff\n",
    "Compute the difference of two elements in a DataFrame.\n",
    "\n",
    "Series.shift\n",
    "Shift the index by some number of periods.\n",
    "\n",
    "DataFrame.shift\n",
    "Shift the index by some number of periods. \"\"\"\n",
    "s = pd.Series([90, 91, 85])\n",
    "s\n",
    "s.pct_change()\n",
    "s.pct_change(periods=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the percentage change in a Series where filling NAs with last valid observation forward to next valid.\n",
    "\n",
    "s = pd.Series([90, 91, None, 85])\n",
    "s\n",
    "s.ffill().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "\n",
    "# Percentage change in French franc, Deutsche Mark, and Italian lira from 1980-01-01 to 1980-03-01.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'FR': [4.0405, 4.0963, 4.3149],\n",
    "    'GR': [1.7246, 1.7482, 1.8519],\n",
    "    'IT': [804.74, 810.01, 860.13]},\n",
    "    index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
    "df\n",
    "df.pct_change()\n",
    "# Percentage of change in GOOG and APPL stock volume. Shows computing the percentage change between columns.\n",
    "df = pd.DataFrame({\n",
    "    '2016': [1769950, 30586265],\n",
    "    '2015': [1500923, 40912316],\n",
    "    '2014': [1371819, 41403351]},\n",
    "    index=['GOOG', 'APPL'])\n",
    "df\n",
    "df.pct_change(axis='columns', periods=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.pct_change` method calculates the **fractional change** (relative change) between the current and a prior element in a Series or DataFrame. It is commonly used to analyze time series data, such as stock prices, economic indicators, or other sequential data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`periods`** (int, default: 1):\n",
    "\n",
    "   - Number of periods to shift for calculating the change.\n",
    "   - Example: `periods=2` computes the change relative to the value two rows prior.\n",
    "\n",
    "2. **`fill_method`** (str, default: `None`):\n",
    "\n",
    "   - Specifies how to handle missing values (`NaN`) before computing the change.\n",
    "   - Options: `'backfill'`, `'bfill'`, `'pad'`, `'ffill'`, or `None`.\n",
    "   - **Deprecated since version 2.1**: Only `fill_method=None` is supported.\n",
    "\n",
    "3. **`limit`** (int, default: `None`):\n",
    "\n",
    "   - Maximum number of consecutive `NaN` values to fill before stopping.\n",
    "   - **Deprecated since version 2.1**.\n",
    "\n",
    "4. **`freq`** (DateOffset, timedelta, or str, optional):\n",
    "\n",
    "   - Increment to use from the time series API (e.g., `'D'` for daily, `'ME'` for month-end).\n",
    "\n",
    "5. **`**kwargs`\\*\\*:\n",
    "   - Additional arguments passed to `Series.shift` or `DataFrame.shift`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - The fractional change between the current and prior elements.\n",
    "  - The first element(s) will be `NaN` because there is no prior value to compare.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Fractional Change**:\n",
    "\n",
    "  - The method calculates the fractional change, not the percentage change. To convert to percentage, multiply the result by 100.\n",
    "  - Formula:  \n",
    "    \\[\n",
    "    \\text{Fractional Change} = \\frac{\\text{Current Value} - \\text{Previous Value}}{\\text{Previous Value}}\n",
    "    \\]\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If `fill_method` is used, missing values are filled before computing the change.\n",
    "  - Example: `ffill` propagates the last valid observation forward.\n",
    "\n",
    "- **Axis in DataFrames**:\n",
    "  - For DataFrames, you can specify `axis='columns'` to compute changes row-wise (between columns).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage with Series**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([90, 91, 85])\n",
    "print(s.pct_change())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0         NaN\n",
    "1    0.011111\n",
    "2   -0.065934\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### **2. Using `periods`**:\n",
    "\n",
    "```python\n",
    "print(s.pct_change(periods=2))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0         NaN\n",
    "1         NaN\n",
    "2   -0.055556\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### **3. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([90, 91, None, 85])\n",
    "print(s.ffill().pct_change())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0         NaN\n",
    "1    0.011111\n",
    "2    0.000000\n",
    "3   -0.065934\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### **4. DataFrame Example**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'FR': [4.0405, 4.0963, 4.3149],\n",
    "    'GR': [1.7246, 1.7482, 1.8519],\n",
    "    'IT': [804.74, 810.01, 860.13]},\n",
    "    index=['1980-01-01', '1980-02-01', '1980-03-01']\n",
    ")\n",
    "print(df.pct_change())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "                  FR        GR        IT\n",
    "1980-01-01       NaN       NaN       NaN\n",
    "1980-02-01  0.013810  0.013684  0.006549\n",
    "1980-03-01  0.053365  0.059318  0.061876\n",
    "```\n",
    "\n",
    "#### **5. Row-wise Change in DataFrame**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    '2016': [1769950, 30586265],\n",
    "    '2015': [1500923, 40912316],\n",
    "    '2014': [1371819, 41403351]},\n",
    "    index=['GOOG', 'APPL']\n",
    ")\n",
    "print(df.pct_change(axis='columns', periods=-1))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "          2016      2015  2014\n",
    "GOOG  0.179241  0.094112   NaN\n",
    "APPL -0.252395 -0.011860   NaN\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.diff`**: Computes the difference between elements.\n",
    "- **`Series.shift`**: Shifts the index by a specified number of periods.\n",
    "- **`DataFrame.pct_change`**: Similar functionality for DataFrames.\n",
    "\n",
    "This method is particularly useful for analyzing trends and growth rates in time series data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.prod\n",
    "Series.prod(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)[source]\n",
    "Return the product of the values over the requested axis.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Warning\n",
    "\n",
    "The behavior of DataFrame.prod with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar To retain the old behavior, pass axis=0 (or do not pass axis).\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "min_countint, default 0\n",
    "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar\n",
    "\n",
    "Series.sum\n",
    "Return the sum.\n",
    "\n",
    "Series.min\n",
    "Return the minimum.\n",
    "\n",
    "Series.max\n",
    "Return the maximum.\n",
    "\n",
    "Series.idxmin\n",
    "Return the index of the minimum.\n",
    "\n",
    "Series.idxmax\n",
    "Return the index of the maximum.\n",
    "\n",
    "DataFrame.sum\n",
    "Return the sum over the requested axis.\n",
    "\n",
    "DataFrame.min\n",
    "Return the minimum over the requested axis.\n",
    "\n",
    "DataFrame.max\n",
    "Return the maximum over the requested axis.\n",
    "\n",
    "DataFrame.idxmin\n",
    "Return the index of the minimum over the requested axis.\n",
    "\n",
    "DataFrame.idxmax\n",
    "Return the index of the maximum over the requested axis. \"\"\"\n",
    "pd.Series([], dtype=\"float64\").prod()\n",
    "# This can be controlled with the min_count parameter \n",
    "\n",
    "pd.Series([], dtype=\"float64\").prod(min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to the skipna parameter, min_count handles all-NA and empty series identically.\n",
    "\n",
    "pd.Series([np.nan]).prod()\n",
    "pd.Series([np.nan]).prod(min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.prod` method calculates the **product** of the values in a Series. It is useful for computing the multiplicative result of all elements in the Series. Here's a detailed explanation of its functionality:\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`axis`** (int, default: `None`):\n",
    "\n",
    "   - Axis for the function to be applied on. For a Series, this parameter is unused and defaults to `0`.\n",
    "   - **Warning**: For DataFrames, the behavior of `axis=None` is deprecated. Use `axis=0` to retain the old behavior.\n",
    "\n",
    "2. **`skipna`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, excludes `NaN` (missing) values when computing the product.\n",
    "   - If `False`, the result will be `NaN` if any value in the Series is `NaN`.\n",
    "\n",
    "3. **`numeric_only`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, includes only numeric columns (float, int, boolean). This parameter is not implemented for Series.\n",
    "\n",
    "4. **`min_count`** (int, default: `0`):\n",
    "\n",
    "   - The minimum number of valid (non-`NaN`) values required to perform the operation.\n",
    "   - If fewer than `min_count` non-`NaN` values are present, the result will be `NaN`.\n",
    "\n",
    "5. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments to be passed to the function.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Scalar**:\n",
    "  - The product of the values in the Series. If the Series is empty or contains only `NaN` values, the result depends on the `min_count` parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Default Behavior**:\n",
    "\n",
    "  - By default, the product of an empty or all-`NaN` Series is `1.0`.\n",
    "  - This behavior can be controlled using the `min_count` parameter.\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If `skipna=True`, `NaN` values are ignored.\n",
    "  - If `skipna=False`, the presence of any `NaN` value will result in `NaN` for the product.\n",
    "\n",
    "- **`min_count` Parameter**:\n",
    "  - If `min_count` is set, the operation requires at least that many non-`NaN` values to return a valid result. Otherwise, the result is `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "print(s.prod())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "24\n",
    "```\n",
    "\n",
    "Explanation: \\(1 \\times 2 \\times 3 \\times 4 = 24\\).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4])\n",
    "print(s.prod(skipna=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "8\n",
    "```\n",
    "\n",
    "Explanation: \\(1 \\times 2 \\times 4 = 8\\). The `NaN` value is ignored.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Using `min_count`**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4])\n",
    "print(s.prod(min_count=4))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "Explanation: There are only 3 non-`NaN` values, which is fewer than `min_count=4`. Hence, the result is `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Empty Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "print(s.prod())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1.0\n",
    "```\n",
    "\n",
    "Explanation: By default, the product of an empty Series is `1.0`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. All-`NaN` Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([np.nan, np.nan])\n",
    "print(s.prod())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1.0\n",
    "```\n",
    "\n",
    "Explanation: By default, the product of an all-`NaN` Series is `1.0`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Controlling Empty/All-`NaN` Behavior with `min_count`**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "print(s.prod(min_count=1))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "Explanation: Since `min_count=1` and there are no valid values, the result is `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.sum`**: Returns the sum of the values.\n",
    "- **`Series.min`**: Returns the minimum value.\n",
    "- **`Series.max`**: Returns the maximum value.\n",
    "- **`Series.idxmin`**: Returns the index of the minimum value.\n",
    "- **`Series.idxmax`**: Returns the index of the maximum value.\n",
    "- **`DataFrame.prod`**: Similar functionality for DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.prod` to compute the product of values in a Series.\n",
    "- Control the handling of missing values with `skipna` and `min_count`.\n",
    "- Be cautious with empty or all-`NaN` Series, as the default behavior returns `1.0` unless `min_count` is specified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.quantile\n",
    "Series.quantile(q=0.5, interpolation='linear')[source]\n",
    "Return value at the given quantile.\n",
    "\n",
    "Parameters:\n",
    "qfloat or array-like, default 0.5 (50% quantile)\n",
    "The quantile(s) to compute, which can lie in range: 0 <= q <= 1.\n",
    "\n",
    "interpolation{‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}\n",
    "This optional parameter specifies the interpolation method to use, when the desired quantile lies between two data points i and j:\n",
    "\n",
    "linear: i + (j - i) * (x-i)/(j-i), where (x-i)/(j-i) is the fractional part of the index surrounded by i > j.\n",
    "\n",
    "lower: i.\n",
    "\n",
    "higher: j.\n",
    "\n",
    "nearest: i or j whichever is nearest.\n",
    "\n",
    "midpoint: (i + j) / 2.\n",
    "\n",
    "Returns:\n",
    "float or Series\n",
    "If q is an array, a Series will be returned where the index is q and the values are the quantiles, otherwise a float will be returned.\n",
    "\n",
    "\n",
    "\n",
    "core.window.Rolling.quantile\n",
    "Calculate the rolling quantile.\n",
    "\n",
    "numpy.percentile\n",
    "Returns the q-th percentile(s) of the array elements. \"\"\"\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "s.quantile(.5)\n",
    "\n",
    "s.quantile([.25, .5, .75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.quantile` method calculates the value at a specified quantile (or quantiles) of the data in a Series. Quantiles are points that divide the data into equal intervals, such as the median (50th percentile), quartiles (25th, 50th, 75th percentiles), etc. Here's a detailed explanation of its functionality:\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`q`** (float or array-like, default: `0.5`):\n",
    "\n",
    "   - The quantile(s) to compute. Must be between `0` and `1` (inclusive).\n",
    "   - Examples:\n",
    "     - `q=0.5` computes the median (50th percentile).\n",
    "     - `q=[0.25, 0.5, 0.75]` computes the first quartile, median, and third quartile.\n",
    "\n",
    "2. **`interpolation`** (str, default: `'linear'`):\n",
    "   - Specifies the interpolation method to use when the desired quantile lies between two data points. Options:\n",
    "     - `'linear'`: Computes \\(i + (j - i) \\times \\text{fraction}\\), where `i` and `j` are the surrounding data points.\n",
    "     - `'lower'`: Uses the lower data point (`i`).\n",
    "     - `'higher'`: Uses the higher data point (`j`).\n",
    "     - `'nearest'`: Uses the nearest data point (`i` or `j`).\n",
    "     - `'midpoint'`: Computes the average of `i` and `j`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **float or Series**:\n",
    "  - If `q` is a single value, returns a float representing the quantile.\n",
    "  - If `q` is an array-like, returns a Series where the index is `q` and the values are the computed quantiles.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Quantile Calculation**:\n",
    "\n",
    "  - The quantile is calculated based on the sorted values of the Series.\n",
    "  - The interpolation method determines how to handle cases where the quantile lies between two data points.\n",
    "\n",
    "- **Handling Edge Cases**:\n",
    "  - If the Series is empty, the result will be `NaN`.\n",
    "  - If `q` is outside the range `[0, 1]`, a `ValueError` will be raised.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage (Single Quantile)**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "print(s.quantile(0.5))  # Median\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "2.5\n",
    "```\n",
    "\n",
    "Explanation: The median (50th percentile) of `[1, 2, 3, 4]` is `2.5`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Multiple Quantiles**:\n",
    "\n",
    "```python\n",
    "print(s.quantile([0.25, 0.5, 0.75]))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0.25    1.75\n",
    "0.50    2.50\n",
    "0.75    3.25\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- 25th percentile: \\(1 + (2 - 1) \\times 0.25 = 1.75\\)\n",
    "- 50th percentile: \\(2 + (3 - 2) \\times 0.5 = 2.5\\)\n",
    "- 75th percentile: \\(3 + (4 - 3) \\times 0.75 = 3.25\\)\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Using Different Interpolation Methods**:\n",
    "\n",
    "```python\n",
    "print(s.quantile(0.5, interpolation='lower'))  # Uses the lower value\n",
    "print(s.quantile(0.5, interpolation='higher'))  # Uses the higher value\n",
    "print(s.quantile(0.5, interpolation='midpoint'))  # Averages the two values\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "2.0  # Lower\n",
    "3.0  # Higher\n",
    "2.5  # Midpoint\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Edge Cases**:\n",
    "\n",
    "- **Empty Series**:\n",
    "\n",
    "  ```python\n",
    "  s = pd.Series([])\n",
    "  print(s.quantile(0.5))\n",
    "  ```\n",
    "\n",
    "  **Output**:\n",
    "\n",
    "  ```\n",
    "  nan\n",
    "  ```\n",
    "\n",
    "- **Quantile Outside Range**:\n",
    "  ```python\n",
    "  s = pd.Series([1, 2, 3, 4])\n",
    "  print(s.quantile(1.5))  # Raises ValueError\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`core.window.Rolling.quantile`**: Calculates the rolling quantile for a Series or DataFrame.\n",
    "- **`numpy.percentile`**: Computes the q-th percentile(s) of array elements.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.quantile` to compute quantiles for a Series.\n",
    "- Specify the quantile(s) using the `q` parameter.\n",
    "- Control interpolation behavior with the `interpolation` parameter.\n",
    "- Returns a float for a single quantile or a Series for multiple quantiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rank\n",
    "Series.rank(axis=0, method='average', numeric_only=False, na_option='keep', ascending=True, pct=False)[source]\n",
    "Compute numerical data ranks (1 through n) along axis.\n",
    "\n",
    "By default, equal values are assigned a rank that is the average of the ranks of those values.\n",
    "\n",
    "Parameters:\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Index to direct ranking. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "method{‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}, default ‘average’\n",
    "How to rank the group of records that have the same value (i.e. ties):\n",
    "\n",
    "average: average rank of the group\n",
    "\n",
    "min: lowest rank in the group\n",
    "\n",
    "max: highest rank in the group\n",
    "\n",
    "first: ranks assigned in order they appear in the array\n",
    "\n",
    "dense: like ‘min’, but rank always increases by 1 between groups.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "For DataFrame objects, rank only numeric columns if set to True.\n",
    "\n",
    "Changed in version 2.0.0: The default value of numeric_only is now False.\n",
    "\n",
    "na_option{‘keep’, ‘top’, ‘bottom’}, default ‘keep’\n",
    "How to rank NaN values:\n",
    "\n",
    "keep: assign NaN rank to NaN values\n",
    "\n",
    "top: assign lowest rank to NaN values\n",
    "\n",
    "bottom: assign highest rank to NaN values\n",
    "\n",
    "ascendingbool, default True\n",
    "Whether or not the elements should be ranked in ascending order.\n",
    "\n",
    "pctbool, default False\n",
    "Whether or not to display the returned rankings in percentile form.\n",
    "\n",
    "Returns:\n",
    "same type as caller\n",
    "Return a Series or DataFrame with data ranks as values.\n",
    "\n",
    "\n",
    "core.groupby.DataFrameGroupBy.rank\n",
    "Rank of values within each group.\n",
    "\n",
    "core.groupby.SeriesGroupBy.rank\n",
    "Rank of values within each group. \"\"\"\n",
    "df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
    "                                   'spider', 'snake'],\n",
    "                        'Number_legs': [4, 2, 4, 8, np.nan]})\n",
    "df\n",
    "\n",
    "\n",
    "# Ties are assigned the mean of the ranks (by default) for the group.\n",
    "\n",
    "s = pd.Series(range(5), index=list(\"abcde\"))\n",
    "s[\"d\"] = s[\"b\"]\n",
    "s.rank()\n",
    "\n",
    "#  The following example shows how the method behaves with the above parameters:\n",
    "\n",
    "#  default_rank: this is the default behaviour obtained without using any parameter.\n",
    "\n",
    "# max_rank: setting method = 'max' the records that have the same values are ranked using the highest rank (e.g.: since ‘cat’ and ‘dog’ are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
    "# \n",
    "# NA_bottom: choosing na_option = 'bottom', if there are records with NaN values they are placed at the bottom of the ranking.\n",
    "\n",
    "# pct_rank: when setting pct = True, the ranking is expressed as percentile rank.\n",
    "\n",
    "df['default_rank'] = df['Number_legs'].rank()\n",
    "df['max_rank'] = df['Number_legs'].rank(method='max')\n",
    "df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
    "df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.rank` method assigns ranks to the values in a Series, where the smallest value is ranked 1 by default. It provides flexibility in handling ties (equal values) and missing values (`NaN`). Here's a detailed explanation of its functionality:\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`axis`** (int or str, default: `0`):\n",
    "\n",
    "   - Axis to rank along. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "2. **`method`** (str, default: `'average'`):\n",
    "\n",
    "   - Specifies how to rank tied values:\n",
    "     - `'average'`: Assigns the average rank of the group (default).\n",
    "     - `'min'`: Assigns the minimum rank of the group.\n",
    "     - `'max'`: Assigns the maximum rank of the group.\n",
    "     - `'first'`: Assigns ranks in the order they appear in the Series.\n",
    "     - `'dense'`: Like `'min'`, but ranks increase by 1 between groups.\n",
    "\n",
    "3. **`numeric_only`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, ranks only numeric columns. Not applicable for Series.\n",
    "\n",
    "4. **`na_option`** (str, default: `'keep'`):\n",
    "\n",
    "   - Specifies how to handle `NaN` values:\n",
    "     - `'keep'`: Assigns `NaN` rank to `NaN` values.\n",
    "     - `'top'`: Assigns the lowest rank to `NaN` values.\n",
    "     - `'bottom'`: Assigns the highest rank to `NaN` values.\n",
    "\n",
    "5. **`ascending`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, ranks values in ascending order (smallest value gets rank 1).\n",
    "   - If `False`, ranks values in descending order (largest value gets rank 1).\n",
    "\n",
    "6. **`pct`** (bool, default: `False`):\n",
    "   - If `True`, returns ranks as percentiles (ranging from 0 to 1).\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Series**:\n",
    "  - A Series with the same index as the original, containing the computed ranks.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Handling Ties**:\n",
    "\n",
    "  - The `method` parameter determines how tied values are ranked.\n",
    "  - Example: For values `[3, 3, 2]`, the ranks depend on the method:\n",
    "    - `'average'`: `[2.5, 2.5, 1]`\n",
    "    - `'min'`: `[2, 2, 1]`\n",
    "    - `'max'`: `[3, 3, 1]`\n",
    "    - `'first'`: `[2, 3, 1]`\n",
    "    - `'dense'`: `[2, 2, 1]`\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - The `na_option` parameter controls how `NaN` values are ranked.\n",
    "  - Example: For `[1, 2, NaN]`:\n",
    "    - `'keep'`: `[1, 2, NaN]`\n",
    "    - `'top'`: `[2, 3, 1]`\n",
    "    - `'bottom'`: `[1, 2, 3]`\n",
    "\n",
    "- **Percentile Ranks**:\n",
    "  - If `pct=True`, ranks are expressed as percentiles (e.g., `0.25` for the 25th percentile).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([3, 2, 3, 1])\n",
    "print(s.rank())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    3.5\n",
    "1    2.0\n",
    "2    3.5\n",
    "3    1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The smallest value (`1`) gets rank `1`.\n",
    "- The tied values (`3` and `3`) get the average rank of `3.5`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Using Different Methods**:\n",
    "\n",
    "```python\n",
    "print(s.rank(method='min'))  # Assigns the minimum rank to ties\n",
    "print(s.rank(method='max'))  # Assigns the maximum rank to ties\n",
    "print(s.rank(method='first'))  # Assigns ranks in order of appearance\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    3.0\n",
    "1    2.0\n",
    "2    3.0\n",
    "3    1.0\n",
    "dtype: float64\n",
    "\n",
    "0    4.0\n",
    "1    2.0\n",
    "2    4.0\n",
    "3    1.0\n",
    "dtype: float64\n",
    "\n",
    "0    3.0\n",
    "1    2.0\n",
    "2    4.0\n",
    "3    1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4])\n",
    "print(s.rank(na_option='top'))  # Assigns the lowest rank to NaN\n",
    "print(s.rank(na_option='bottom'))  # Assigns the highest rank to NaN\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    3.0\n",
    "2    1.0\n",
    "3    4.0\n",
    "dtype: float64\n",
    "\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    4.0\n",
    "3    3.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Percentile Ranks**:\n",
    "\n",
    "```python\n",
    "print(s.rank(pct=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    0.333333\n",
    "1    0.666667\n",
    "2         NaN\n",
    "3    1.000000\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Ranks are expressed as percentiles (e.g., `0.333333` for the 33rd percentile).\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. DataFrame Example**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Animal': ['cat', 'penguin', 'dog', 'spider', 'snake'],\n",
    "    'Number_legs': [4, 2, 4, 8, None]\n",
    "})\n",
    "df['default_rank'] = df['Number_legs'].rank()\n",
    "df['max_rank'] = df['Number_legs'].rank(method='max')\n",
    "df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
    "df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "    Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
    "0      cat          4.0           2.5       3.0        2.5     0.625\n",
    "1  penguin          2.0           1.0       1.0        1.0     0.250\n",
    "2      dog          4.0           2.5       3.0        2.5     0.625\n",
    "3   spider          8.0           4.0       4.0        4.0     1.000\n",
    "4    snake          NaN           NaN       NaN        5.0       NaN\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`core.groupby.DataFrameGroupBy.rank`**: Ranks values within each group in a DataFrame.\n",
    "- **`core.groupby.SeriesGroupBy.rank`**: Ranks values within each group in a Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.rank` to assign ranks to values in a Series.\n",
    "- Control tie-breaking behavior with the `method` parameter.\n",
    "- Handle missing values using the `na_option` parameter.\n",
    "- Use `pct=True` to express ranks as percentiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.sem\n",
    "Series.sem(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)[source]\n",
    "Return unbiased standard error of the mean over requested axis.\n",
    "\n",
    "Normalized by N-1 by default. This can be changed using the ddof argument\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Warning\n",
    "\n",
    "The behavior of DataFrame.sem with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar To retain the old behavior, pass axis=0 (or do not pass axis).\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "ddofint, default 1\n",
    "Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "Returns:\n",
    "scalar or Series (if level specified) \"\"\"\n",
    "s = pd.Series([1, 2, 3])\n",
    "s.sem().round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a DataFrame\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
    "df\n",
    "\n",
    "# Using axis=1\n",
    "\n",
    "df.sem(axis=1)\n",
    "\n",
    "# In this case, numeric_only should be set to True to avoid getting an error.\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']},\n",
    "                  index=['tiger', 'zebra'])\n",
    "df.sem(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.sem` method calculates the **standard error of the mean (SEM)** for the values in a Series. The SEM measures the precision of the sample mean as an estimate of the population mean. It is calculated as the standard deviation divided by the square root of the sample size, adjusted by the degrees of freedom (`ddof`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`axis`** (int or str, default: `0`):\n",
    "\n",
    "   - Axis to compute the SEM along. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "2. **`skipna`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, excludes `NaN` (missing) values when computing the SEM.\n",
    "   - If `False`, the result will be `NaN` if any value in the Series is `NaN`.\n",
    "\n",
    "3. **`ddof`** (int, default: `1`):\n",
    "\n",
    "   - Delta Degrees of Freedom. The divisor used in the calculation is (N - ddof) , where N is the number of non-`NaN` values.\n",
    "   - Default is `1`, which corresponds to the unbiased estimate of the SEM.\n",
    "\n",
    "4. **`numeric_only`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, includes only numeric columns (float, int, boolean). Not implemented for Series.\n",
    "\n",
    "5. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments to be passed to the function.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Scalar**:\n",
    "  - The standard error of the mean for the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Formula**:\n",
    "\n",
    "  SEM = Standard Deviation/ (sqrt{N - ddof})\n",
    "\n",
    "  - Standard Deviation: Measures the spread of the data.\n",
    "  - N: Number of non-`NaN` values.\n",
    "  - `ddof`: Adjusts the degrees of freedom.\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If `skipna=True`, `NaN` values are ignored.\n",
    "  - If `skipna=False`, the presence of any `NaN` value will result in `NaN` for the SEM.\n",
    "\n",
    "- **Degrees of Freedom (`ddof`)**:\n",
    "  - The default `ddof=1` provides an unbiased estimate of the SEM.\n",
    "  - Set `ddof=0` to use the population formula (no adjustment).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.sem().round(6))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0.57735\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4])\n",
    "print(s.sem(skipna=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0.881917\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Using `ddof`**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.sem(ddof=0))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0.471405\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. DataFrame Example**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [2, 3]}, index=['tiger', 'zebra'])\n",
    "print(df.sem())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a   0.5\n",
    "b   0.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Handling Non-Numeric Columns**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': ['T', 'Z']}, index=['tiger', 'zebra'])\n",
    "print(df.sem(numeric_only=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a   0.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Only numeric column `a` is included in the calculation.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.std`**: Computes the standard deviation of the Series.\n",
    "- **`Series.mean`**: Computes the mean of the Series.\n",
    "- **`DataFrame.sem`**: Computes the SEM for each column in a DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.sem` to compute the standard error of the mean for a Series.\n",
    "- Adjust the degrees of freedom using the `ddof` parameter.\n",
    "- Handle missing values with the `skipna` parameter.\n",
    "- For DataFrames, use `numeric_only=True` to exclude non-numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.skew\n",
    "Series.skew(axis=0, skipna=True, numeric_only=False, **kwargs)[source]\n",
    "Return unbiased skew over requested axis.\n",
    "\n",
    "Normalized by N-1.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "For DataFrames, specifying axis=None will apply the aggregation across both axes.\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar \"\"\"\n",
    "s=pd.Series([1, 2, 3])\n",
    "s.skew()\n",
    "\n",
    "# With a DataFrame \n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 3, 4], 'c': [1, 3, 5]},\n",
    "                  index=['tiger', 'zebra', 'cow'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using axis=1\n",
    "\n",
    "df.skew(axis=1)\n",
    "\n",
    "# In this case, numeric_only should be set to True to avoid getting an error. \n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': ['T', 'Z', 'X']},\n",
    "                  index=['tiger', 'zebra', 'cow'])\n",
    "df.skew(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.skew` method calculates the **skewness** of the data in a Series. Skewness measures the asymmetry of the distribution of values around the mean. A skewness of 0 indicates a symmetric distribution, while positive or negative skewness indicates a longer tail on the right or left side, respectively.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`axis`** (int or str, default: `0`):\n",
    "\n",
    "   - Axis to compute skewness along. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "2. **`skipna`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, excludes `NaN` (missing) values when computing skewness.\n",
    "   - If `False`, the result will be `NaN` if any value in the Series is `NaN`.\n",
    "\n",
    "3. **`numeric_only`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, includes only numeric columns (float, int, boolean). Not implemented for Series.\n",
    "\n",
    "4. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments to be passed to the function.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Scalar**:\n",
    "  - The skewness of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Skewness Formula**:\n",
    "\n",
    "  Skewness = (1/N) _ (sum\\_{i=1}^N (x_i - bar{x})^3)_ (left(1/N)_ (sum\\_{i=1}^N (x_i - bar{x})^2_ right)^{3/2})\n",
    "\n",
    "  - x_i: Individual data points.\n",
    "  - bar{x}: Mean of the data.\n",
    "  - N: Number of non-`NaN` values.\n",
    "\n",
    "- **Interpretation**:\n",
    "\n",
    "  - **Skewness = 0**: Symmetric distribution.\n",
    "  - **Skewness > 0**: Positive skew (longer tail on the right).\n",
    "  - **Skewness < 0**: Negative skew (longer tail on the left).\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "  - If `skipna=True`, `NaN` values are ignored.\n",
    "  - If `skipna=False`, the presence of any `NaN` value will result in `NaN` for skewness.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.skew())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0.0\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The distribution `[1, 2, 3]` is symmetric, so skewness is `0`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Positive Skew**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3, 4, 100])\n",
    "print(s.skew())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "2.038\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The distribution has a longer tail on the right, indicating positive skewness.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Negative Skew**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([100, 4, 3, 2, 1])\n",
    "print(s.skew())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "-2.038\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The distribution has a longer tail on the left, indicating negative skewness.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4])\n",
    "print(s.skew(skipna=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0.0\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Non-`NaN` values: `[1, 2, 4]`\n",
    "- The distribution is symmetric, so skewness is `0`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. DataFrame Example**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [2, 3, 4], 'c': [1, 3, 5]},\n",
    "                  index=['tiger', 'zebra', 'cow'])\n",
    "print(df.skew())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a   0.0\n",
    "b   0.0\n",
    "c   0.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- All columns have symmetric distributions, so skewness is `0`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Row-wise Skewness**:\n",
    "\n",
    "```python\n",
    "print(df.skew(axis=1))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "tiger   1.732051\n",
    "zebra  -1.732051\n",
    "cow     0.000000\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Skewness is computed row-wise for each row in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Handling Non-Numeric Columns**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': ['T', 'Z', 'X']},\n",
    "                  index=['tiger', 'zebra', 'cow'])\n",
    "print(df.skew(numeric_only=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a   0.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Only numeric column `a` is included in the calculation.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.kurt`**: Computes the kurtosis of the Series.\n",
    "- **`Series.mean`**: Computes the mean of the Series.\n",
    "- **`Series.std`**: Computes the standard deviation of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.skew` to compute the skewness of a Series.\n",
    "- Skewness measures the asymmetry of the data distribution.\n",
    "- Handle missing values with the `skipna` parameter.\n",
    "- For DataFrames, use `numeric_only=True` to exclude non-numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.std\n",
    "Series.std(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)[source]\n",
    "Return sample standard deviation over requested axis.\n",
    "\n",
    "Normalized by N-1 by default. This can be changed using the ddof argument.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Warning\n",
    "\n",
    "The behavior of DataFrame.std with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar To retain the old behavior, pass axis=0 (or do not pass axis).\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "ddofint, default 1\n",
    "Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "Returns:\n",
    "scalar or Series (if level specified)\n",
    "Notes\n",
    "\n",
    "To have the same behaviour as numpy.std, use ddof=0 (instead of the default ddof=1) \"\"\"\n",
    "\n",
    "df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
    "                   'age': [21, 25, 62, 43],\n",
    "                   'height': [1.61, 1.87, 1.49, 2.01]}\n",
    "                  ).set_index('person_id')\n",
    "df\n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, ddof=0 can be set to normalize by N instead of N-1:\n",
    "\n",
    "df.std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.std` method calculates the **standard deviation** of the values in a Series. The standard deviation measures the amount of variation or dispersion in the data. By default, it uses \\(N-1\\) as the denominator (Bessel's correction) to provide an unbiased estimate of the population standard deviation when working with a sample.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`axis`** (int or str, default: `0`):\n",
    "\n",
    "   - Axis to compute the standard deviation along. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "2. **`skipna`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, excludes `NaN` (missing) values when computing the standard deviation.\n",
    "   - If `False`, the result will be `NaN` if any value in the Series is `NaN`.\n",
    "\n",
    "3. **`ddof`** (int, default: `1`):\n",
    "\n",
    "   - Delta Degrees of Freedom. The divisor used in the calculation is (N - text{ddof}), where N is the number of non-`NaN` values.\n",
    "   - Default is `1`, which corresponds to the sample standard deviation.\n",
    "   - Set `ddof=0` to compute the population standard deviation.\n",
    "\n",
    "4. **`numeric_only`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, includes only numeric columns (float, int, boolean). Not implemented for Series.\n",
    "\n",
    "5. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments to be passed to the function.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Scalar**:\n",
    "  - The standard deviation of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Formula**:\n",
    "\n",
    "  Standard Deviation = sqrt((1/{N - {ddof}}) _(sum\\_{i=1}^N _ (x_i - bar{x})^2)\n",
    "\n",
    "  - x_i: Individual data points.\n",
    "    -bar{x}: Mean of the data.\n",
    "  - N: Number of non-`NaN` values.\n",
    "  - text{ddof}: Adjusts the degrees of freedom.\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If `skipna=True`, `NaN` values are ignored.\n",
    "  - If `skipna=False`, the presence of any `NaN` value will result in `NaN` for the standard deviation.\n",
    "\n",
    "- **Degrees of Freedom (`ddof`)**:\n",
    "  - The default `ddof=1` provides an unbiased estimate of the standard deviation for a sample.\n",
    "  - Set `ddof=0` to use the population formula (no adjustment).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "print(s.std())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1.581139\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Using `ddof=0`**:\n",
    "\n",
    "```python\n",
    "print(s.std(ddof=0))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1.414214\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4, 5])\n",
    "print(s.std(skipna=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1.825742\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. DataFrame Example**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'age': [21, 25, 62, 43],\n",
    "    'height': [1.61, 1.87, 1.49, 2.01]\n",
    "})\n",
    "print(df.std())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "age       18.786076\n",
    "height     0.237417\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Standard deviation is computed for each column.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Population Standard Deviation**:\n",
    "\n",
    "```python\n",
    "print(df.std(ddof=0))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "age       16.269219\n",
    "height     0.205609\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Population standard deviation is computed for each column.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.var`**: Computes the variance of the Series.\n",
    "- **`Series.mean`**: Computes the mean of the Series.\n",
    "- **`Series.sem`**: Computes the standard error of the mean.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.std` to compute the standard deviation of a Series.\n",
    "- Adjust the degrees of freedom using the `ddof` parameter.\n",
    "- Handle missing values with the `skipna` parameter.\n",
    "- For DataFrames, the method computes the standard deviation for each column by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.sum\n",
    "Series.sum(axis=None, skipna=True, numeric_only=False, min_count=0, **kwargs)[source]\n",
    "Return the sum of the values over the requested axis.\n",
    "\n",
    "This is equivalent to the method numpy.sum.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Warning\n",
    "\n",
    "The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar To retain the old behavior, pass axis=0 (or do not pass axis).\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "min_countint, default 0\n",
    "The required number of valid values to perform the operation. If fewer than min_count non-NA values are present the result will be NA.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar\n",
    "\n",
    "Series.sum\n",
    "Return the sum.\n",
    "\n",
    "Series.min\n",
    "Return the minimum.\n",
    "\n",
    "Series.max\n",
    "Return the maximum.\n",
    "\n",
    "Series.idxmin\n",
    "Return the index of the minimum.\n",
    "\n",
    "Series.idxmax\n",
    "Return the index of the maximum.\n",
    "\n",
    "DataFrame.sum\n",
    "Return the sum over the requested axis.\n",
    "\n",
    "DataFrame.min\n",
    "Return the minimum over the requested axis.\n",
    "\n",
    "DataFrame.max\n",
    "Return the maximum over the requested axis.\n",
    "\n",
    "DataFrame.idxmin\n",
    "Return the index of the minimum over the requested axis.\n",
    "\n",
    "DataFrame.idxmax\n",
    "Return the index of the maximum over the requested axis. \"\"\"\n",
    "idx = pd.MultiIndex.from_arrays([\n",
    "    ['warm', 'warm', 'cold', 'cold'],\n",
    "    ['dog', 'falcon', 'fish', 'spider']],\n",
    "    names=['blooded', 'animal'])\n",
    "s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    "s\n",
    "s.sum()\n",
    "# By default, the sum of an empty or all-NA Series is 0.\n",
    "\n",
    "pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
    "# This can be controlled with the min_count parameter. For example, if you’d like the sum of an empty series to be NaN, pass min_count=1.\n",
    "\n",
    "pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
    "# Thanks to the skipna parameter, min_count handles all-NA and empty series identically.\n",
    "\n",
    "pd.Series([np.nan]).sum()\n",
    "pd.Series([np.nan]).sum(min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.sum` method calculates the **sum** of the values in a Series. It is a versatile method that allows you to handle missing values (`NaN`) and control the behavior when there are insufficient non-missing values using the `min_count` parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`axis`** (int or str, default: `0`):\n",
    "\n",
    "   - Axis to compute the sum along. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "2. **`skipna`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, excludes `NaN` (missing) values when computing the sum.\n",
    "   - If `False`, the result will be `NaN` if any value in the Series is `NaN`.\n",
    "\n",
    "3. **`numeric_only`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, includes only numeric columns (float, int, boolean). Not implemented for Series.\n",
    "\n",
    "4. **`min_count`** (int, default: `0`):\n",
    "\n",
    "   - The minimum number of valid (non-`NaN`) values required to perform the operation.\n",
    "   - If fewer than `min_count` non-`NaN` values are present, the result will be `NaN`.\n",
    "\n",
    "5. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments to be passed to the function.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Scalar**:\n",
    "  - The sum of the values in the Series. If the Series is empty or contains only `NaN` values, the result depends on the `min_count` parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Default Behavior**:\n",
    "\n",
    "  - By default, the sum of an empty or all-`NaN` Series is `0.0`.\n",
    "  - This behavior can be controlled using the `min_count` parameter.\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If `skipna=True`, `NaN` values are ignored.\n",
    "  - If `skipna=False`, the presence of any `NaN` value will result in `NaN` for the sum.\n",
    "\n",
    "- **`min_count` Parameter**:\n",
    "  - If `min_count` is set, the operation requires at least that many non-`NaN` values to return a valid result. Otherwise, the result is `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "print(s.sum())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "15\n",
    "```\n",
    "\n",
    "Explanation: \\(1 + 2 + 3 + 4 + 5 = 15\\).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4, 5])\n",
    "print(s.sum(skipna=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "12\n",
    "```\n",
    "\n",
    "Explanation: \\(1 + 2 + 4 + 5 = 12\\). The `NaN` value is ignored.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Using `min_count`**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4, 5])\n",
    "print(s.sum(min_count=5))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "Explanation: There are only 4 non-`NaN` values, which is fewer than `min_count=5`. Hence, the result is `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Empty Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "print(s.sum())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0.0\n",
    "```\n",
    "\n",
    "Explanation: By default, the sum of an empty Series is `0.0`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. All-`NaN` Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([np.nan, np.nan])\n",
    "print(s.sum())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0.0\n",
    "```\n",
    "\n",
    "Explanation: By default, the sum of an all-`NaN` Series is `0.0`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Controlling Empty/All-`NaN` Behavior with `min_count`**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "print(s.sum(min_count=1))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "Explanation: Since `min_count=1` and there are no valid values, the result is `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. MultiIndex Series**:\n",
    "\n",
    "```python\n",
    "idx = pd.MultiIndex.from_arrays([\n",
    "    ['warm', 'warm', 'cold', 'cold'],\n",
    "    ['dog', 'falcon', 'fish', 'spider']],\n",
    "    names=['blooded', 'animal'])\n",
    "s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    "print(s.sum())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "14\n",
    "```\n",
    "\n",
    "Explanation: (4 + 2 + 0 + 8 = 14).\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.min`**: Returns the minimum value.\n",
    "- **`Series.max`**: Returns the maximum value.\n",
    "- **`Series.mean`**: Returns the mean of the values.\n",
    "- **`DataFrame.sum`**: Similar functionality for DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.sum` to compute the sum of values in a Series.\n",
    "- Control the handling of missing values with `skipna` and `min_count`.\n",
    "- Be cautious with empty or all-`NaN` Series, as the default behavior returns `0.0` unless `min_count` is specified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.var\n",
    "Series.var(axis=None, skipna=True, ddof=1, numeric_only=False, **kwargs)[source]\n",
    "Return unbiased variance over requested axis.\n",
    "\n",
    "Normalized by N-1 by default. This can be changed using the ddof argument.\n",
    "\n",
    "Parameters:\n",
    "axis: {index (0)}\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Warning\n",
    "\n",
    "The behavior of DataFrame.var with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar To retain the old behavior, pass axis=0 (or do not pass axis).\n",
    "\n",
    "skipna : bool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "ddof: int, default 1\n",
    "Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements.\n",
    "\n",
    "numeric_only : bool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "Returns:\n",
    "scalar or Series (if level specified) \"\"\"\n",
    "\n",
    "df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
    "                   'age': [21, 25, 62, 43],\n",
    "                   'height': [1.61, 1.87, 1.49, 2.01]}\n",
    "                  ).set_index('person_id')\n",
    "df \n",
    "df.var()\n",
    "# Alternatively, ddof=0 can be set to normalize by N instead of N-1:\n",
    "\n",
    "df.var(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.var` method calculates the **variance** of the values in a Series. Variance measures the spread or dispersion of the data points around the mean. By default, it uses \\(N-1\\) as the denominator (Bessel's correction) to provide an unbiased estimate of the population variance when working with a sample.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`axis`** (int or str, default: `0`):\n",
    "\n",
    "   - Axis to compute the variance along. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "2. **`skipna`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, excludes `NaN` (missing) values when computing the variance.\n",
    "   - If `False`, the result will be `NaN` if any value in the Series is `NaN`.\n",
    "\n",
    "3. **`ddof`** (int, default: `1`):\n",
    "\n",
    "   - Delta Degrees of Freedom. The divisor used in the calculation is \\(N - \\text{ddof}\\), where \\(N\\) is the number of non-`NaN` values.\n",
    "   - Default is `1`, which corresponds to the sample variance.\n",
    "   - Set `ddof=0` to compute the population variance.\n",
    "\n",
    "4. **`numeric_only`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, includes only numeric columns (float, int, boolean). Not implemented for Series.\n",
    "\n",
    "5. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments to be passed to the function.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Scalar**:\n",
    "  - The variance of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Formula**:\n",
    "  \\[\n",
    "  \\text{Variance} = \\frac{1}{N - \\text{ddof}} \\sum\\_{i=1}^N (x_i - \\bar{x})^2\n",
    "  \\]\n",
    "\n",
    "  - \\(x_i\\): Individual data points.\n",
    "  - \\(\\bar{x}\\): Mean of the data.\n",
    "  - \\(N\\): Number of non-`NaN` values.\n",
    "  - \\(\\text{ddof}\\): Adjusts the degrees of freedom.\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If `skipna=True`, `NaN` values are ignored.\n",
    "  - If `skipna=False`, the presence of any `NaN` value will result in `NaN` for the variance.\n",
    "\n",
    "- **Degrees of Freedom (`ddof`)**:\n",
    "  - The default `ddof=1` provides an unbiased estimate of the variance for a sample.\n",
    "  - Set `ddof=0` to use the population formula (no adjustment).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "print(s.var())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "2.5\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Mean: \\(\\frac{1 + 2 + 3 + 4 + 5}{5} = 3\\)\n",
    "- Variance: \\(\\frac{(1-3)^2 + (2-3)^2 + (3-3)^2 + (4-3)^2 + (5-3)^2}{5 - 1} = 2.5\\)\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Using `ddof=0`**:\n",
    "\n",
    "```python\n",
    "print(s.var(ddof=0))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "2.0\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Variance: \\(\\frac{(1-3)^2 + (2-3)^2 + (3-3)^2 + (4-3)^2 + (5-3)^2}{5} = 2.0\\)\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 4, 5])\n",
    "print(s.var(skipna=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "2.666667\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Non-`NaN` values: `[1, 2, 4, 5]`\n",
    "- Mean: \\(\\frac{1 + 2 + 4 + 5}{4} = 3\\)\n",
    "- Variance: \\(\\frac{(1-3)^2 + (2-3)^2 + (4-3)^2 + (5-3)^2}{4 - 1} = \\frac{10}{3} \\approx 3.333\\)\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. DataFrame Example**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'age': [21, 25, 62, 43],\n",
    "    'height': [1.61, 1.87, 1.49, 2.01]\n",
    "})\n",
    "print(df.var())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "age       352.916667\n",
    "height      0.056367\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Variance is computed for each column.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Population Variance**:\n",
    "\n",
    "```python\n",
    "print(df.var(ddof=0))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "age       264.687500\n",
    "height      0.042275\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Population variance is computed for each column.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.std`**: Computes the standard deviation of the Series.\n",
    "- **`Series.mean`**: Computes the mean of the Series.\n",
    "- **`Series.sem`**: Computes the standard error of the mean.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.var` to compute the variance of a Series.\n",
    "- Adjust the degrees of freedom using the `ddof` parameter.\n",
    "- Handle missing values with the `skipna` parameter.\n",
    "- For DataFrames, the method computes the variance for each column by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.kurtosis\n",
    "Series.kurtosis(axis=0, skipna=True, numeric_only=False, **kwargs)[source]\n",
    "Return unbiased kurtosis over requested axis.\n",
    "\n",
    "Kurtosis obtained using Fisher’s definition of kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
    "\n",
    "Parameters:\n",
    "axis{index (0)}\n",
    "Axis for the function to be applied on. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "For DataFrames, specifying axis=None will apply the aggregation across both axes.\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "skipnabool, default True\n",
    "Exclude NA/null values when computing the result.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int, boolean columns. Not implemented for Series.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns:\n",
    "scalar or scalar \"\"\"\n",
    "s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n",
    "s\n",
    "# With a DataFrame \n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},\n",
    "                  index=['cat', 'dog', 'dog', 'mouse'])\n",
    "df\n",
    "#  With axis=None\n",
    "\n",
    "df.kurt(axis=None).round(6)\n",
    "# Using axis=1\n",
    "\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},\n",
    "                  index=['cat', 'dog'])\n",
    "df.kurt(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.kurtosis` method calculates the **kurtosis** of the values in a Series. Kurtosis measures the \"tailedness\" of the distribution of the data. It indicates whether the data has heavy tails (more outliers) or light tails (fewer outliers) compared to a normal distribution. By default, it uses Fisher's definition of kurtosis, where the kurtosis of a normal distribution is `0.0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`axis`** (int or str, default: `0`):\n",
    "\n",
    "   - Axis to compute kurtosis along. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "2. **`skipna`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, excludes `NaN` (missing) values when computing kurtosis.\n",
    "   - If `False`, the result will be `NaN` if any value in the Series is `NaN`.\n",
    "\n",
    "3. **`numeric_only`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, includes only numeric columns (float, int, boolean). Not implemented for Series.\n",
    "\n",
    "4. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments to be passed to the function.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Scalar**:\n",
    "  - The kurtosis of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Kurtosis Formula**:\n",
    "  \\[\n",
    "  \\text{Kurtosis} = \\frac{\\frac{1}{N} \\sum*{i=1}^N (x_i - \\bar{x})^4}{\\left(\\frac{1}{N} \\sum*{i=1}^N (x_i - \\bar{x})^2\\right)^2} - 3\n",
    "  \\]\n",
    "\n",
    "  - \\(x_i\\): Individual data points.\n",
    "  - \\(\\bar{x}\\): Mean of the data.\n",
    "  - \\(N\\): Number of non-`NaN` values.\n",
    "  - The `-3` adjustment ensures that the kurtosis of a normal distribution is `0.0`.\n",
    "\n",
    "- **Interpretation**:\n",
    "\n",
    "  - **Kurtosis = 0**: The distribution has the same tailedness as a normal distribution (mesokurtic).\n",
    "  - **Kurtosis > 0**: The distribution has heavier tails than a normal distribution (leptokurtic).\n",
    "  - **Kurtosis < 0**: The distribution has lighter tails than a normal distribution (platykurtic).\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "  - If `skipna=True`, `NaN` values are ignored.\n",
    "  - If `skipna=False`, the presence of any `NaN` value will result in `NaN` for kurtosis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 2, 3])\n",
    "print(s.kurtosis())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "-1.5\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The distribution has lighter tails than a normal distribution (platykurtic).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Handling Missing Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 3])\n",
    "print(s.kurtosis(skipna=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "-1.5\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Non-`NaN` values: `[1, 2, 3]`\n",
    "- The kurtosis is calculated for the non-missing values.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. DataFrame Example**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'a': [1, 2, 2, 3],\n",
    "    'b': [3, 4, 4, 4]\n",
    "})\n",
    "print(df.kurtosis())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a    -1.5\n",
    "b     4.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Column `a` has lighter tails (platykurtic).\n",
    "- Column `b` has heavier tails (leptokurtic).\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Row-wise Kurtosis**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'a': [1, 2],\n",
    "    'b': [3, 4],\n",
    "    'c': [3, 4],\n",
    "    'd': [1, 2]\n",
    "})\n",
    "print(df.kurtosis(axis=1))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0   -6.0\n",
    "1   -6.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Kurtosis is computed row-wise for each row in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Handling Non-Numeric Columns**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'a': [1, 2, 2, 3],\n",
    "    'b': ['x', 'y', 'y', 'z']\n",
    "})\n",
    "print(df.kurtosis(numeric_only=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "a   -1.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Only numeric column `a` is included in the calculation.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.skew`**: Computes the skewness of the Series.\n",
    "- **`Series.mean`**: Computes the mean of the Series.\n",
    "- **`Series.std`**: Computes the standard deviation of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.kurtosis` to compute the kurtosis of a Series.\n",
    "- Kurtosis measures the tailedness of the data distribution.\n",
    "- Handle missing values with the `skipna` parameter.\n",
    "- For DataFrames, the method computes kurtosis for each column by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "pandas.Series.unique\n",
    "\n",
    "Series.unique()[source]\n",
    "Return unique values of Series object.\n",
    "\n",
    "Uniques are returned in order of appearance. Hash table-based unique, therefore does NOT sort.\n",
    "\n",
    "Returns\n",
    ":\n",
    "ndarray or ExtensionArray\n",
    "The unique values returned as a NumPy array. See Notes.\n",
    "\n",
    "\n",
    "Series.drop_duplicates\n",
    "Return Series with duplicate values removed.\n",
    "\n",
    "unique\n",
    "Top-level unique method for any 1-d array-like object.\n",
    "\n",
    "Index.unique\n",
    "Return Index with unique values from an Index object.\n",
    "\n",
    "Notes\n",
    "\n",
    "Returns the unique values as a NumPy array. In case of an extension-array backed Series, a new ExtensionArray of that type with just the unique values is returned. This includes\n",
    "\n",
    "Categorical\n",
    "\n",
    "Period\n",
    "\n",
    "Datetime with Timezone\n",
    "\n",
    "Datetime without Timezone\n",
    "\n",
    "Timedelta\n",
    "\n",
    "Interval\n",
    "\n",
    "Sparse\n",
    "\n",
    "IntegerNA \"\"\"\n",
    "pd.Series([2, 1, 3, 3], name='A').unique()\n",
    "pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
    "pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
    "           for _ in range(3)]).unique()\n",
    "pd.Series(pd.Categorical(list('baabc'))).unique()\n",
    "pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
    "                         ordered=True)).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.unique` method returns the **unique values** in a Series. The unique values are returned in the order of their first occurrence, and the method does not sort the values. It is useful for identifying distinct elements in a Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **ndarray or ExtensionArray**:\n",
    "  - The unique values are returned as a NumPy array (for standard data types) or as an ExtensionArray (for specialized data types like `Categorical`, `Datetime`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Order of Appearance**:\n",
    "\n",
    "  - Unique values are returned in the order they first appear in the Series.\n",
    "  - The method does **not** sort the values.\n",
    "\n",
    "- **Hash Table-Based**:\n",
    "\n",
    "  - The method uses a hash table to identify unique values, making it efficient for large datasets.\n",
    "\n",
    "- **Supported Data Types**:\n",
    "  - Works with standard data types (e.g., integers, floats, strings) as well as specialized types like `Categorical`, `Datetime`, `Timedelta`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([2, 1, 3, 3], name='A')\n",
    "print(s.unique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "array([2, 1, 3])\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `[2, 1, 3]`, returned in the order of their first occurrence.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Handling Duplicates**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(['apple', 'banana', 'apple', 'orange'])\n",
    "print(s.unique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "array(['apple', 'banana', 'orange'], dtype=object)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `['apple', 'banana', 'orange']`, returned in the order of their first occurrence.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Datetime Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)])\n",
    "print(s.unique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "<DatetimeArray>\n",
    "['2016-01-01 00:00:00']\n",
    "Length: 1, dtype: datetime64[ns]\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique value is `2016-01-01`, returned as a `DatetimeArray`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Categorical Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.Categorical(list('baabc')))\n",
    "print(s.unique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "['b', 'a', 'c']\n",
    "Categories (3, object): ['a', 'b', 'c']\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `['b', 'a', 'c']`, returned in the order of their first occurrence. The categories are preserved.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Ordered Categorical Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.Categorical(list('baabc'), categories=list('abc'), ordered=True))\n",
    "print(s.unique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "['b', 'a', 'c']\n",
    "Categories (3, object): ['a' < 'b' < 'c']\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `['b', 'a', 'c']`, returned in the order of their first occurrence. The categories are ordered as `['a' < 'b' < 'c']`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Timezone-Aware Datetime Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern') for _ in range(3)])\n",
    "print(s.unique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "<DatetimeArray>\n",
    "['2016-01-01 00:00:00-05:00']\n",
    "Length: 1, dtype: datetime64[ns, US/Eastern]\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique value is `2016-01-01 00:00:00-05:00`, returned as a `DatetimeArray` with timezone information.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.drop_duplicates`**: Returns a Series with duplicate values removed.\n",
    "- **`pandas.unique`**: A top-level function to find unique values in any 1-D array-like object.\n",
    "- **`Index.unique`**: Returns unique values from an Index object.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.unique` to extract unique values from a Series.\n",
    "- Unique values are returned in the order of their first occurrence.\n",
    "- Works with standard and specialized data types (e.g., `Categorical`, `Datetime`).\n",
    "- Does **not** sort the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.nunique\n",
    "Series.nunique(dropna=True)[source]\n",
    "Return number of unique elements in the object.\n",
    "\n",
    "Excludes NA values by default.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "dropna\n",
    "bool, default True\n",
    "Don’t include NaN in the count.\n",
    "\n",
    "Returns\n",
    ":\n",
    "int\n",
    "\n",
    "\n",
    "DataFrame.nunique\n",
    "Method nunique for DataFrame.\n",
    "\n",
    "Series.count\n",
    "Count non-NA/null observations in the Series. \"\"\"\n",
    "s = pd.Series([1, 3, 5, 7, 7])\n",
    "s\n",
    "s.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.nunique` method calculates the **number of unique values** in a Series. It is useful for quickly determining the count of distinct elements in the data. By default, it excludes `NaN` (missing) values from the count.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`dropna`** (bool, default: `True`):\n",
    "   - If `True`, excludes `NaN` values from the count of unique values.\n",
    "   - If `False`, includes `NaN` as a unique value in the count.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **int**:\n",
    "  - The number of unique values in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If `dropna=True`, `NaN` values are ignored.\n",
    "  - If `dropna=False`, `NaN` is counted as a unique value.\n",
    "\n",
    "- **Efficiency**:\n",
    "  - The method is efficient and uses a hash table to count unique values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 3, 5, 7, 7])\n",
    "print(s.nunique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "4\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `[1, 3, 5, 7]`, so the count is `4`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Including `NaN` Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 3, 5, 7, 7, None])\n",
    "print(s.nunique(dropna=False))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "5\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `[1, 3, 5, 7, NaN]`, so the count is `5`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Excluding `NaN` Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 3, 5, 7, 7, None])\n",
    "print(s.nunique(dropna=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "4\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `[1, 3, 5, 7]`, so the count is `4`. The `NaN` value is excluded.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. String Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(['apple', 'banana', 'apple', 'orange'])\n",
    "print(s.nunique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `['apple', 'banana', 'orange']`, so the count is `3`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Categorical Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.Categorical(['a', 'b', 'a', 'c']))\n",
    "print(s.nunique())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "3\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The unique values are `['a', 'b', 'c']`, so the count is `3`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`DataFrame.nunique`**: Computes the number of unique values for each column in a DataFrame.\n",
    "- **`Series.count`**: Counts the number of non-NA/null observations in the Series.\n",
    "- **`Series.unique`**: Returns the unique values in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.nunique` to count the number of unique values in a Series.\n",
    "- Control the inclusion of `NaN` values with the `dropna` parameter.\n",
    "- Efficiently computes the count using a hash table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.is_unique\n",
    "property Series.is_unique[source]\n",
    "Return boolean if values in the object are unique.\n",
    "\n",
    "Returns\n",
    ":\n",
    "bool \"\"\"\n",
    "s = pd.Series([1, 2, 3])\n",
    "s.is_unique\n",
    "\n",
    "s = pd.Series([1, 2, 3, 1])\n",
    "s.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.is_unique` property checks whether all values in a Series are **unique**. It returns a boolean value (`True` if all values are unique, `False` otherwise). This property is useful for quickly verifying the uniqueness of values in a Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **bool**:\n",
    "  - `True`: If all values in the Series are unique.\n",
    "  - `False`: If there are duplicate values in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Efficiency**:\n",
    "  - The property uses a hash table to check for uniqueness, making it efficient for large datasets.\n",
    "- **Handling Missing Values**:\n",
    "  - `NaN` values are treated as unique. If there are multiple `NaN` values, the property will return `False`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.is_unique)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- All values in the Series are unique, so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Series with Duplicates**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3, 1])\n",
    "print(s.is_unique)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The value `1` appears twice, so the result is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Series with `NaN` Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3, None])\n",
    "print(s.is_unique)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- All values, including `NaN`, are unique, so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Series with Duplicate `NaN` Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3, None, None])\n",
    "print(s.is_unique)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The `NaN` value appears twice, so the result is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. String Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(['apple', 'banana', 'orange'])\n",
    "print(s.is_unique)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- All values in the Series are unique, so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Categorical Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(pd.Categorical(['a', 'b', 'c']))\n",
    "print(s.is_unique)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- All values in the Series are unique, so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.unique`**: Returns the unique values in the Series.\n",
    "- **`Series.nunique`**: Counts the number of unique values in the Series.\n",
    "- **`Series.drop_duplicates`**: Returns a Series with duplicate values removed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.is_unique` to check if all values in a Series are unique.\n",
    "- Returns `True` if all values are unique, otherwise `False`.\n",
    "- Efficiently checks uniqueness using a hash table.\n",
    "- Handles `NaN` values appropriately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.is_monotonic_increasing\n",
    "\n",
    "\n",
    "property Series.is_monotonic_increasing\n",
    "Return boolean if values in the object are monotonically increasing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "bool \"\"\"\n",
    "s = pd.Series([1, 2, 2])\n",
    "s.is_monotonic_increasing\n",
    "\n",
    "s = pd.Series([3, 2, 1])\n",
    "s.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.is_monotonic_increasing` property checks whether the values in a Series are **monotonically increasing**. A Series is monotonically increasing if each value is greater than or equal to the previous value. This property is useful for verifying trends or ordered data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **bool**:\n",
    "  - `True`: If the values in the Series are monotonically increasing.\n",
    "  - `False`: If the values are not monotonically increasing.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "  - A Series is monotonically increasing if for all \\(i \\leq j\\), \\(s_i \\leq s_j\\).\n",
    "  - Equal values are allowed (e.g., `[1, 2, 2]` is considered monotonically increasing).\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If the Series contains `NaN` values, the property will return `False` because `NaN` cannot be compared.\n",
    "\n",
    "- **Efficiency**:\n",
    "  - The property is efficient and checks the condition in a single pass through the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.is_monotonic_increasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are strictly increasing, so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Series with Equal Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 2])\n",
    "print(s.is_monotonic_increasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are non-decreasing (equal values are allowed), so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Series That Is Not Monotonic**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([3, 2, 1])\n",
    "print(s.is_monotonic_increasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are decreasing, so the result is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Series with `NaN` Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, None, 3])\n",
    "print(s.is_monotonic_increasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The presence of `NaN` makes the Series non-monotonic, so the result is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. String Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(['a', 'b', 'c'])\n",
    "print(s.is_monotonic_increasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are in alphabetical order, so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Series with Mixed Order**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 3, 2])\n",
    "print(s.is_monotonic_increasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are not in increasing order, so the result is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.is_monotonic_decreasing`**: Checks if the values in the Series are monotonically decreasing.\n",
    "- **`Series.is_monotonic`**: Checks if the values are either monotonically increasing or decreasing.\n",
    "- **`Series.sort_values`**: Sorts the values in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.is_monotonic_increasing` to check if the values in a Series are monotonically increasing.\n",
    "- Returns `True` if the values are non-decreasing, otherwise `False`.\n",
    "- Handles `NaN` values by returning `False`.\n",
    "- Works with numeric, string, and other comparable data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.is_monotonic_decreasing\n",
    "\n",
    "property Series.is_monotonic_decreasing\n",
    "Return boolean if values in the object are monotonically decreasing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "bool \"\"\"\n",
    "s = pd.Series([3, 2, 2, 1])\n",
    "s.is_monotonic_decreasing\n",
    "s = pd.Series([1, 2, 3])\n",
    "s.is_monotonic_decreasing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.is_monotonic_decreasing` property checks whether the values in a Series are **monotonically decreasing**. A Series is monotonically decreasing if each value is less than or equal to the previous value. This property is useful for verifying trends or ordered data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **bool**:\n",
    "  - `True`: If the values in the Series are monotonically decreasing.\n",
    "  - `False`: If the values are not monotonically decreasing.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Definition**:\n",
    "\n",
    "  - A Series is monotonically decreasing if for all \\(i \\leq j\\), \\(s_i \\geq s_j\\).\n",
    "  - Equal values are allowed (e.g., `[3, 2, 2]` is considered monotonically decreasing).\n",
    "\n",
    "- **Handling Missing Values**:\n",
    "\n",
    "  - If the Series contains `NaN` values, the property will return `False` because `NaN` cannot be compared.\n",
    "\n",
    "- **Efficiency**:\n",
    "  - The property is efficient and checks the condition in a single pass through the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([3, 2, 1])\n",
    "print(s.is_monotonic_decreasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are strictly decreasing, so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Series with Equal Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([3, 2, 2, 1])\n",
    "print(s.is_monotonic_decreasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are non-increasing (equal values are allowed), so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Series That Is Not Monotonic**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, 3])\n",
    "print(s.is_monotonic_decreasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are increasing, so the result is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Series with `NaN` Values**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([3, 2, None, 1])\n",
    "print(s.is_monotonic_decreasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The presence of `NaN` makes the Series non-monotonic, so the result is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. String Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(['c', 'b', 'a'])\n",
    "print(s.is_monotonic_decreasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are in reverse alphabetical order, so the result is `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Series with Mixed Order**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([3, 1, 2])\n",
    "print(s.is_monotonic_decreasing)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The values are not in decreasing order, so the result is `False`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.is_monotonic_increasing`**: Checks if the values in the Series are monotonically increasing.\n",
    "- **`Series.is_monotonic`**: Checks if the values are either monotonically increasing or decreasing.\n",
    "- **`Series.sort_values`**: Sorts the values in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.is_monotonic_decreasing` to check if the values in a Series are monotonically decreasing.\n",
    "- Returns `True` if the values are non-increasing, otherwise `False`.\n",
    "- Handles `NaN` values by returning `False`.\n",
    "- Works with numeric, string, and other comparable data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.value_counts\n",
    "\n",
    "Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
    "\n",
    "Return a Series containing counts of unique values.\n",
    "\n",
    "The resulting object will be in descending order so that the first element is the most frequently-occurring element. Excludes NA values by default.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "normalize\n",
    "bool, default False\n",
    "If True then the object returned will contain the relative frequencies of the unique values.\n",
    "\n",
    "sort\n",
    "bool, default True\n",
    "Sort by frequencies when True. Preserve the order of the data when False.\n",
    "\n",
    "ascending\n",
    "bool, default False\n",
    "Sort in ascending order.\n",
    "\n",
    "bins\n",
    "int, optional\n",
    "Rather than count values, group them into half-open bins, a convenience for pd.cut, only works with numeric data.\n",
    "\n",
    "dropna\n",
    "bool, default True\n",
    "Don’t include counts of NaN.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series \"\"\"\n",
    "index = pd.Index([3, 1, 2, 3, 4, np.nan])\n",
    "index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With normalize set to True, returns the relative frequency by dividing all values by the sum of values.\n",
    "\n",
    "s = pd.Series([3, 1, 2, 3, 4, np.nan])\n",
    "s.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins\n",
    "\n",
    "# Bins can be useful for going from a continuous variable to a categorical variable; instead of counting unique apparitions of values, divide the index in the specified number of half-open bins.\n",
    "\n",
    "s.value_counts(bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna\n",
    "\n",
    "# With dropna set to False we can also see NaN index values.\n",
    "\n",
    "s.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.value_counts` method returns a **Series containing the counts of unique values** in the original Series. It is a powerful tool for summarizing categorical or discrete data. By default, it excludes `NaN` values and sorts the results in descending order of frequency.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`normalize`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, returns the relative frequencies (proportions) of the unique values instead of counts.\n",
    "   - If `False`, returns the absolute counts.\n",
    "\n",
    "2. **`sort`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, sorts the result by frequency (descending by default).\n",
    "   - If `False`, preserves the order of the unique values as they appear in the data.\n",
    "\n",
    "3. **`ascending`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, sorts the result in ascending order of frequency.\n",
    "   - If `False`, sorts the result in descending order of frequency.\n",
    "\n",
    "4. **`bins`** (int, optional):\n",
    "\n",
    "   - If specified, groups numeric data into the specified number of half-open bins (intervals).\n",
    "   - Only works with numeric data.\n",
    "\n",
    "5. **`dropna`** (bool, default: `True`):\n",
    "   - If `True`, excludes `NaN` values from the count.\n",
    "   - If `False`, includes `NaN` as a unique value in the count.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Series**:\n",
    "  - A Series with unique values as the index and their counts (or proportions) as the values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Default Behavior**:\n",
    "  - Counts unique values, excludes `NaN`, and sorts the result in descending order of frequency.\n",
    "- **Handling Missing Values**:\n",
    "  - Use `dropna=False` to include `NaN` in the count.\n",
    "- **Binning**:\n",
    "  - The `bins` parameter is useful for converting continuous numeric data into categorical intervals.\n",
    "- **Normalization**:\n",
    "  - Use `normalize=True` to get relative frequencies (proportions) instead of absolute counts.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([3, 1, 2, 3, 4, None])\n",
    "print(s.value_counts())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "3.0    2\n",
    "1.0    1\n",
    "2.0    1\n",
    "4.0    1\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The value `3.0` appears twice, and the other values appear once. `NaN` is excluded by default.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Including `NaN` Values**:\n",
    "\n",
    "```python\n",
    "print(s.value_counts(dropna=False))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "3.0    2\n",
    "1.0    1\n",
    "2.0    1\n",
    "4.0    1\n",
    "NaN    1\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- `NaN` is included in the count as a unique value.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Relative Frequencies**:\n",
    "\n",
    "```python\n",
    "print(s.value_counts(normalize=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "3.0    0.4\n",
    "1.0    0.2\n",
    "2.0    0.2\n",
    "4.0    0.2\n",
    "Name: proportion, dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The relative frequencies are calculated by dividing each count by the total number of non-`NaN` values.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Sorting in Ascending Order**:\n",
    "\n",
    "```python\n",
    "print(s.value_counts(ascending=True))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "1.0    1\n",
    "2.0    1\n",
    "4.0    1\n",
    "3.0    2\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The result is sorted in ascending order of frequency.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Preserving Order of Appearance**:\n",
    "\n",
    "```python\n",
    "print(s.value_counts(sort=False))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "3.0    2\n",
    "1.0    1\n",
    "2.0    1\n",
    "4.0    1\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The order of unique values is preserved as they appear in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Binning Numeric Data**:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.2, 2.5, 3.7, 4.1, 5.0])\n",
    "print(s.value_counts(bins=3))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "(0.999, 2.333]    2\n",
    "(2.333, 3.667]    1\n",
    "(3.667, 5.0]      2\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The numeric data is divided into 3 bins, and the counts for each bin are returned.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. String Series**:\n",
    "\n",
    "```python\n",
    "s = pd.Series(['apple', 'banana', 'apple', 'orange'])\n",
    "print(s.value_counts())\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "apple     2\n",
    "banana    1\n",
    "orange    1\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The value `'apple'` appears twice, and the other values appear once.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.count`**: Counts the number of non-NA/null observations in the Series.\n",
    "- **`DataFrame.value_counts`**: Equivalent method for DataFrames.\n",
    "- **`pd.cut`**: Bins numeric data into intervals.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.value_counts` to count the occurrences of unique values in a Series.\n",
    "- Control the inclusion of `NaN` values with the `dropna` parameter.\n",
    "- Use `normalize=True` to get relative frequencies instead of counts.\n",
    "- Use `bins` to group numeric data into intervals.\n",
    "- Sort the results by frequency or preserve the order of appearance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.align\n",
    "Series.align(other, join='outer', axis=None, level=None, copy=None, fill_value=None, method=<no_default>, limit=<no_default>, fill_axis=<no_default>, broadcast_axis=<no_default>)\n",
    "\n",
    "\n",
    "\n",
    "Align two objects on their axes with the specified join method.\n",
    "\n",
    "Join method is specified for each axis Index.\n",
    "\n",
    "Parameters:\n",
    "otherDataFrame or Series\n",
    "join{‘outer’, ‘inner’, ‘left’, ‘right’}, default ‘outer’\n",
    "Type of alignment to be performed.\n",
    "\n",
    "left: use only keys from left frame, preserve key order.\n",
    "\n",
    "right: use only keys from right frame, preserve key order.\n",
    "\n",
    "outer: use union of keys from both frames, sort keys lexicographically.\n",
    "\n",
    "inner: use intersection of keys from both frames, preserve the order of the left keys.\n",
    "\n",
    "axisallowed axis of the other object, default None\n",
    "Align on index (0), columns (1), or both (None).\n",
    "\n",
    "levelint or level name, default None\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "copybool, default True\n",
    "Always returns new objects. If copy=False and no reindexing is required then original objects are returned.\n",
    "\n",
    "Note\n",
    "\n",
    "The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and ignore the copy keyword. The copy keyword will be removed in a future version of pandas.\n",
    "\n",
    "You can already get the future behavior and improvements through enabling copy on write pd.options.mode.copy_on_write = True\n",
    "\n",
    "fill_valuescalar, default np.nan\n",
    "Value to use for missing values. Defaults to NaN, but can be any “compatible” value.\n",
    "\n",
    "method{‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None\n",
    "Method to use for filling holes in reindexed Series:\n",
    "\n",
    "pad / ffill: propagate last valid observation forward to next valid.\n",
    "\n",
    "backfill / bfill: use NEXT valid observation to fill gap.\n",
    "\n",
    "Deprecated since version 2.1.\n",
    "\n",
    "limitint, default None\n",
    "If method is specified, this is the maximum number of consecutive NaN values to forward/backward fill. In other words, if there is a gap with more than this number of consecutive NaNs, it will only be partially filled. If method is not specified, this is the maximum number of entries along the entire axis where NaNs will be filled. Must be greater than 0 if not None.\n",
    "\n",
    "Deprecated since version 2.1.\n",
    "\n",
    "fill_axis{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default 0\n",
    "Filling axis, method and limit.\n",
    "\n",
    "Deprecated since version 2.1.\n",
    "\n",
    "broadcast_axis{0 or ‘index’} for Series, {0 or ‘index’, 1 or ‘columns’} for DataFrame, default None\n",
    "Broadcast values along this axis, if aligning two objects of different dimensions.\n",
    "\n",
    "Deprecated since version 2.1.\n",
    "\n",
    "Returns:\n",
    "tuple of (Series/DataFrame, type of other)\n",
    "Aligned objects. \"\"\"\n",
    "df = pd.DataFrame(\n",
    "    [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[\"D\", \"B\", \"E\", \"A\"], index=[1, 2]\n",
    ")\n",
    "other = pd.DataFrame(\n",
    "    [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],\n",
    "    columns=[\"A\", \"B\", \"C\", \"D\"],\n",
    "    index=[2, 3, 4],\n",
    ")\n",
    "df\n",
    "# Align on columns:\n",
    "\n",
    "left, right = df.align(other, join=\"outer\", axis=1)\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also align on the index:\n",
    "\n",
    "left, right = df.align(other, join=\"outer\", axis=0)\n",
    "left\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the default axis=None will align on both index and columns:\n",
    "\n",
    "left, right = df.align(other, join=\"outer\", axis=None)\n",
    "left\n",
    "right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.align` method aligns two objects (Series or DataFrames) along their axes using a specified join method. This is useful for ensuring that two datasets have the same index or columns before performing operations like arithmetic or merging. The method returns a tuple of aligned objects.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`other`** (DataFrame or Series):\n",
    "\n",
    "   - The object to align with the current Series or DataFrame.\n",
    "\n",
    "2. **`join`** ({‘outer’, ‘inner’, ‘left’, ‘right’}, default: `'outer'`):\n",
    "\n",
    "   - Specifies the type of alignment:\n",
    "     - `'outer'`: Use the union of keys from both objects.\n",
    "     - `'inner'`: Use the intersection of keys from both objects.\n",
    "     - `'left'`: Use only keys from the left object.\n",
    "     - `'right'`: Use only keys from the right object.\n",
    "\n",
    "3. **`axis`** (int or str, default: `None`):\n",
    "\n",
    "   - Axis to align along:\n",
    "     - `0` or `'index'`: Align on the index.\n",
    "     - `1` or `'columns'`: Align on the columns.\n",
    "     - `None`: Align on both index and columns.\n",
    "\n",
    "4. **`level`** (int or level name, default: `None`):\n",
    "\n",
    "   - If the objects are MultiIndex, align on the specified level.\n",
    "\n",
    "5. **`copy`** (bool, default: `True`):\n",
    "\n",
    "   - If `True`, always returns new objects. If `False` and no reindexing is required, the original objects are returned.\n",
    "   - **Note**: The `copy` keyword will be deprecated in future versions of pandas due to the introduction of Copy-on-Write (CoW).\n",
    "\n",
    "6. **`fill_value`** (scalar, default: `np.nan`):\n",
    "\n",
    "   - Value to use for missing values after alignment.\n",
    "\n",
    "7. **`method`** ({‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default: `None`):\n",
    "\n",
    "   - Method to fill missing values:\n",
    "     - `'pad'` or `'ffill'`: Propagate the last valid observation forward.\n",
    "     - `'backfill'` or `'bfill'`: Use the next valid observation to fill gaps.\n",
    "   - **Deprecated since version 2.1**.\n",
    "\n",
    "8. **`limit`** (int, default: `None`):\n",
    "\n",
    "   - Maximum number of consecutive `NaN` values to fill if `method` is specified.\n",
    "   - **Deprecated since version 2.1**.\n",
    "\n",
    "9. **`fill_axis`** ({0 or ‘index’, 1 or ‘columns’}, default: `0`):\n",
    "\n",
    "   - Axis to fill missing values along.\n",
    "   - **Deprecated since version 2.1**.\n",
    "\n",
    "10. **`broadcast_axis`** ({0 or ‘index’, 1 or ‘columns’}, default: `None`):\n",
    "    - Axis to broadcast values along if aligning objects of different dimensions.\n",
    "    - **Deprecated since version 2.1**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **tuple**:\n",
    "  - A tuple of two aligned objects (e.g., `(left, right)`), where `left` is the aligned version of the original object and `right` is the aligned version of `other`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Alignment**:\n",
    "  - The method ensures that the two objects have the same index, columns, or both, depending on the `axis` parameter.\n",
    "- **Join Types**:\n",
    "  - `'outer'`: Includes all keys from both objects.\n",
    "  - `'inner'`: Includes only keys present in both objects.\n",
    "  - `'left'`: Includes only keys from the left object.\n",
    "  - `'right'`: Includes only keys from the right object.\n",
    "- **Handling Missing Values**:\n",
    "  - Missing values introduced during alignment are filled with `fill_value` (default: `NaN`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Aligning on Columns**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [[1, 2, 3, 4], [6, 7, 8, 9]],\n",
    "    columns=[\"D\", \"B\", \"E\", \"A\"],\n",
    "    index=[1, 2]\n",
    ")\n",
    "other = pd.DataFrame(\n",
    "    [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],\n",
    "    columns=[\"A\", \"B\", \"C\", \"D\"],\n",
    "    index=[2, 3, 4]\n",
    ")\n",
    "\n",
    "left, right = df.align(other, join=\"outer\", axis=1)\n",
    "print(left)\n",
    "print(right)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A  B   C  D  E\n",
    "1  4  2 NaN  1  3\n",
    "2  9  7 NaN  6  8\n",
    "\n",
    "    A    B    C    D   E\n",
    "2   10   20   30   40 NaN\n",
    "3   60   70   80   90 NaN\n",
    "4  600  700  800  900 NaN\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The columns of both DataFrames are aligned using an outer join. Missing values are filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Aligning on Index**:\n",
    "\n",
    "```python\n",
    "left, right = df.align(other, join=\"outer\", axis=0)\n",
    "print(left)\n",
    "print(right)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "    D    B    E    A\n",
    "1  1.0  2.0  3.0  4.0\n",
    "2  6.0  7.0  8.0  9.0\n",
    "3  NaN  NaN  NaN  NaN\n",
    "4  NaN  NaN  NaN  NaN\n",
    "\n",
    "    A      B      C      D\n",
    "1    NaN    NaN    NaN    NaN\n",
    "2   10.0   20.0   30.0   40.0\n",
    "3   60.0   70.0   80.0   90.0\n",
    "4  600.0  700.0  800.0  900.0\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The indices of both DataFrames are aligned using an outer join. Missing values are filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Aligning on Both Index and Columns**:\n",
    "\n",
    "```python\n",
    "left, right = df.align(other, join=\"outer\", axis=None)\n",
    "print(left)\n",
    "print(right)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     A    B   C    D    E\n",
    "1  4.0  2.0 NaN  1.0  3.0\n",
    "2  9.0  7.0 NaN  6.0  8.0\n",
    "3  NaN  NaN NaN  NaN  NaN\n",
    "4  NaN  NaN NaN  NaN  NaN\n",
    "\n",
    "       A      B      C      D   E\n",
    "1    NaN    NaN    NaN    NaN NaN\n",
    "2   10.0   20.0   30.0   40.0 NaN\n",
    "3   60.0   70.0   80.0   90.0 NaN\n",
    "4  600.0  700.0  800.0  900.0 NaN\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Both the index and columns are aligned using an outer join. Missing values are filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Using `fill_value`**:\n",
    "\n",
    "```python\n",
    "left, right = df.align(other, join=\"outer\", axis=1, fill_value=0)\n",
    "print(left)\n",
    "print(right)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A  B  C  D  E\n",
    "1  4  2  0  1  3\n",
    "2  9  7  0  6  8\n",
    "\n",
    "    A    B    C    D  E\n",
    "2   10   20   30   40  0\n",
    "3   60   70   80   90  0\n",
    "4  600  700  800  900  0\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- Missing values are filled with `0` instead of `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`DataFrame.align`**: Equivalent method for DataFrames.\n",
    "- **`Series.reindex`**: Reindexes a Series to match a new index.\n",
    "- **`DataFrame.reindex`**: Reindexes a DataFrame to match new indices or columns.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.align` to align two objects (Series or DataFrames) along their axes.\n",
    "- Specify the join type (`'outer'`, `'inner'`, `'left'`, `'right'`) and the axis (`0`, `1`, or `None`).\n",
    "- Handle missing values with the `fill_value` parameter.\n",
    "- Returns a tuple of aligned objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.case_when\n",
    "Series.case_when(caselist)[source]\n",
    "Replace values where the conditions are True.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "caselist : A list of tuples of conditions and expected replacements\n",
    "Takes the form: (condition0, replacement0), (condition1, replacement1), … . condition should be a 1-D boolean array-like object or a callable. If condition is a callable, it is computed on the Series and should return a boolean Series or array. The callable must not change the input Series (though pandas doesn`t check it). replacement should be a 1-D array-like object, a scalar or a callable. If replacement is a callable, it is computed on the Series and should return a scalar or Series. The callable must not change the input Series (though pandas doesn`t check it).\n",
    "\n",
    "Added in version 2.2.0.\n",
    "\n",
    "Returns:\n",
    "Series\n",
    "\n",
    "\n",
    "Series.mask\n",
    "Replace values where the condition is True. \"\"\"\n",
    "c = pd.Series([6, 7, 8, 9], name='c')\n",
    "a = pd.Series([0, 0, 1, 2])\n",
    "b = pd.Series([0, 3, 4, 5])\n",
    "c.case_when(caselist=[(a.gt(0), a),  # condition, replacement\n",
    "                      (b.gt(0), b)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.case_when` method, introduced in **pandas 2.2.0**, allows you to replace values in a Series based on specified conditions. It is similar to SQL's `CASE WHEN` statement or Python's `if-elif-else` logic. The method takes a list of tuples, where each tuple contains a condition and a replacement value. The conditions are evaluated in order, and the first condition that evaluates to `True` determines the replacement value for that element.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`caselist`** (list of tuples):\n",
    "   - A list of tuples of the form `(condition, replacement)`.\n",
    "   - **`condition`**: A 1-D boolean array-like object or a callable. If it is a callable, it is applied to the Series and must return a boolean Series or array.\n",
    "   - **`replacement`**: A 1-D array-like object, a scalar, or a callable. If it is a callable, it is applied to the Series and must return a scalar or Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Series**:\n",
    "  - A new Series with values replaced according to the conditions specified in `caselist`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Order of Evaluation**:\n",
    "  - Conditions are evaluated in the order they are provided. The first condition that evaluates to `True` determines the replacement value.\n",
    "- **Callable Conditions and Replacements**:\n",
    "  - Both `condition` and `replacement` can be callable functions. These functions are applied to the Series and must not modify the input Series.\n",
    "- **Default Behavior**:\n",
    "  - If no condition evaluates to `True` for a particular element, the original value is retained.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "c = pd.Series([6, 7, 8, 9], name='c')\n",
    "a = pd.Series([0, 0, 1, 2])\n",
    "b = pd.Series([0, 3, 4, 5])\n",
    "\n",
    "result = c.case_when(caselist=[\n",
    "    (a.gt(0), a),  # Replace with `a` where `a > 0`\n",
    "    (b.gt(0), b)   # Replace with `b` where `b > 0`\n",
    "])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    6\n",
    "1    3\n",
    "2    1\n",
    "3    2\n",
    "Name: c, dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- For the first element (`6`), neither `a > 0` nor `b > 0` is `True`, so the original value `6` is retained.\n",
    "- For the second element (`7`), `b > 0` is `True`, so it is replaced with `3`.\n",
    "- For the third element (`8`), `a > 0` is `True`, so it is replaced with `1`.\n",
    "- For the fourth element (`9`), `a > 0` is `True`, so it is replaced with `2`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Using Callable Conditions and Replacements**:\n",
    "\n",
    "```python\n",
    "c = pd.Series([10, 20, 30, 40])\n",
    "\n",
    "result = c.case_when(caselist=[\n",
    "    (lambda x: x > 25, lambda x: x * 2),  # Replace with `x * 2` where `x > 25`\n",
    "    (lambda x: x < 15, lambda x: x + 100) # Replace with `x + 100` where `x < 15`\n",
    "])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    110\n",
    "1     20\n",
    "2     60\n",
    "3     80\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- For the first element (`10`), `x < 15` is `True`, so it is replaced with `10 + 100 = 110`.\n",
    "- For the second element (`20`), neither condition is `True`, so the original value `20` is retained.\n",
    "- For the third and fourth elements (`30` and `40`), `x > 25` is `True`, so they are replaced with `30 * 2 = 60` and `40 * 2 = 80`, respectively.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Using Scalar Replacements**:\n",
    "\n",
    "```python\n",
    "c = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "result = c.case_when(caselist=[\n",
    "    (c > 2, 100),  # Replace with `100` where `c > 2`\n",
    "    (c < 2, 200)   # Replace with `200` where `c < 2`\n",
    "])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    200\n",
    "1      2\n",
    "2    100\n",
    "3    100\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- For the first element (`1`), `c < 2` is `True`, so it is replaced with `200`.\n",
    "- For the second element (`2`), neither condition is `True`, so the original value `2` is retained.\n",
    "- For the third and fourth elements (`3` and `4`), `c > 2` is `True`, so they are replaced with `100`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Retaining Original Values**:\n",
    "\n",
    "```python\n",
    "c = pd.Series([5, 10, 15, 20])\n",
    "\n",
    "result = c.case_when(caselist=[\n",
    "    (c > 20, 100)  # Replace with `100` where `c > 20`\n",
    "])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0     5\n",
    "1    10\n",
    "2    15\n",
    "3    20\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- None of the elements satisfy `c > 20`, so all original values are retained.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.mask`**: Replace values where a condition is `True`.\n",
    "- **`Series.where`**: Replace values where a condition is `False`.\n",
    "- **`numpy.select`**: Similar functionality for NumPy arrays.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.case_when` to replace values in a Series based on conditions.\n",
    "- Conditions and replacements can be specified as arrays, scalars, or callable functions.\n",
    "- The first condition that evaluates to `True` determines the replacement value.\n",
    "- If no condition is `True`, the original value is retained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])\n",
    "s\n",
    "# Drop labels B en C\n",
    "\n",
    "s.drop(labels=['B', 'C'])\n",
    "# Drop 2nd level label in MultiIndex Series\n",
    "\n",
    "midx = pd.MultiIndex(levels=[['llama', 'cow', 'falcon'],\n",
    "                             ['speed', 'weight', 'length']],\n",
    "                     codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
    "                            [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
    "s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n",
    "              index=midx)\n",
    "s\n",
    "s.drop(labels='weight', level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.drop` method removes specified index labels from a Series. It is useful for filtering out unwanted data based on the index. The method returns a new Series with the specified labels removed, unless `inplace=True` is specified, in which case the operation is performed in-place.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**:\n",
    "\n",
    "1. **`labels`** (single label or list-like):\n",
    "\n",
    "   - Index labels to drop. Can be a single label or a list of labels.\n",
    "\n",
    "2. **`axis`** ({0 or ‘index’}, default: `0`):\n",
    "\n",
    "   - Unused for Series. Included for compatibility with DataFrame.\n",
    "\n",
    "3. **`index`** (single label or list-like):\n",
    "\n",
    "   - Alias for `labels`. Redundant for Series but can be used instead of `labels`.\n",
    "\n",
    "4. **`columns`** (single label or list-like):\n",
    "\n",
    "   - Unused for Series. Included for compatibility with DataFrame.\n",
    "\n",
    "5. **`level`** (int or level name, optional):\n",
    "\n",
    "   - For MultiIndex Series, specifies the level from which to drop labels.\n",
    "\n",
    "6. **`inplace`** (bool, default: `False`):\n",
    "\n",
    "   - If `True`, performs the operation in-place and returns `None`.\n",
    "   - If `False`, returns a new Series with the specified labels removed.\n",
    "\n",
    "7. **`errors`** ({‘ignore’, ‘raise’}, default: `'raise'`):\n",
    "   - If `'raise'`, raises a `KeyError` if any of the labels are not found in the index.\n",
    "   - If `'ignore'`, suppresses the error and only drops existing labels.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "\n",
    "- **Series or None**:\n",
    "  - If `inplace=False`, returns a new Series with the specified labels removed.\n",
    "  - If `inplace=True`, returns `None` and modifies the original Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**:\n",
    "\n",
    "- **Handling Missing Labels**:\n",
    "  - If `errors='raise'` (default), a `KeyError` is raised if any of the specified labels are not found in the index.\n",
    "  - If `errors='ignore'`, missing labels are ignored, and only existing labels are dropped.\n",
    "- **MultiIndex Series**:\n",
    "  - Use the `level` parameter to specify the level from which to drop labels in a MultiIndex Series.\n",
    "- **In-Place Operation**:\n",
    "  - Use `inplace=True` to modify the original Series instead of returning a new one.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**:\n",
    "\n",
    "#### **1. Basic Usage**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(data=[0, 1, 2], index=['A', 'B', 'C'])\n",
    "print(s.drop(labels=['B', 'C']))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A    0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The labels `'B'` and `'C'` are dropped, leaving only `'A'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Using `index` Parameter**:\n",
    "\n",
    "```python\n",
    "print(s.drop(index=['B', 'C']))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A    0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The `index` parameter is an alias for `labels` and behaves the same way.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Handling Missing Labels**:\n",
    "\n",
    "```python\n",
    "print(s.drop(labels=['B', 'D'], errors='ignore'))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A    0\n",
    "C    2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The label `'D'` does not exist in the index, but since `errors='ignore'`, it is ignored, and only `'B'` is dropped.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. In-Place Operation**:\n",
    "\n",
    "```python\n",
    "s.drop(labels=['B', 'C'], inplace=True)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A    0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The original Series is modified in-place, and the method returns `None`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. MultiIndex Series**:\n",
    "\n",
    "```python\n",
    "midx = pd.MultiIndex(levels=[['llama', 'cow', 'falcon'],\n",
    "                             ['speed', 'weight', 'length']],\n",
    "                     codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
    "                            [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
    "s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3], index=midx)\n",
    "print(s.drop(labels='weight', level=1))\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "llama   speed      45.0\n",
    "        length      1.2\n",
    "cow     speed      30.0\n",
    "        length      1.5\n",
    "falcon  speed     320.0\n",
    "        length      0.3\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- The label `'weight'` is dropped from the second level of the MultiIndex.\n",
    "\n",
    "---\n",
    "\n",
    "### **See Also**:\n",
    "\n",
    "- **`Series.reindex`**: Return a Series with specified index labels.\n",
    "- **`Series.dropna`**: Remove missing values from a Series.\n",
    "- **`Series.drop_duplicates`**: Remove duplicate values from a Series.\n",
    "- **`DataFrame.drop`**: Drop specified labels from rows or columns in a DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**:\n",
    "\n",
    "- Use `Series.drop` to remove specified index labels from a Series.\n",
    "- Specify labels to drop using the `labels` or `index` parameter.\n",
    "- Use `errors='ignore'` to suppress errors for missing labels.\n",
    "- Use `inplace=True` to modify the original Series.\n",
    "- For MultiIndex Series, use the `level` parameter to specify the level from which to drop labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.droplevel\n",
    "Series.droplevel(level, axis=0)[source]\n",
    "Return Series/DataFrame with requested index / column level(s) removed.\n",
    "\n",
    "Parameters:\n",
    "levelint, str, or list-like\n",
    "If a string is given, must be the name of a level If list-like, elements must be names or positional indexes of levels.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Axis along which the level(s) is removed:\n",
    "\n",
    "0 or ‘index’: remove level(s) in column.\n",
    "\n",
    "1 or ‘columns’: remove level(s) in row.\n",
    "\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Returns:\n",
    "Series/DataFrame\n",
    "Series/DataFrame with requested index / column level(s) removed. \"\"\"\n",
    "df = pd.DataFrame([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12]\n",
    "]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
    "\n",
    "df.columns = pd.MultiIndex.from_tuples([\n",
    "    ('c', 'e'), ('d', 'f')\n",
    "], names=['level_1', 'level_2'])\n",
    "df\n",
    "\n",
    "df.droplevel('a')\n",
    "\n",
    "df.droplevel('level_2', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.droplevel` method is used to remove one or more levels from a **MultiIndex** in a Series or DataFrame. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.droplevel(level, axis=0)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`level`** : `int`, `str`, or `list-like`\n",
    "\n",
    "   - Specifies the level(s) to remove.\n",
    "   - If a **string** is provided, it must be the name of a level.\n",
    "   - If **list-like**, elements must be names or positional indexes of levels.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "   - Specifies the axis along which the level(s) is removed:\n",
    "     - `0` or `'index'`: Remove level(s) from the **index**.\n",
    "     - `1` or `'columns'`: Remove level(s) from the **columns**.\n",
    "   - For **Series**, this parameter is unused and defaults to `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - The object with the requested index or column level(s) removed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Dropping a Level from a MultiIndex in a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series with a MultiIndex\n",
    "index = pd.MultiIndex.from_tuples([('A', 1), ('A', 2), ('B', 1)], names=['group', 'number'])\n",
    "s = pd.Series([10, 20, 30], index=index)\n",
    "\n",
    "print(\"Original Series:\")\n",
    "print(s)\n",
    "\n",
    "# Drop the 'group' level\n",
    "result = s.droplevel('group')\n",
    "print(\"\\nSeries after dropping 'group' level:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original Series:\n",
    "group  number\n",
    "A      1         10\n",
    "       2         20\n",
    "B      1         30\n",
    "dtype: int64\n",
    "\n",
    "Series after dropping 'group' level:\n",
    "number\n",
    "1    10\n",
    "2    20\n",
    "1    30\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Dropping a Level from a MultiIndex in a DataFrame (Index)\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with a MultiIndex\n",
    "index = pd.MultiIndex.from_tuples([('A', 1), ('A', 2), ('B', 1)], names=['group', 'number'])\n",
    "df = pd.DataFrame({'value': [10, 20, 30]}, index=index)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Drop the 'group' level from the index\n",
    "result = df.droplevel('group')\n",
    "print(\"\\nDataFrame after dropping 'group' level:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "           value\n",
    "group number\n",
    "A     1        10\n",
    "      2        20\n",
    "B     1        30\n",
    "\n",
    "DataFrame after dropping 'group' level:\n",
    "         value\n",
    "number\n",
    "1          10\n",
    "2          20\n",
    "1          30\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Dropping a Level from a MultiIndex in a DataFrame (Columns)\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with MultiIndex columns\n",
    "columns = pd.MultiIndex.from_tuples([('c', 'e'), ('d', 'f')], names=['level_1', 'level_2'])\n",
    "df = pd.DataFrame([[1, 2], [3, 4]], columns=columns)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Drop the 'level_2' level from the columns\n",
    "result = df.droplevel('level_2', axis=1)\n",
    "print(\"\\nDataFrame after dropping 'level_2' level:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "level_1   c   d\n",
    "level_2   e   f\n",
    "0         1   2\n",
    "1         3   4\n",
    "\n",
    "DataFrame after dropping 'level_2' level:\n",
    "level_1   c   d\n",
    "0         1   2\n",
    "1         3   4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Dropping Multiple Levels\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with a MultiIndex\n",
    "index = pd.MultiIndex.from_tuples([('A', 1, 'X'), ('A', 2, 'Y'), ('B', 1, 'Z')], names=['group', 'number', 'type'])\n",
    "df = pd.DataFrame({'value': [10, 20, 30]}, index=index)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Drop both 'group' and 'type' levels\n",
    "result = df.droplevel(['group', 'type'])\n",
    "print(\"\\nDataFrame after dropping 'group' and 'type' levels:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "                value\n",
    "group number type\n",
    "A     1      X      10\n",
    "      2      Y      20\n",
    "B     1      Z      30\n",
    "\n",
    "DataFrame after dropping 'group' and 'type' levels:\n",
    "         value\n",
    "number\n",
    "1          10\n",
    "2          20\n",
    "1          30\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `droplevel` method is particularly useful when working with **MultiIndex** objects in pandas.\n",
    "- If you drop all levels from a MultiIndex, the result will have a flat index or columns.\n",
    "- For **Series**, the `axis` parameter is ignored because Series only has one axis (the index).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pandas.Series.drop_duplicates\n",
    "Series.drop_duplicates(*, keep='first', inplace=False, ignore_index=False)[source]\n",
    "Return Series with duplicate values removed.\n",
    "\n",
    "Parameters:\n",
    "keep{‘first’, ‘last’, False}, default ‘first’\n",
    "Method to handle dropping duplicates:\n",
    "\n",
    "‘first’ : Drop duplicates except for the first occurrence.\n",
    "\n",
    "‘last’ : Drop duplicates except for the last occurrence.\n",
    "\n",
    "False : Drop all duplicates.\n",
    "\n",
    "inplacebool, default False\n",
    "If True, performs operation inplace and returns None.\n",
    "\n",
    "ignore_indexbool, default False\n",
    "If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
    "\n",
    "Added in version 2.0.0.\n",
    "\n",
    "Returns:\n",
    "Series or None\n",
    "Series with duplicates dropped or None if inplace=True.\n",
    "\n",
    "Index.drop_duplicates\n",
    "Equivalent method on Index.\n",
    "\n",
    "DataFrame.drop_duplicates\n",
    "Equivalent method on DataFrame.\n",
    "\n",
    "Series.duplicated\n",
    "Related method on Series, indicating duplicate Series values.\n",
    "\n",
    "Series.unique\n",
    "Return unique values as an array.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama', 'hippo'],\n",
    "              name='animal')\n",
    "s\n",
    "s.drop_duplicates()\n",
    "s.drop_duplicates(keep='last')\n",
    "s.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.drop_duplicates` method is used to remove duplicate values from a pandas Series. Below is a detailed explanation of its parameters and usage:\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.drop_duplicates(*, keep='first', inplace=False, ignore_index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`keep`** : `{'first', 'last', False}`, default `'first'`\n",
    "\n",
    "   - Determines which duplicates (if any) to keep.\n",
    "   - Options:\n",
    "     - `'first'` : Drop all duplicates except for the **first occurrence**.\n",
    "     - `'last'` : Drop all duplicates except for the **last occurrence**.\n",
    "     - `False` : Drop **all duplicates** (this will remove all occurrences of duplicate values).\n",
    "\n",
    "2. **`inplace`** : `bool`, default `False`\n",
    "\n",
    "   - If `True`, the operation is performed in place (i.e., the original Series is modified), and the method returns `None`.\n",
    "   - If `False`, a new Series with duplicates removed is returned.\n",
    "\n",
    "3. **`ignore_index`** : `bool`, default `False`\n",
    "   - If `True`, the resulting Series will have its index reset to `0, 1, ..., n-1`.\n",
    "   - Added in pandas version 2.0.0.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series or None**:\n",
    "  - If `inplace=False` (default), a new Series with duplicates removed is returned.\n",
    "  - If `inplace=True`, the method returns `None`, and the original Series is modified.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series with duplicate values\n",
    "s = pd.Series([1, 2, 2, 3, 3, 3, 4])\n",
    "\n",
    "# Drop duplicates, keeping the first occurrence\n",
    "result = s.drop_duplicates()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "3    3\n",
    "6    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Keep Last Occurrence\n",
    "\n",
    "```python\n",
    "# Drop duplicates, keeping the last occurrence\n",
    "result = s.drop_duplicates(keep='last')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "2    2\n",
    "5    3\n",
    "6    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Drop All Duplicates\n",
    "\n",
    "```python\n",
    "# Drop all duplicates (remove all occurrences of duplicate values)\n",
    "result = s.drop_duplicates(keep=False)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "6    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Inplace Modification\n",
    "\n",
    "```python\n",
    "# Drop duplicates in place\n",
    "s.drop_duplicates(inplace=True)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "3    3\n",
    "6    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Reset Index\n",
    "\n",
    "```python\n",
    "# Drop duplicates and reset the index\n",
    "result = s.drop_duplicates(ignore_index=True)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "3    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `drop_duplicates` method is useful for cleaning data by removing redundant or repeated values.\n",
    "- Use `ignore_index=True` if you want the resulting Series to have a clean, sequential index.\n",
    "- Be cautious with `inplace=True`, as it modifies the original Series and does not return a new object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.duplicated\n",
    "Series.duplicated(keep='first')[source]\n",
    "Indicate duplicate Series values.\n",
    "\n",
    "Duplicated values are indicated as True values in the resulting Series. Either all duplicates, all except the first or all except the last occurrence of duplicates can be indicated.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "keep\n",
    "{‘first’, ‘last’, False}, default ‘first’\n",
    "Method to handle dropping duplicates:\n",
    "\n",
    "‘first’ : Mark duplicates as True except for the first occurrence.\n",
    "\n",
    "‘last’ : Mark duplicates as True except for the last occurrence.\n",
    "\n",
    "False : Mark all duplicates as True.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series[bool]\n",
    "Series indicating whether each value has occurred in the preceding values.\n",
    "\n",
    "See also\n",
    "\n",
    "Index.duplicated\n",
    "Equivalent method on pandas.Index.\n",
    "\n",
    "DataFrame.duplicated\n",
    "Equivalent method on pandas.DataFrame.\n",
    "\n",
    "Series.drop_duplicates\n",
    "Remove duplicate values from Series. \"\"\"\n",
    "animals = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama'])\n",
    "animals.duplicated()\n",
    "animals.duplicated(keep='first')\n",
    "\n",
    "# By using ‘last’, the last occurrence of each set of duplicated values is set on False and all others on True:\n",
    "\n",
    "animals.duplicated(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting keep on False, all duplicates are True:\n",
    "\n",
    "animals.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.duplicated` method is used to identify duplicate values in a pandas Series. It returns a boolean Series where `True` indicates that the value at that position is a duplicate, and `False` indicates that it is unique. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.duplicated(keep='first')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`keep`** : `{'first', 'last', False}`, default `'first'`\n",
    "   - Determines which duplicates (if any) to mark as `True`.\n",
    "   - Options:\n",
    "     - `'first'` : Mark all duplicates as `True` **except for the first occurrence**.\n",
    "     - `'last'` : Mark all duplicates as `True` **except for the last occurrence**.\n",
    "     - `False` : Mark **all duplicates** as `True`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series[bool]**:\n",
    "  - A boolean Series where `True` indicates that the value is a duplicate, and `False` indicates that it is unique.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Default Behavior (`keep='first'`)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series with duplicate values\n",
    "animals = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama'])\n",
    "\n",
    "# Identify duplicates (default: keep='first')\n",
    "duplicates = animals.duplicated()\n",
    "print(duplicates)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    False\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- The first occurrence of `'llama'` (index `0`) is marked as `False`.\n",
    "- Subsequent occurrences of `'llama'` (indices `2` and `4`) are marked as `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Keep Last Occurrence (`keep='last'`)\n",
    "\n",
    "```python\n",
    "# Identify duplicates, keeping the last occurrence\n",
    "duplicates = animals.duplicated(keep='last')\n",
    "print(duplicates)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- The last occurrence of `'llama'` (index `4`) is marked as `False`.\n",
    "- Previous occurrences of `'llama'` (indices `0` and `2`) are marked as `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Mark All Duplicates (`keep=False`)\n",
    "\n",
    "```python\n",
    "# Identify all duplicates\n",
    "duplicates = animals.duplicated(keep=False)\n",
    "print(duplicates)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- All occurrences of `'llama'` (indices `0`, `2`, and `4`) are marked as `True`.\n",
    "- Unique values (`'cow'` and `'beetle'`) are marked as `False`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `duplicated` method is useful for identifying duplicate values in a Series.\n",
    "- It is often used in conjunction with other methods like `drop_duplicates` to clean data.\n",
    "- The `keep` parameter allows flexibility in determining which occurrences of duplicates to mark.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`Series.drop_duplicates`**:\n",
    "\n",
    "   - Removes duplicate values from a Series.\n",
    "   - Example:\n",
    "     ```python\n",
    "     animals.drop_duplicates()\n",
    "     ```\n",
    "\n",
    "2. **`Index.duplicated`**:\n",
    "\n",
    "   - Equivalent method for identifying duplicates in a pandas Index.\n",
    "\n",
    "3. **`DataFrame.duplicated`**:\n",
    "   - Equivalent method for identifying duplicates in a pandas DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a dataset with duplicate entries, and you want to identify and remove them:\n",
    "\n",
    "```python\n",
    "# Identify duplicates\n",
    "duplicates = animals.duplicated()\n",
    "\n",
    "# Filter out duplicates\n",
    "unique_animals = animals[~duplicates]\n",
    "print(unique_animals)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     llama\n",
    "1       cow\n",
    "3    beetle\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "- The `~` operator is used to negate the boolean Series, keeping only unique values.\n",
    "\n",
    "---\n",
    "\n",
    "This method is a powerful tool for data cleaning and ensuring data integrity in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.equals\n",
    "Series.equals(other)[source]\n",
    "Test whether two objects contain the same elements.\n",
    "\n",
    "This function allows two Series or DataFrames to be compared against each other to see if they have the same shape and elements. NaNs in the same location are considered equal.\n",
    "\n",
    "The row/column index do not need to have the same type, as long as the values are considered equal. Corresponding columns and index must be of the same dtype.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series or DataFrame\n",
    "The other Series or DataFrame to be compared with the first.\n",
    "\n",
    "Returns\n",
    ":\n",
    "bool\n",
    "True if all elements are the same in both objects, False otherwise.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.eq\n",
    "Compare two Series objects of the same length and return a Series where each element is True if the element in each Series is equal, False otherwise.\n",
    "\n",
    "DataFrame.eq\n",
    "Compare two DataFrame objects of the same shape and return a DataFrame where each element is True if the respective element in each DataFrame is equal, False otherwise.\n",
    "\n",
    "testing.assert_series_equal\n",
    "Raises an AssertionError if left and right are not equal. Provides an easy interface to ignore inequality in dtypes, indexes and precision among others.\n",
    "\n",
    "testing.assert_frame_equal\n",
    "Like assert_series_equal, but targets DataFrames.\n",
    "\n",
    "numpy.array_equal\n",
    "Return True if two arrays have the same shape and elements, False otherwise. \"\"\"\n",
    "df = pd.DataFrame({1: [10], 2: [20]})\n",
    "df\n",
    "\n",
    "\n",
    "# DataFrames df and exactly_equal have the same types and values for their elements and column labels, which will return True.\n",
    "\n",
    "exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
    "exactly_equal\n",
    "df.equals(exactly_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames df and different_column_type have the same element types and values, but have different types for the column labels, which will still return True.\n",
    "\n",
    "different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
    "different_column_type\n",
    "df.equals(different_column_type)\n",
    "\n",
    "# DataFrames df and different_data_type have different types for the same values for their elements, and will return False even though their column labels are the same values and types.\n",
    "\n",
    "different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
    "different_data_type\n",
    "df.equals(different_data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.equals` method is used to compare two pandas objects (Series or DataFrame) to determine if they have the **same shape and elements**. It is a strict comparison method that checks for equality in values, index, and data types. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.equals(other)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`** : `Series` or `DataFrame`\n",
    "   - The object to compare with the current Series or DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **`bool`**:\n",
    "  - `True` if the two objects have the **same shape, elements, and data types**.\n",
    "  - `False` otherwise.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features**\n",
    "\n",
    "1. **Element-wise Comparison**:\n",
    "\n",
    "   - Compares each element in the two objects for equality.\n",
    "   - `NaN` values in the same location are considered equal.\n",
    "\n",
    "2. **Index Comparison**:\n",
    "\n",
    "   - The index of the two objects must match in terms of values, but the types of the index can differ (e.g., integer index vs. string index).\n",
    "\n",
    "3. **Data Type Comparison**:\n",
    "\n",
    "   - The data types of the elements must match. If the data types differ, the method returns `False`.\n",
    "\n",
    "4. **Shape Comparison**:\n",
    "   - The two objects must have the same shape (same number of rows and columns for DataFrames, or same length for Series).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Comparing Two Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series\n",
    "s1 = pd.Series([1, 2, 3])\n",
    "s2 = pd.Series([1, 2, 3])\n",
    "s3 = pd.Series([1, 2, 4])\n",
    "\n",
    "# Compare s1 and s2\n",
    "print(s1.equals(s2))  # True\n",
    "\n",
    "# Compare s1 and s3\n",
    "print(s1.equals(s3))  # False\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "True\n",
    "False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Comparing Series with Different Index Types\n",
    "\n",
    "```python\n",
    "# Create Series with different index types\n",
    "s4 = pd.Series([1, 2, 3], index=[0, 1, 2])\n",
    "s5 = pd.Series([1, 2, 3], index=['0', '1', '2'])\n",
    "\n",
    "# Compare s4 and s5\n",
    "print(s4.equals(s5))  # True (index values are the same, even though types differ)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Comparing Series with NaN Values\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create Series with NaN values\n",
    "s6 = pd.Series([1, 2, np.nan])\n",
    "s7 = pd.Series([1, 2, np.nan])\n",
    "\n",
    "# Compare s6 and s7\n",
    "print(s6.equals(s7))  # True (NaN values are considered equal)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Comparing Series with Different Data Types\n",
    "\n",
    "```python\n",
    "# Create Series with different data types\n",
    "s8 = pd.Series([1, 2, 3])\n",
    "s9 = pd.Series([1.0, 2.0, 3.0])\n",
    "\n",
    "# Compare s8 and s9\n",
    "print(s8.equals(s9))  # False (data types differ)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Comparing DataFrames\n",
    "\n",
    "```python\n",
    "# Create DataFrames\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df3 = pd.DataFrame({'A': [1, 2], 'B': [3.0, 4.0]})  # Different data types\n",
    "\n",
    "# Compare df1 and df2\n",
    "print(df1.equals(df2))  # True\n",
    "\n",
    "# Compare df1 and df3\n",
    "print(df1.equals(df3))  # False (data types differ)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "True\n",
    "False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `equals` method is stricter than the `==` operator because it checks for equality in **values, index, and data types**.\n",
    "- For a more flexible comparison (e.g., ignoring data types or index differences), you can use `pandas.testing.assert_series_equal` or `pandas.testing.assert_frame_equal`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`Series.eq`**:\n",
    "\n",
    "   - Element-wise comparison of two Series. Returns a boolean Series.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s1.eq(s2)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.eq`**:\n",
    "\n",
    "   - Element-wise comparison of two DataFrames. Returns a boolean DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df1.eq(df2)\n",
    "     ```\n",
    "\n",
    "3. **`pandas.testing.assert_series_equal`**:\n",
    "\n",
    "   - Raises an `AssertionError` if two Series are not equal. Allows for flexible comparisons (e.g., ignoring data types or index differences).\n",
    "   - Example:\n",
    "     ```python\n",
    "     pd.testing.assert_series_equal(s1, s2)\n",
    "     ```\n",
    "\n",
    "4. **`pandas.testing.assert_frame_equal`**:\n",
    "\n",
    "   - Raises an `AssertionError` if two DataFrames are not equal. Similar to `assert_series_equal` but for DataFrames.\n",
    "   - Example:\n",
    "     ```python\n",
    "     pd.testing.assert_frame_equal(df1, df2)\n",
    "     ```\n",
    "\n",
    "5. **`numpy.array_equal`**:\n",
    "   - Compares two NumPy arrays for equality in shape and elements.\n",
    "   - Example:\n",
    "     ```python\n",
    "     np.array_equal(arr1, arr2)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you want to verify if two datasets are identical after some transformations:\n",
    "\n",
    "```python\n",
    "# After some data processing\n",
    "processed_data = df1.copy()\n",
    "\n",
    "# Compare with the original data\n",
    "if df1.equals(processed_data):\n",
    "    print(\"The datasets are identical.\")\n",
    "else:\n",
    "    print(\"The datasets are different.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "The `equals` method is a powerful tool for ensuring data integrity and verifying the correctness of data transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.first\n",
    "Series.first(offset)[source]\n",
    "Select initial periods of time series data based on a date offset.\n",
    "\n",
    "Deprecated since version 2.1: first() is deprecated and will be removed in a future version. Please create a mask and filter using .loc instead.\n",
    "\n",
    "For a DataFrame with a sorted DatetimeIndex, this function can select the first few rows based on a date offset.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "offset\n",
    "str, DateOffset or dateutil.relativedelta\n",
    "The offset length of the data that will be selected. For instance, ‘1ME’ will display all the rows having their index within the first month.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "A subset of the caller.\n",
    "\n",
    "Raises\n",
    ":\n",
    "TypeError\n",
    "If the index is not a DatetimeIndex \n",
    "\n",
    "last\n",
    "Select final periods of time series based on a date offset.\n",
    "\n",
    "at_time\n",
    "Select values at a particular time of the day.\n",
    "\n",
    "between_time\n",
    "Select values between particular times of the day.\n",
    "\n",
    "\"\"\"\n",
    "i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
    "ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
    "ts\n",
    "#  Get the rows for the first 3 days:\n",
    "\n",
    "ts.first('3D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.first` method is used to select the initial periods of time series data based on a date offset. It is particularly useful for filtering data from the beginning of a time series. However, **this method is deprecated starting from pandas version 2.1** and will be removed in a future version. The recommended approach is to use `.loc` with a mask for filtering.\n",
    "\n",
    "Below is a detailed explanation of the method, its parameters, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.first(offset)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`offset`** : `str`, `DateOffset`, or `dateutil.relativedelta`\n",
    "   - Specifies the offset length of the data to be selected.\n",
    "   - Examples:\n",
    "     - `'3D'` : Selects the first 3 calendar days.\n",
    "     - `'1ME'` : Selects the first month of data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - A subset of the original object containing the initial periods of the time series based on the specified offset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Raises**\n",
    "\n",
    "- **`TypeError`**:\n",
    "  - If the index of the Series or DataFrame is not a `DatetimeIndex`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Deprecation Notice**\n",
    "\n",
    "- The `first` method is deprecated starting from pandas version 2.1.\n",
    "- The recommended alternative is to use `.loc` with a mask for filtering.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Using `first` with a Time Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a time series with a DatetimeIndex\n",
    "index = pd.date_range('2023-01-01', periods=6, freq='2D')\n",
    "ts = pd.Series([1, 2, 3, 4, 5, 6], index=index)\n",
    "\n",
    "print(\"Original Series:\")\n",
    "print(ts)\n",
    "\n",
    "# Select the first 3 days of data\n",
    "result = ts.first('3D')\n",
    "print(\"\\nFirst 3 days of data:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original Series:\n",
    "2023-01-01    1\n",
    "2023-01-03    2\n",
    "2023-01-05    3\n",
    "2023-01-07    4\n",
    "2023-01-09    5\n",
    "2023-01-11    6\n",
    "Freq: 2D, dtype: int64\n",
    "\n",
    "First 3 days of data:\n",
    "2023-01-01    1\n",
    "2023-01-03    2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The `first('3D')` method selects data within the first 3 calendar days (`2023-01-01` to `2023-01-03`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Using `first` with a DataFrame\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with a DatetimeIndex\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, 5, 6]}, index=index)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Select the first 5 days of data\n",
    "result = df.first('5D')\n",
    "print(\"\\nFirst 5 days of data:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "            A\n",
    "2023-01-01  1\n",
    "2023-01-03  2\n",
    "2023-01-05  3\n",
    "2023-01-07  4\n",
    "2023-01-09  5\n",
    "2023-01-11  6\n",
    "\n",
    "First 5 days of data:\n",
    "            A\n",
    "2023-01-01  1\n",
    "2023-01-03  2\n",
    "2023-01-05  3\n",
    "```\n",
    "\n",
    "- The `first('5D')` method selects data within the first 5 calendar days (`2023-01-01` to `2023-01-05`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Recommended Alternative (Using `.loc`)**\n",
    "\n",
    "Since `first` is deprecated, you can achieve the same result using `.loc` with a mask.\n",
    "\n",
    "#### Example: Using `.loc` to Filter Data\n",
    "\n",
    "```python\n",
    "# Filter the first 3 days of data using .loc\n",
    "mask = ts.index <= ts.index[0] + pd.Timedelta('3D')\n",
    "result = ts.loc[mask]\n",
    "\n",
    "print(\"First 3 days of data (using .loc):\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "First 3 days of data (using .loc):\n",
    "2023-01-01    1\n",
    "2023-01-03    2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`last`**:\n",
    "\n",
    "   - Selects the final periods of time series data based on a date offset.\n",
    "   - Example:\n",
    "     ```python\n",
    "     ts.last('3D')\n",
    "     ```\n",
    "\n",
    "2. **`at_time`**:\n",
    "\n",
    "   - Selects values at a specific time of the day.\n",
    "   - Example:\n",
    "     ```python\n",
    "     ts.at_time('09:00')\n",
    "     ```\n",
    "\n",
    "3. **`between_time`**:\n",
    "   - Selects values between specific times of the day.\n",
    "   - Example:\n",
    "     ```python\n",
    "     ts.between_time('09:00', '12:00')\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `first` method is useful for quickly filtering time series data based on a date offset.\n",
    "- However, due to its deprecation, it is recommended to use `.loc` with a mask for filtering.\n",
    "- Ensure that the index of the Series or DataFrame is a `DatetimeIndex` before using this method.\n",
    "\n",
    "---\n",
    "\n",
    "By using the recommended `.loc` approach, you can achieve the same functionality in a more future-proof way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.head\n",
    "\n",
    "Series.head(n=5)\n",
    "Return the first n rows.\n",
    "\n",
    "This function returns the first n rows for the object based on position. It is useful for quickly testing if your object has the right type of data in it.\n",
    "\n",
    "For negative values of n, this function returns all rows except the last |n| rows, equivalent to df[:n].\n",
    "\n",
    "If n is larger than the number of rows, this function returns all rows.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "n\n",
    "int, default 5\n",
    "Number of rows to select.\n",
    "\n",
    "Returns\n",
    ":\n",
    "same type as caller\n",
    "The first n rows of the caller object.\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.tail\n",
    "Returns the last n rows. \"\"\"\n",
    "df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "                   'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    "df\n",
    "df.head()\n",
    "df.head(3)\n",
    "# For negative values of n\n",
    "\n",
    "df.head(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.head` method is used to return the first `n` rows of a Series or DataFrame. It is a convenient way to quickly inspect the beginning of your data. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.head(n=5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`n`** : `int`, default `5`\n",
    "   - The number of rows to return.\n",
    "   - If `n` is positive, it returns the first `n` rows.\n",
    "   - If `n` is negative, it returns all rows **except the last `|n|` rows**.\n",
    "   - If `n` is larger than the number of rows, it returns all rows.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Same type as caller**:\n",
    "  - The first `n` rows of the Series or DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Default Behavior (`n=5`)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "\n",
    "# Return the first 5 rows (default)\n",
    "print(s.head())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    10\n",
    "1    20\n",
    "2    30\n",
    "3    40\n",
    "4    50\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Specifying `n`\n",
    "\n",
    "```python\n",
    "# Return the first 3 rows\n",
    "print(s.head(3))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    10\n",
    "1    20\n",
    "2    30\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Negative `n`\n",
    "\n",
    "```python\n",
    "# Return all rows except the last 3\n",
    "print(s.head(-3))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    10\n",
    "1    20\n",
    "2    30\n",
    "3    40\n",
    "4    50\n",
    "5    60\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: `n` Larger Than the Number of Rows\n",
    "\n",
    "```python\n",
    "# Return all rows (n is larger than the number of rows)\n",
    "print(s.head(20))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    10\n",
    "1    20\n",
    "2    30\n",
    "3    40\n",
    "4    50\n",
    "5    60\n",
    "6    70\n",
    "7    80\n",
    "8    90\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples with DataFrame**\n",
    "\n",
    "#### Example 5: Default Behavior (`n=5`)\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'animal': ['alligator', 'bee', 'falcon', 'lion', 'monkey', 'parrot', 'shark', 'whale', 'zebra']\n",
    "})\n",
    "\n",
    "# Return the first 5 rows (default)\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 6: Specifying `n`\n",
    "\n",
    "```python\n",
    "# Return the first 3 rows\n",
    "print(df.head(3))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 7: Negative `n`\n",
    "\n",
    "```python\n",
    "# Return all rows except the last 3\n",
    "print(df.head(-3))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`tail`**:\n",
    "\n",
    "   - Returns the last `n` rows of a Series or DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.tail(3)\n",
    "     ```\n",
    "\n",
    "2. **`iloc`**:\n",
    "   - Allows positional indexing to select rows or columns.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.iloc[:5]  # Equivalent to df.head(5)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "The `head` method is commonly used for quick data inspection, especially when working with large datasets. For example:\n",
    "\n",
    "```python\n",
    "# Load a large dataset\n",
    "df = pd.read_csv('large_dataset.csv')\n",
    "\n",
    "# Inspect the first 5 rows\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `head` method is a simple and efficient way to preview the beginning of your data.\n",
    "- For more advanced row selection, you can use `.iloc` or `.loc`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `head`, you can quickly verify the structure and content of your data, making it an essential tool for data exploration and debugging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.idxmax\n",
    "Series.idxmax(axis=0, skipna=True, *args, **kwargs)[source]\n",
    "Return the row label of the maximum value.\n",
    "\n",
    "If multiple values equal the maximum, the first row label with that value is returned.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If the entire Series is NA, the result will be NA.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional arguments and keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Index\n",
    "Label of the maximum value.\n",
    "\n",
    "Raises\n",
    ":\n",
    "ValueError\n",
    "If the Series is empty.\n",
    "\n",
    "See also\n",
    "\n",
    "numpy.argmax\n",
    "Return indices of the maximum values along the given axis.\n",
    "\n",
    "DataFrame.idxmax\n",
    "Return index of first occurrence of maximum over requested axis.\n",
    "\n",
    "Series.idxmin\n",
    "Return index label of the first occurrence of minimum of values.\n",
    "\n",
    "Notes\n",
    "\n",
    "This method is the Series version of ndarray.argmax. This method returns the label of the maximum, while ndarray.argmax returns the position. To get the position, use series.values.argmax(). \"\"\"\n",
    "s = pd.Series(data=[1, None, 4, 3, 4],\n",
    "              index=['A', 'B', 'C', 'D', 'E'])\n",
    "s\n",
    "s.idxmax()\n",
    "# If skipna is False and there is an NA value in the data, the function returns nan.\n",
    "\n",
    "s.idxmax(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.idxmax` method is used to return the **row label (index)** of the **maximum value** in a pandas Series. If multiple values are equal to the maximum, the label of the **first occurrence** is returned. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.idxmax(axis=0, skipna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`axis`** : `{0 or 'index'}`\n",
    "\n",
    "   - This parameter is **unused** for Series. It is included for compatibility with DataFrame.\n",
    "\n",
    "2. **`skipna`** : `bool`, default `True`\n",
    "\n",
    "   - If `True`, **exclude** `NaN` (missing) values when searching for the maximum.\n",
    "   - If `False`, the result will be `NaN` if there are any `NaN` values in the Series.\n",
    "\n",
    "3. **`\\*args, **kwargs`\\*\\*:\n",
    "   - Additional arguments and keywords are accepted for compatibility with NumPy but have no effect.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Index**:\n",
    "  - The label (index) of the **first occurrence** of the maximum value in the Series.\n",
    "  - If all values are `NaN` and `skipna=True`, the result will be `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Raises**\n",
    "\n",
    "- **`ValueError`**:\n",
    "  - If the Series is **empty**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([1, 3, 2, 5, 4], index=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "# Find the index of the maximum value\n",
    "max_index = s.idxmax()\n",
    "print(max_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "'D'\n",
    "```\n",
    "\n",
    "- The maximum value is `5`, and its index is `'D'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Multiple Maximum Values\n",
    "\n",
    "```python\n",
    "# Create a Series with multiple maximum values\n",
    "s = pd.Series([1, 5, 2, 5, 4], index=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "# Find the index of the first occurrence of the maximum value\n",
    "max_index = s.idxmax()\n",
    "print(max_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "'B'\n",
    "```\n",
    "\n",
    "- The maximum value is `5`, and the first occurrence is at index `'B'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Handling NaN Values\n",
    "\n",
    "```python\n",
    "# Create a Series with NaN values\n",
    "s = pd.Series([1, None, 4, 3, 4], index=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "# Find the index of the maximum value (skipna=True by default)\n",
    "max_index = s.idxmax()\n",
    "print(max_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "'C'\n",
    "```\n",
    "\n",
    "- The maximum value is `4`, and the first occurrence is at index `'C'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Handling NaN Values with `skipna=False`\n",
    "\n",
    "```python\n",
    "# Find the index of the maximum value (skipna=False)\n",
    "max_index = s.idxmax(skipna=False)\n",
    "print(max_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "- Since `skipna=False` and there is a `NaN` value in the Series, the result is `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Empty Series\n",
    "\n",
    "```python\n",
    "# Create an empty Series\n",
    "s = pd.Series([])\n",
    "\n",
    "# Attempt to find the index of the maximum value\n",
    "try:\n",
    "    max_index = s.idxmax()\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "attempt to get argmax of an empty sequence\n",
    "```\n",
    "\n",
    "- A `ValueError` is raised because the Series is empty.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`Series.idxmin`**:\n",
    "\n",
    "   - Returns the index of the **minimum value** in the Series.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.idxmin()\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.idxmax`**:\n",
    "\n",
    "   - Returns the index of the maximum value for each row or column in a DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.idxmax(axis=0)  # Maximum along columns\n",
    "     ```\n",
    "\n",
    "3. **`numpy.argmax`**:\n",
    "\n",
    "   - Returns the **position** (integer index) of the maximum value in a NumPy array.\n",
    "   - Example:\n",
    "     ```python\n",
    "     import numpy as np\n",
    "     np.argmax(s.values)\n",
    "     ```\n",
    "\n",
    "4. **`Series.values.argmax()`**:\n",
    "   - Returns the **position** (integer index) of the maximum value in the underlying NumPy array of the Series.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.values.argmax()\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `idxmax` method is useful for finding the **label** of the maximum value in a Series.\n",
    "- If you need the **position** (integer index) of the maximum value, use `s.values.argmax()`.\n",
    "- By default, `NaN` values are ignored. If you want to include `NaN` values in the calculation, set `skipna=False`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a dataset of student scores and want to find the student with the highest score:\n",
    "\n",
    "```python\n",
    "# Create a Series of student scores\n",
    "scores = pd.Series([85, 92, 78, 95, 88], index=['Alice', 'Bob', 'Charlie', 'David', 'Eve'])\n",
    "\n",
    "# Find the student with the highest score\n",
    "top_student = scores.idxmax()\n",
    "print(f\"The student with the highest score is: {top_student}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "The student with the highest score is: David\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "By using `idxmax`, you can easily identify the label (index) associated with the maximum value in a Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.idxmin\n",
    "Series.idxmin(axis=0, skipna=True, *args, **kwargs)[source]\n",
    "Return the row label of the minimum value.\n",
    "\n",
    "If multiple values equal the minimum, the first row label with that value is returned.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If the entire Series is NA, the result will be NA.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional arguments and keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Index\n",
    "Label of the minimum value.\n",
    "\n",
    "Raises\n",
    ":\n",
    "ValueError\n",
    "If the Series is empty.\n",
    "\n",
    "\n",
    "numpy.argmin\n",
    "Return indices of the minimum values along the given axis.\n",
    "\n",
    "DataFrame.idxmin\n",
    "Return index of first occurrence of minimum over requested axis.\n",
    "\n",
    "Series.idxmax\n",
    "Return index label of the first occurrence of maximum of values.\n",
    "\n",
    "Notes\n",
    "\n",
    "This method is the Series version of ndarray.argmin. This method returns the label of the minimum, while ndarray.argmin returns the position. To get the position, use series.values.argmin(). \"\"\"\n",
    "\n",
    "s = pd.Series(data=[1, None, 4, 1],\n",
    "              index=['A', 'B', 'C', 'D'])\n",
    "s\n",
    "s.idxmin()\n",
    "# If skipna is False and there is an NA value in the data, the function returns nan.\n",
    "\n",
    "s.idxmin(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.idxmin` method is used to return the **row label (index)** of the **minimum value** in a pandas Series. If multiple values are equal to the minimum, the label of the **first occurrence** is returned. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.idxmin(axis=0, skipna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`axis`** : `{0 or 'index'}`\n",
    "\n",
    "   - This parameter is **unused** for Series. It is included for compatibility with DataFrame.\n",
    "\n",
    "2. **`skipna`** : `bool`, default `True`\n",
    "\n",
    "   - If `True`, **exclude** `NaN` (missing) values when searching for the minimum.\n",
    "   - If `False`, the result will be `NaN` if there are any `NaN` values in the Series.\n",
    "\n",
    "3. **`\\*args, **kwargs`\\*\\*:\n",
    "   - Additional arguments and keywords are accepted for compatibility with NumPy but have no effect.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Index**:\n",
    "  - The label (index) of the **first occurrence** of the minimum value in the Series.\n",
    "  - If all values are `NaN` and `skipna=True`, the result will be `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Raises**\n",
    "\n",
    "- **`ValueError`**:\n",
    "  - If the Series is **empty**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([5, 3, 2, 1, 4], index=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "# Find the index of the minimum value\n",
    "min_index = s.idxmin()\n",
    "print(min_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "'D'\n",
    "```\n",
    "\n",
    "- The minimum value is `1`, and its index is `'D'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Multiple Minimum Values\n",
    "\n",
    "```python\n",
    "# Create a Series with multiple minimum values\n",
    "s = pd.Series([1, 5, 2, 1, 4], index=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "# Find the index of the first occurrence of the minimum value\n",
    "min_index = s.idxmin()\n",
    "print(min_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "'A'\n",
    "```\n",
    "\n",
    "- The minimum value is `1`, and the first occurrence is at index `'A'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Handling NaN Values\n",
    "\n",
    "```python\n",
    "# Create a Series with NaN values\n",
    "s = pd.Series([1, None, 4, 3, 1], index=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "# Find the index of the minimum value (skipna=True by default)\n",
    "min_index = s.idxmin()\n",
    "print(min_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "'A'\n",
    "```\n",
    "\n",
    "- The minimum value is `1`, and the first occurrence is at index `'A'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Handling NaN Values with `skipna=False`\n",
    "\n",
    "```python\n",
    "# Find the index of the minimum value (skipna=False)\n",
    "min_index = s.idxmin(skipna=False)\n",
    "print(min_index)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "nan\n",
    "```\n",
    "\n",
    "- Since `skipna=False` and there is a `NaN` value in the Series, the result is `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Empty Series\n",
    "\n",
    "```python\n",
    "# Create an empty Series\n",
    "s = pd.Series([])\n",
    "\n",
    "# Attempt to find the index of the minimum value\n",
    "try:\n",
    "    min_index = s.idxmin()\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "attempt to get argmin of an empty sequence\n",
    "```\n",
    "\n",
    "- A `ValueError` is raised because the Series is empty.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`Series.idxmax`**:\n",
    "\n",
    "   - Returns the index of the **maximum value** in the Series.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.idxmax()\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.idxmin`**:\n",
    "\n",
    "   - Returns the index of the minimum value for each row or column in a DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.idxmin(axis=0)  # Minimum along columns\n",
    "     ```\n",
    "\n",
    "3. **`numpy.argmin`**:\n",
    "\n",
    "   - Returns the **position** (integer index) of the minimum value in a NumPy array.\n",
    "   - Example:\n",
    "     ```python\n",
    "     import numpy as np\n",
    "     np.argmin(s.values)\n",
    "     ```\n",
    "\n",
    "4. **`Series.values.argmin()`**:\n",
    "   - Returns the **position** (integer index) of the minimum value in the underlying NumPy array of the Series.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.values.argmin()\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `idxmin` method is useful for finding the **label** of the minimum value in a Series.\n",
    "- If you need the **position** (integer index) of the minimum value, use `s.values.argmin()`.\n",
    "- By default, `NaN` values are ignored. If you want to include `NaN` values in the calculation, set `skipna=False`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a dataset of student scores and want to find the student with the lowest score:\n",
    "\n",
    "```python\n",
    "# Create a Series of student scores\n",
    "scores = pd.Series([85, 92, 78, 95, 88], index=['Alice', 'Bob', 'Charlie', 'David', 'Eve'])\n",
    "\n",
    "# Find the student with the lowest score\n",
    "lowest_student = scores.idxmin()\n",
    "print(f\"The student with the lowest score is: {lowest_student}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "The student with the lowest score is: Charlie\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "By using `idxmin`, you can easily identify the label (index) associated with the minimum value in a Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.isin\n",
    "Series.isin(values)[source]\n",
    "Whether elements in Series are contained in values.\n",
    "\n",
    "Return a boolean Series showing whether each element in the Series matches an element in the passed sequence of values exactly.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "values\n",
    "set or list-like\n",
    "The sequence of values to test. Passing in a single string will raise a TypeError. Instead, turn a single string into a list of one element.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "Series of booleans indicating if each element is in values.\n",
    "\n",
    "Raises\n",
    ":\n",
    "TypeError\n",
    "If values is a string\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.isin\n",
    "Equivalent method on DataFrame. \"\"\"\n",
    "s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama',\n",
    "               'hippo'], name='animal')\n",
    "s.isin(['cow', 'llama'])\n",
    "\n",
    "# o invert the boolean values, use the ~ operator:\n",
    "\n",
    "~s.isin(['cow', 'llama'])\n",
    "\n",
    "# Passing a single string as s.isin('llama') will raise an error. Use a list of one element instead:\n",
    "\n",
    "s.isin(['llama'])\n",
    "# Strings and integers are distinct and are therefore not comparable:\n",
    "\n",
    "pd.Series([1]).isin(['1'])\n",
    "pd.Series([1.1]).isin(['1.1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.isin` method is used to check whether elements in a Series are contained in a specified sequence of values. It returns a boolean Series where `True` indicates that the element is present in the sequence, and `False` indicates that it is not. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.isin(values)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`values`** : `set` or `list-like`\n",
    "   - The sequence of values to test against the Series.\n",
    "   - If a single string is passed, it will raise a `TypeError`. Instead, pass a list containing the single string.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**:\n",
    "  - A boolean Series where each element indicates whether the corresponding element in the original Series is present in `values`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Raises**\n",
    "\n",
    "- **`TypeError`**:\n",
    "  - If `values` is a single string (instead of a list or set).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series(['llama', 'cow', 'llama', 'beetle', 'llama', 'hippo'], name='animal')\n",
    "\n",
    "# Check if elements are in the list ['cow', 'llama']\n",
    "result = s.isin(['cow', 'llama'])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     True\n",
    "1     True\n",
    "2     True\n",
    "3    False\n",
    "4     True\n",
    "5    False\n",
    "Name: animal, dtype: bool\n",
    "```\n",
    "\n",
    "- The elements `'llama'` and `'cow'` are present in the list, so their corresponding positions are marked as `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Inverting the Result\n",
    "\n",
    "You can use the `~` operator to invert the boolean values:\n",
    "\n",
    "```python\n",
    "# Invert the boolean values\n",
    "inverted_result = ~s.isin(['cow', 'llama'])\n",
    "print(inverted_result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    False\n",
    "1    False\n",
    "2    False\n",
    "3     True\n",
    "4    False\n",
    "5     True\n",
    "Name: animal, dtype: bool\n",
    "```\n",
    "\n",
    "- The elements not present in the list (`'beetle'` and `'hippo'`) are now marked as `True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Single String in `values`\n",
    "\n",
    "Passing a single string directly will raise a `TypeError`. Instead, use a list with a single element:\n",
    "\n",
    "```python\n",
    "# Check if elements are equal to 'llama'\n",
    "result = s.isin(['llama'])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4     True\n",
    "5    False\n",
    "Name: animal, dtype: bool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Comparing Numbers and Strings\n",
    "\n",
    "Strings and integers are distinct, so comparisons between them will return `False`:\n",
    "\n",
    "```python\n",
    "# Create a Series of integers\n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# Check if elements are in the list ['1', '2']\n",
    "result = s.isin(['1', '2'])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    False\n",
    "1    False\n",
    "2    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "- The integers `1` and `2` are not equal to the strings `'1'` and `'2'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using a Set for `values`\n",
    "\n",
    "You can also use a set for the `values` parameter:\n",
    "\n",
    "```python\n",
    "# Check if elements are in the set {'llama', 'cow'}\n",
    "result = s.isin({'llama', 'cow'})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     True\n",
    "1     True\n",
    "2     True\n",
    "3    False\n",
    "4     True\n",
    "5    False\n",
    "Name: animal, dtype: bool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.isin`**:\n",
    "\n",
    "   - Equivalent method for DataFrames. Checks if elements are contained in a sequence of values for each row or column.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.isin(['llama', 'cow'])\n",
    "     ```\n",
    "\n",
    "2. **`Series.str.contains`**:\n",
    "   - Checks if elements contain a substring or match a regex pattern.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.str.contains('ll')\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a dataset of animals and want to filter out only specific animals:\n",
    "\n",
    "```python\n",
    "# Filter the Series to include only 'llama' and 'cow'\n",
    "filtered_series = s[s.isin(['llama', 'cow'])]\n",
    "print(filtered_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    llama\n",
    "1      cow\n",
    "2    llama\n",
    "4    llama\n",
    "Name: animal, dtype: object\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `isin` method is case-sensitive. For case-insensitive comparisons, you can use `str.lower()` or `str.upper()`.\n",
    "- It is a powerful tool for filtering and subsetting data based on specific values.\n",
    "\n",
    "---\n",
    "\n",
    "By using `isin`, you can efficiently check for membership in a sequence and perform filtering operations on your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.last\n",
    "\n",
    "Series.last(offset)\n",
    "\n",
    "Select final periods of time series data based on a date offset.\n",
    "\n",
    "Deprecated since version 2.1: last() is deprecated and will be removed in a future version. Please create a mask and filter using .loc instead.\n",
    "\n",
    "For a DataFrame with a sorted DatetimeIndex, this function selects the last few rows based on a date offset.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "offset\n",
    "str, DateOffset, dateutil.relativedelta\n",
    "The offset length of the data that will be selected. For instance, ‘3D’ will display all the rows having their index within the last 3 days.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "A subset of the caller.\n",
    "\n",
    "Raises\n",
    ":\n",
    "TypeError\n",
    "If the index is not a DatetimeIndex\n",
    "\n",
    "See also\n",
    "\n",
    "first\n",
    "Select initial periods of time series based on a date offset.\n",
    "\n",
    "at_time\n",
    "Select values at a particular time of the day.\n",
    "\n",
    "between_time\n",
    "Select values between particular times of the day.\n",
    "\n",
    "Notes\n",
    "\n",
    "Deprecated since version 2.1.0: Please create a mask and filter using .loc instead \"\"\"\n",
    "\n",
    "i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
    "ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
    "ts\n",
    "# Get the rows for the last 3 days:\n",
    "\n",
    "ts.last('3D')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.last` method is used to select the **final periods** of time series data based on a date offset. It is particularly useful for filtering data from the end of a time series. However, **this method is deprecated starting from pandas version 2.1** and will be removed in a future version. The recommended approach is to use `.loc` with a mask for filtering.\n",
    "\n",
    "Below is a detailed explanation of the method, its parameters, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.last(offset)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`offset`** : `str`, `DateOffset`, or `dateutil.relativedelta`\n",
    "   - Specifies the offset length of the data to be selected.\n",
    "   - Examples:\n",
    "     - `'3D'` : Selects the last 3 calendar days.\n",
    "     - `'1ME'` : Selects the last month of data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - A subset of the original object containing the final periods of the time series based on the specified offset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Raises**\n",
    "\n",
    "- **`TypeError`**:\n",
    "  - If the index of the Series or DataFrame is not a `DatetimeIndex`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Deprecation Notice**\n",
    "\n",
    "- The `last` method is deprecated starting from pandas version 2.1.\n",
    "- The recommended alternative is to use `.loc` with a mask for filtering.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Using `last` with a Time Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a time series with a DatetimeIndex\n",
    "index = pd.date_range('2023-01-01', periods=6, freq='2D')\n",
    "ts = pd.Series([1, 2, 3, 4, 5, 6], index=index)\n",
    "\n",
    "print(\"Original Series:\")\n",
    "print(ts)\n",
    "\n",
    "# Select the last 3 days of data\n",
    "result = ts.last('3D')\n",
    "print(\"\\nLast 3 days of data:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original Series:\n",
    "2023-01-01    1\n",
    "2023-01-03    2\n",
    "2023-01-05    3\n",
    "2023-01-07    4\n",
    "2023-01-09    5\n",
    "2023-01-11    6\n",
    "Freq: 2D, dtype: int64\n",
    "\n",
    "Last 3 days of data:\n",
    "2023-01-09    5\n",
    "2023-01-11    6\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The `last('3D')` method selects data within the last 3 calendar days (`2023-01-09` to `2023-01-11`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Using `last` with a DataFrame\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with a DatetimeIndex\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, 5, 6]}, index=index)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Select the last 5 days of data\n",
    "result = df.last('5D')\n",
    "print(\"\\nLast 5 days of data:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "            A\n",
    "2023-01-01  1\n",
    "2023-01-03  2\n",
    "2023-01-05  3\n",
    "2023-01-07  4\n",
    "2023-01-09  5\n",
    "2023-01-11  6\n",
    "\n",
    "Last 5 days of data:\n",
    "            A\n",
    "2023-01-07  4\n",
    "2023-01-09  5\n",
    "2023-01-11  6\n",
    "```\n",
    "\n",
    "- The `last('5D')` method selects data within the last 5 calendar days (`2023-01-07` to `2023-01-11`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Recommended Alternative (Using `.loc`)**\n",
    "\n",
    "Since `last` is deprecated, you can achieve the same result using `.loc` with a mask.\n",
    "\n",
    "#### Example: Using `.loc` to Filter Data\n",
    "\n",
    "```python\n",
    "# Filter the last 3 days of data using .loc\n",
    "mask = ts.index >= ts.index[-1] - pd.Timedelta('3D')\n",
    "result = ts.loc[mask]\n",
    "\n",
    "print(\"Last 3 days of data (using .loc):\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Last 3 days of data (using .loc):\n",
    "2023-01-09    5\n",
    "2023-01-11    6\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`first`**:\n",
    "\n",
    "   - Selects the initial periods of time series data based on a date offset.\n",
    "   - Example:\n",
    "     ```python\n",
    "     ts.first('3D')\n",
    "     ```\n",
    "\n",
    "2. **`at_time`**:\n",
    "\n",
    "   - Selects values at a specific time of the day.\n",
    "   - Example:\n",
    "     ```python\n",
    "     ts.at_time('09:00')\n",
    "     ```\n",
    "\n",
    "3. **`between_time`**:\n",
    "   - Selects values between specific times of the day.\n",
    "   - Example:\n",
    "     ```python\n",
    "     ts.between_time('09:00', '12:00')\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `last` method is useful for quickly filtering time series data based on a date offset.\n",
    "- However, due to its deprecation, it is recommended to use `.loc` with a mask for filtering.\n",
    "- Ensure that the index of the Series or DataFrame is a `DatetimeIndex` before using this method.\n",
    "\n",
    "---\n",
    "\n",
    "By using the recommended `.loc` approach, you can achieve the same functionality in a more future-proof way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.reindex\n",
    "Series.reindex(index=None, *, axis=None, method=None, copy=None, level=None, fill_value=None, limit=None, tolerance=None)[source]\n",
    "Conform Series to new index with optional filling logic.\n",
    "\n",
    "Places NA/NaN in locations having no value in the previous index. A new object is produced unless the new index is equivalent to the current one and copy=False.\n",
    "\n",
    "Parameters:\n",
    "indexarray-like, optional\n",
    "New labels for the index. Preferably an Index object to avoid duplicating data.\n",
    "\n",
    "axisint or str, optional\n",
    "Unused.\n",
    "\n",
    "method{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}\n",
    "Method to use for filling holes in reindexed DataFrame. Please note: this is only applicable to DataFrames/Series with a monotonically increasing/decreasing index.\n",
    "\n",
    "None (default): don’t fill gaps\n",
    "\n",
    "pad / ffill: Propagate last valid observation forward to next valid.\n",
    "\n",
    "backfill / bfill: Use next valid observation to fill gap.\n",
    "\n",
    "nearest: Use nearest valid observations to fill gap.\n",
    "\n",
    "copybool, default True\n",
    "Return a new object, even if the passed indexes are the same.\n",
    "\n",
    "Note\n",
    "\n",
    "The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and ignore the copy keyword. The copy keyword will be removed in a future version of pandas.\n",
    "\n",
    "You can already get the future behavior and improvements through enabling copy on write pd.options.mode.copy_on_write = True\n",
    "\n",
    "levelint or name\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_valuescalar, default np.nan\n",
    "Value to use for missing values. Defaults to NaN, but can be any “compatible” value.\n",
    "\n",
    "limitint, default None\n",
    "Maximum number of consecutive elements to forward or backward fill.\n",
    "\n",
    "toleranceoptional\n",
    "Maximum distance between original and new labels for inexact matches. The values of the index at the matching locations most satisfy the equation abs(index[indexer] - target) <= tolerance.\n",
    "\n",
    "Tolerance may be a scalar value, which applies the same tolerance to all values, or list-like, which applies variable tolerance per element. List-like includes list, tuple, array, Series, and must be the same size as the index and its dtype must exactly match the index’s type.\n",
    "\n",
    "Returns:\n",
    "Series with changed index.\n",
    "See also\n",
    "\n",
    "DataFrame.set_index\n",
    "Set row labels.\n",
    "\n",
    "DataFrame.reset_index\n",
    "Remove row labels or move them to new columns.\n",
    "\n",
    "DataFrame.reindex_like\n",
    "Change to same indices as other DataFrame.\n",
    "\n",
    " \"\"\"\n",
    "index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
    "df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
    "                  'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
    "                  index=index)\n",
    "df\n",
    "new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
    "             'Chrome']\n",
    "df.reindex(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can fill in the missing values by passing a value to the keyword fill_value. Because the index is not monotonically increasing or decreasing, we cannot use arguments to the keyword method to fill the NaN values.\n",
    "\n",
    "df.reindex(new_index, fill_value=0)\n",
    "df.reindex(new_index, fill_value='missing')\n",
    "# We can also reindex the columns.\n",
    "\n",
    "df.reindex(columns=['http_status', 'user_agent'])\n",
    "\n",
    "# Or we can use “axis-style” keyword arguments\n",
    "\n",
    "df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
    "# To further illustrate the filling functionality in reindex, we will create a dataframe with a monotonically increasing index (for example, a sequence of dates).\n",
    "\n",
    "date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
    "df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
    "                   index=date_index)\n",
    "df2\n",
    "date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
    "df2.reindex(date_index2)\n",
    "df2.reindex(date_index2, method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.reindex` method is used to conform a Series to a new index. It allows you to change the index of a Series, optionally filling in missing values using various methods. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.reindex(index=None, *, axis=None, method=None, copy=None, level=None, fill_value=None, limit=None, tolerance=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`index`** : `array-like`, optional\n",
    "\n",
    "   - New labels for the index. Preferably an `Index` object to avoid duplicating data.\n",
    "\n",
    "2. **`axis`** : `int` or `str`, optional\n",
    "\n",
    "   - Unused for Series. Included for compatibility with DataFrame.\n",
    "\n",
    "3. **`method`** : `{None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}`, optional\n",
    "\n",
    "   - Method to use for filling holes in the reindexed Series:\n",
    "     - `None` (default): Do not fill gaps.\n",
    "     - `'pad'` or `'ffill'`: Propagate the last valid observation forward.\n",
    "     - `'backfill'` or `'bfill'`: Use the next valid observation to fill the gap.\n",
    "     - `'nearest'`: Use the nearest valid observation to fill the gap.\n",
    "\n",
    "4. **`copy`** : `bool`, default `True`\n",
    "\n",
    "   - If `True`, a new object is returned even if the new index is the same as the current one.\n",
    "   - **Note**: The behavior of `copy` will change in pandas 3.0 with the introduction of Copy-on-Write.\n",
    "\n",
    "5. **`level`** : `int` or `name`, optional\n",
    "\n",
    "   - Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "6. **`fill_value`** : `scalar`, default `np.nan`\n",
    "\n",
    "   - Value to use for missing values. Defaults to `NaN`.\n",
    "\n",
    "7. **`limit`** : `int`, default `None`\n",
    "\n",
    "   - Maximum number of consecutive elements to forward or backward fill.\n",
    "\n",
    "8. **`tolerance`** : optional\n",
    "   - Maximum distance between original and new labels for inexact matches.\n",
    "   - Can be a scalar value or list-like (e.g., list, tuple, array, Series).\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**:\n",
    "  - A new Series with the specified index. Missing values are filled according to the specified method or `fill_value`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Reindexing\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([10, 20, 30], index=['A', 'B', 'C'])\n",
    "\n",
    "# Reindex with new labels\n",
    "new_index = ['A', 'B', 'C', 'D']\n",
    "result = s.reindex(new_index)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "A    10.0\n",
    "B    20.0\n",
    "C    30.0\n",
    "D     NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- The new index `'D'` has no corresponding value, so it is filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Filling Missing Values\n",
    "\n",
    "```python\n",
    "# Reindex with a fill value\n",
    "result = s.reindex(new_index, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "A    10\n",
    "B    20\n",
    "C    30\n",
    "D     0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The missing value at `'D'` is filled with `0`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Forward Fill (`ffill`)\n",
    "\n",
    "```python\n",
    "# Create a Series with a monotonic index\n",
    "s = pd.Series([1, 2, 3], index=pd.date_range('2023-01-01', periods=3))\n",
    "\n",
    "# Reindex with a new index\n",
    "new_index = pd.date_range('2023-01-01', periods=5)\n",
    "result = s.reindex(new_index, method='ffill')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2023-01-01    1.0\n",
    "2023-01-02    2.0\n",
    "2023-01-03    3.0\n",
    "2023-01-04    3.0\n",
    "2023-01-05    3.0\n",
    "Freq: D, dtype: float64\n",
    "```\n",
    "\n",
    "- The last valid value (`3`) is propagated forward to fill the gaps.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Backward Fill (`bfill`)\n",
    "\n",
    "```python\n",
    "# Reindex with backward fill\n",
    "result = s.reindex(new_index, method='bfill')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2023-01-01    1.0\n",
    "2023-01-02    2.0\n",
    "2023-01-03    3.0\n",
    "2023-01-04    NaN\n",
    "2023-01-05    NaN\n",
    "Freq: D, dtype: float64\n",
    "```\n",
    "\n",
    "- The next valid value is used to fill gaps, but since there are no values after `2023-01-03`, the gaps remain `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `tolerance`\n",
    "\n",
    "```python\n",
    "# Reindex with tolerance\n",
    "result = s.reindex(new_index, method='ffill', tolerance=pd.Timedelta('1D'))\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2023-01-01    1.0\n",
    "2023-01-02    2.0\n",
    "2023-01-03    3.0\n",
    "2023-01-04    NaN\n",
    "2023-01-05    NaN\n",
    "Freq: D, dtype: float64\n",
    "```\n",
    "\n",
    "- The `tolerance` parameter limits the distance between the original and new labels for filling.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.reindex`**:\n",
    "\n",
    "   - Reindexes both rows and columns of a DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.reindex(index=new_index, columns=new_columns)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.reindex_like`**:\n",
    "\n",
    "   - Reindexes a DataFrame to match the index and columns of another DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df1.reindex_like(df2)\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.set_index`**:\n",
    "\n",
    "   - Sets the DataFrame index using existing columns.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.set_index('column_name')\n",
    "     ```\n",
    "\n",
    "4. **`DataFrame.reset_index`**:\n",
    "   - Resets the index, moving it into a column.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.reset_index()\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a time series with missing dates and want to reindex it to include all dates, filling missing values with `0`:\n",
    "\n",
    "```python\n",
    "# Create a time series with missing dates\n",
    "s = pd.Series([10, 20, 30], index=pd.to_datetime(['2023-01-01', '2023-01-03', '2023-01-05']))\n",
    "\n",
    "# Reindex to include all dates\n",
    "new_index = pd.date_range('2023-01-01', '2023-01-05')\n",
    "result = s.reindex(new_index, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2023-01-01    10\n",
    "2023-01-02     0\n",
    "2023-01-03    20\n",
    "2023-01-04     0\n",
    "2023-01-05    30\n",
    "Freq: D, dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `reindex` method is useful for aligning data to a new index, especially when working with time series or hierarchical data.\n",
    "- Use `fill_value` or `method` to handle missing values during reindexing.\n",
    "- For advanced use cases, consider using `tolerance` to control the filling logic.\n",
    "\n",
    "---\n",
    "\n",
    "By using `reindex`, you can easily align your data to a new index while handling missing values in a flexible way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.reindex_like\n",
    "Series.reindex_like(other, method=None, copy=None, limit=None, tolerance=None)[source]\n",
    "Return an object with matching indices as other object.\n",
    "\n",
    "Conform the object to the same index on all axes. Optional filling logic, placing NaN in locations having no value in the previous index. A new object is produced unless the new index is equivalent to the current one and copy=False.\n",
    "\n",
    "Parameters:\n",
    "otherObject of the same data type\n",
    "Its row and column indices are used to define the new indices of this object.\n",
    "\n",
    "method{None, ‘backfill’/’bfill’, ‘pad’/’ffill’, ‘nearest’}\n",
    "Method to use for filling holes in reindexed DataFrame. Please note: this is only applicable to DataFrames/Series with a monotonically increasing/decreasing index.\n",
    "\n",
    "None (default): don’t fill gaps\n",
    "\n",
    "pad / ffill: propagate last valid observation forward to next valid\n",
    "\n",
    "backfill / bfill: use next valid observation to fill gap\n",
    "\n",
    "nearest: use nearest valid observations to fill gap.\n",
    "\n",
    "copybool, default True\n",
    "Return a new object, even if the passed indexes are the same.\n",
    "\n",
    "Note\n",
    "\n",
    "The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and ignore the copy keyword. The copy keyword will be removed in a future version of pandas.\n",
    "\n",
    "You can already get the future behavior and improvements through enabling copy on write pd.options.mode.copy_on_write = True\n",
    "\n",
    "limitint, default None\n",
    "Maximum number of consecutive labels to fill for inexact matches.\n",
    "\n",
    "toleranceoptional\n",
    "Maximum distance between original and new labels for inexact matches. The values of the index at the matching locations must satisfy the equation abs(index[indexer] - target) <= tolerance.\n",
    "\n",
    "Tolerance may be a scalar value, which applies the same tolerance to all values, or list-like, which applies variable tolerance per element. List-like includes list, tuple, array, Series, and must be the same size as the index and its dtype must exactly match the index’s type.\n",
    "\n",
    "Returns:\n",
    "Series or DataFrame\n",
    "Same type as caller, but with changed indices on each axis.\n",
    "\n",
    "\n",
    "DataFrame.set_index\n",
    "Set row labels.\n",
    "\n",
    "DataFrame.reset_index\n",
    "Remove row labels or move them to new columns.\n",
    "\n",
    "DataFrame.reindex\n",
    "Change to new indices or expand indices.\n",
    "\n",
    "Notes\n",
    "\n",
    "Same as calling .reindex(index=other.index, columns=other.columns,...). \"\"\"\n",
    "df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
    "                    [31, 87.8, 'high'],\n",
    "                    [22, 71.6, 'medium'],\n",
    "                    [35, 95, 'medium']],\n",
    "                   columns=['temp_celsius', 'temp_fahrenheit',\n",
    "                            'windspeed'],\n",
    "                   index=pd.date_range(start='2014-02-12',\n",
    "                                       end='2014-02-15', freq='D'))\n",
    "df1\n",
    "df2 = pd.DataFrame([[28, 'low'],\n",
    "                    [30, 'low'],\n",
    "                    [35.1, 'medium']],\n",
    "                   columns=['temp_celsius', 'windspeed'],\n",
    "                   index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
    "                                           '2014-02-15']))\n",
    "df2\n",
    "df2.reindex_like(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.reindex_like` method is used to conform a Series or DataFrame to the **same index** as another object. It is a convenient way to align the indices of two objects, optionally filling in missing values using various methods. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.reindex_like(other, method=None, copy=None, limit=None, tolerance=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`** : `Series` or `DataFrame`\n",
    "\n",
    "   - The object whose index is used to define the new index of the current object.\n",
    "\n",
    "2. **`method`** : `{None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}`, optional\n",
    "\n",
    "   - Method to use for filling holes in the reindexed object:\n",
    "     - `None` (default): Do not fill gaps.\n",
    "     - `'pad'` or `'ffill'`: Propagate the last valid observation forward.\n",
    "     - `'backfill'` or `'bfill'`: Use the next valid observation to fill the gap.\n",
    "     - `'nearest'`: Use the nearest valid observation to fill the gap.\n",
    "\n",
    "3. **`copy`** : `bool`, default `True`\n",
    "\n",
    "   - If `True`, a new object is returned even if the new index is the same as the current one.\n",
    "   - **Note**: The behavior of `copy` will change in pandas 3.0 with the introduction of Copy-on-Write.\n",
    "\n",
    "4. **`limit`** : `int`, default `None`\n",
    "\n",
    "   - Maximum number of consecutive labels to fill for inexact matches.\n",
    "\n",
    "5. **`tolerance`** : optional\n",
    "   - Maximum distance between original and new labels for inexact matches.\n",
    "   - Can be a scalar value or list-like (e.g., list, tuple, array, Series).\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - A new object with the same index as `other`. Missing values are filled according to the specified method.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Reindexing a Series to Match Another Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create two Series with different indices\n",
    "s1 = pd.Series([10, 20, 30], index=['A', 'B', 'C'])\n",
    "s2 = pd.Series([40, 50], index=['A', 'D'])\n",
    "\n",
    "# Reindex s1 to match the index of s2\n",
    "result = s1.reindex_like(s2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "A    10.0\n",
    "D     NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- The index of `s1` is aligned to match the index of `s2`. Missing values are filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Reindexing a DataFrame to Match Another DataFrame\n",
    "\n",
    "```python\n",
    "# Create two DataFrames with different indices\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=['X', 'Y', 'Z'])\n",
    "df2 = pd.DataFrame({'A': [7, 8], 'B': [9, 10]}, index=['X', 'W'])\n",
    "\n",
    "# Reindex df1 to match the index of df2\n",
    "result = df1.reindex_like(df2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "X  1.0  4.0\n",
    "W  NaN  NaN\n",
    "```\n",
    "\n",
    "- The index of `df1` is aligned to match the index of `df2`. Missing values are filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Using `method` to Fill Missing Values\n",
    "\n",
    "```python\n",
    "# Create a Series with a monotonic index\n",
    "s1 = pd.Series([1, 2, 3], index=pd.date_range('2023-01-01', periods=3))\n",
    "s2 = pd.Series([], index=pd.date_range('2023-01-01', periods=5))\n",
    "\n",
    "# Reindex s1 to match the index of s2, using forward fill\n",
    "result = s1.reindex_like(s2, method='ffill')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2023-01-01    1.0\n",
    "2023-01-02    2.0\n",
    "2023-01-03    3.0\n",
    "2023-01-04    3.0\n",
    "2023-01-05    3.0\n",
    "Freq: D, dtype: float64\n",
    "```\n",
    "\n",
    "- The last valid value (`3`) is propagated forward to fill the gaps.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Using `tolerance` for Inexact Matches\n",
    "\n",
    "```python\n",
    "# Reindex with tolerance\n",
    "result = s1.reindex_like(s2, method='ffill', tolerance=pd.Timedelta('1D'))\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2023-01-01    1.0\n",
    "2023-01-02    2.0\n",
    "2023-01-03    3.0\n",
    "2023-01-04    NaN\n",
    "2023-01-05    NaN\n",
    "Freq: D, dtype: float64\n",
    "```\n",
    "\n",
    "- The `tolerance` parameter limits the distance between the original and new labels for filling.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.reindex`**:\n",
    "\n",
    "   - Reindexes both rows and columns of a DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.reindex(index=new_index, columns=new_columns)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.set_index`**:\n",
    "\n",
    "   - Sets the DataFrame index using existing columns.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.set_index('column_name')\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.reset_index`**:\n",
    "   - Resets the index, moving it into a column.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.reset_index()\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have two datasets with different indices and want to align them for comparison or merging:\n",
    "\n",
    "```python\n",
    "# Create two DataFrames with different indices\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3]}, index=['X', 'Y', 'Z'])\n",
    "df2 = pd.DataFrame({'A': [4, 5]}, index=['X', 'W'])\n",
    "\n",
    "# Align df1 to match the index of df2\n",
    "aligned_df1 = df1.reindex_like(df2)\n",
    "print(aligned_df1)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A\n",
    "X  1.0\n",
    "W  NaN\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `reindex_like` method is useful for aligning data to the same index as another object.\n",
    "- Use `method` or `fill_value` to handle missing values during reindexing.\n",
    "- For advanced use cases, consider using `tolerance` to control the filling logic.\n",
    "\n",
    "---\n",
    "\n",
    "By using `reindex_like`, you can easily align your data to match the index of another object, making it a powerful tool for data alignment and comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rename\n",
    "Series.rename(index=None, *, axis=None, copy=None, inplace=False, level=None, errors='ignore')[source]\n",
    "Alter Series index labels or name.\n",
    "\n",
    "Function / dict values must be unique (1-to-1). Labels not contained in a dict / Series will be left as-is. Extra labels listed don’t throw an error.\n",
    "\n",
    "Alternatively, change Series.name with a scalar value.\n",
    "\n",
    "See the user guide for more.\n",
    "\n",
    "Parameters:\n",
    "indexscalar, hashable sequence, dict-like or function optional\n",
    "Functions or dict-like are transformations to apply to the index. Scalar or hashable sequence-like will alter the Series.name attribute.\n",
    "\n",
    "axis{0 or ‘index’}\n",
    "Unused. Parameter needed for compatibility with DataFrame.\n",
    "\n",
    "copybool, default True\n",
    "Also copy underlying data.\n",
    "\n",
    "Note\n",
    "\n",
    "The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and ignore the copy keyword. The copy keyword will be removed in a future version of pandas.\n",
    "\n",
    "You can already get the future behavior and improvements through enabling copy on write pd.options.mode.copy_on_write = True\n",
    "\n",
    "inplacebool, default False\n",
    "Whether to return a new Series. If True the value of copy is ignored.\n",
    "\n",
    "levelint or level name, default None\n",
    "In case of MultiIndex, only rename labels in the specified level.\n",
    "\n",
    "errors{‘ignore’, ‘raise’}, default ‘ignore’\n",
    "If ‘raise’, raise KeyError when a dict-like mapper or index contains labels that are not present in the index being transformed. If ‘ignore’, existing keys will be renamed and extra keys will be ignored.\n",
    "\n",
    "Returns:\n",
    "Series or None\n",
    "Series with index labels or name altered or None if inplace=True.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.rename\n",
    "Corresponding DataFrame method.\n",
    "\n",
    "Series.rename_axis\n",
    "Set the name of the axis. \"\"\"\n",
    "s = pd.Series([1, 2, 3])\n",
    "s\n",
    "s.rename(\"my_name\")  # scalar, changes Series.name\n",
    "s.rename(lambda x: x ** 2)  # function, changes labels\n",
    "s.rename({1: 3, 2: 5})  # mapping, changes labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.rename` method is used to alter the **index labels** or the **name** of a Series. It provides flexibility in renaming by allowing you to use a scalar, function, or dictionary-like object to transform the index labels or the Series name. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rename(index=None, *, axis=None, copy=None, inplace=False, level=None, errors='ignore')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`index`** : `scalar`, `hashable sequence`, `dict-like`, or `function`, optional\n",
    "\n",
    "   - Specifies how to rename the index labels or the Series name:\n",
    "     - **Scalar or hashable sequence**: Changes the `Series.name` attribute.\n",
    "     - **Function**: Applies a transformation to the index labels.\n",
    "     - **Dict-like**: Maps old labels to new labels.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index'}`\n",
    "\n",
    "   - Unused for Series. Included for compatibility with DataFrame.\n",
    "\n",
    "3. **`copy`** : `bool`, default `True`\n",
    "\n",
    "   - If `True`, a copy of the underlying data is made.\n",
    "   - **Note**: The behavior of `copy` will change in pandas 3.0 with the introduction of Copy-on-Write.\n",
    "\n",
    "4. **`inplace`** : `bool`, default `False`\n",
    "\n",
    "   - If `True`, the operation is performed in place (i.e., the original Series is modified), and the method returns `None`.\n",
    "\n",
    "5. **`level`** : `int` or `level name`, default `None`\n",
    "\n",
    "   - For MultiIndex, specifies the level to rename.\n",
    "\n",
    "6. **`errors`** : `{'ignore', 'raise'}`, default `'ignore'`\n",
    "   - If `'raise'`, a `KeyError` is raised when a dict-like mapper or index contains labels not present in the Series.\n",
    "   - If `'ignore'`, extra keys are ignored.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series or None**:\n",
    "  - A new Series with the renamed index labels or name, or `None` if `inplace=True`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Renaming the Series Name\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# Rename the Series\n",
    "renamed_s = s.rename(\"my_series\")\n",
    "print(renamed_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "Name: my_series, dtype: int64\n",
    "```\n",
    "\n",
    "- The `Series.name` attribute is changed to `\"my_series\"`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Renaming Index Labels Using a Function\n",
    "\n",
    "```python\n",
    "# Rename index labels using a function\n",
    "renamed_s = s.rename(lambda x: x ** 2)\n",
    "print(renamed_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "4    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The index labels are transformed using the function `lambda x: x ** 2`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Renaming Index Labels Using a Dictionary\n",
    "\n",
    "```python\n",
    "# Rename index labels using a dictionary\n",
    "renamed_s = s.rename({0: 'a', 1: 'b', 2: 'c'})\n",
    "print(renamed_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1\n",
    "b    2\n",
    "c    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The index labels are mapped using the dictionary `{0: 'a', 1: 'b', 2: 'c'}`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Renaming with `errors='raise'`\n",
    "\n",
    "```python\n",
    "# Attempt to rename with a dictionary containing invalid keys\n",
    "try:\n",
    "    renamed_s = s.rename({0: 'a', 1: 'b', 3: 'c'}, errors='raise')\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "\"[3] not found in axis\"\n",
    "```\n",
    "\n",
    "- A `KeyError` is raised because the key `3` is not present in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Renaming in Place\n",
    "\n",
    "```python\n",
    "# Rename the Series in place\n",
    "s.rename(\"new_name\", inplace=True)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "Name: new_name, dtype: int64\n",
    "```\n",
    "\n",
    "- The `Series.name` is updated in place.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.rename`**:\n",
    "\n",
    "   - Renames the index, columns, or both of a DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.rename(columns={'old_name': 'new_name'})\n",
    "     ```\n",
    "\n",
    "2. **`Series.rename_axis`**:\n",
    "   - Sets the name of the index or columns axis.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.rename_axis(\"index_name\")\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a Series representing sales data and want to rename the index labels for better readability:\n",
    "\n",
    "```python\n",
    "# Create a Series with default integer index\n",
    "sales = pd.Series([100, 200, 300])\n",
    "\n",
    "# Rename the index labels\n",
    "sales = sales.rename({0: 'Q1', 1: 'Q2', 2: 'Q3'})\n",
    "print(sales)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Q1    100\n",
    "Q2    200\n",
    "Q3    300\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `rename` method is flexible and supports renaming using scalars, functions, or dictionary-like objects.\n",
    "- Use `inplace=True` to modify the Series in place.\n",
    "- For MultiIndex Series, use the `level` parameter to specify which level to rename.\n",
    "\n",
    "---\n",
    "\n",
    "By using `rename`, you can easily modify the index labels or the name of a Series to make your data more readable and meaningful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.rename_axis\n",
    "Series.rename_axis(mapper=<no_default>, *, index=<no_default>, axis=0, copy=True, inplace=False)[source]\n",
    "Set the name of the axis for the index or columns.\n",
    "\n",
    "Parameters:\n",
    "mapperscalar, list-like, optional\n",
    "Value to set the axis name attribute.\n",
    "\n",
    "index, columnsscalar, list-like, dict-like or function, optional\n",
    "A scalar, list-like, dict-like or functions transformations to apply to that axis’ values. Note that the columns parameter is not allowed if the object is a Series. This parameter only apply for DataFrame type objects.\n",
    "\n",
    "Use either mapper and axis to specify the axis to target with mapper, or index and/or columns.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "The axis to rename. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "copybool, default None\n",
    "Also copy underlying data.\n",
    "\n",
    "Note\n",
    "\n",
    "The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and ignore the copy keyword. The copy keyword will be removed in a future version of pandas.\n",
    "\n",
    "You can already get the future behavior and improvements through enabling copy on write pd.options.mode.copy_on_write = True\n",
    "\n",
    "inplacebool, default False\n",
    "Modifies the object directly, instead of creating a new Series or DataFrame.\n",
    "\n",
    "Returns:\n",
    "Series, DataFrame, or None\n",
    "The same type as the caller or None if inplace=True.\n",
    "\n",
    "\n",
    "Series.rename\n",
    "Alter Series index labels or name.\n",
    "\n",
    "DataFrame.rename\n",
    "Alter DataFrame index labels or name.\n",
    "\n",
    "Index.rename\n",
    "Set new names on index.\n",
    "\n",
    "Notes\n",
    "\n",
    "DataFrame.rename_axis supports two calling conventions\n",
    "\n",
    "(index=index_mapper, columns=columns_mapper, ...)\n",
    "\n",
    "(mapper, axis={'index', 'columns'}, ...)\n",
    "\n",
    "The first calling convention will only modify the names of the index and/or the names of the Index object that is the columns. In this case, the parameter copy is ignored.\n",
    "\n",
    "The second calling convention will modify the names of the corresponding index if mapper is a list or a scalar. However, if mapper is dict-like or a function, it will use the deprecated behavior of modifying the axis labels.\n",
    "\n",
    "We highly recommend using keyword arguments to clarify your intent.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Series\n",
    "\n",
    "import pandas as pd\n",
    "s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
    "s\n",
    "s.rename_axis(\"animal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame\n",
    "df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
    "                   \"num_arms\": [0, 0, 2]},\n",
    "                  [\"dog\", \"cat\", \"monkey\"])\n",
    "df\n",
    "df = df.rename_axis(\"animal\")\n",
    "df\n",
    "df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiIndex\n",
    "\n",
    "df.index = pd.MultiIndex.from_product([['mammal'],\n",
    "                                       ['dog', 'cat', 'monkey']],\n",
    "                                      names=['type', 'name'])\n",
    "df\n",
    "df.rename_axis(index={'type': 'class'})\n",
    "df.rename_axis(columns=str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.rename_axis` method is used to set or modify the **name of the axis** (index or columns) for a Series or DataFrame. It allows you to assign a name to the index or columns, making the data more readable and meaningful. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.rename_axis(mapper=<no_default>, *, index=<no_default>, axis=0, copy=True, inplace=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`mapper`** : `scalar`, `list-like`, optional\n",
    "\n",
    "   - Value to set as the name of the axis. This can be a string (for a single name) or a list-like object (for MultiIndex).\n",
    "\n",
    "2. **`index`** : `scalar`, `list-like`, `dict-like`, or `function`, optional\n",
    "\n",
    "   - Specifies the name or transformation for the index axis. Use this parameter to rename the index explicitly.\n",
    "\n",
    "3. **`axis`** : `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "   - The axis to rename. For Series, this parameter is unused and defaults to `0` (index).\n",
    "\n",
    "4. **`copy`** : `bool`, default `True`\n",
    "\n",
    "   - If `True`, a copy of the underlying data is made.\n",
    "   - **Note**: The behavior of `copy` will change in pandas 3.0 with the introduction of Copy-on-Write.\n",
    "\n",
    "5. **`inplace`** : `bool`, default `False`\n",
    "   - If `True`, the operation is performed in place (i.e., the original object is modified), and the method returns `None`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series, DataFrame, or None**:\n",
    "  - The same type as the caller (Series or DataFrame) with the updated axis name, or `None` if `inplace=True`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Renaming the Index Axis of a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
    "\n",
    "# Rename the index axis\n",
    "renamed_s = s.rename_axis(\"animal\")\n",
    "print(renamed_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "animal\n",
    "0       dog\n",
    "1       cat\n",
    "2    monkey\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "- The index axis is renamed to `\"animal\"`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Renaming the Index Axis in Place\n",
    "\n",
    "```python\n",
    "# Rename the index axis in place\n",
    "s.rename_axis(\"animal\", inplace=True)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "animal\n",
    "0       dog\n",
    "1       cat\n",
    "2    monkey\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "- The index axis is renamed in place.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Renaming the Columns Axis of a DataFrame\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"num_legs\": [4, 4, 2], \"num_arms\": [0, 0, 2]}, index=[\"dog\", \"cat\", \"monkey\"])\n",
    "\n",
    "# Rename the columns axis\n",
    "renamed_df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
    "print(renamed_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "limbs   num_legs  num_arms\n",
    "dog            4         0\n",
    "cat            4         0\n",
    "monkey         2         2\n",
    "```\n",
    "\n",
    "- The columns axis is renamed to `\"limbs\"`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Renaming MultiIndex Levels\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with a MultiIndex\n",
    "df.index = pd.MultiIndex.from_product([['mammal'], ['dog', 'cat', 'monkey']], names=['type', 'name'])\n",
    "\n",
    "# Rename a specific level of the MultiIndex\n",
    "renamed_df = df.rename_axis(index={'type': 'class'})\n",
    "print(renamed_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "limbs          num_legs  num_arms\n",
    "class  name\n",
    "mammal dog            4         0\n",
    "       cat            4         0\n",
    "       monkey         2         2\n",
    "```\n",
    "\n",
    "- The `'type'` level of the MultiIndex is renamed to `'class'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Renaming Columns with a Function\n",
    "\n",
    "```python\n",
    "# Rename columns using a function\n",
    "renamed_df = df.rename_axis(columns=str.upper)\n",
    "print(renamed_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "LIMBS          num_legs  num_arms\n",
    "type   name\n",
    "mammal dog            4         0\n",
    "       cat            4         0\n",
    "       monkey         2         2\n",
    "```\n",
    "\n",
    "- The columns axis is renamed using the `str.upper` function.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`Series.rename`**:\n",
    "\n",
    "   - Renames the index labels or the Series name.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.rename(\"new_name\")\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.rename`**:\n",
    "\n",
    "   - Renames the index, columns, or both of a DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.rename(columns={'old_name': 'new_name'})\n",
    "     ```\n",
    "\n",
    "3. **`Index.rename`**:\n",
    "   - Sets new names on an Index object.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.index.rename(\"new_index_name\")\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame representing sales data and want to rename the index and columns for better readability:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "sales = pd.DataFrame({\"Q1\": [100, 200], \"Q2\": [150, 250]}, index=[\"Region A\", \"Region B\"])\n",
    "\n",
    "# Rename the index and columns\n",
    "sales = sales.rename_axis(index=\"Region\", columns=\"Quarter\")\n",
    "print(sales)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Quarter     Q1   Q2\n",
    "Region\n",
    "Region A   100  150\n",
    "Region B   200  250\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `rename_axis` method is useful for setting or modifying the name of the index or columns axis.\n",
    "- For MultiIndex objects, you can rename specific levels using a dictionary.\n",
    "- Use `inplace=True` to modify the object directly.\n",
    "\n",
    "---\n",
    "\n",
    "By using `rename_axis`, you can make your data more readable and organized by assigning meaningful names to the index and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.reset_index\n",
    "Series.reset_index(level=None, *, drop=False, name=<no_default>, inplace=False, allow_duplicates=False)[source]\n",
    "Generate a new DataFrame or Series with the index reset.\n",
    "\n",
    "This is useful when the index needs to be treated as a column, or when the index is meaningless and needs to be reset to the default before another operation.\n",
    "\n",
    "Parameters:\n",
    "levelint, str, tuple, or list, default optional\n",
    "For a Series with a MultiIndex, only remove the specified levels from the index. Removes all levels by default.\n",
    "\n",
    "dropbool, default False\n",
    "Just reset the index, without inserting it as a column in the new DataFrame.\n",
    "\n",
    "nameobject, optional\n",
    "The name to use for the column containing the original Series values. Uses self.name by default. This argument is ignored when drop is True.\n",
    "\n",
    "inplacebool, default False\n",
    "Modify the Series in place (do not create a new object).\n",
    "\n",
    "allow_duplicatesbool, default False\n",
    "Allow duplicate column labels to be created.\n",
    "\n",
    "Added in version 1.5.0.\n",
    "\n",
    "Returns:\n",
    "Series or DataFrame or None\n",
    "When drop is False (the default), a DataFrame is returned. The newly created columns will come first in the DataFrame, followed by the original Series values. When drop is True, a Series is returned. In either case, if inplace=True, no value is returned.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.reset_index\n",
    "Analogous function for DataFrame. \"\"\"\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4], name='foo',\n",
    "              index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n",
    "# Generate a DataFrame with default index.\n",
    "\n",
    "s.reset_index()\n",
    "# To specify the name of the new column use name.\n",
    "\n",
    "s.reset_index(name='values')\n",
    "# To generate a new Series with the default set drop to True.\n",
    "\n",
    "s.reset_index(drop=True)\n",
    "# The level parameter is interesting for Series with a multi-level index.\n",
    "\n",
    "arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n",
    "          np.array(['one', 'two', 'one', 'two'])]\n",
    "s2 = pd.Series(\n",
    "    range(4), name='foo',\n",
    "    index=pd.MultiIndex.from_arrays(arrays,\n",
    "                                    names=['a', 'b']) )\n",
    "# To remove a specific level from the Index, use level. \n",
    "\n",
    "s2.reset_index(level='a')\n",
    "\n",
    "# If level is not set, all levels are removed from the Index.\n",
    "\n",
    "s2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.reset_index` method is used to reset the index of a Series, optionally turning the index into a column. This is particularly useful when the index needs to be treated as a column or when the index is meaningless and needs to be reset to the default integer index. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.reset_index(level=None, *, drop=False, name=<no_default>, inplace=False, allow_duplicates=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`level`** : `int`, `str`, `tuple`, or `list`, optional\n",
    "\n",
    "   - For a Series with a MultiIndex, specifies which levels of the index to reset. By default, all levels are reset.\n",
    "\n",
    "2. **`drop`** : `bool`, default `False`\n",
    "\n",
    "   - If `True`, the index is reset without being added as a column in the resulting DataFrame.\n",
    "   - If `False`, the index is added as a column in the resulting DataFrame.\n",
    "\n",
    "3. **`name`** : `object`, optional\n",
    "\n",
    "   - The name to use for the column containing the original Series values. If not provided, the Series name (`self.name`) is used.\n",
    "   - This parameter is ignored if `drop=True`.\n",
    "\n",
    "4. **`inplace`** : `bool`, default `False`\n",
    "\n",
    "   - If `True`, the operation is performed in place (i.e., the original Series is modified), and the method returns `None`.\n",
    "\n",
    "5. **`allow_duplicates`** : `bool`, default `False`\n",
    "   - If `True`, allows duplicate column labels to be created in the resulting DataFrame.\n",
    "   - Added in pandas version 1.5.0.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series, DataFrame, or None**:\n",
    "  - If `drop=False` (default), a **DataFrame** is returned with the index reset and the original index added as a column.\n",
    "  - If `drop=True`, a **Series** is returned with the index reset to the default integer index.\n",
    "  - If `inplace=True`, the method returns `None`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Resetting the Index (Default Behavior)\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series with a custom index\n",
    "s = pd.Series([1, 2, 3, 4], name='foo', index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n",
    "\n",
    "# Reset the index\n",
    "result = s.reset_index()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "  idx  foo\n",
    "0   a    1\n",
    "1   b    2\n",
    "2   c    3\n",
    "3   d    4\n",
    "```\n",
    "\n",
    "- The index is reset, and the original index is added as a column named `'idx'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Resetting the Index with `drop=True`\n",
    "\n",
    "```python\n",
    "# Reset the index without adding it as a column\n",
    "result = s.reset_index(drop=True)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "3    4\n",
    "Name: foo, dtype: int64\n",
    "```\n",
    "\n",
    "- The index is reset to the default integer index, and the original index is not added as a column.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Specifying a Name for the Value Column\n",
    "\n",
    "```python\n",
    "# Reset the index and specify a name for the value column\n",
    "result = s.reset_index(name='values')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "  idx  values\n",
    "0   a       1\n",
    "1   b       2\n",
    "2   c       3\n",
    "3   d       4\n",
    "```\n",
    "\n",
    "- The value column is renamed to `'values'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Resetting a MultiIndex\n",
    "\n",
    "```python\n",
    "# Create a Series with a MultiIndex\n",
    "arrays = [['bar', 'bar', 'baz', 'baz'], ['one', 'two', 'one', 'two']]\n",
    "s2 = pd.Series(range(4), name='foo', index=pd.MultiIndex.from_arrays(arrays, names=['a', 'b']))\n",
    "\n",
    "# Reset a specific level of the MultiIndex\n",
    "result = s2.reset_index(level='a')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       a  foo\n",
    "b\n",
    "one  bar    0\n",
    "two  bar    1\n",
    "one  baz    2\n",
    "two  baz    3\n",
    "```\n",
    "\n",
    "- Only the `'a'` level of the MultiIndex is reset and added as a column.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Resetting All Levels of a MultiIndex\n",
    "\n",
    "```python\n",
    "# Reset all levels of the MultiIndex\n",
    "result = s2.reset_index()\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     a    b  foo\n",
    "0  bar  one    0\n",
    "1  bar  two    1\n",
    "2  baz  one    2\n",
    "3  baz  two    3\n",
    "```\n",
    "\n",
    "- All levels of the MultiIndex are reset and added as columns.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 6: Inplace Reset\n",
    "\n",
    "```python\n",
    "# Reset the index in place\n",
    "s2.reset_index(inplace=True)\n",
    "print(s2)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     a    b  foo\n",
    "0  bar  one    0\n",
    "1  bar  two    1\n",
    "2  baz  one    2\n",
    "3  baz  two    3\n",
    "```\n",
    "\n",
    "- The Series is modified in place, and the index is reset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.reset_index`**:\n",
    "\n",
    "   - Resets the index of a DataFrame, optionally turning the index into columns.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.reset_index()\n",
    "     ```\n",
    "\n",
    "2. **`Series.set_index`**:\n",
    "\n",
    "   - Sets the Series index using existing columns.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.set_index('column_name')\n",
    "     ```\n",
    "\n",
    "3. **`Series.rename`**:\n",
    "   - Renames the index labels or the Series name.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.rename(\"new_name\")\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a Series representing sales data with a custom index and want to reset the index for further analysis:\n",
    "\n",
    "```python\n",
    "# Create a Series with a custom index\n",
    "sales = pd.Series([100, 200, 150, 250], index=['Q1', 'Q2', 'Q3', 'Q4'], name='sales')\n",
    "\n",
    "# Reset the index and add it as a column\n",
    "sales_df = sales.reset_index()\n",
    "print(sales_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "  index  sales\n",
    "0    Q1    100\n",
    "1    Q2    200\n",
    "2    Q3    150\n",
    "3    Q4    250\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `reset_index` method is useful for converting the index into a column or resetting it to the default integer index.\n",
    "- Use `drop=True` if you want to discard the original index.\n",
    "- For MultiIndex Series, use the `level` parameter to control which levels are reset.\n",
    "\n",
    "---\n",
    "\n",
    "By using `reset_index`, you can easily manipulate the index of a Series to suit your data analysis needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.sample\n",
    "Series.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)\n",
    "Return a random sample of items from an axis of object.\n",
    "\n",
    "You can use random_state for reproducibility.\n",
    "\n",
    "Parameters:\n",
    "nint, optional\n",
    "Number of items from axis to return. Cannot be used with frac. Default = 1 if frac = None.\n",
    "\n",
    "fracfloat, optional\n",
    "Fraction of axis items to return. Cannot be used with n.\n",
    "\n",
    "replacebool, default False\n",
    "Allow or disallow sampling of the same row more than once.\n",
    "\n",
    "weightsstr or ndarray-like, optional\n",
    "Default ‘None’ results in equal probability weighting. If passed a Series, will align with target object on index. Index values in weights not found in sampled object will be ignored and index values in sampled object not in weights will be assigned weights of zero. If called on a DataFrame, will accept the name of a column when axis = 0. Unless weights are a Series, weights must be same length as axis being sampled. If weights do not sum to 1, they will be normalized to sum to 1. Missing values in the weights column will be treated as zero. Infinite values not allowed.\n",
    "\n",
    "random_stateint, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
    "If int, array-like, or BitGenerator, seed for random number generator. If np.random.RandomState or np.random.Generator, use as given.\n",
    "\n",
    "Changed in version 1.4.0: np.random.Generator objects now accepted\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’, None}, default None\n",
    "Axis to sample. Accepts axis number or name. Default is stat axis for given data type. For Series this parameter is unused and defaults to None.\n",
    "\n",
    "ignore_indexbool, default False\n",
    "If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
    "\n",
    "Added in version 1.3.0.\n",
    "\n",
    "Returns:\n",
    "Series or DataFrame\n",
    "A new object of same type as caller containing n items randomly sampled from the caller object.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrameGroupBy.sample\n",
    "Generates random samples from each group of a DataFrame object.\n",
    "\n",
    "SeriesGroupBy.sample\n",
    "Generates random samples from each group of a Series object.\n",
    "\n",
    "numpy.random.choice\n",
    "Generates a random sample from a given 1-D numpy array.\n",
    "\n",
    "Notes\n",
    "\n",
    "If frac > 1, replacement should be set to True. \"\"\"\n",
    "df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
    "                   'num_wings': [2, 0, 0, 0],\n",
    "                   'num_specimen_seen': [10, 2, 1, 8]},\n",
    "                  index=['falcon', 'dog', 'spider', 'fish'])\n",
    "df\n",
    "# Extract 3 random elements from the Series df['num_legs']\n",
    "df['num_legs'].sample(n=3, random_state=1)\n",
    "df.sample(frac=0.5, replace=True, random_state=1)\n",
    "df.sample(frac=2, replace=True, random_state=1)\n",
    "df.sample(n=2, weights='num_specimen_seen', random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.sample` method is used to return a random sample of items from a Series. It is useful for tasks like random sampling, bootstrapping, or creating training/test datasets. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`n`** : `int`, optional\n",
    "\n",
    "   - Number of items to return. Cannot be used with `frac`.\n",
    "   - Default is `1` if `frac` is `None`.\n",
    "\n",
    "2. **`frac`** : `float`, optional\n",
    "\n",
    "   - Fraction of items to return. For example, `frac=0.5` returns 50% of the items.\n",
    "   - Cannot be used with `n`.\n",
    "\n",
    "3. **`replace`** : `bool`, default `False`\n",
    "\n",
    "   - If `True`, sampling is done with replacement (i.e., the same item can be sampled more than once).\n",
    "   - If `False`, sampling is done without replacement.\n",
    "\n",
    "4. **`weights`** : `str` or `ndarray-like`, optional\n",
    "\n",
    "   - Weights for each item in the Series. Items with higher weights are more likely to be sampled.\n",
    "   - If a string is passed, it is interpreted as a column name (for DataFrames).\n",
    "   - Weights are automatically normalized to sum to 1.\n",
    "\n",
    "5. **`random_state`** : `int`, `array-like`, `BitGenerator`, `np.random.RandomState`, or `np.random.Generator`, optional\n",
    "\n",
    "   - Seed for the random number generator to ensure reproducibility.\n",
    "   - If an integer or array-like is passed, it is used as a seed.\n",
    "   - If a `RandomState` or `Generator` object is passed, it is used directly.\n",
    "\n",
    "6. **`axis`** : `{0 or 'index', 1 or 'columns', None}`, default `None`\n",
    "\n",
    "   - Axis to sample. For Series, this parameter is unused and defaults to `None`.\n",
    "\n",
    "7. **`ignore_index`** : `bool`, default `False`\n",
    "   - If `True`, the resulting index is labeled `0, 1, ..., n-1`.\n",
    "   - Added in pandas version 1.3.0.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**:\n",
    "  - A new Series containing the randomly sampled items.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Random Sampling\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([10, 20, 30, 40, 50])\n",
    "\n",
    "# Randomly sample 3 items\n",
    "sampled_s = s.sample(n=3, random_state=1)\n",
    "print(sampled_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "1    20\n",
    "4    50\n",
    "0    10\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The method returns 3 randomly sampled items.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Sampling with Replacement\n",
    "\n",
    "```python\n",
    "# Randomly sample 5 items with replacement\n",
    "sampled_s = s.sample(n=5, replace=True, random_state=1)\n",
    "print(sampled_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "1    20\n",
    "4    50\n",
    "0    10\n",
    "3    40\n",
    "1    20\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The same item (`20`) is sampled more than once because `replace=True`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Sampling a Fraction of Items\n",
    "\n",
    "```python\n",
    "# Randomly sample 50% of the items\n",
    "sampled_s = s.sample(frac=0.5, random_state=1)\n",
    "print(sampled_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "1    20\n",
    "4    50\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The method returns 50% of the items (rounded down).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Sampling with Weights\n",
    "\n",
    "```python\n",
    "# Randomly sample 2 items with weights\n",
    "weights = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "sampled_s = s.sample(n=2, weights=weights, random_state=1)\n",
    "print(sampled_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2    30\n",
    "4    50\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Items with higher weights are more likely to be sampled.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Sampling with `ignore_index`\n",
    "\n",
    "```python\n",
    "# Randomly sample 3 items and reset the index\n",
    "sampled_s = s.sample(n=3, random_state=1, ignore_index=True)\n",
    "print(sampled_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    20\n",
    "1    50\n",
    "2    10\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The index is reset to `0, 1, 2`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.sample`**:\n",
    "\n",
    "   - Randomly samples rows or columns from a DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.sample(n=5)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrameGroupBy.sample`**:\n",
    "\n",
    "   - Randomly samples from each group of a DataFrame.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.groupby('column').sample(n=2)\n",
    "     ```\n",
    "\n",
    "3. **`SeriesGroupBy.sample`**:\n",
    "\n",
    "   - Randomly samples from each group of a Series.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.groupby(level=0).sample(n=2)\n",
    "     ```\n",
    "\n",
    "4. **`numpy.random.choice`**:\n",
    "   - Randomly samples from a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.set_axis\n",
    "Series.set_axis(labels, *, axis=0, copy=None)[source]\n",
    "Assign desired index to given axis.\n",
    "\n",
    "Indexes for row labels can be changed by assigning a list-like or Index.\n",
    "\n",
    "Parameters:\n",
    "labelslist-like, Index\n",
    "The values for the new index.\n",
    "\n",
    "axis{0 or ‘index’}, default 0\n",
    "The axis to update. The value 0 identifies the rows. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "copybool, default True\n",
    "Whether to make a copy of the underlying data.\n",
    "\n",
    "Note\n",
    "\n",
    "The copy keyword will change behavior in pandas 3.0. Copy-on-Write will be enabled by default, which means that all methods with a copy keyword will use a lazy copy mechanism to defer the copy and ignore the copy keyword. The copy keyword will be removed in a future version of pandas.\n",
    "\n",
    "You can already get the future behavior and improvements through enabling copy on write pd.options.mode.copy_on_write = True\n",
    "\n",
    "Returns:\n",
    "Series\n",
    "An object of type Series.\n",
    "\n",
    "\n",
    "Series.rename_axis\n",
    "Alter the name of the index. \"\"\"\n",
    "\n",
    "s = pd.Series([1, 2, 3])\n",
    "s\n",
    "s.set_axis(['a', 'b', 'c'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.set_axis` method is used to assign a new index to a Series. It allows you to replace the existing index with a new set of labels. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.set_axis(labels, *, axis=0, copy=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`labels`** : `list-like` or `Index`\n",
    "\n",
    "   - The new index labels to assign to the Series.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index'}`, default `0`\n",
    "\n",
    "   - The axis to update. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "3. **`copy`** : `bool`, default `True`\n",
    "   - If `True`, a copy of the underlying data is made.\n",
    "   - **Note**: The behavior of `copy` will change in pandas 3.0 with the introduction of Copy-on-Write.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**:\n",
    "  - A new Series with the updated index.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# Set a new index\n",
    "new_s = s.set_axis(['a', 'b', 'c'])\n",
    "print(new_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1\n",
    "b    2\n",
    "c    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The index is updated to `['a', 'b', 'c']`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Inplace Modification\n",
    "\n",
    "```python\n",
    "# Set a new index in place\n",
    "s.set_axis(['a', 'b', 'c'], inplace=True)\n",
    "print(s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1\n",
    "b    2\n",
    "c    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The index is updated in place.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Using `copy=False`\n",
    "\n",
    "```python\n",
    "# Set a new index without copying the data\n",
    "new_s = s.set_axis(['x', 'y', 'z'], copy=False)\n",
    "print(new_s)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "x    1\n",
    "y    2\n",
    "z    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The index is updated, and the data is not copied.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`Series.rename_axis`**:\n",
    "\n",
    "   - Sets the name of the index or columns axis.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.rename_axis(\"index_name\")\n",
    "     ```\n",
    "\n",
    "2. **`Series.rename`**:\n",
    "\n",
    "   - Renames the index labels or the Series name.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.rename({0: 'a', 1: 'b', 2: 'c'})\n",
    "     ```\n",
    "\n",
    "3. **`Series.reset_index`**:\n",
    "   - Resets the index, optionally turning it into a column.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.reset_index()\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a Series with a default integer index and want to assign meaningful labels:\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "sales = pd.Series([100, 200, 150, 250], index=[0, 1, 2, 3])\n",
    "\n",
    "# Set a new index with meaningful labels\n",
    "sales = sales.set_axis(['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "print(sales)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Q1    100\n",
    "Q2    200\n",
    "Q3    150\n",
    "Q4    250\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `set_axis` method is useful for replacing the index of a Series with a new set of labels.\n",
    "- Use `inplace=True` to modify the Series in place.\n",
    "- For MultiIndex Series, you can use `set_axis` to update specific levels of the index.\n",
    "\n",
    "---\n",
    "\n",
    "By using `set_axis`, you can easily update the index of a Series to make your data more meaningful and organized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.take\n",
    "Series.take(indices, axis=0, **kwargs)[source]\n",
    "Return the elements in the given positional indices along an axis.\n",
    "\n",
    "This means that we are not indexing according to actual values in the index attribute of the object. We are indexing according to the actual position of the element in the object.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "indices\n",
    "array-like\n",
    "An array of ints indicating which positions to take.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
    "The axis on which to select elements. 0 means that we are selecting rows, 1 means that we are selecting columns. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "**kwargs\n",
    "For compatibility with numpy.take(). Has no effect on the output.\n",
    "\n",
    "Returns\n",
    ":\n",
    "same type as caller\n",
    "An array-like containing the elements taken from the object.\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.loc\n",
    "Select a subset of a DataFrame by labels.\n",
    "\n",
    "DataFrame.iloc\n",
    "Select a subset of a DataFrame by positions.\n",
    "\n",
    "numpy.take\n",
    "Take elements from an array along an axis. \"\"\"\n",
    "df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
    "                   ('parrot', 'bird', 24.0),\n",
    "                   ('lion', 'mammal', 80.5),\n",
    "                   ('monkey', 'mammal', np.nan)],\n",
    "                  columns=['name', 'class', 'max_speed'],\n",
    "                  index=[0, 2, 3, 1])\n",
    "df\n",
    "df.take([0, 3])\n",
    "df.take([1, 2], axis=1)\n",
    "df.take([-1, -2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.Series.take` method is used to return elements from a Series based on their **positional indices** (not the actual index labels). This is useful when you want to select elements by their position in the Series, regardless of their index values. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "Series.take(indices, axis=0, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`indices`** : `array-like`\n",
    "\n",
    "   - A list or array of integers indicating the positions of the elements to select.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index', 1 or 'columns', None}`, default `0`\n",
    "\n",
    "   - The axis along which to select elements. For Series, this parameter is unused and defaults to `0`.\n",
    "\n",
    "3. **`**kwargs`\\*\\*:\n",
    "   - For compatibility with `numpy.take()`. Has no effect on the output.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**:\n",
    "  - A new Series containing the elements at the specified positions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Take elements at positions 0 and 2\n",
    "result = s.take([0, 2])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    10\n",
    "c    30\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- The elements at positions `0` and `2` are selected, regardless of their index labels.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Using Negative Indices\n",
    "\n",
    "```python\n",
    "# Take elements at positions -1 and -2 (last and second-to-last)\n",
    "result = s.take([-1, -2])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "d    40\n",
    "c    30\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Negative indices count from the end of the Series.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Using `take` with a DataFrame\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['falcon', 'parrot', 'lion', 'monkey'],\n",
    "    'class': ['bird', 'bird', 'mammal', 'mammal'],\n",
    "    'max_speed': [389.0, 24.0, 80.5, None]\n",
    "})\n",
    "\n",
    "# Take rows at positions 0 and 3\n",
    "result = df.take([0, 3])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     name   class  max_speed\n",
    "0  falcon    bird      389.0\n",
    "3  monkey  mammal        NaN\n",
    "```\n",
    "\n",
    "- The rows at positions `0` and `3` are selected.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Taking Columns\n",
    "\n",
    "```python\n",
    "# Take columns at positions 1 and 2\n",
    "result = df.take([1, 2], axis=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    class  max_speed\n",
    "0    bird      389.0\n",
    "1    bird       24.0\n",
    "2  mammal       80.5\n",
    "3  mammal        NaN\n",
    "```\n",
    "\n",
    "- The columns at positions `1` and `2` are selected.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`Series.iloc`**:\n",
    "\n",
    "   - Selects elements by their integer position.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.iloc[[0, 2]]\n",
    "     ```\n",
    "\n",
    "2. **`Series.loc`**:\n",
    "\n",
    "   - Selects elements by their index labels.\n",
    "   - Example:\n",
    "     ```python\n",
    "     s.loc[['a', 'c']]\n",
    "     ```\n",
    "\n",
    "3. **`numpy.take`**:\n",
    "   - Takes elements from an array along an axis.\n",
    "   - Example:\n",
    "     ```python\n",
    "     import numpy as np\n",
    "     np.take(s.values, [0, 2])\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a Series and want to select specific elements by their positions:\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "data = pd.Series([100, 200, 300, 400, 500], index=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "# Select elements at positions 1, 3, and 4\n",
    "selected_data = data.take([1, 3, 4])\n",
    "print(selected_data)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "B    200\n",
    "D    400\n",
    "E    500\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `take` method is useful for selecting elements by their position, regardless of their index labels.\n",
    "- Negative indices can be used to count positions from the end of the Series.\n",
    "- For DataFrames, you can use `axis=1` to select columns by their position.\n",
    "\n",
    "---\n",
    "\n",
    "By using `take`, you can easily extract elements from a Series or DataFrame based on their positional indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.Series.tail\n",
    "Series.tail(n=5)[source]\n",
    "Return the last n rows.\n",
    "\n",
    "This function returns last n rows from the object based on position. It is useful for quickly verifying data, for example, after sorting or appending rows.\n",
    "\n",
    "For negative values of n, this function returns all rows except the first |n| rows, equivalent to df[|n|:].\n",
    "\n",
    "If n is larger than the number of rows, this function returns all rows.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "n\n",
    "int, default 5\n",
    "Number of rows to select.\n",
    "\n",
    "Returns\n",
    ":\n",
    "type of caller\n",
    "The last n rows of the caller object.\n",
    "\n",
    "DataFrame.head\n",
    "The first n rows of the caller object.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "                   'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    "df\n",
    "\n",
    "# Viewing the last 5 lines\n",
    "\n",
    "df.tail()\n",
    "\n",
    "# Viewing the last n lines (three in this case)\n",
    "\n",
    "df.tail(3)\n",
    "\n",
    "# For negative values of n\n",
    "\n",
    "df.tail(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.DataFrame.xs\n",
    "DataFrame.xs(key, axis=0, level=None, drop_level=True)[source]\n",
    "Return cross-section from the Series/DataFrame.\n",
    "\n",
    "This method takes a key argument to select data at a particular level of a MultiIndex.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "key\n",
    "label or tuple of label\n",
    "Label contained in the index, or partially in a MultiIndex.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Axis to retrieve cross-section on.\n",
    "\n",
    "level\n",
    "object, defaults to first n levels (n=1 or len(key))\n",
    "In case of a key partially contained in a MultiIndex, indicate which levels are used. Levels can be referred by label or position.\n",
    "\n",
    "drop_level\n",
    "bool, default True\n",
    "If False, returns object with same levels as self.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "Cross-section from the original Series or DataFrame corresponding to the selected index levels.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.loc\n",
    "Access a group of rows and columns by label(s) or a boolean array.\n",
    "\n",
    "DataFrame.iloc\n",
    "Purely integer-location based indexing for selection by position.\n",
    "\n",
    "Notes\n",
    "\n",
    "xs can not be used to set values.\n",
    "\n",
    "MultiIndex Slicers is a generic way to get/set values on any level or levels. It is a superset of xs functionality, see MultiIndex Slicers.\n",
    "\n",
    "Examples\n",
    "\n",
    "d = {'num_legs': [4, 4, 2, 2],\n",
    "'num_wings': [0, 0, 2, 2],\n",
    "'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
    "'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
    "'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.set_index(['class', 'animal', 'locomotion'])\n",
    "df\n",
    "num_legs num_wings\n",
    "class animal locomotion\n",
    "mammal cat walks 4 0\n",
    "dog walks 4 0\n",
    "bat flies 2 2\n",
    "bird penguin walks 2 2\n",
    "Get values at specified index\n",
    "\n",
    "df.xs('mammal')\n",
    "num_legs num_wings\n",
    "animal locomotion\n",
    "cat walks 4 0\n",
    "dog walks 4 0\n",
    "bat flies 2 2\n",
    "Get values at several indexes\n",
    "\n",
    "df.xs(('mammal', 'dog', 'walks'))\n",
    "num_legs 4\n",
    "num_wings 0\n",
    "Name: (mammal, dog, walks), dtype: int64\n",
    "Get values at specified index and level\n",
    "\n",
    "df.xs('cat', level=1)\n",
    "num_legs num_wings\n",
    "class locomotion\n",
    "mammal walks 4 0\n",
    "Get values at several indexes and levels\n",
    "\n",
    "df.xs(('bird', 'walks'),\n",
    "level=[0, 'locomotion'])\n",
    "num_legs num_wings\n",
    "animal\n",
    "penguin 2 2\n",
    "Get values at specified column and axis\n",
    "\n",
    "df.xs('num_wings', axis=1)\n",
    "class animal locomotion\n",
    "mammal cat walks 0\n",
    "dog walks 0\n",
    "bat flies 2\n",
    "bird penguin walks 2\n",
    "Name: num_wings, dtype: int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.xs\n",
    "DataFrame.xs(key, axis=0, level=None, drop_level=True)[source]\n",
    "Return cross-section from the Series/DataFrame.\n",
    "\n",
    "This method takes a key argument to select data at a particular level of a MultiIndex.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "key\n",
    "label or tuple of label\n",
    "Label contained in the index, or partially in a MultiIndex.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Axis to retrieve cross-section on.\n",
    "\n",
    "level\n",
    "object, defaults to first n levels (n=1 or len(key))\n",
    "In case of a key partially contained in a MultiIndex, indicate which levels are used. Levels can be referred by label or position.\n",
    "\n",
    "drop_level\n",
    "bool, default True\n",
    "If False, returns object with same levels as self.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "Cross-section from the original Series or DataFrame corresponding to the selected index levels.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.loc\n",
    "Access a group of rows and columns by label(s) or a boolean array.\n",
    "\n",
    "DataFrame.iloc\n",
    "Purely integer-location based indexing for selection by position.\n",
    "\n",
    "Notes\n",
    "\n",
    "xs can not be used to set values.\n",
    "\n",
    "MultiIndex Slicers is a generic way to get/set values on any level or levels. It is a superset of xs functionality, see MultiIndex Slicers. \"\"\"\n",
    "\n",
    "d = {'num_legs': [4, 4, 2, 2],\n",
    "     'num_wings': [0, 0, 2, 2],\n",
    "     'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
    "     'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
    "     'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.set_index(['class', 'animal', 'locomotion'])\n",
    "df\n",
    "# Get values at specified index\n",
    "\n",
    "df.xs('mammal')\n",
    "\n",
    "# Get values at several indexes\n",
    "\n",
    "df.xs(('mammal', 'dog', 'walks'))\n",
    "# Get values at specified index and level\n",
    "\n",
    "df.xs('cat', level=1)\n",
    "# Get values at several indexes and levels\n",
    "\n",
    "df.xs(('bird', 'walks'),\n",
    "      level=[0, 'locomotion'])\n",
    "# Get values at specified column and axis\n",
    "\n",
    "df.xs('num_wings', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.xs` method is used to retrieve a **cross-section** from a DataFrame or Series. It is particularly useful when working with **MultiIndex** objects, as it allows you to select data at a specific level or combination of levels. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.xs(key, axis=0, level=None, drop_level=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`key`** : `label` or `tuple of labels`\n",
    "\n",
    "   - The label(s) to select from the index. For a MultiIndex, you can specify a single label or a tuple of labels.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "   - The axis to retrieve the cross-section from:\n",
    "     - `0` or `'index'`: Select from the rows (default).\n",
    "     - `1` or `'columns'`: Select from the columns.\n",
    "\n",
    "3. **`level`** : `object`, optional\n",
    "\n",
    "   - For a MultiIndex, specifies the level(s) to use for selection. Levels can be referred to by label or position.\n",
    "   - If not provided, the first level is used.\n",
    "\n",
    "4. **`drop_level`** : `bool`, default `True`\n",
    "   - If `True`, the selected level(s) are dropped from the result.\n",
    "   - If `False`, the selected level(s) are retained in the result.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - A cross-section from the original object corresponding to the selected key and level(s).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Selecting a Cross-Section from a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with a MultiIndex\n",
    "data = {\n",
    "    'num_legs': [4, 4, 2, 2],\n",
    "    'num_wings': [0, 0, 2, 2],\n",
    "    'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
    "    'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
    "    'locomotion': ['walks', 'walks', 'flies', 'walks']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index(['class', 'animal', 'locomotion'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Select rows where 'class' is 'mammal'\n",
    "result = df.xs('mammal')\n",
    "print(\"\\nCross-section for 'mammal':\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "                           num_legs  num_wings\n",
    "class  animal  locomotion\n",
    "mammal cat     walks              4          0\n",
    "       dog     walks              4          0\n",
    "       bat     flies              2          2\n",
    "bird   penguin walks              2          2\n",
    "\n",
    "Cross-section for 'mammal':\n",
    "                   num_legs  num_wings\n",
    "animal locomotion\n",
    "cat    walks              4          0\n",
    "dog    walks              4          0\n",
    "bat    flies              2          2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Selecting a Specific Combination of Levels\n",
    "\n",
    "```python\n",
    "# Select rows where 'class' is 'mammal' and 'animal' is 'dog'\n",
    "result = df.xs(('mammal', 'dog'))\n",
    "print(\"\\nCross-section for ('mammal', 'dog'):\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cross-section for ('mammal', 'dog'):\n",
    "            num_legs  num_wings\n",
    "locomotion\n",
    "walks              4          0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Selecting a Cross-Section from Columns\n",
    "\n",
    "```python\n",
    "# Select the column 'num_wings'\n",
    "result = df.xs('num_wings', axis=1)\n",
    "print(\"\\nCross-section for 'num_wings':\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cross-section for 'num_wings':\n",
    "class   animal   locomotion\n",
    "mammal  cat      walks         0\n",
    "        dog      walks         0\n",
    "        bat      flies         2\n",
    "bird    penguin  walks         2\n",
    "Name: num_wings, dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Retaining Levels in the Result\n",
    "\n",
    "```python\n",
    "# Select rows where 'class' is 'mammal' and retain the 'class' level\n",
    "result = df.xs('mammal', level='class', drop_level=False)\n",
    "print(\"\\nCross-section for 'mammal' (retaining levels):\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cross-section for 'mammal' (retaining levels):\n",
    "                           num_legs  num_wings\n",
    "class  animal  locomotion\n",
    "mammal cat     walks              4          0\n",
    "       dog     walks              4          0\n",
    "       bat     flies              2          2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.loc`**:\n",
    "\n",
    "   - Access a group of rows and columns by label(s) or a boolean array.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.loc['mammal']\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.iloc`**:\n",
    "\n",
    "   - Access a group of rows and columns by integer position.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.iloc[0]\n",
    "     ```\n",
    "\n",
    "3. **`MultiIndex Slicers`**:\n",
    "   - A generic way to get/set values on any level or levels of a MultiIndex.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.loc[(slice(None), 'dog'), :]\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a MultiIndex DataFrame and want to extract data for a specific combination of levels:\n",
    "\n",
    "```python\n",
    "# Extract data for 'bird' class and 'penguin' animal\n",
    "result = df.xs(('bird', 'penguin'))\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "            num_legs  num_wings\n",
    "locomotion\n",
    "walks              2          2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `xs` method is particularly useful for working with MultiIndex DataFrames.\n",
    "- Use `drop_level=False` to retain the selected levels in the result.\n",
    "- For more advanced slicing, consider using `DataFrame.loc` or MultiIndex slicers.\n",
    "\n",
    "---\n",
    "\n",
    "By using `xs`, you can easily retrieve cross-sections from a DataFrame or Series, making it a powerful tool for working with hierarchical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.get\n",
    "DataFrame.get(key, default=None)[source]\n",
    "Get item from object for given key (ex: DataFrame column).\n",
    "\n",
    "Returns default value if not found.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "key\n",
    "object\n",
    "Returns\n",
    ":\n",
    "same type as items contained in object\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [24.3, 75.7, \"high\"],\n",
    "        [31, 87.8, \"high\"],\n",
    "        [22, 71.6, \"medium\"],\n",
    "        [35, 95, \"medium\"],\n",
    "    ],\n",
    "    columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n",
    "    index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n",
    ")\n",
    "df \n",
    "\n",
    "df.get([\"temp_celsius\", \"windspeed\"])\n",
    "ser = df['windspeed']\n",
    "df.get([\"temp_celsius\", \"temp_kelvin\"], default=\"default_value\")\n",
    "ser.get('2014-02-10', '[unknown]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.get` method is used to retrieve an item (e.g., a column or a value) from a DataFrame or Series using a key. If the key is not found, it returns a default value instead of raising an error. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.get(key, default=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`key`** : `object`\n",
    "\n",
    "   - The key to retrieve from the object. For a DataFrame, this is typically a column name. For a Series, this is typically an index label.\n",
    "\n",
    "2. **`default`** : `object`, optional\n",
    "   - The value to return if the key is not found. Default is `None`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Same type as items contained in the object**:\n",
    "  - If the key is found, the corresponding item (column, value, etc.) is returned.\n",
    "  - If the key is not found, the `default` value is returned.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Retrieving a Column from a DataFrame\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'temp_celsius': [24.3, 31.0, 22.0, 35.0],\n",
    "    'temp_fahrenheit': [75.7, 87.8, 71.6, 95.0],\n",
    "    'windspeed': ['high', 'high', 'medium', 'medium']\n",
    "}, index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"))\n",
    "\n",
    "# Retrieve a single column\n",
    "column = df.get('temp_celsius')\n",
    "print(column)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "2014-02-12    24.3\n",
    "2014-02-13    31.0\n",
    "2014-02-14    22.0\n",
    "2014-02-15    35.0\n",
    "Freq: D, Name: temp_celsius, dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Retrieving Multiple Columns\n",
    "\n",
    "```python\n",
    "# Retrieve multiple columns\n",
    "columns = df.get(['temp_celsius', 'windspeed'])\n",
    "print(columns)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "            temp_celsius windspeed\n",
    "2014-02-12          24.3      high\n",
    "2014-02-13          31.0      high\n",
    "2014-02-14          22.0    medium\n",
    "2014-02-15          35.0    medium\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Retrieving a Value from a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "ser = df['windspeed']\n",
    "\n",
    "# Retrieve a value using an index label\n",
    "value = ser.get('2014-02-13')\n",
    "print(value)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "high\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Using a Default Value\n",
    "\n",
    "```python\n",
    "# Retrieve a non-existent column with a default value\n",
    "result = df.get('temp_kelvin', default=\"default_value\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "default_value\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Retrieving a Non-Existent Index Label\n",
    "\n",
    "```python\n",
    "# Retrieve a non-existent index label with a default value\n",
    "value = ser.get('2014-02-10', default='[unknown]')\n",
    "print(value)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "[unknown]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.loc`**:\n",
    "\n",
    "   - Access a group of rows and columns by label(s) or a boolean array.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.loc[:, 'temp_celsius']\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.iloc`**:\n",
    "\n",
    "   - Access a group of rows and columns by integer position.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.iloc[:, 0]\n",
    "     ```\n",
    "\n",
    "3. **`Series.get`**:\n",
    "   - Retrieve a value from a Series using a key.\n",
    "   - Example:\n",
    "     ```python\n",
    "     ser.get('2014-02-13')\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame and want to safely retrieve a column without worrying about whether it exists:\n",
    "\n",
    "```python\n",
    "# Safely retrieve a column\n",
    "column = df.get('humidity', default='Column not found')\n",
    "print(column)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Column not found\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `get` method is useful for safely retrieving items without raising an error if the key is not found.\n",
    "- Use the `default` parameter to specify a fallback value when the key is missing.\n",
    "- For more advanced indexing, consider using `DataFrame.loc` or `DataFrame.iloc`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `get`, you can handle missing keys gracefully and avoid errors in your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.isin\n",
    "DataFrame.isin(values)[source]\n",
    "Whether each element in the DataFrame is contained in values.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "values\n",
    "iterable, Series, DataFrame or dict\n",
    "The result will only be true at a location if all the labels match. If values is a Series, that’s the index. If values is a dict, the keys must be the column names, which must match. If values is a DataFrame, then both the index and column labels must match.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "DataFrame of booleans showing whether each element in the DataFrame is contained in values.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.eq\n",
    "Equality test for DataFrame.\n",
    "\n",
    "Series.isin\n",
    "Equivalent method on Series.\n",
    "\n",
    "Series.str.contains\n",
    "Test if pattern or regex is contained within a string of a Series or Index. \"\"\"\n",
    "\n",
    "df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
    "                  index=['falcon', 'dog'])\n",
    "df\n",
    "\n",
    "\n",
    "# When values is a list check whether every value in the DataFrame is present in the list (which animals have 0 or 2 legs or wings)\n",
    "\n",
    "df.isin([0, 2])\n",
    "# To check if values is not in the DataFrame, use the ~ operator:\n",
    "\n",
    "~df.isin([0, 2])\n",
    "\n",
    "# When values is a dict, we can pass values to check for each column separately:\n",
    "\n",
    "df.isin({'num_wings': [0, 3]})\n",
    "# When values is a Series or DataFrame the index and column must match. Note that ‘falcon’ does not match based on the number of legs in other.\n",
    "\n",
    "other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]},\n",
    "                     index=['spider', 'falcon'])\n",
    "df.isin(other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.isin` method is used to check whether each element in a DataFrame is contained in a specified set of values. It returns a DataFrame of boolean values (`True` or `False`) indicating whether each element matches any of the values in the provided iterable, Series, DataFrame, or dictionary. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.isin(values)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`values`** : `iterable`, `Series`, `DataFrame`, or `dict`\n",
    "   - The set of values to check against.\n",
    "   - If `values` is a **list**, it checks whether each element in the DataFrame is present in the list.\n",
    "   - If `values` is a **dict**, the keys must be column names, and the values are lists or sets to check against the corresponding columns.\n",
    "   - If `values` is a **Series**, the index of the Series must match the DataFrame's columns.\n",
    "   - If `values` is a **DataFrame**, both the index and column labels must match.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A DataFrame of boolean values (`True` or `False`) indicating whether each element in the original DataFrame is contained in `values`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Checking Against a List\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'num_legs': [2, 4],\n",
    "    'num_wings': [2, 0]\n",
    "}, index=['falcon', 'dog'])\n",
    "\n",
    "# Check if elements are in the list [0, 2]\n",
    "result = df.isin([0, 2])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        num_legs  num_wings\n",
    "falcon      True       True\n",
    "dog        False       True\n",
    "```\n",
    "\n",
    "- The elements `2` and `0` are checked against each value in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Inverting the Result\n",
    "\n",
    "```python\n",
    "# Invert the result using the ~ operator\n",
    "result = ~df.isin([0, 2])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        num_legs  num_wings\n",
    "falcon     False      False\n",
    "dog         True      False\n",
    "```\n",
    "\n",
    "- The `~` operator negates the boolean values.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Checking Against a Dictionary\n",
    "\n",
    "```python\n",
    "# Check each column against a dictionary of values\n",
    "result = df.isin({'num_wings': [0, 3]})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        num_legs  num_wings\n",
    "falcon     False      False\n",
    "dog        False       True\n",
    "```\n",
    "\n",
    "- Only the `num_wings` column is checked against the list `[0, 3]`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Checking Against Another DataFrame\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "other = pd.DataFrame({\n",
    "    'num_legs': [8, 3],\n",
    "    'num_wings': [0, 2]\n",
    "}, index=['spider', 'falcon'])\n",
    "\n",
    "# Check if elements match the other DataFrame\n",
    "result = df.isin(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        num_legs  num_wings\n",
    "falcon     False       True\n",
    "dog        False      False\n",
    "```\n",
    "\n",
    "- Only the `num_wings` value `2` in the `falcon` row matches the other DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.eq`**:\n",
    "\n",
    "   - Performs element-wise equality check.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.eq(2)\n",
    "     ```\n",
    "\n",
    "2. **`Series.isin`**:\n",
    "\n",
    "   - Checks whether elements in a Series are contained in a set of values.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df['num_legs'].isin([2, 4])\n",
    "     ```\n",
    "\n",
    "3. **`Series.str.contains`**:\n",
    "   - Checks whether a pattern or regex is contained within strings in a Series.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df['animal'].str.contains('cat')\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame and want to filter rows where specific columns match certain values:\n",
    "\n",
    "```python\n",
    "# Filter rows where 'num_legs' is 2 or 4 and 'num_wings' is 0 or 2\n",
    "filtered_df = df[df.isin({'num_legs': [2, 4], 'num_wings': [0, 2]}).all(axis=1)]\n",
    "print(filtered_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        num_legs  num_wings\n",
    "falcon         2          2\n",
    "dog            4          0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `isin` method is useful for filtering or masking DataFrames based on specific values.\n",
    "- Use the `~` operator to invert the boolean result.\n",
    "- For more complex filtering, combine `isin` with other methods like `all` or `any`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `isin`, you can efficiently check for membership of elements in a DataFrame and perform filtering or conditional operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.where\n",
    "DataFrame.where(cond, other=nan, *, inplace=False, axis=None, level=None)[source]\n",
    "Replace values where the condition is False.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "cond\n",
    "bool Series/DataFrame, array-like, or callable\n",
    "Where cond is True, keep the original value. Where False, replace with corresponding value from other. If cond is callable, it is computed on the Series/DataFrame and should return boolean Series/DataFrame or array. The callable must not change input Series/DataFrame (though pandas doesn’t check it).\n",
    "\n",
    "other\n",
    "scalar, Series/DataFrame, or callable\n",
    "Entries where cond is False are replaced with corresponding value from other. If other is callable, it is computed on the Series/DataFrame and should return scalar or Series/DataFrame. The callable must not change input Series/DataFrame (though pandas doesn’t check it). If not specified, entries will be filled with the corresponding NULL value (np.nan for numpy dtypes, pd.NA for extension dtypes).\n",
    "\n",
    "inplace\n",
    "bool, default False\n",
    "Whether to perform the operation in place on the data.\n",
    "\n",
    "axis\n",
    "int, default None\n",
    "Alignment axis if needed. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "level\n",
    "int, default None\n",
    "Alignment level if needed.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Same type as caller or None if\n",
    "inplace=True\n",
    ".\n",
    "See also\n",
    "\n",
    "DataFrame.mask()\n",
    "Return an object of same shape as self.\n",
    "\n",
    "Notes\n",
    "\n",
    "The where method is an application of the if-then idiom. For each element in the calling DataFrame, if cond is True the element is used; otherwise the corresponding element from the DataFrame other is used. If the axis of other does not align with axis of cond Series/DataFrame, the misaligned index positions will be filled with False.\n",
    "\n",
    "The signature for DataFrame.where() differs from numpy.where(). Roughly df1.where(m, df2) is equivalent to np.where(m, df1, df2).\n",
    "\n",
    "For further details and examples see the where documentation in indexing.\n",
    "\n",
    "The dtype of the object takes precedence. The fill value is casted to the object’s dtype, if this can be done losslessly. \"\"\"\n",
    "s = pd.Series(range(5))\n",
    "s.where(s > 0)\n",
    "s.mask(s > 0)\n",
    "\n",
    "s = pd.Series(range(5))\n",
    "t = pd.Series([True, False])\n",
    "s.where(t, 99)\n",
    "s.mask(t, 99)\n",
    "s.where(s > 1, 10)\n",
    "s.mask(s > 1, 10)\n",
    "df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.where` method is used to replace values in a DataFrame or Series where a specified condition is `False`. It is an application of the **if-then idiom**: for each element, if the condition is `True`, the original value is kept; otherwise, it is replaced with a value from `other`. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.where(cond, other=nan, *, inplace=False, axis=None, level=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`cond`** : `bool Series/DataFrame`, `array-like`, or `callable`\n",
    "\n",
    "   - The condition to check. Where `cond` is `True`, the original value is kept. Where `cond` is `False`, the value is replaced with the corresponding value from `other`.\n",
    "   - If `cond` is callable, it is computed on the DataFrame/Series and should return a boolean DataFrame/Series or array.\n",
    "\n",
    "2. **`other`** : `scalar`, `Series/DataFrame`, or `callable`, optional\n",
    "\n",
    "   - The value to replace elements where `cond` is `False`. If not provided, the default is `NaN`.\n",
    "   - If `other` is callable, it is computed on the DataFrame/Series and should return a scalar or DataFrame/Series.\n",
    "\n",
    "3. **`inplace`** : `bool`, default `False`\n",
    "\n",
    "   - If `True`, the operation is performed in place (i.e., the original DataFrame/Series is modified), and the method returns `None`.\n",
    "\n",
    "4. **`axis`** : `int`, optional\n",
    "\n",
    "   - Alignment axis if needed. For Series, this parameter is unused.\n",
    "\n",
    "5. **`level`** : `int`, optional\n",
    "   - Alignment level if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Same type as caller**:\n",
    "  - A new DataFrame/Series with values replaced where the condition is `False`.\n",
    "  - If `inplace=True`, the method returns `None`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage with a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series(range(5))\n",
    "\n",
    "# Replace values where the condition is False\n",
    "result = s.where(s > 0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    NaN\n",
    "1    1.0\n",
    "2    2.0\n",
    "3    3.0\n",
    "4    4.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- Values where `s > 0` is `False` (i.e., `0`) are replaced with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Using `other` to Replace Values\n",
    "\n",
    "```python\n",
    "# Replace values where the condition is False with 99\n",
    "result = s.where(s > 0, 99)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    99\n",
    "1     1\n",
    "2     2\n",
    "3     3\n",
    "4     4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Values where `s > 0` is `False` (i.e., `0`) are replaced with `99`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Using a Callable for `cond`\n",
    "\n",
    "```python\n",
    "# Use a callable for the condition\n",
    "result = s.where(lambda x: x > 1, 10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    10\n",
    "1    10\n",
    "2     2\n",
    "3     3\n",
    "4     4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Values where `x > 1` is `False` (i.e., `0` and `1`) are replaced with `10`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Using `where` with a DataFrame\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# Replace values where the condition is False\n",
    "result = df.where(df > 2, -df)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B\n",
    "0 -1 -4\n",
    "1 -2 -5\n",
    "2  3  6\n",
    "```\n",
    "\n",
    "- Values where `df > 2` is `False` are replaced with the negative of the original value.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `inplace=True`\n",
    "\n",
    "```python\n",
    "# Modify the DataFrame in place\n",
    "df.where(df > 2, -df, inplace=True)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B\n",
    "0 -1 -4\n",
    "1 -2 -5\n",
    "2  3  6\n",
    "```\n",
    "\n",
    "- The original DataFrame is modified in place.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.mask`**:\n",
    "\n",
    "   - The inverse of `where`. It replaces values where the condition is `True`.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.mask(df > 2, -df)\n",
    "     ```\n",
    "\n",
    "2. **`numpy.where`**:\n",
    "   - Similar functionality but with a different syntax.\n",
    "   - Example:\n",
    "     ```python\n",
    "     import numpy as np\n",
    "     np.where(df > 2, df, -df)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame and want to replace all negative values with `NaN`:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with negative values\n",
    "df = pd.DataFrame({'A': [1, -2, 3], 'B': [-4, 5, -6]})\n",
    "\n",
    "# Replace negative values with NaN\n",
    "result = df.where(df >= 0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  1.0  NaN\n",
    "1  NaN  5.0\n",
    "2  3.0  NaN\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `where` method is useful for conditional replacement of values in a DataFrame or Series.\n",
    "- Use `inplace=True` to modify the original object directly.\n",
    "- For more complex conditions, you can use callables for `cond` or `other`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `where`, you can efficiently perform conditional replacements in your data, making it a powerful tool for data cleaning and transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.mask\n",
    "DataFrame.mask(cond, other=<no_default>, *, inplace=False, axis=None, level=None)[source]\n",
    "Replace values where the condition is True.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "cond\n",
    "bool Series/DataFrame, array-like, or callable\n",
    "Where cond is False, keep the original value. Where True, replace with corresponding value from other. If cond is callable, it is computed on the Series/DataFrame and should return boolean Series/DataFrame or array. The callable must not change input Series/DataFrame (though pandas doesn’t check it).\n",
    "\n",
    "other\n",
    "scalar, Series/DataFrame, or callable\n",
    "Entries where cond is True are replaced with corresponding value from other. If other is callable, it is computed on the Series/DataFrame and should return scalar or Series/DataFrame. The callable must not change input Series/DataFrame (though pandas doesn’t check it). If not specified, entries will be filled with the corresponding NULL value (np.nan for numpy dtypes, pd.NA for extension dtypes).\n",
    "\n",
    "inplace\n",
    "bool, default False\n",
    "Whether to perform the operation in place on the data.\n",
    "\n",
    "axis\n",
    "int, default None\n",
    "Alignment axis if needed. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "level\n",
    "int, default None\n",
    "Alignment level if needed.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Same type as caller or None if\n",
    "inplace=True\n",
    ".\n",
    "See also\n",
    "\n",
    "DataFrame.where()\n",
    "Return an object of same shape as self.\n",
    "\n",
    "Notes\n",
    "\n",
    "The mask method is an application of the if-then idiom. For each element in the calling DataFrame, if cond is False the element is used; otherwise the corresponding element from the DataFrame other is used. If the axis of other does not align with axis of cond Series/DataFrame, the misaligned index positions will be filled with True.\n",
    "\n",
    "The signature for DataFrame.where() differs from numpy.where(). Roughly df1.where(m, df2) is equivalent to np.where(m, df1, df2).\n",
    "\n",
    "For further details and examples see the mask documentation in indexing.\n",
    "\n",
    "The dtype of the object takes precedence. The fill value is casted to the object’s dtype, if this can be done losslessly. \"\"\"\n",
    "s = pd.Series(range(5))\n",
    "s.where(s > 0)\n",
    "s.mask(s > 0)\n",
    "\n",
    "\n",
    "s = pd.Series(range(5))\n",
    "t = pd.Series([True, False])\n",
    "s.where(t, 99)\n",
    "\n",
    "s.mask(t, 99)\n",
    "s.where(s > 1, 10)\n",
    "s.mask(s > 1, 10)\n",
    "df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
    "df\n",
    "m = df % 3 == 0\n",
    "df.where(m, -df)\n",
    "df.where(m, -df) == np.where(m, df, -df)\n",
    "\n",
    "df.where(m, -df) == df.mask(~m, -df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.mask` method is used to replace values in a DataFrame or Series where a specified condition is `True`. It is the **inverse** of the `where` method: for each element, if the condition is `True`, the value is replaced with a value from `other`; otherwise, the original value is kept. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.mask(cond, other=<no_default>, *, inplace=False, axis=None, level=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`cond`** : `bool Series/DataFrame`, `array-like`, or `callable`\n",
    "\n",
    "   - The condition to check. Where `cond` is `True`, the value is replaced with the corresponding value from `other`. Where `cond` is `False`, the original value is kept.\n",
    "   - If `cond` is callable, it is computed on the DataFrame/Series and should return a boolean DataFrame/Series or array.\n",
    "\n",
    "2. **`other`** : `scalar`, `Series/DataFrame`, or `callable`, optional\n",
    "\n",
    "   - The value to replace elements where `cond` is `True`. If not provided, the default is `NaN`.\n",
    "   - If `other` is callable, it is computed on the DataFrame/Series and should return a scalar or DataFrame/Series.\n",
    "\n",
    "3. **`inplace`** : `bool`, default `False`\n",
    "\n",
    "   - If `True`, the operation is performed in place (i.e., the original DataFrame/Series is modified), and the method returns `None`.\n",
    "\n",
    "4. **`axis`** : `int`, optional\n",
    "\n",
    "   - Alignment axis if needed. For Series, this parameter is unused.\n",
    "\n",
    "5. **`level`** : `int`, optional\n",
    "   - Alignment level if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Same type as caller**:\n",
    "  - A new DataFrame/Series with values replaced where the condition is `True`.\n",
    "  - If `inplace=True`, the method returns `None`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Usage with a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series(range(5))\n",
    "\n",
    "# Replace values where the condition is True\n",
    "result = s.mask(s > 0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    0.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "- Values where `s > 0` is `True` (i.e., `1`, `2`, `3`, `4`) are replaced with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Using `other` to Replace Values\n",
    "\n",
    "```python\n",
    "# Replace values where the condition is True with 99\n",
    "result = s.mask(s > 0, 99)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     0\n",
    "1    99\n",
    "2    99\n",
    "3    99\n",
    "4    99\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Values where `s > 0` is `True` (i.e., `1`, `2`, `3`, `4`) are replaced with `99`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Using a Callable for `cond`\n",
    "\n",
    "```python\n",
    "# Use a callable for the condition\n",
    "result = s.mask(lambda x: x > 1, 10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0     0\n",
    "1     1\n",
    "2    10\n",
    "3    10\n",
    "4    10\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Values where `x > 1` is `True` (i.e., `2`, `3`, `4`) are replaced with `10`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Using `mask` with a DataFrame\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# Replace values where the condition is True\n",
    "result = df.mask(df > 2, -df)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B\n",
    "0  1  4\n",
    "1  2  5\n",
    "2 -3 -6\n",
    "```\n",
    "\n",
    "- Values where `df > 2` is `True` are replaced with the negative of the original value.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `inplace=True`\n",
    "\n",
    "```python\n",
    "# Modify the DataFrame in place\n",
    "df.mask(df > 2, -df, inplace=True)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B\n",
    "0  1  4\n",
    "1  2  5\n",
    "2 -3 -6\n",
    "```\n",
    "\n",
    "- The original DataFrame is modified in place.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.where`**:\n",
    "\n",
    "   - The inverse of `mask`. It replaces values where the condition is `False`.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.where(df > 2, -df)\n",
    "     ```\n",
    "\n",
    "2. **`numpy.where`**:\n",
    "   - Similar functionality but with a different syntax.\n",
    "   - Example:\n",
    "     ```python\n",
    "     import numpy as np\n",
    "     np.where(df > 2, df, -df)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame and want to replace all positive values with `NaN`:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with positive and negative values\n",
    "df = pd.DataFrame({'A': [1, -2, 3], 'B': [-4, 5, -6]})\n",
    "\n",
    "# Replace positive values with NaN\n",
    "result = df.mask(df > 0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  NaN -4.0\n",
    "1 -2.0  NaN\n",
    "2  NaN -6.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `mask` method is useful for conditional replacement of values in a DataFrame or Series.\n",
    "- Use `inplace=True` to modify the original object directly.\n",
    "- For more complex conditions, you can use callables for `cond` or `other`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `mask`, you can efficiently perform conditional replacements in your data, making it a powerful tool for data cleaning and transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.query\n",
    "DataFrame.query(expr, *, inplace=False, **kwargs)[source]\n",
    "Query the columns of a DataFrame with a boolean expression.\n",
    "\n",
    "Parameters:\n",
    "exprstr\n",
    "The query string to evaluate.\n",
    "\n",
    "You can refer to variables in the environment by prefixing them with an ‘@’ character like @a + b.\n",
    "\n",
    "You can refer to column names that are not valid Python variable names by surrounding them in backticks. Thus, column names containing spaces or punctuations (besides underscores) or starting with digits must be surrounded by backticks. (For example, a column named “Area (cm^2)” would be referenced as `Area (cm^2)`). Column names which are Python keywords (like “list”, “for”, “import”, etc) cannot be used.\n",
    "\n",
    "For example, if one of your columns is called a a and you want to sum it with b, your query should be `a a` + b.\n",
    "\n",
    "inplacebool\n",
    "Whether to modify the DataFrame rather than creating a new one.\n",
    "\n",
    "**kwargs\n",
    "See the documentation for eval() for complete details on the keyword arguments accepted by DataFrame.query().\n",
    "\n",
    "Returns:\n",
    "DataFrame or None\n",
    "DataFrame resulting from the provided query expression or None if inplace=True.\n",
    "\n",
    "See also\n",
    "\n",
    "eval\n",
    "Evaluate a string describing operations on DataFrame columns.\n",
    "\n",
    "DataFrame.eval\n",
    "Evaluate a string describing operations on DataFrame columns.\n",
    "\n",
    "Notes\n",
    "\n",
    "The result of the evaluation of this expression is first passed to DataFrame.loc and if that fails because of a multidimensional key (e.g., a DataFrame) then the result will be passed to DataFrame.__getitem__().\n",
    "\n",
    "This method uses the top-level eval() function to evaluate the passed query.\n",
    "\n",
    "The query() method uses a slightly modified Python syntax by default. For example, the & and | (bitwise) operators have the precedence of their boolean cousins, and and or. This is syntactically valid Python, however the semantics are different.\n",
    "\n",
    "You can change the semantics of the expression by passing the keyword argument parser='python'. This enforces the same semantics as evaluation in Python space. Likewise, you can pass engine='python' to evaluate an expression using Python itself as a backend. This is not recommended as it is inefficient compared to using numexpr as the engine.\n",
    "\n",
    "The DataFrame.index and DataFrame.columns attributes of the DataFrame instance are placed in the query namespace by default, which allows you to treat both the index and columns of the frame as a column in the frame. The identifier index is used for the frame index; you can also use the name of the index to identify it in a query. Please note that Python keywords may not be used as identifiers.\n",
    "\n",
    "For further details and examples see the query documentation in indexing.\n",
    "\n",
    "Backtick quoted variables\n",
    "\n",
    "Backtick quoted variables are parsed as literal Python code and are converted internally to a Python valid identifier. This can lead to the following problems.\n",
    "\n",
    "During parsing a number of disallowed characters inside the backtick quoted string are replaced by strings that are allowed as a Python identifier. These characters include all operators in Python, the space character, the question mark, the exclamation mark, the dollar sign, and the euro sign. For other characters that fall outside the ASCII range (U+0001..U+007F) and those that are not further specified in PEP 3131, the query parser will raise an error. This excludes whitespace different than the space character, but also the hashtag (as it is used for comments) and the backtick itself (backtick can also not be escaped).\n",
    "\n",
    "In a special case, quotes that make a pair around a backtick can confuse the parser. For example, `it's` > `that's` will raise an error, as it forms a quoted string ('s > `that') with a backtick inside.\n",
    "\n",
    "See also the Python documentation about lexical analysis (https://docs.python.org/3/reference/lexical_analysis.html) in combination with the source code in pandas.core.computation.parsing. \"\"\"\n",
    "\n",
    "df = pd.DataFrame({'A': range(1, 6),\n",
    "                   'B': range(10, 0, -2),\n",
    "                   'C C': range(10, 5, -1)})\n",
    "df\n",
    "df.query('A > B')\n",
    "df[df.A > df.B]\n",
    "# For columns with spaces in their name, you can use backtick quoting.\n",
    "\n",
    "df.query('B == `C C`')\n",
    "# The previous expression is equivalent to\n",
    "\n",
    "df[df.B == df['C C']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.query` method is used to filter rows of a DataFrame using a **boolean expression** written as a string. It provides a concise and readable way to perform row selection based on column values. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.query(expr, *, inplace=False, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`expr`** : `str`\n",
    "\n",
    "   - The query string to evaluate. This string is a boolean expression that filters rows based on column values.\n",
    "   - You can refer to:\n",
    "     - Column names directly (e.g., `A > B`).\n",
    "     - Variables in the environment by prefixing them with `@` (e.g., `A > @threshold`).\n",
    "     - Column names with spaces or special characters by enclosing them in backticks (e.g., `` `C C` == 10``).\n",
    "\n",
    "2. **`inplace`** : `bool`, default `False`\n",
    "\n",
    "   - If `True`, the operation is performed in place (i.e., the original DataFrame is modified), and the method returns `None`.\n",
    "\n",
    "3. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments passed to `eval()`. These include:\n",
    "     - `engine`: The engine to use for evaluation (`'numexpr'` by default or `'python'`).\n",
    "     - `parser`: The parser to use (`'pandas'` by default or `'python'`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame or None**:\n",
    "  - A new DataFrame containing the rows that satisfy the query expression.\n",
    "  - If `inplace=True`, the method returns `None`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Basic Query\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': range(1, 6),\n",
    "    'B': range(10, 0, -2),\n",
    "    'C C': range(10, 5, -1)\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Query rows where column A is greater than column B\n",
    "result = df.query('A > B')\n",
    "print(\"\\nFiltered DataFrame:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "   A   B  C C\n",
    "0  1  10   10\n",
    "1  2   8    9\n",
    "2  3   6    8\n",
    "3  4   4    7\n",
    "4  5   2    6\n",
    "\n",
    "Filtered DataFrame:\n",
    "   A  B  C C\n",
    "4  5  2    6\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Query with Variables\n",
    "\n",
    "```python\n",
    "# Define a variable\n",
    "threshold = 5\n",
    "\n",
    "# Query rows where column A is greater than the threshold\n",
    "result = df.query('A > @threshold')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C C\n",
    "4  5  2    6\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Query with Special Column Names\n",
    "\n",
    "```python\n",
    "# Query rows where column 'C C' equals 10\n",
    "result = df.query('`C C` == 10')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A   B  C C\n",
    "0  1  10   10\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Combining Conditions\n",
    "\n",
    "```python\n",
    "# Query rows where A > 2 and B < 8\n",
    "result = df.query('A > 2 and B < 8')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C C\n",
    "2  3  6    8\n",
    "3  4  4    7\n",
    "4  5  2    6\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `inplace=True`\n",
    "\n",
    "```python\n",
    "# Modify the DataFrame in place\n",
    "df.query('A > 3', inplace=True)\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B  C C\n",
    "3  4  4    7\n",
    "4  5  2    6\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.eval`**:\n",
    "\n",
    "   - Evaluates a string describing operations on DataFrame columns.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.eval('A + B')\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.loc`**:\n",
    "\n",
    "   - Filters rows using boolean indexing.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df[df.A > df.B]\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.filter`**:\n",
    "   - Filters rows or columns based on labels.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.filter(items=['A', 'B'])\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame and want to filter rows based on multiple conditions:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Salary': [50000, 60000, 70000, 80000]\n",
    "})\n",
    "\n",
    "# Query rows where Age is greater than 30 and Salary is less than 75000\n",
    "result = df.query('Age > 30 and Salary < 75000')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      Name  Age  Salary\n",
    "2  Charlie   35   70000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `query` method is useful for writing concise and readable filtering expressions.\n",
    "- Use backticks (`` ` ``) to refer to column names with spaces or special characters.\n",
    "- Use `@` to refer to variables in the environment.\n",
    "- For complex queries, consider using `eval()` or `loc` for more flexibility.\n",
    "\n",
    "---\n",
    "\n",
    "By using `query`, you can efficiently filter rows of a DataFrame based on column values, making it a powerful tool for data analysis and manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" pandas.DataFrame.__add__\n",
    "DataFrame.__add__(other)[source]\n",
    "Get Addition of DataFrame and other, column-wise.\n",
    "\n",
    "Equivalent to DataFrame.add(other).\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Object to be added to the DataFrame.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "The result of adding other to DataFrame.\n",
    "\n",
    "\n",
    "DataFrame.add\n",
    "Add a DataFrame and another object, with option for index- or column-oriented addition. \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'height': [1.5, 2.6], 'weight': [500, 800]},\n",
    "                  index=['elk', 'moose'])\n",
    "df\n",
    "df[['height', 'weight']] + 1.5\n",
    "df[['height', 'weight']] + [0.5, 1.5]\n",
    "df[['height', 'weight']] + {'height': 0.5, 'weight': 1.5}\n",
    "# When other is a Series, the index of other is aligned with the columns of the DataFrame.\n",
    "\n",
    "s1 = pd.Series([0.5, 1.5], index=['weight', 'height'])\n",
    "df[['height', 'weight']] + s1\n",
    "\n",
    "# Even when the index of other is the same as the index of the DataFrame, the Series will not be reoriented. If index-wise alignment is desired, DataFrame.add() should be used with axis=’index’.\n",
    "\n",
    "s2 = pd.Series([0.5, 1.5], index=['elk', 'moose'])\n",
    "df[['height', 'weight']] + s2\n",
    "df[['height', 'weight']].add(s2, axis='index')\n",
    " \n",
    "# When other is a DataFrame, both columns names and the index are aligned.\n",
    "\n",
    "other = pd.DataFrame({'height': [0.2, 0.4, 0.6]},\n",
    "                     index=['elk', 'moose', 'deer'])\n",
    "df[['height', 'weight']] + other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.__add__` method is used to perform **element-wise addition** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). It is equivalent to using the `+` operator or the `DataFrame.add()` method. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.__add__(other)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`** : `scalar`, `sequence`, `Series`, `dict`, or `DataFrame`\n",
    "   - The object to be added to the DataFrame.\n",
    "   - If `other` is a:\n",
    "     - **scalar**: The scalar is added to every element in the DataFrame.\n",
    "     - **sequence**: Each element in the sequence is added to the corresponding column in the DataFrame.\n",
    "     - **Series**: The Series is aligned with the DataFrame's columns, and element-wise addition is performed.\n",
    "     - **dict**: The keys of the dict are aligned with the DataFrame's columns, and the corresponding values are added.\n",
    "     - **DataFrame**: Both the columns and index are aligned, and element-wise addition is performed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A new DataFrame containing the result of the addition.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Adding a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'height': [1.5, 2.6], 'weight': [500, 800]}, index=['elk', 'moose'])\n",
    "\n",
    "# Add a scalar to the DataFrame\n",
    "result = df + 1.5\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       height  weight\n",
    "elk       3.0   501.5\n",
    "moose     4.1   801.5\n",
    "```\n",
    "\n",
    "- The scalar `1.5` is added to every element in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Adding a Sequence\n",
    "\n",
    "```python\n",
    "# Add a sequence to the DataFrame\n",
    "result = df + [0.5, 1.5]\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       height  weight\n",
    "elk       2.0   501.5\n",
    "moose     3.1   801.5\n",
    "```\n",
    "\n",
    "- The sequence `[0.5, 1.5]` is added to the corresponding columns (`height` and `weight`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Adding a Dictionary\n",
    "\n",
    "```python\n",
    "# Add a dictionary to the DataFrame\n",
    "result = df + {'height': 0.5, 'weight': 1.5}\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       height  weight\n",
    "elk       2.0   501.5\n",
    "moose     3.1   801.5\n",
    "```\n",
    "\n",
    "- The dictionary values are added to the corresponding columns.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Adding a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "s1 = pd.Series([0.5, 1.5], index=['weight', 'height'])\n",
    "\n",
    "# Add the Series to the DataFrame\n",
    "result = df + s1\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       height  weight\n",
    "elk       3.0   500.5\n",
    "moose     4.1   800.5\n",
    "```\n",
    "\n",
    "- The Series is aligned with the DataFrame's columns, and element-wise addition is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Adding a DataFrame\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "other = pd.DataFrame({'height': [0.2, 0.4, 0.6]}, index=['elk', 'moose', 'deer'])\n",
    "\n",
    "# Add the other DataFrame to the original DataFrame\n",
    "result = df + other\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       height  weight\n",
    "deer      NaN     NaN\n",
    "elk       1.7     NaN\n",
    "moose     3.0     NaN\n",
    "```\n",
    "\n",
    "- The DataFrames are aligned by both columns and index, and element-wise addition is performed. Missing values (`NaN`) are introduced where there is no alignment.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.add`**:\n",
    "\n",
    "   - Equivalent to `__add__` but provides additional options like `axis` and `fill_value`.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.add(other, axis='index')\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.sub`**:\n",
    "\n",
    "   - Performs element-wise subtraction.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.sub(other)\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.mul`**:\n",
    "\n",
    "   - Performs element-wise multiplication.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.mul(other)\n",
    "     ```\n",
    "\n",
    "4. **`DataFrame.div`**:\n",
    "   - Performs element-wise division.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.div(other)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame representing measurements and want to add a constant offset to all values:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'temperature': [20.5, 22.3, 19.8], 'humidity': [45, 50, 48]})\n",
    "\n",
    "# Add an offset to all measurements\n",
    "offset = 2.5\n",
    "result = df + offset\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   temperature  humidity\n",
    "0         23.0      47.5\n",
    "1         24.8      52.5\n",
    "2         22.3      50.5\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `__add__` method performs element-wise addition and aligns objects by columns and index.\n",
    "- Use `DataFrame.add` for more advanced operations, such as specifying the `axis` or handling missing values with `fill_value`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `__add__` or the `+` operator, you can efficiently perform element-wise addition on DataFrames and other compatible objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.add\n",
    "DataFrame.add(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Addition of dataframe and other, element-wise (binary operator add).\n",
    "\n",
    "Equivalent to dataframe + other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, radd.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power. \"\"\"\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "df + 1\n",
    "df.add(1)\n",
    "# Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "df.rdiv(10)\n",
    "# Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "df.sub([1, 2], axis='columns')\n",
    "\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "\n",
    "# Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "# Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "df * other\n",
    "df.mul(other, fill_value=0)\n",
    "# Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "df.div(df_multindex, level=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.add` method is used to perform **element-wise addition** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). It is equivalent to using the `+` operator but provides additional flexibility, such as handling missing values with `fill_value` and specifying the `axis` for alignment. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.add(other, axis='columns', level=None, fill_value=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`** : `scalar`, `sequence`, `Series`, `dict`, or `DataFrame`\n",
    "\n",
    "   - The object to be added to the DataFrame.\n",
    "   - If `other` is a:\n",
    "     - **scalar**: The scalar is added to every element in the DataFrame.\n",
    "     - **sequence**: Each element in the sequence is added to the corresponding column in the DataFrame.\n",
    "     - **Series**: The Series is aligned with the DataFrame's columns or index, depending on the `axis`.\n",
    "     - **dict**: The keys of the dict are aligned with the DataFrame's columns, and the corresponding values are added.\n",
    "     - **DataFrame**: Both the columns and index are aligned, and element-wise addition is performed.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index', 1 or 'columns'}`, default `'columns'`\n",
    "\n",
    "   - The axis to align the addition operation:\n",
    "     - `0` or `'index'`: Align along the index (rows).\n",
    "     - `1` or `'columns'`: Align along the columns (default).\n",
    "\n",
    "3. **`level`** : `int` or `label`, optional\n",
    "\n",
    "   - For MultiIndex DataFrames, specifies the level to align on.\n",
    "\n",
    "4. **`fill_value`** : `float` or `None`, default `None`\n",
    "   - A value to fill missing (`NaN`) values in the DataFrame or `other` before performing the addition.\n",
    "   - If `None`, missing values remain as `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A new DataFrame containing the result of the element-wise addition.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Adding a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, 180, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Add a scalar to the DataFrame\n",
    "result = df.add(1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "```\n",
    "\n",
    "- The scalar `1` is added to every element in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Adding a Sequence\n",
    "\n",
    "```python\n",
    "# Add a sequence to the DataFrame\n",
    "result = df.add([1, 2], axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1      362\n",
    "triangle        4      182\n",
    "rectangle       5      362\n",
    "```\n",
    "\n",
    "- The sequence `[1, 2]` is added to the corresponding columns (`angles` and `degrees`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Adding a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "\n",
    "# Add the Series to the DataFrame\n",
    "result = df.add(s, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1      362\n",
    "triangle        4      182\n",
    "rectangle       5      362\n",
    "```\n",
    "\n",
    "- The Series is aligned with the DataFrame's columns, and element-wise addition is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Adding a DataFrame\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "other = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [10, 20, 30]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Add the other DataFrame to the original DataFrame\n",
    "result = df.add(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      370\n",
    "triangle        6      200\n",
    "rectangle       8      390\n",
    "```\n",
    "\n",
    "- The DataFrames are aligned by both columns and index, and element-wise addition is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `fill_value`\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, None, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Add a scalar, filling missing values with 0\n",
    "result = df.add(1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      1.0\n",
    "rectangle       5      361\n",
    "```\n",
    "\n",
    "- Missing values (`NaN`) are filled with `0` before the addition.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.sub`**:\n",
    "\n",
    "   - Performs element-wise subtraction.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.sub(other)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.mul`**:\n",
    "\n",
    "   - Performs element-wise multiplication.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.mul(other)\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.div`**:\n",
    "\n",
    "   - Performs element-wise division.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.div(other)\n",
    "     ```\n",
    "\n",
    "4. **`DataFrame.radd`**:\n",
    "   - Reverse version of `add` (e.g., `other + df`).\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.radd(other)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame representing measurements and want to add an offset to specific columns:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'temperature': [20.5, 22.3, 19.8], 'humidity': [45, 50, 48]})\n",
    "\n",
    "# Add an offset to the 'temperature' column\n",
    "offset = pd.Series([2.5, 0, 0], index=['temperature', 'humidity', 'pressure'])\n",
    "result = df.add(offset, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   temperature  humidity\n",
    "0         23.0      45.0\n",
    "1         22.3      50.0\n",
    "2         19.8      48.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `add` method performs element-wise addition and aligns objects by columns and index.\n",
    "- Use `fill_value` to handle missing values during the operation.\n",
    "- For more advanced operations, consider using `DataFrame.apply` or `DataFrame.eval`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `add`, you can efficiently perform element-wise addition on DataFrames and other compatible objects, with options for handling missing values and specifying alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.sub\n",
    "DataFrame.sub(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Subtraction of dataframe and other, element-wise (binary operator sub).\n",
    "\n",
    "Equivalent to dataframe - other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, rsub.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power. \"\"\"\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "df +1\n",
    "df.add(1)\n",
    "# Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "df.rdiv(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "\n",
    "df.sub([1, 2], axis='columns')\n",
    "\n",
    "\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "\n",
    "df * other\n",
    "\n",
    "df.mul(other, fill_value=0)\n",
    "\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "\n",
    "\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.sub` method is used to perform **element-wise subtraction** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). It is equivalent to using the `-` operator but provides additional flexibility, such as handling missing values with `fill_value` and specifying the `axis` for alignment. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.sub(other, axis='columns', level=None, fill_value=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`** : `scalar`, `sequence`, `Series`, `dict`, or `DataFrame`\n",
    "\n",
    "   - The object to be subtracted from the DataFrame.\n",
    "   - If `other` is a:\n",
    "     - **scalar**: The scalar is subtracted from every element in the DataFrame.\n",
    "     - **sequence**: Each element in the sequence is subtracted from the corresponding column in the DataFrame.\n",
    "     - **Series**: The Series is aligned with the DataFrame's columns or index, depending on the `axis`.\n",
    "     - **dict**: The keys of the dict are aligned with the DataFrame's columns, and the corresponding values are subtracted.\n",
    "     - **DataFrame**: Both the columns and index are aligned, and element-wise subtraction is performed.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index', 1 or 'columns'}`, default `'columns'`\n",
    "\n",
    "   - The axis to align the subtraction operation:\n",
    "     - `0` or `'index'`: Align along the index (rows).\n",
    "     - `1` or `'columns'`: Align along the columns (default).\n",
    "\n",
    "3. **`level`** : `int` or `label`, optional\n",
    "\n",
    "   - For MultiIndex DataFrames, specifies the level to align on.\n",
    "\n",
    "4. **`fill_value`** : `float` or `None`, default `None`\n",
    "   - A value to fill missing (`NaN`) values in the DataFrame or `other` before performing the subtraction.\n",
    "   - If `None`, missing values remain as `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A new DataFrame containing the result of the element-wise subtraction.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Subtracting a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, 180, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Subtract a scalar from the DataFrame\n",
    "result = df.sub(1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "```\n",
    "\n",
    "- The scalar `1` is subtracted from every element in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Subtracting a Sequence\n",
    "\n",
    "```python\n",
    "# Subtract a sequence from the DataFrame\n",
    "result = df.sub([1, 2], axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "```\n",
    "\n",
    "- The sequence `[1, 2]` is subtracted from the corresponding columns (`angles` and `degrees`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Subtracting a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "\n",
    "# Subtract the Series from the DataFrame\n",
    "result = df.sub(s, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "```\n",
    "\n",
    "- The Series is aligned with the DataFrame's columns, and element-wise subtraction is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Subtracting a DataFrame\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "other = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [10, 20, 30]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Subtract the other DataFrame from the original DataFrame\n",
    "result = df.sub(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      350\n",
    "triangle        0      160\n",
    "rectangle       0      330\n",
    "```\n",
    "\n",
    "- The DataFrames are aligned by both columns and index, and element-wise subtraction is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `fill_value`\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, None, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Subtract a scalar, filling missing values with 0\n",
    "result = df.sub(1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2     -1.0\n",
    "rectangle       3      359\n",
    "```\n",
    "\n",
    "- Missing values (`NaN`) are filled with `0` before the subtraction.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.add`**:\n",
    "\n",
    "   - Performs element-wise addition.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.add(other)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.mul`**:\n",
    "\n",
    "   - Performs element-wise multiplication.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.mul(other)\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.div`**:\n",
    "\n",
    "   - Performs element-wise division.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.div(other)\n",
    "     ```\n",
    "\n",
    "4. **`DataFrame.rsub`**:\n",
    "   - Reverse version of `sub` (e.g., `other - df`).\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.rsub(other)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame representing measurements and want to subtract an offset from specific columns:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'temperature': [20.5, 22.3, 19.8], 'humidity': [45, 50, 48]})\n",
    "\n",
    "# Subtract an offset from the 'temperature' column\n",
    "offset = pd.Series([2.5, 0, 0], index=['temperature', 'humidity', 'pressure'])\n",
    "result = df.sub(offset, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   temperature  humidity\n",
    "0         18.0      45.0\n",
    "1         22.3      50.0\n",
    "2         19.8      48.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `sub` method performs element-wise subtraction and aligns objects by columns and index.\n",
    "- Use `fill_value` to handle missing values during the operation.\n",
    "- For more advanced operations, consider using `DataFrame.apply` or `DataFrame.eval`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `sub`, you can efficiently perform element-wise subtraction on DataFrames and other compatible objects, with options for handling missing values and specifying alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.mul\n",
    "DataFrame.mul(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Multiplication of dataframe and other, element-wise (binary operator mul).\n",
    "\n",
    "Equivalent to dataframe * other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, rmul.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.mul` method is used to perform **element-wise multiplication** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). It is equivalent to using the `*` operator but provides additional flexibility, such as handling missing values with `fill_value` and specifying the `axis` for alignment. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.mul(other, axis='columns', level=None, fill_value=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`** : `scalar`, `sequence`, `Series`, `dict`, or `DataFrame`\n",
    "\n",
    "   - The object to multiply with the DataFrame.\n",
    "   - If `other` is a:\n",
    "     - **scalar**: The scalar is multiplied with every element in the DataFrame.\n",
    "     - **sequence**: Each element in the sequence is multiplied with the corresponding column in the DataFrame.\n",
    "     - **Series**: The Series is aligned with the DataFrame's columns or index, depending on the `axis`.\n",
    "     - **dict**: The keys of the dict are aligned with the DataFrame's columns, and the corresponding values are multiplied.\n",
    "     - **DataFrame**: Both the columns and index are aligned, and element-wise multiplication is performed.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index', 1 or 'columns'}`, default `'columns'`\n",
    "\n",
    "   - The axis to align the multiplication operation:\n",
    "     - `0` or `'index'`: Align along the index (rows).\n",
    "     - `1` or `'columns'`: Align along the columns (default).\n",
    "\n",
    "3. **`level`** : `int` or `label`, optional\n",
    "\n",
    "   - For MultiIndex DataFrames, specifies the level to align on.\n",
    "\n",
    "4. **`fill_value`** : `float` or `None`, default `None`\n",
    "   - A value to fill missing (`NaN`) values in the DataFrame or `other` before performing the multiplication.\n",
    "   - If `None`, missing values remain as `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A new DataFrame containing the result of the element-wise multiplication.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Multiplying by a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, 180, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Multiply the DataFrame by a scalar\n",
    "result = df.mul(2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      720\n",
    "triangle        6      360\n",
    "rectangle       8      720\n",
    "```\n",
    "\n",
    "- The scalar `2` is multiplied with every element in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Multiplying by a Sequence\n",
    "\n",
    "```python\n",
    "# Multiply the DataFrame by a sequence\n",
    "result = df.mul([1, 2], axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      720\n",
    "triangle        3      360\n",
    "rectangle       4      720\n",
    "```\n",
    "\n",
    "- The sequence `[1, 2]` is multiplied with the corresponding columns (`angles` and `degrees`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Multiplying by a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "\n",
    "# Multiply the DataFrame by the Series\n",
    "result = df.mul(s, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      720\n",
    "triangle        3      360\n",
    "rectangle       4      720\n",
    "```\n",
    "\n",
    "- The Series is aligned with the DataFrame's columns, and element-wise multiplication is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Multiplying by a DataFrame\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "other = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [10, 20, 30]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Multiply the original DataFrame by the other DataFrame\n",
    "result = df.mul(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0     3600\n",
    "triangle        9     3600\n",
    "rectangle      16    10800\n",
    "```\n",
    "\n",
    "- The DataFrames are aligned by both columns and index, and element-wise multiplication is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `fill_value`\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, None, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Multiply by a scalar, filling missing values with 1\n",
    "result = df.mul(2, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      720\n",
    "triangle        6      2.0\n",
    "rectangle       8      720\n",
    "```\n",
    "\n",
    "- Missing values (`NaN`) are filled with `1` before the multiplication.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.add`**:\n",
    "\n",
    "   - Performs element-wise addition.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.add(other)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.sub`**:\n",
    "\n",
    "   - Performs element-wise subtraction.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.sub(other)\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.div`**:\n",
    "\n",
    "   - Performs element-wise division.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.div(other)\n",
    "     ```\n",
    "\n",
    "4. **`DataFrame.rmul`**:\n",
    "   - Reverse version of `mul` (e.g., `other * df`).\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.rmul(other)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame representing measurements and want to scale specific columns by a factor:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'temperature': [20.5, 22.3, 19.8], 'humidity': [45, 50, 48]})\n",
    "\n",
    "# Scale the 'temperature' column by a factor\n",
    "factor = pd.Series([2, 1], index=['temperature', 'humidity'])\n",
    "result = df.mul(factor, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   temperature  humidity\n",
    "0         41.0        45\n",
    "1         44.6        50\n",
    "2         39.6        48\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `mul` method performs element-wise multiplication and aligns objects by columns and index.\n",
    "- Use `fill_value` to handle missing values during the operation.\n",
    "- For more advanced operations, consider using `DataFrame.apply` or `DataFrame.eval`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `mul`, you can efficiently perform element-wise multiplication on DataFrames and other compatible objects, with options for handling missing values and specifying alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.div\n",
    "DataFrame.div(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Floating division of dataframe and other, element-wise (binary operator truediv).\n",
    "\n",
    "Equivalent to dataframe / other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, rtruediv.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.div` method is used to perform **element-wise division** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). It is equivalent to using the `/` operator but provides additional flexibility, such as handling missing values with `fill_value` and specifying the `axis` for alignment. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.div(other, axis='columns', level=None, fill_value=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`** : `scalar`, `sequence`, `Series`, `dict`, or `DataFrame`\n",
    "\n",
    "   - The object to divide the DataFrame by.\n",
    "   - If `other` is a:\n",
    "     - **scalar**: The scalar is used to divide every element in the DataFrame.\n",
    "     - **sequence**: Each element in the sequence is used to divide the corresponding column in the DataFrame.\n",
    "     - **Series**: The Series is aligned with the DataFrame's columns or index, depending on the `axis`.\n",
    "     - **dict**: The keys of the dict are aligned with the DataFrame's columns, and the corresponding values are used for division.\n",
    "     - **DataFrame**: Both the columns and index are aligned, and element-wise division is performed.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index', 1 or 'columns'}`, default `'columns'`\n",
    "\n",
    "   - The axis to align the division operation:\n",
    "     - `0` or `'index'`: Align along the index (rows).\n",
    "     - `1` or `'columns'`: Align along the columns (default).\n",
    "\n",
    "3. **`level`** : `int` or `label`, optional\n",
    "\n",
    "   - For MultiIndex DataFrames, specifies the level to align on.\n",
    "\n",
    "4. **`fill_value`** : `float` or `None`, default `None`\n",
    "   - A value to fill missing (`NaN`) values in the DataFrame or `other` before performing the division.\n",
    "   - If `None`, missing values remain as `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A new DataFrame containing the result of the element-wise division.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Dividing by a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, 180, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Divide the DataFrame by a scalar\n",
    "result = df.div(2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0    180.0\n",
    "triangle      1.5     90.0\n",
    "rectangle     2.0    180.0\n",
    "```\n",
    "\n",
    "- The scalar `2` is used to divide every element in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Dividing by a Sequence\n",
    "\n",
    "```python\n",
    "# Divide the DataFrame by a sequence\n",
    "result = df.div([1, 2], axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0    180.0\n",
    "triangle      3.0     90.0\n",
    "rectangle     4.0    180.0\n",
    "```\n",
    "\n",
    "- The sequence `[1, 2]` is used to divide the corresponding columns (`angles` and `degrees`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Dividing by a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "\n",
    "# Divide the DataFrame by the Series\n",
    "result = df.div(s, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0    180.0\n",
    "triangle      3.0     90.0\n",
    "rectangle     4.0    180.0\n",
    "```\n",
    "\n",
    "- The Series is aligned with the DataFrame's columns, and element-wise division is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Dividing by a DataFrame\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "other = pd.DataFrame({'angles': [1, 3, 4], 'degrees': [10, 20, 30]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Divide the original DataFrame by the other DataFrame\n",
    "result = df.div(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      1.0      9.0\n",
    "rectangle     1.0     12.0\n",
    "```\n",
    "\n",
    "- The DataFrames are aligned by both columns and index, and element-wise division is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `fill_value`\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, None, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Divide by a scalar, filling missing values with 1\n",
    "result = df.div(2, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0    180.0\n",
    "triangle      1.5      0.5\n",
    "rectangle     2.0    180.0\n",
    "```\n",
    "\n",
    "- Missing values (`NaN`) are filled with `1` before the division.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.add`**:\n",
    "\n",
    "   - Performs element-wise addition.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.add(other)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.sub`**:\n",
    "\n",
    "   - Performs element-wise subtraction.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.sub(other)\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.mul`**:\n",
    "\n",
    "   - Performs element-wise multiplication.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.mul(other)\n",
    "     ```\n",
    "\n",
    "4. **`DataFrame.rtruediv`**:\n",
    "   - Reverse version of `div` (e.g., `other / df`).\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.rtruediv(other)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame representing measurements and want to normalize specific columns by a factor:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'temperature': [20.5, 22.3, 19.8], 'humidity': [45, 50, 48]})\n",
    "\n",
    "# Normalize the 'temperature' column by a factor\n",
    "factor = pd.Series([2, 1], index=['temperature', 'humidity'])\n",
    "result = df.div(factor, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   temperature  humidity\n",
    "0        10.25      45.0\n",
    "1        11.15      50.0\n",
    "2         9.90      48.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `div` method performs element-wise division and aligns objects by columns and index.\n",
    "- Use `fill_value` to handle missing values during the operation.\n",
    "- For more advanced operations, consider using `DataFrame.apply` or `DataFrame.eval`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `div`, you can efficiently perform element-wise division on DataFrames and other compatible objects, with options for handling missing values and specifying alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.truediv\n",
    "DataFrame.truediv(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Floating division of dataframe and other, element-wise (binary operator truediv).\n",
    "\n",
    "Equivalent to dataframe / other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, rtruediv.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\"\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.truediv` method is used to perform **element-wise floating-point division** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). It is equivalent to using the `/` operator but provides additional flexibility, such as handling missing values with `fill_value` and specifying the `axis` for alignment. Below is a detailed explanation of its parameters, usage, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.truediv(other, axis='columns', level=None, fill_value=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`** : `scalar`, `sequence`, `Series`, `dict`, or `DataFrame`\n",
    "\n",
    "   - The object to divide the DataFrame by.\n",
    "   - If `other` is a:\n",
    "     - **scalar**: The scalar is used to divide every element in the DataFrame.\n",
    "     - **sequence**: Each element in the sequence is used to divide the corresponding column in the DataFrame.\n",
    "     - **Series**: The Series is aligned with the DataFrame's columns or index, depending on the `axis`.\n",
    "     - **dict**: The keys of the dict are aligned with the DataFrame's columns, and the corresponding values are used for division.\n",
    "     - **DataFrame**: Both the columns and index are aligned, and element-wise division is performed.\n",
    "\n",
    "2. **`axis`** : `{0 or 'index', 1 or 'columns'}`, default `'columns'`\n",
    "\n",
    "   - The axis to align the division operation:\n",
    "     - `0` or `'index'`: Align along the index (rows).\n",
    "     - `1` or `'columns'`: Align along the columns (default).\n",
    "\n",
    "3. **`level`** : `int` or `label`, optional\n",
    "\n",
    "   - For MultiIndex DataFrames, specifies the level to align on.\n",
    "\n",
    "4. **`fill_value`** : `float` or `None`, default `None`\n",
    "   - A value to fill missing (`NaN`) values in the DataFrame or `other` before performing the division.\n",
    "   - If `None`, missing values remain as `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A new DataFrame containing the result of the element-wise floating-point division.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### Example 1: Dividing by a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, 180, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Divide the DataFrame by a scalar\n",
    "result = df.truediv(2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0    180.0\n",
    "triangle      1.5     90.0\n",
    "rectangle     2.0    180.0\n",
    "```\n",
    "\n",
    "- The scalar `2` is used to divide every element in the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Dividing by a Sequence\n",
    "\n",
    "```python\n",
    "# Divide the DataFrame by a sequence\n",
    "result = df.truediv([1, 2], axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0    180.0\n",
    "triangle      3.0     90.0\n",
    "rectangle     4.0    180.0\n",
    "```\n",
    "\n",
    "- The sequence `[1, 2]` is used to divide the corresponding columns (`angles` and `degrees`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Dividing by a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "s = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "\n",
    "# Divide the DataFrame by the Series\n",
    "result = df.truediv(s, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0    180.0\n",
    "triangle      3.0     90.0\n",
    "rectangle     4.0    180.0\n",
    "```\n",
    "\n",
    "- The Series is aligned with the DataFrame's columns, and element-wise division is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Dividing by a DataFrame\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "other = pd.DataFrame({'angles': [1, 3, 4], 'degrees': [10, 20, 30]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Divide the original DataFrame by the other DataFrame\n",
    "result = df.truediv(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      1.0      9.0\n",
    "rectangle     1.0     12.0\n",
    "```\n",
    "\n",
    "- The DataFrames are aligned by both columns and index, and element-wise division is performed.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Using `fill_value`\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({'angles': [0, 3, 4], 'degrees': [360, None, 360]}, index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Divide by a scalar, filling missing values with 1\n",
    "result = df.truediv(2, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        0.0    180.0\n",
    "triangle      1.5      0.5\n",
    "rectangle     2.0    180.0\n",
    "```\n",
    "\n",
    "- Missing values (`NaN`) are filled with `1` before the division.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "1. **`DataFrame.add`**:\n",
    "\n",
    "   - Performs element-wise addition.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.add(other)\n",
    "     ```\n",
    "\n",
    "2. **`DataFrame.sub`**:\n",
    "\n",
    "   - Performs element-wise subtraction.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.sub(other)\n",
    "     ```\n",
    "\n",
    "3. **`DataFrame.mul`**:\n",
    "\n",
    "   - Performs element-wise multiplication.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.mul(other)\n",
    "     ```\n",
    "\n",
    "4. **`DataFrame.rtruediv`**:\n",
    "   - Reverse version of `truediv` (e.g., `other / df`).\n",
    "   - Example:\n",
    "     ```python\n",
    "     df.rtruediv(other)\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Practical Use Case**\n",
    "\n",
    "Suppose you have a DataFrame representing measurements and want to normalize specific columns by a factor:\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'temperature': [20.5, 22.3, 19.8], 'humidity': [45, 50, 48]})\n",
    "\n",
    "# Normalize the 'temperature' column by a factor\n",
    "factor = pd.Series([2, 1], index=['temperature', 'humidity'])\n",
    "result = df.truediv(factor, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   temperature  humidity\n",
    "0        10.25      45.0\n",
    "1        11.15      50.0\n",
    "2         9.90      48.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- The `truediv` method performs element-wise floating-point division and aligns objects by columns and index.\n",
    "- Use `fill_value` to handle missing values during the operation.\n",
    "- For more advanced operations, consider using `DataFrame.apply` or `DataFrame.eval`.\n",
    "\n",
    "---\n",
    "\n",
    "By using `truediv`, you can efficiently perform element-wise floating-point division on DataFrames and other compatible objects, with options for handling missing values and specifying alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.floordiv\n",
    "DataFrame.floordiv(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Integer division of dataframe and other, element-wise (binary operator floordiv).\n",
    "\n",
    "Equivalent to dataframe // other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, rfloordiv.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.floordiv` method is used to perform element-wise integer division (also known as floor division) between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). The result is a DataFrame where each element is the result of the floor division operation.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Floor Division**: The operation `//` is used, which divides the elements and returns the largest integer less than or equal to the division result.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be divided element-wise with the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the floor division operation.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Floor Division by a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Floor division by a scalar\n",
    "result = df.floordiv(10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0       36\n",
    "triangle        0       18\n",
    "rectangle       0       36\n",
    "```\n",
    "\n",
    "#### 2. Floor Division with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Floor division with another DataFrame\n",
    "result = df.floordiv(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0       36\n",
    "triangle        1        9\n",
    "rectangle       1       12\n",
    "```\n",
    "\n",
    "#### 3. Floor Division with `fill_value`\n",
    "\n",
    "```python\n",
    "# Floor division with fill_value\n",
    "result = df.floordiv(other, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0       36\n",
    "triangle        1        9\n",
    "rectangle       1       12\n",
    "```\n",
    "\n",
    "#### 4. Floor Division with a Series\n",
    "\n",
    "```python\n",
    "# Floor division with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.floordiv(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      180\n",
    "triangle        3       90\n",
    "rectangle       4      180\n",
    "```\n",
    "\n",
    "#### 5. Floor Division with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Floor division by level\n",
    "result = df.floordiv(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The reverse version of the operation (`rfloordiv`) can be used to perform the operation with the operands reversed.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "These methods provide flexible wrappers around arithmetic operations, allowing for easy element-wise operations between DataFrames and other objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.mod\n",
    "DataFrame.mod(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Modulo of dataframe and other, element-wise (binary operator mod).\n",
    "\n",
    "Equivalent to dataframe % other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, rmod.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.mod` method is used to perform **element-wise modulo operation** (remainder after division) between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). The result is a DataFrame where each element is the remainder of the division operation.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Modulo Operation**: The operation `%` is used, which returns the remainder after division.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be used in the modulo operation with the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the modulo operation.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Modulo Operation with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Modulo operation with a scalar\n",
    "result = df.mod(10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0        0\n",
    "triangle        3        0\n",
    "rectangle       4        0\n",
    "```\n",
    "\n",
    "#### 2. Modulo Operation with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Modulo operation with another DataFrame\n",
    "result = df.mod(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0        0\n",
    "triangle        1        0\n",
    "rectangle       1        0\n",
    "```\n",
    "\n",
    "#### 3. Modulo Operation with `fill_value`\n",
    "\n",
    "```python\n",
    "# Modulo operation with fill_value\n",
    "result = df.mod(other, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0        0\n",
    "triangle        1        0\n",
    "rectangle       1        0\n",
    "```\n",
    "\n",
    "#### 4. Modulo Operation with a Series\n",
    "\n",
    "```python\n",
    "# Modulo operation with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.mod(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0        0\n",
    "triangle        0        0\n",
    "rectangle       0        0\n",
    "```\n",
    "\n",
    "#### 5. Modulo Operation with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Modulo operation by level\n",
    "result = df.mod(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle        0.0      0.0\n",
    "  triangle      0.0      0.0\n",
    "  rectangle     0.0      0.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The reverse version of the operation (`rmod`) can be used to perform the operation with the operands reversed.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "These methods provide flexible wrappers around arithmetic operations, allowing for easy element-wise operations between DataFrames and other objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.pow\n",
    "DataFrame.pow(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Exponential power of dataframe and other, element-wise (binary operator pow).\n",
    "\n",
    "Equivalent to dataframe ** other, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, rpow.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.pow` method is used to perform **element-wise exponential power** (raising to a power) between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame). The result is a DataFrame where each element is the result of raising the corresponding element in the DataFrame to the power of the corresponding element in `other`.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Exponential Power**: The operation `**` is used, which raises each element in the DataFrame to the power of the corresponding element in `other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object used as the exponent in the power operation.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the exponential power operation.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Exponential Power with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Exponential power with a scalar\n",
    "result = df.pow(2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles   degrees\n",
    "circle          0    129600\n",
    "triangle        9     32400\n",
    "rectangle      16    129600\n",
    "```\n",
    "\n",
    "#### 2. Exponential Power with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [2, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Exponential power with another DataFrame\n",
    "result = df.pow(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles   degrees\n",
    "circle          0    129600\n",
    "triangle        9     5832000\n",
    "rectangle      64  1.679616e+08\n",
    "```\n",
    "\n",
    "#### 3. Exponential Power with `fill_value`\n",
    "\n",
    "```python\n",
    "# Exponential power with fill_value\n",
    "result = df.pow(other, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles   degrees\n",
    "circle          0    129600\n",
    "triangle        9     5832000\n",
    "rectangle      64  1.679616e+08\n",
    "```\n",
    "\n",
    "#### 4. Exponential Power with a Series\n",
    "\n",
    "```python\n",
    "# Exponential power with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.pow(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles   degrees\n",
    "circle          0    129600\n",
    "triangle        3     32400\n",
    "rectangle       4    129600\n",
    "```\n",
    "\n",
    "#### 5. Exponential Power with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Exponential power by level\n",
    "result = df.pow(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "A circle        1.0       1.0\n",
    "  triangle      27.0       1.0\n",
    "  rectangle    256.0       1.0\n",
    "B square        1.0       1.0\n",
    "  pentagon      1.0       1.0\n",
    "  hexagon       1.0       1.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The reverse version of the operation (`rpow`) can be used to perform the operation with the operands reversed.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "\n",
    "These methods provide flexible wrappers around arithmetic operations, allowing for easy element-wise operations between DataFrames and other objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" API reference\n",
    "DataFrame\n",
    "pandas.DataFrame.dot\n",
    "pandas.DataFrame.dot\n",
    "DataFrame.dot(other)[source]\n",
    "Compute the matrix multiplication between the DataFrame and other.\n",
    "\n",
    "This method computes the matrix product between the DataFrame and the values of an other Series, DataFrame or a numpy array.\n",
    "\n",
    "It can also be called using self @ other.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "Series, DataFrame or array-like\n",
    "The other object to compute the matrix product with.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "If other is a Series, return the matrix product between self and other as a Series. If other is a DataFrame or a numpy.array, return the matrix product of self and other in a DataFrame of a np.array.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.dot\n",
    "Similar method for Series.\n",
    "\n",
    "Notes\n",
    "\n",
    "The dimensions of DataFrame and other must be compatible in order to compute the matrix multiplication. In addition, the column names of DataFrame and the index of other must contain the same values, as they will be aligned prior to the multiplication.\n",
    "\n",
    "The dot method for Series computes the inner product, instead of the matrix product here.\n",
    "\n",
    "Examples\n",
    "\n",
    "Here we multiply a DataFrame with a Series.\n",
    "\n",
    "df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n",
    "s = pd.Series([1, 1, 2, 1])\n",
    "df.dot(s)\n",
    "0    -4\n",
    "1     5\n",
    "dtype: int64\n",
    "Here we multiply a DataFrame with another DataFrame.\n",
    "\n",
    "other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
    "df.dot(other)\n",
    "    0   1\n",
    "0   1   4\n",
    "1   2   2\n",
    "Note that the dot method give the same result as @\n",
    "\n",
    "df @ other\n",
    "    0   1\n",
    "0   1   4\n",
    "1   2   2\n",
    "The dot method works also if other is an np.array.\n",
    "\n",
    "arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
    "df.dot(arr)\n",
    "    0   1\n",
    "0   1   4\n",
    "1   2   2\n",
    "Note how shuffling of the objects does not change the result.\n",
    "\n",
    "s2 = s.reindex([1, 0, 2, 3])\n",
    "df.dot(s2)\n",
    "0    -4\n",
    "1     5\n",
    "dtype: int64 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.dot` method is used to compute the **matrix multiplication** (also known as the dot product) between a DataFrame and another object (Series, DataFrame, or array-like). This method aligns the columns of the DataFrame with the index of the other object before performing the multiplication.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Matrix Multiplication**: The operation computes the dot product, which is the sum of the products of corresponding elements.\n",
    "- **Alignment**: The columns of the DataFrame and the index of `other` must align for the operation to work.\n",
    "- **Flexibility**: It can be used with a Series, DataFrame, or numpy array.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a Series, DataFrame, or array-like object. It is the object to compute the matrix product with.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - If `other` is a **Series**, the result is a **Series**.\n",
    "  - If `other` is a **DataFrame** or **numpy array**, the result is a **DataFrame** or **numpy array**.\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- The dimensions of the DataFrame and `other` must be compatible for matrix multiplication.\n",
    "- The column names of the DataFrame and the index of `other` must align. If they don't, the operation will fail or produce unexpected results.\n",
    "- The `@` operator can also be used to perform the same operation (e.g., `df @ other`).\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Matrix Multiplication with a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n",
    "s = pd.Series([1, 1, 2, 1])\n",
    "\n",
    "# Matrix multiplication with a Series\n",
    "result = df.dot(s)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0   -4\n",
    "1    5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### 2. Matrix Multiplication with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
    "\n",
    "# Matrix multiplication with another DataFrame\n",
    "result = df.dot(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   0  1\n",
    "0  1  4\n",
    "1  2  2\n",
    "```\n",
    "\n",
    "#### 3. Matrix Multiplication with a Numpy Array\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
    "\n",
    "# Matrix multiplication with a numpy array\n",
    "result = df.dot(arr)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   0  1\n",
    "0  1  4\n",
    "1  2  2\n",
    "```\n",
    "\n",
    "#### 4. Using the `@` Operator\n",
    "\n",
    "The `@` operator is equivalent to the `dot` method:\n",
    "\n",
    "```python\n",
    "# Using the @ operator\n",
    "result = df @ other\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   0  1\n",
    "0  1  4\n",
    "1  2  2\n",
    "```\n",
    "\n",
    "#### 5. Alignment of Indices\n",
    "\n",
    "Even if the indices of the Series are shuffled, the result remains the same because the alignment is based on column names and index:\n",
    "\n",
    "```python\n",
    "s2 = s.reindex([1, 0, 2, 3])\n",
    "\n",
    "# Matrix multiplication with a shuffled Series\n",
    "result = df.dot(s2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0   -4\n",
    "1    5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### Notes on Alignment:\n",
    "\n",
    "- The column names of the DataFrame must match the index of `other` for the operation to work correctly.\n",
    "- If the indices do not align, the operation will either fail or produce unexpected results.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`Series.dot`**: Computes the dot product for Series objects.\n",
    "- **`numpy.dot`**: The underlying numpy function used for matrix multiplication.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.dot`** is used for matrix multiplication.\n",
    "- It aligns the columns of the DataFrame with the index of `other`.\n",
    "- It can be used with Series, DataFrames, or numpy arrays.\n",
    "- The `@` operator is a shorthand for the same operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.radd\n",
    "DataFrame.radd(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Addition of dataframe and other, element-wise (binary operator radd).\n",
    "\n",
    "Equivalent to other + dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, add.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.radd` method is used to perform **element-wise addition** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other + dataframe` instead of `dataframe + other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Addition**: The operation computes `other + dataframe` instead of `dataframe + other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be added to the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise addition.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Addition with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse addition with a scalar\n",
    "result = df.radd(1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "```\n",
    "\n",
    "#### 2. Reverse Addition with a Series\n",
    "\n",
    "```python\n",
    "# Reverse addition with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.radd(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1      362\n",
    "triangle        4      182\n",
    "rectangle       5      362\n",
    "```\n",
    "\n",
    "#### 3. Reverse Addition with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse addition with another DataFrame\n",
    "result = df.radd(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1      370\n",
    "triangle        5      200\n",
    "rectangle       7      390\n",
    "```\n",
    "\n",
    "#### 4. Reverse Addition with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse addition with fill_value\n",
    "result = df.radd(other, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1      370\n",
    "triangle        5      200\n",
    "rectangle       7      390\n",
    "```\n",
    "\n",
    "#### 5. Reverse Addition with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse addition by level\n",
    "result = df.radd(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle        0.0    720.0\n",
    "  triangle      6.0    360.0\n",
    "  rectangle     8.0    720.0\n",
    "B square        4.0    360.0\n",
    "  pentagon      5.0    540.0\n",
    "  hexagon       6.0    720.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `radd` method is the reverse version of `add`. It is equivalent to `other + dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.add`**: Element-wise addition (`dataframe + other`).\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.radd`** performs element-wise addition with the operands reversed (`other + dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.rsub\n",
    "DataFrame.rsub(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Subtraction of dataframe and other, element-wise (binary operator rsub).\n",
    "\n",
    "Equivalent to other - dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, sub.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rmul` method is used to perform **element-wise multiplication** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other * dataframe` instead of `dataframe * other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Multiplication**: The operation computes `other * dataframe` instead of `dataframe * other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be multiplied with the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise multiplication.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Multiplication with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse multiplication with a scalar\n",
    "result = df.rmul(2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      720\n",
    "triangle        6      360\n",
    "rectangle       8      720\n",
    "```\n",
    "\n",
    "#### 2. Reverse Multiplication with a Series\n",
    "\n",
    "```python\n",
    "# Reverse multiplication with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.rmul(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      720\n",
    "triangle        3      360\n",
    "rectangle       4      720\n",
    "```\n",
    "\n",
    "#### 3. Reverse Multiplication with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse multiplication with another DataFrame\n",
    "result = df.rmul(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0     3600\n",
    "triangle        6     3600\n",
    "rectangle      12    10800\n",
    "```\n",
    "\n",
    "#### 4. Reverse Multiplication with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse multiplication with fill_value\n",
    "result = df.rmul(other, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0     3600\n",
    "triangle        6     3600\n",
    "rectangle      12    10800\n",
    "```\n",
    "\n",
    "#### 5. Reverse Multiplication with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse multiplication by level\n",
    "result = df.rmul(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle          0   129600\n",
    "  triangle        9    32400\n",
    "  rectangle      16   129600\n",
    "B square          0        0\n",
    "  pentagon        0        0\n",
    "  hexagon         0        0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `rmul` method is the reverse version of `mul`. It is equivalent to `other * dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.mul`**: Element-wise multiplication (`dataframe * other`).\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.rmul`** performs element-wise multiplication with the operands reversed (`other * dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" API reference\n",
    "DataFrame\n",
    "pandas.DataF...\n",
    "pandas.DataFrame.rmul\n",
    "DataFrame.rmul(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Multiplication of dataframe and other, element-wise (binary operator rmul).\n",
    "\n",
    "Equivalent to other * dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, mul.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rsub` method is used to perform **element-wise subtraction** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other - dataframe` instead of `dataframe - other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Subtraction**: The operation computes `other - dataframe` instead of `dataframe - other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to subtract the DataFrame from.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise subtraction.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Subtraction with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse subtraction with a scalar\n",
    "result = df.rsub(10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle         10     -350\n",
    "triangle        7     -170\n",
    "rectangle       6     -350\n",
    "```\n",
    "\n",
    "#### 2. Reverse Subtraction with a Series\n",
    "\n",
    "```python\n",
    "# Reverse subtraction with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.rsub(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1     -358\n",
    "triangle       -2     -178\n",
    "rectangle      -3     -358\n",
    "```\n",
    "\n",
    "#### 3. Reverse Subtraction with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse subtraction with another DataFrame\n",
    "result = df.rsub(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1     -350\n",
    "triangle       -1     -160\n",
    "rectangle      -1     -330\n",
    "```\n",
    "\n",
    "#### 4. Reverse Subtraction with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse subtraction with fill_value\n",
    "result = df.rsub(other, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          1     -350\n",
    "triangle       -1     -160\n",
    "rectangle      -1     -330\n",
    "```\n",
    "\n",
    "#### 5. Reverse Subtraction with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse subtraction by level\n",
    "result = df.rsub(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle        0.0      0.0\n",
    "  triangle      0.0      0.0\n",
    "  rectangle     0.0      0.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      1.0      0.0\n",
    "  hexagon       2.0      0.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `rsub` method is the reverse version of `sub`. It is equivalent to `other - dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.sub`**: Element-wise subtraction (`dataframe - other`).\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.rsub`** performs element-wise subtraction with the operands reversed (`other - dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.rmul\n",
    "DataFrame.rmul(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Multiplication of dataframe and other, element-wise (binary operator rmul).\n",
    "\n",
    "Equivalent to other * dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, mul.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rmul` method is used to perform **element-wise multiplication** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other * dataframe` instead of `dataframe * other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Multiplication**: The operation computes `other * dataframe` instead of `dataframe * other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be multiplied with the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise multiplication.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Multiplication with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse multiplication with a scalar\n",
    "result = df.rmul(2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      720\n",
    "triangle        6      360\n",
    "rectangle       8      720\n",
    "```\n",
    "\n",
    "#### 2. Reverse Multiplication with a Series\n",
    "\n",
    "```python\n",
    "# Reverse multiplication with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.rmul(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0      720\n",
    "triangle        3      360\n",
    "rectangle       4      720\n",
    "```\n",
    "\n",
    "#### 3. Reverse Multiplication with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse multiplication with another DataFrame\n",
    "result = df.rmul(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0     3600\n",
    "triangle        6     3600\n",
    "rectangle      12    10800\n",
    "```\n",
    "\n",
    "#### 4. Reverse Multiplication with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse multiplication with fill_value\n",
    "result = df.rmul(other, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle          0     3600\n",
    "triangle        6     3600\n",
    "rectangle      12    10800\n",
    "```\n",
    "\n",
    "#### 5. Reverse Multiplication with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse multiplication by level\n",
    "result = df.rmul(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle          0   129600\n",
    "  triangle        9    32400\n",
    "  rectangle      16   129600\n",
    "B square          0        0\n",
    "  pentagon        0        0\n",
    "  hexagon         0        0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `rmul` method is the reverse version of `mul`. It is equivalent to `other * dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.mul`**: Element-wise multiplication (`dataframe * other`).\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.rmul`** performs element-wise multiplication with the operands reversed (`other * dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.rdiv\n",
    "DataFrame.rdiv(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Floating division of dataframe and other, element-wise (binary operator rtruediv).\n",
    "\n",
    "Equivalent to other / dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, truediv.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rdiv` method is used to perform **element-wise floating division** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other / dataframe` instead of `dataframe / other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Division**: The operation computes `other / dataframe` instead of `dataframe / other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be divided by the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise floating division.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Division with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse division with a scalar\n",
    "result = df.rdiv(10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "```\n",
    "\n",
    "#### 2. Reverse Division with a Series\n",
    "\n",
    "```python\n",
    "# Reverse division with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.rdiv(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "circle          inf  0.005556\n",
    "triangle  0.333333  0.011111\n",
    "rectangle 0.250000  0.005556\n",
    "```\n",
    "\n",
    "#### 3. Reverse Division with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse division with another DataFrame\n",
    "result = df.rdiv(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle  0.666667  0.111111\n",
    "rectangle 0.750000  0.083333\n",
    "```\n",
    "\n",
    "#### 4. Reverse Division with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse division with fill_value\n",
    "result = df.rdiv(other, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle  0.666667  0.111111\n",
    "rectangle 0.750000  0.083333\n",
    "```\n",
    "\n",
    "#### 5. Reverse Division with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse division by level\n",
    "result = df.rdiv(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `rdiv` method is the reverse version of `truediv`. It is equivalent to `other / dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.truediv`**: Element-wise floating division (`dataframe / other`).\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.rdiv`** performs element-wise floating division with the operands reversed (`other / dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.rtruediv\n",
    "DataFrame.rtruediv(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Floating division of dataframe and other, element-wise (binary operator rtruediv).\n",
    "\n",
    "Equivalent to other / dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, truediv.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rtruediv` method is used to perform **element-wise floating division** between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other / dataframe` instead of `dataframe / other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Division**: The operation computes `other / dataframe` instead of `dataframe / other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be divided by the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise floating division.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Division with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse division with a scalar\n",
    "result = df.rtruediv(10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "```\n",
    "\n",
    "#### 2. Reverse Division with a Series\n",
    "\n",
    "```python\n",
    "# Reverse division with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.rtruediv(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "circle          inf  0.005556\n",
    "triangle  0.333333  0.011111\n",
    "rectangle 0.250000  0.005556\n",
    "```\n",
    "\n",
    "#### 3. Reverse Division with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse division with another DataFrame\n",
    "result = df.rtruediv(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle  0.666667  0.111111\n",
    "rectangle 0.750000  0.083333\n",
    "```\n",
    "\n",
    "#### 4. Reverse Division with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse division with fill_value\n",
    "result = df.rtruediv(other, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle  0.666667  0.111111\n",
    "rectangle 0.750000  0.083333\n",
    "```\n",
    "\n",
    "#### 5. Reverse Division with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse division by level\n",
    "result = df.rtruediv(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `rtruediv` method is the reverse version of `truediv`. It is equivalent to `other / dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.truediv`**: Element-wise floating division (`dataframe / other`).\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.rtruediv`** performs element-wise floating division with the operands reversed (`other / dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.rfloordiv\n",
    "DataFrame.rfloordiv(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Integer division of dataframe and other, element-wise (binary operator rfloordiv).\n",
    "\n",
    "Equivalent to other // dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, floordiv.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rfloordiv` method is used to perform **element-wise integer division** (also known as floor division) between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other // dataframe` instead of `dataframe // other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Floor Division**: The operation computes `other // dataframe` instead of `dataframe // other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be divided by the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise integer division.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Floor Division with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse floor division with a scalar\n",
    "result = df.rfloordiv(10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        inf        0\n",
    "triangle        3        0\n",
    "rectangle       2        0\n",
    "```\n",
    "\n",
    "#### 2. Reverse Floor Division with a Series\n",
    "\n",
    "```python\n",
    "# Reverse floor division with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.rfloordiv(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        inf        0\n",
    "triangle        0        0\n",
    "rectangle       0        0\n",
    "```\n",
    "\n",
    "#### 3. Reverse Floor Division with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse floor division with another DataFrame\n",
    "result = df.rfloordiv(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        inf        0\n",
    "triangle        0        0\n",
    "rectangle       0        0\n",
    "```\n",
    "\n",
    "#### 4. Reverse Floor Division with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse floor division with fill_value\n",
    "result = df.rfloordiv(other, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        inf        0\n",
    "triangle        0        0\n",
    "rectangle       0        0\n",
    "```\n",
    "\n",
    "#### 5. Reverse Floor Division with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse floor division by level\n",
    "result = df.rfloordiv(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `rfloordiv` method is the reverse version of `floordiv`. It is equivalent to `other // dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division (`dataframe // other`).\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.rfloordiv`** performs element-wise integer division with the operands reversed (`other // dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.rmod\n",
    "DataFrame.rmod(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Modulo of dataframe and other, element-wise (binary operator rmod).\n",
    "\n",
    "Equivalent to other % dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, mod.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rmod` method is used to perform **element-wise modulo operation** (remainder after division) between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other % dataframe` instead of `dataframe % other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Modulo Operation**: The operation computes `other % dataframe` instead of `dataframe % other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be used in the modulo operation with the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise modulo operation.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Modulo Operation with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse modulo operation with a scalar\n",
    "result = df.rmod(10)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        NaN       10\n",
    "triangle        1       10\n",
    "rectangle       2       10\n",
    "```\n",
    "\n",
    "#### 2. Reverse Modulo Operation with a Series\n",
    "\n",
    "```python\n",
    "# Reverse modulo operation with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.rmod(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        NaN        1\n",
    "triangle        0        0\n",
    "rectangle       0        0\n",
    "```\n",
    "\n",
    "#### 3. Reverse Modulo Operation with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse modulo operation with another DataFrame\n",
    "result = df.rmod(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        NaN       10\n",
    "triangle        2        0\n",
    "rectangle       3        0\n",
    "```\n",
    "\n",
    "#### 4. Reverse Modulo Operation with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse modulo operation with fill_value\n",
    "result = df.rmod(other, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles  degrees\n",
    "circle        NaN       10\n",
    "triangle        2        0\n",
    "rectangle       3        0\n",
    "```\n",
    "\n",
    "#### 5. Reverse Modulo Operation with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse modulo operation by level\n",
    "result = df.rmod(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles  degrees\n",
    "A circle        NaN      0.0\n",
    "  triangle      0.0      0.0\n",
    "  rectangle     0.0      0.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `rmod` method is the reverse version of `mod`. It is equivalent to `other % dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation (`dataframe % other`).\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.pow`**: Element-wise exponential power.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.rmod`** performs element-wise modulo operation with the operands reversed (`other % dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.rpow\n",
    "DataFrame.rpow(other, axis='columns', level=None, fill_value=None)[source]\n",
    "Get Exponential power of dataframe and other, element-wise (binary operator rpow).\n",
    "\n",
    "Equivalent to other ** dataframe, but with support to substitute a fill_value for missing data in one of the inputs. With reverse version, pow.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, floordiv, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, dict or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}\n",
    "Whether to compare by the index (0 or ‘index’) or columns. (1 or ‘columns’). For Series input, axis to match Series index on.\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "fill_value\n",
    "float or None, default None\n",
    "Fill existing missing (NaN) values, and any new element needed for successful DataFrame alignment, with this value before computation. If data in both corresponding DataFrame locations is missing the result will be missing.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Result of the arithmetic operation.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.add\n",
    "Add DataFrames.\n",
    "\n",
    "DataFrame.sub\n",
    "Subtract DataFrames.\n",
    "\n",
    "DataFrame.mul\n",
    "Multiply DataFrames.\n",
    "\n",
    "DataFrame.div\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.truediv\n",
    "Divide DataFrames (float division).\n",
    "\n",
    "DataFrame.floordiv\n",
    "Divide DataFrames (integer division).\n",
    "\n",
    "DataFrame.mod\n",
    "Calculate modulo (remainder after division).\n",
    "\n",
    "DataFrame.pow\n",
    "Calculate exponential power.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "df\n",
    "           angles  degrees\n",
    "circle          0      360\n",
    "triangle        3      180\n",
    "rectangle       4      360\n",
    "Add a scalar with operator version which return the same results.\n",
    "\n",
    "df + 1\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "df.add(1)\n",
    "           angles  degrees\n",
    "circle          1      361\n",
    "triangle        4      181\n",
    "rectangle       5      361\n",
    "Divide by constant with reverse version.\n",
    "\n",
    "df.div(10)\n",
    "           angles  degrees\n",
    "circle        0.0     36.0\n",
    "triangle      0.3     18.0\n",
    "rectangle     0.4     36.0\n",
    "df.rdiv(10)\n",
    "             angles   degrees\n",
    "circle          inf  0.027778\n",
    "triangle   3.333333  0.055556\n",
    "rectangle  2.500000  0.027778\n",
    "Subtract a list and Series by axis with operator version.\n",
    "\n",
    "df - [1, 2]\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub([1, 2], axis='columns')\n",
    "           angles  degrees\n",
    "circle         -1      358\n",
    "triangle        2      178\n",
    "rectangle       3      358\n",
    "df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
    "       axis='index')\n",
    "           angles  degrees\n",
    "circle         -1      359\n",
    "triangle        2      179\n",
    "rectangle       3      359\n",
    "Multiply a dictionary by axis.\n",
    "\n",
    "df.mul({'angles': 0, 'degrees': 2})\n",
    "            angles  degrees\n",
    "circle           0      720\n",
    "triangle         0      360\n",
    "rectangle        0      720\n",
    "df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
    "            angles  degrees\n",
    "circle           0        0\n",
    "triangle         6      360\n",
    "rectangle       12     1080\n",
    "Multiply a DataFrame of different shape with operator version.\n",
    "\n",
    "other = pd.DataFrame({'angles': [0, 3, 4]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "other\n",
    "           angles\n",
    "circle          0\n",
    "triangle        3\n",
    "rectangle       4\n",
    "df * other\n",
    "           angles  degrees\n",
    "circle          0      NaN\n",
    "triangle        9      NaN\n",
    "rectangle      16      NaN\n",
    "df.mul(other, fill_value=0)\n",
    "           angles  degrees\n",
    "circle          0      0.0\n",
    "triangle        9      0.0\n",
    "rectangle      16      0.0\n",
    "Divide by a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "df_multindex\n",
    "             angles  degrees\n",
    "A circle          0      360\n",
    "  triangle        3      180\n",
    "  rectangle       4      360\n",
    "B square          4      360\n",
    "  pentagon        5      540\n",
    "  hexagon         6      720\n",
    "df.div(df_multindex, level=1, fill_value=0)\n",
    "             angles  degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rpow` method is used to perform **element-wise exponential power** (raising to a power) between a DataFrame and another object (scalar, sequence, Series, dict, or DataFrame), but with the operands reversed. This means it computes `other ** dataframe` instead of `dataframe ** other`. It is particularly useful when the order of operands matters, and it supports handling missing values (`NaN`) by allowing a `fill_value` to be specified.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Reverse Exponential Power**: The operation computes `other ** dataframe` instead of `dataframe ** other`.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Fill Value**: You can specify a `fill_value` to replace missing values (`NaN`) in either of the inputs before performing the operation.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, dict, or DataFrame. It is the object to be raised to the power of the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`).\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "- **`fill_value`**: A value to replace missing values (`NaN`) in the DataFrame or `other` before performing the operation.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame**: The result of the element-wise exponential power operation.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Reverse Exponential Power with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse exponential power with a scalar\n",
    "result = df.rpow(2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles   degrees\n",
    "circle          1  1.296e+77\n",
    "triangle        8  1.532e+54\n",
    "rectangle      16  1.296e+77\n",
    "```\n",
    "\n",
    "#### 2. Reverse Exponential Power with a Series\n",
    "\n",
    "```python\n",
    "# Reverse exponential power with a Series\n",
    "series = pd.Series([1, 2], index=['angles', 'degrees'])\n",
    "result = df.rpow(series, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles   degrees\n",
    "circle          0  1.296e+77\n",
    "triangle        1  1.532e+54\n",
    "rectangle       1  1.296e+77\n",
    "```\n",
    "\n",
    "#### 3. Reverse Exponential Power with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'angles': [1, 2, 3],\n",
    "                      'degrees': [10, 20, 30]},\n",
    "                     index=['circle', 'triangle', 'rectangle'])\n",
    "\n",
    "# Reverse exponential power with another DataFrame\n",
    "result = df.rpow(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles   degrees\n",
    "circle          0  1.296e+77\n",
    "triangle        9  1.532e+54\n",
    "rectangle      64  1.296e+77\n",
    "```\n",
    "\n",
    "#### 4. Reverse Exponential Power with `fill_value`\n",
    "\n",
    "```python\n",
    "# Reverse exponential power with fill_value\n",
    "result = df.rpow(other, fill_value=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "           angles   degrees\n",
    "circle          0  1.296e+77\n",
    "triangle        9  1.532e+54\n",
    "rectangle      64  1.296e+77\n",
    "```\n",
    "\n",
    "#### 5. Reverse Exponential Power with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "\n",
    "# Reverse exponential power by level\n",
    "result = df.rpow(df_multindex, level=1, fill_value=0)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "             angles   degrees\n",
    "A circle        NaN      1.0\n",
    "  triangle      1.0      1.0\n",
    "  rectangle     1.0      1.0\n",
    "B square        0.0      0.0\n",
    "  pentagon      0.0      0.0\n",
    "  hexagon       0.0      0.0\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together, and missing values will be filled with `NaN` unless a `fill_value` is specified.\n",
    "- **Reverse Version**: The `rpow` method is the reverse version of `pow`. It is equivalent to `other ** dataframe`.\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.pow`**: Element-wise exponential power (`dataframe ** other`).\n",
    "- **`DataFrame.add`**: Element-wise addition.\n",
    "- **`DataFrame.sub`**: Element-wise subtraction.\n",
    "- **`DataFrame.mul`**: Element-wise multiplication.\n",
    "- **`DataFrame.div`**: Element-wise float division.\n",
    "- **`DataFrame.truediv`**: Element-wise float division.\n",
    "- **`DataFrame.floordiv`**: Element-wise integer division.\n",
    "- **`DataFrame.mod`**: Element-wise modulo operation.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.rpow`** performs element-wise exponential power with the operands reversed (`other ** dataframe`).\n",
    "- It supports alignment of indices and handling of missing values using `fill_value`.\n",
    "- It is part of the flexible arithmetic operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.lt\n",
    "DataFrame.lt(other, axis='columns', level=None)[source]\n",
    "Get Less than of dataframe and other, element-wise (binary operator lt).\n",
    "\n",
    "Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison operators.\n",
    "\n",
    "Equivalent to ==, !=, <=, <, >=, > with support to choose axis (rows or columns) and level for comparison.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’\n",
    "Whether to compare by the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame of bool\n",
    "Result of the comparison.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.eq\n",
    "Compare DataFrames for equality elementwise.\n",
    "\n",
    "DataFrame.ne\n",
    "Compare DataFrames for inequality elementwise.\n",
    "\n",
    "DataFrame.le\n",
    "Compare DataFrames for less than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.lt\n",
    "Compare DataFrames for strictly less than inequality elementwise.\n",
    "\n",
    "DataFrame.ge\n",
    "Compare DataFrames for greater than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.gt\n",
    "Compare DataFrames for strictly greater than inequality elementwise.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together. NaN values are considered different (i.e. NaN != NaN).\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100],\n",
    "                   'revenue': [100, 250, 300]},\n",
    "                  index=['A', 'B', 'C'])\n",
    "df\n",
    "   cost  revenue\n",
    "A   250      100\n",
    "B   150      250\n",
    "C   100      300\n",
    "Comparison with a scalar, using either the operator or method:\n",
    "\n",
    "df == 100\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "df.eq(100)\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "When other is a Series, the columns of a DataFrame are aligned with the index of other and broadcast:\n",
    "\n",
    "df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "Use the method to control the broadcast axis:\n",
    "\n",
    "df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
    "   cost  revenue\n",
    "A  True    False\n",
    "B  True     True\n",
    "C  True     True\n",
    "D  True     True\n",
    "When comparing to an arbitrary sequence, the number of columns must match the number elements in other:\n",
    "\n",
    "df == [250, 100]\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False    False\n",
    "C  False    False\n",
    "Use the method to control the axis:\n",
    "\n",
    "df.eq([250, 250, 100], axis='index')\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C   True    False\n",
    "Compare to a DataFrame of different shape.\n",
    "\n",
    "other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
    "                     index=['A', 'B', 'C', 'D'])\n",
    "other\n",
    "   revenue\n",
    "A      300\n",
    "B      250\n",
    "C      100\n",
    "D      150\n",
    "df.gt(other)\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False    False\n",
    "C  False     True\n",
    "D  False    False\n",
    "Compare to a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
    "                             'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "                            index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
    "                                   ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "df_multindex\n",
    "      cost  revenue\n",
    "Q1 A   250      100\n",
    "   B   150      250\n",
    "   C   100      300\n",
    "Q2 A   150      200\n",
    "   B   300      175\n",
    "   C   220      225\n",
    "df.le(df_multindex, level=1)\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.lt` method is used to perform **element-wise less than comparison** between a DataFrame and another object (scalar, sequence, Series, or DataFrame). It returns a DataFrame of boolean values indicating whether each element in the DataFrame is less than the corresponding element in `other`.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Less Than Comparison**: The operation computes `dataframe < other` element-wise.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Boolean Result**: The result is a DataFrame of boolean values (`True` or `False`).\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, or DataFrame. It is the object to compare with the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`). Default is `'columns'`.\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame of bool**: The result of the element-wise less than comparison.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Less Than Comparison with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100],\n",
    "                   'revenue': [100, 250, 300]},\n",
    "                  index=['A', 'B', 'C'])\n",
    "\n",
    "# Less than comparison with a scalar\n",
    "result = df.lt(200)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B   True    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "#### 2. Less Than Comparison with a Series\n",
    "\n",
    "```python\n",
    "# Less than comparison with a Series\n",
    "series = pd.Series([200, 150], index=['cost', 'revenue'])\n",
    "result = df.lt(series)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B   True    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "#### 3. Less Than Comparison with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'cost': [200, 100, 150],\n",
    "                      'revenue': [150, 200, 250]},\n",
    "                     index=['A', 'B', 'C'])\n",
    "\n",
    "# Less than comparison with another DataFrame\n",
    "result = df.lt(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "#### 4. Less Than Comparison with `axis` Parameter\n",
    "\n",
    "```python\n",
    "# Less than comparison with axis parameter\n",
    "result = df.lt([200, 150], axis='index')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B   True    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "#### 5. Less Than Comparison with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
    "                             'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "                            index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
    "                                   ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "\n",
    "# Less than comparison by level\n",
    "result = df.lt(df_multindex, level=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "       cost  revenue\n",
    "Q1 A  False     True\n",
    "   B  False     True\n",
    "   C  False     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together.\n",
    "- **NaN Values**: NaN values are considered different (i.e., `NaN != NaN`).\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.eq`**: Element-wise equality comparison.\n",
    "- **`DataFrame.ne`**: Element-wise inequality comparison.\n",
    "- **`DataFrame.le`**: Element-wise less than or equal to comparison.\n",
    "- **`DataFrame.lt`**: Element-wise less than comparison.\n",
    "- **`DataFrame.ge`**: Element-wise greater than or equal to comparison.\n",
    "- **`DataFrame.gt`**: Element-wise greater than comparison.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.lt`** performs element-wise less than comparison (`dataframe < other`).\n",
    "- It supports alignment of indices and handling of missing values.\n",
    "- It is part of the flexible comparison operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.gt\n",
    "DataFrame.gt(other, axis='columns', level=None)[source]\n",
    "Get Greater than of dataframe and other, element-wise (binary operator gt).\n",
    "\n",
    "Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison operators.\n",
    "\n",
    "Equivalent to ==, !=, <=, <, >=, > with support to choose axis (rows or columns) and level for comparison.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’\n",
    "Whether to compare by the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame of bool\n",
    "Result of the comparison.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.eq\n",
    "Compare DataFrames for equality elementwise.\n",
    "\n",
    "DataFrame.ne\n",
    "Compare DataFrames for inequality elementwise.\n",
    "\n",
    "DataFrame.le\n",
    "Compare DataFrames for less than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.lt\n",
    "Compare DataFrames for strictly less than inequality elementwise.\n",
    "\n",
    "DataFrame.ge\n",
    "Compare DataFrames for greater than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.gt\n",
    "Compare DataFrames for strictly greater than inequality elementwise.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together. NaN values are considered different (i.e. NaN != NaN).\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100],\n",
    "                   'revenue': [100, 250, 300]},\n",
    "                  index=['A', 'B', 'C'])\n",
    "df\n",
    "   cost  revenue\n",
    "A   250      100\n",
    "B   150      250\n",
    "C   100      300\n",
    "Comparison with a scalar, using either the operator or method:\n",
    "\n",
    "df == 100\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "df.eq(100)\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "When other is a Series, the columns of a DataFrame are aligned with the index of other and broadcast:\n",
    "\n",
    "df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "Use the method to control the broadcast axis:\n",
    "\n",
    "df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
    "   cost  revenue\n",
    "A  True    False\n",
    "B  True     True\n",
    "C  True     True\n",
    "D  True     True\n",
    "When comparing to an arbitrary sequence, the number of columns must match the number elements in other:\n",
    "\n",
    "df == [250, 100]\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False    False\n",
    "C  False    False\n",
    "Use the method to control the axis:\n",
    "\n",
    "df.eq([250, 250, 100], axis='index')\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C   True    False\n",
    "Compare to a DataFrame of different shape.\n",
    "\n",
    "other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
    "                     index=['A', 'B', 'C', 'D'])\n",
    "other\n",
    "   revenue\n",
    "A      300\n",
    "B      250\n",
    "C      100\n",
    "D      150\n",
    "df.gt(other)\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False    False\n",
    "C  False     True\n",
    "D  False    False\n",
    "Compare to a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
    "                             'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "                            index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
    "                                   ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "df_multindex\n",
    "      cost  revenue\n",
    "Q1 A   250      100\n",
    "   B   150      250\n",
    "   C   100      300\n",
    "Q2 A   150      200\n",
    "   B   300      175\n",
    "   C   220      225\n",
    "df.le(df_multindex, level=1)\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.gt` method is used to perform **element-wise greater than comparison** between a DataFrame and another object (scalar, sequence, Series, or DataFrame). It returns a DataFrame of boolean values indicating whether each element in the DataFrame is greater than the corresponding element in `other`.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Greater Than Comparison**: The operation computes `dataframe > other` element-wise.\n",
    "- **Alignment**: The operation aligns the indices of the DataFrame and the `other` object.\n",
    "- **Boolean Result**: The result is a DataFrame of boolean values (`True` or `False`).\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- **`other`**: This can be a scalar, sequence, Series, or DataFrame. It is the object to compare with the DataFrame.\n",
    "- **`axis`**: Determines whether to align the operation by index (`0` or `'index'`) or columns (`1` or `'columns'`). Default is `'columns'`.\n",
    "- **`level`**: If the DataFrame has a MultiIndex, this parameter specifies the level to broadcast across.\n",
    "\n",
    "### Returns:\n",
    "\n",
    "- **DataFrame of bool**: The result of the element-wise greater than comparison.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "#### 1. Greater Than Comparison with a Scalar\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100],\n",
    "                   'revenue': [100, 250, 300]},\n",
    "                  index=['A', 'B', 'C'])\n",
    "\n",
    "# Greater than comparison with a scalar\n",
    "result = df.gt(200)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C  False     True\n",
    "```\n",
    "\n",
    "#### 2. Greater Than Comparison with a Series\n",
    "\n",
    "```python\n",
    "# Greater than comparison with a Series\n",
    "series = pd.Series([200, 150], index=['cost', 'revenue'])\n",
    "result = df.gt(series)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C  False     True\n",
    "```\n",
    "\n",
    "#### 3. Greater Than Comparison with Another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'cost': [200, 100, 150],\n",
    "                      'revenue': [150, 200, 250]},\n",
    "                     index=['A', 'B', 'C'])\n",
    "\n",
    "# Greater than comparison with another DataFrame\n",
    "result = df.gt(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B   True     True\n",
    "C  False     True\n",
    "```\n",
    "\n",
    "#### 4. Greater Than Comparison with `axis` Parameter\n",
    "\n",
    "```python\n",
    "# Greater than comparison with axis parameter\n",
    "result = df.gt([200, 150], axis='index')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C  False     True\n",
    "```\n",
    "\n",
    "#### 5. Greater Than Comparison with a MultiIndex DataFrame\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
    "                             'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "                            index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
    "                                   ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "\n",
    "# Greater than comparison by level\n",
    "result = df.gt(df_multindex, level=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "       cost  revenue\n",
    "Q1 A  False    False\n",
    "   B  False    False\n",
    "   C  False    False\n",
    "Q2 A  False    False\n",
    "   B  False     True\n",
    "   C  False    False\n",
    "```\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Mismatched Indices**: If the indices of the DataFrame and `other` do not match, they will be unioned together.\n",
    "- **NaN Values**: NaN values are considered different (i.e., `NaN != NaN`).\n",
    "\n",
    "### Related Methods:\n",
    "\n",
    "- **`DataFrame.eq`**: Element-wise equality comparison.\n",
    "- **`DataFrame.ne`**: Element-wise inequality comparison.\n",
    "- **`DataFrame.le`**: Element-wise less than or equal to comparison.\n",
    "- **`DataFrame.lt`**: Element-wise less than comparison.\n",
    "- **`DataFrame.ge`**: Element-wise greater than or equal to comparison.\n",
    "- **`DataFrame.gt`**: Element-wise greater than comparison.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`DataFrame.gt`** performs element-wise greater than comparison (`dataframe > other`).\n",
    "- It supports alignment of indices and handling of missing values.\n",
    "- It is part of the flexible comparison operation wrappers in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.le\n",
    "DataFrame.le(other, axis='columns', level=None)[source]\n",
    "Get Less than or equal to of dataframe and other, element-wise (binary operator le).\n",
    "\n",
    "Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison operators.\n",
    "\n",
    "Equivalent to ==, !=, <=, <, >=, > with support to choose axis (rows or columns) and level for comparison.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’\n",
    "Whether to compare by the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame of bool\n",
    "Result of the comparison.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.eq\n",
    "Compare DataFrames for equality elementwise.\n",
    "\n",
    "DataFrame.ne\n",
    "Compare DataFrames for inequality elementwise.\n",
    "\n",
    "DataFrame.le\n",
    "Compare DataFrames for less than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.lt\n",
    "Compare DataFrames for strictly less than inequality elementwise.\n",
    "\n",
    "DataFrame.ge\n",
    "Compare DataFrames for greater than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.gt\n",
    "Compare DataFrames for strictly greater than inequality elementwise.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together. NaN values are considered different (i.e. NaN != NaN).\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100],\n",
    "                   'revenue': [100, 250, 300]},\n",
    "                  index=['A', 'B', 'C'])\n",
    "df\n",
    "   cost  revenue\n",
    "A   250      100\n",
    "B   150      250\n",
    "C   100      300\n",
    "Comparison with a scalar, using either the operator or method:\n",
    "\n",
    "df == 100\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "df.eq(100)\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "When other is a Series, the columns of a DataFrame are aligned with the index of other and broadcast:\n",
    "\n",
    "df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "Use the method to control the broadcast axis:\n",
    "\n",
    "df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
    "   cost  revenue\n",
    "A  True    False\n",
    "B  True     True\n",
    "C  True     True\n",
    "D  True     True\n",
    "When comparing to an arbitrary sequence, the number of columns must match the number elements in other:\n",
    "\n",
    "df == [250, 100]\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False    False\n",
    "C  False    False\n",
    "Use the method to control the axis:\n",
    "\n",
    "df.eq([250, 250, 100], axis='index')\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C   True    False\n",
    "Compare to a DataFrame of different shape.\n",
    "\n",
    "other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
    "                     index=['A', 'B', 'C', 'D'])\n",
    "other\n",
    "   revenue\n",
    "A      300\n",
    "B      250\n",
    "C      100\n",
    "D      150\n",
    "df.gt(other)\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False    False\n",
    "C  False     True\n",
    "D  False    False\n",
    "Compare to a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
    "                             'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "                            index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
    "                                   ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "df_multindex\n",
    "      cost  revenue\n",
    "Q1 A   250      100\n",
    "   B   150      250\n",
    "   C   100      300\n",
    "Q2 A   150      200\n",
    "   B   300      175\n",
    "   C   220      225\n",
    "df.le(df_multindex, level=1)\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`pandas.DataFrame.le`** method is used to perform element-wise **\"less than or equal to\"** comparison between a DataFrame and another object (scalar, sequence, Series, or DataFrame). It is one of the flexible comparison methods provided by Pandas, along with `eq`, `ne`, `lt`, `gt`, and `ge`. Below is a detailed explanation of the **`DataFrame.le`** method, including its syntax, parameters, return value, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.le(other, axis='columns', level=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Parameters**\n",
    "\n",
    "| Parameter   | Description                                                                                                                              |\n",
    "| ----------- | ---------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **`other`** | The object to compare with the DataFrame. Can be a scalar, sequence, Series, or DataFrame.                                               |\n",
    "| **`axis`**  | The axis to align the comparison on. <br> - `0` or `'index'`: Compare by index. <br> - `1` or `'columns'`: Compare by columns (default). |\n",
    "| **`level`** | If the DataFrame has a MultiIndex, specify the level to broadcast the comparison across.                                                 |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Return Value**\n",
    "\n",
    "- Returns a **DataFrame of boolean values** (`True` or `False`) indicating the result of the element-wise comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Key Notes**\n",
    "\n",
    "- **Alignment**: The comparison aligns the indices of the DataFrame and the `other` object.\n",
    "- **NaN Handling**: NaN values are considered unequal (i.e., `NaN != NaN`).\n",
    "- **Broadcasting**: If `other` is a scalar or a sequence, it is broadcasted to match the shape of the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Examples**\n",
    "\n",
    "#### **5.1 Comparison with a Scalar**\n",
    "\n",
    "Compare each element of the DataFrame with a scalar value.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'cost': [250, 150, 100], 'revenue': [100, 250, 300]}, index=['A', 'B', 'C'])\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   cost  revenue\n",
    "A   250      100\n",
    "B   150      250\n",
    "C   100      300\n",
    "```\n",
    "\n",
    "```python\n",
    "# Compare with a scalar\n",
    "print(df.le(150))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B   True    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5.2 Comparison with a Series**\n",
    "\n",
    "Compare each column of the DataFrame with a Series. The Series index aligns with the DataFrame columns.\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "s = pd.Series([100, 250], index=['cost', 'revenue'])\n",
    "\n",
    "# Compare with the Series\n",
    "print(df.le(s))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False     True\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5.3 Comparison with Another DataFrame**\n",
    "\n",
    "Compare two DataFrames element-wise. The indices and columns must align.\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "other_df = pd.DataFrame({'cost': [200, 150, 50], 'revenue': [100, 300, 250]}, index=['A', 'B', 'C'])\n",
    "\n",
    "# Compare with the other DataFrame\n",
    "print(df.le(other_df))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B   True     True\n",
    "C  False    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5.4 Comparison Along Rows (`axis='index'`)**\n",
    "\n",
    "Compare each row of the DataFrame with a sequence or Series along the row axis.\n",
    "\n",
    "```python\n",
    "# Compare with a list along rows\n",
    "print(df.le([250, 250, 100], axis='index'))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5.5 Comparison with MultiIndex**\n",
    "\n",
    "Compare a DataFrame with a MultiIndex DataFrame using the `level` parameter.\n",
    "\n",
    "```python\n",
    "# Create a MultiIndex DataFrame\n",
    "df_multiindex = pd.DataFrame(\n",
    "    {'cost': [250, 150, 100, 150, 300, 220], 'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "    index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'], ['A', 'B', 'C', 'A', 'B', 'C']]\n",
    ")\n",
    "print(df_multiindex)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "      cost  revenue\n",
    "Q1 A   250      100\n",
    "   B   150      250\n",
    "   C   100      300\n",
    "Q2 A   150      200\n",
    "   B   300      175\n",
    "   C   220      225\n",
    "```\n",
    "\n",
    "```python\n",
    "# Compare with the original DataFrame at level 1\n",
    "print(df.le(df_multiindex, level=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Comparison with Other Operators**\n",
    "\n",
    "Pandas provides similar methods for other comparison operators:\n",
    "\n",
    "| Method   | Operator | Description              |\n",
    "| -------- | -------- | ------------------------ |\n",
    "| **`eq`** | `==`     | Equal to                 |\n",
    "| **`ne`** | `!=`     | Not equal to             |\n",
    "| **`lt`** | `<`      | Less than                |\n",
    "| **`le`** | `<=`     | Less than or equal to    |\n",
    "| **`gt`** | `>`      | Greater than             |\n",
    "| **`ge`** | `>=`     | Greater than or equal to |\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Practical Use Cases**\n",
    "\n",
    "- **Filtering Data**: Use comparison results to filter rows or columns.\n",
    "- **Conditional Operations**: Perform operations based on comparison results.\n",
    "- **Data Validation**: Check if values in a DataFrame meet certain conditions.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Summary**\n",
    "\n",
    "- The **`DataFrame.le`** method performs element-wise \"less than or equal to\" comparisons.\n",
    "- It supports comparison with scalars, sequences, Series, and DataFrames.\n",
    "- Use the `axis` parameter to control the alignment of the comparison.\n",
    "- Use the `level` parameter for MultiIndex DataFrames.\n",
    "\n",
    "By mastering this method, you can efficiently compare and analyze data in Pandas DataFrames. Let me know if you need further clarification or additional examples!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.ge\n",
    "DataFrame.ge(other, axis='columns', level=None)[source]\n",
    "Get Greater than or equal to of dataframe and other, element-wise (binary operator ge).\n",
    "\n",
    "Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison operators.\n",
    "\n",
    "Equivalent to ==, !=, <=, <, >=, > with support to choose axis (rows or columns) and level for comparison.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’\n",
    "Whether to compare by the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame of bool\n",
    "Result of the comparison.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.eq\n",
    "Compare DataFrames for equality elementwise.\n",
    "\n",
    "DataFrame.ne\n",
    "Compare DataFrames for inequality elementwise.\n",
    "\n",
    "DataFrame.le\n",
    "Compare DataFrames for less than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.lt\n",
    "Compare DataFrames for strictly less than inequality elementwise.\n",
    "\n",
    "DataFrame.ge\n",
    "Compare DataFrames for greater than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.gt\n",
    "Compare DataFrames for strictly greater than inequality elementwise.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together. NaN values are considered different (i.e. NaN != NaN).\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100],\n",
    "                   'revenue': [100, 250, 300]},\n",
    "                  index=['A', 'B', 'C'])\n",
    "df\n",
    "   cost  revenue\n",
    "A   250      100\n",
    "B   150      250\n",
    "C   100      300\n",
    "Comparison with a scalar, using either the operator or method:\n",
    "\n",
    "df == 100\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "df.eq(100)\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "When other is a Series, the columns of a DataFrame are aligned with the index of other and broadcast:\n",
    "\n",
    "df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "Use the method to control the broadcast axis:\n",
    "\n",
    "df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
    "   cost  revenue\n",
    "A  True    False\n",
    "B  True     True\n",
    "C  True     True\n",
    "D  True     True\n",
    "When comparing to an arbitrary sequence, the number of columns must match the number elements in other:\n",
    "\n",
    "df == [250, 100]\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False    False\n",
    "C  False    False\n",
    "Use the method to control the axis:\n",
    "\n",
    "df.eq([250, 250, 100], axis='index')\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C   True    False\n",
    "Compare to a DataFrame of different shape.\n",
    "\n",
    "other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
    "                     index=['A', 'B', 'C', 'D'])\n",
    "other\n",
    "   revenue\n",
    "A      300\n",
    "B      250\n",
    "C      100\n",
    "D      150\n",
    "df.gt(other)\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False    False\n",
    "C  False     True\n",
    "D  False    False\n",
    "Compare to a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
    "                             'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "                            index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
    "                                   ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "df_multindex\n",
    "      cost  revenue\n",
    "Q1 A   250      100\n",
    "   B   150      250\n",
    "   C   100      300\n",
    "Q2 A   150      200\n",
    "   B   300      175\n",
    "   C   220      225\n",
    "df.le(df_multindex, level=1)\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.ge` method is used to perform element-wise comparison of a DataFrame with another object (scalar, sequence, Series, or DataFrame) to check if the elements in the DataFrame are **greater than or equal to** the corresponding elements in the other object. The method returns a DataFrame of boolean values indicating the result of the comparison.\n",
    "\n",
    "Here’s a detailed explanation of the syntax, parameters, and usage:\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.ge(other, axis='columns', level=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`**:\n",
    "\n",
    "   - The object to compare with the DataFrame.\n",
    "   - Can be a scalar, sequence, Series, or DataFrame.\n",
    "   - If `other` is a DataFrame, it must have the same shape as the original DataFrame unless alignment is performed using `axis` or `level`.\n",
    "\n",
    "2. **`axis`**:\n",
    "\n",
    "   - Determines the axis along which the comparison is performed.\n",
    "   - Options:\n",
    "     - `0` or `'index'`: Compare along the index (rows).\n",
    "     - `1` or `'columns'`: Compare along the columns (default).\n",
    "   - If `other` is a Series, the alignment is performed based on the `axis`.\n",
    "\n",
    "3. **`level`**:\n",
    "   - Used when comparing with a MultiIndex DataFrame.\n",
    "   - Specifies the level of the MultiIndex to align the comparison.\n",
    "   - If `None`, the comparison is performed element-wise without considering the MultiIndex levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- A DataFrame of boolean values (`True` or `False`) indicating whether each element in the original DataFrame is **greater than or equal to** the corresponding element in `other`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- Mismatched indices between the DataFrame and `other` will be unioned, and missing values will be filled with `NaN`.\n",
    "- `NaN` values are considered unequal (i.e., `NaN != NaN`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Comparison with a Scalar**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100], 'revenue': [100, 250, 300]}, index=['A', 'B', 'C'])\n",
    "\n",
    "# Compare if elements are greater than or equal to 150\n",
    "result = df.ge(150)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B   True     True\n",
    "C  False     True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Comparison with a Series**\n",
    "\n",
    "```python\n",
    "# Compare with a Series (aligned by index)\n",
    "other = pd.Series([100, 250], index=['cost', 'revenue'])\n",
    "result = df.ge(other, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B   True     True\n",
    "C   True     True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Comparison with a DataFrame**\n",
    "\n",
    "```python\n",
    "# Compare with another DataFrame\n",
    "other_df = pd.DataFrame({'cost': [200, 150, 50], 'revenue': [50, 300, 350]}, index=['A', 'B', 'C'])\n",
    "result = df.ge(other_df)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Comparison with a MultiIndex DataFrame**\n",
    "\n",
    "```python\n",
    "# Create a MultiIndex DataFrame\n",
    "df_multiindex = pd.DataFrame(\n",
    "    {'cost': [250, 150, 100, 150, 300, 220], 'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "    index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'], ['A', 'B', 'C', 'A', 'B', 'C']]\n",
    ")\n",
    "\n",
    "# Compare with another DataFrame at a specific MultiIndex level\n",
    "result = df.ge(df_multiindex, level=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "- `DataFrame.eq`: Equality comparison.\n",
    "- `DataFrame.ne`: Inequality comparison.\n",
    "- `DataFrame.le`: Less than or equal to comparison.\n",
    "- `DataFrame.lt`: Less than comparison.\n",
    "- `DataFrame.gt`: Greater than comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "\n",
    "- Use `axis` to control the alignment of the comparison (rows or columns).\n",
    "- Use `level` for MultiIndex DataFrames to specify the level of alignment.\n",
    "- The result is a boolean DataFrame indicating the comparison result.\n",
    "\n",
    "This method is particularly useful for filtering or conditional operations in data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.ne\n",
    "DataFrame.ne(other, axis='columns', level=None)[source]\n",
    "Get Not equal to of dataframe and other, element-wise (binary operator ne).\n",
    "\n",
    "Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison operators.\n",
    "\n",
    "Equivalent to ==, !=, <=, <, >=, > with support to choose axis (rows or columns) and level for comparison.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’\n",
    "Whether to compare by the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame of bool\n",
    "Result of the comparison.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.eq\n",
    "Compare DataFrames for equality elementwise.\n",
    "\n",
    "DataFrame.ne\n",
    "Compare DataFrames for inequality elementwise.\n",
    "\n",
    "DataFrame.le\n",
    "Compare DataFrames for less than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.lt\n",
    "Compare DataFrames for strictly less than inequality elementwise.\n",
    "\n",
    "DataFrame.ge\n",
    "Compare DataFrames for greater than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.gt\n",
    "Compare DataFrames for strictly greater than inequality elementwise.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together. NaN values are considered different (i.e. NaN != NaN).\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100],\n",
    "                   'revenue': [100, 250, 300]},\n",
    "                  index=['A', 'B', 'C'])\n",
    "df\n",
    "   cost  revenue\n",
    "A   250      100\n",
    "B   150      250\n",
    "C   100      300\n",
    "Comparison with a scalar, using either the operator or method:\n",
    "\n",
    "df == 100\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "df.eq(100)\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "When other is a Series, the columns of a DataFrame are aligned with the index of other and broadcast:\n",
    "\n",
    "df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "Use the method to control the broadcast axis:\n",
    "\n",
    "df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
    "   cost  revenue\n",
    "A  True    False\n",
    "B  True     True\n",
    "C  True     True\n",
    "D  True     True\n",
    "When comparing to an arbitrary sequence, the number of columns must match the number elements in other:\n",
    "\n",
    "df == [250, 100]\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False    False\n",
    "C  False    False\n",
    "Use the method to control the axis:\n",
    "\n",
    "df.eq([250, 250, 100], axis='index')\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C   True    False\n",
    "Compare to a DataFrame of different shape.\n",
    "\n",
    "other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
    "                     index=['A', 'B', 'C', 'D'])\n",
    "other\n",
    "   revenue\n",
    "A      300\n",
    "B      250\n",
    "C      100\n",
    "D      150\n",
    "df.gt(other)\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False    False\n",
    "C  False     True\n",
    "D  False    False\n",
    "Compare to a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
    "                             'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "                            index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
    "                                   ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "df_multindex\n",
    "      cost  revenue\n",
    "Q1 A   250      100\n",
    "   B   150      250\n",
    "   C   100      300\n",
    "Q2 A   150      200\n",
    "   B   300      175\n",
    "   C   220      225\n",
    "df.le(df_multindex, level=1)\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.ne` method is used to perform element-wise **inequality comparison** between a DataFrame and another object (scalar, sequence, Series, or DataFrame). It checks if the elements in the DataFrame are **not equal** to the corresponding elements in the other object. The method returns a DataFrame of boolean values (`True` or `False`) indicating the result of the comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.ne(other, axis='columns', level=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`**:\n",
    "\n",
    "   - The object to compare with the DataFrame.\n",
    "   - Can be a scalar, sequence, Series, or DataFrame.\n",
    "   - If `other` is a DataFrame, it must have the same shape as the original DataFrame unless alignment is performed using `axis` or `level`.\n",
    "\n",
    "2. **`axis`**:\n",
    "\n",
    "   - Determines the axis along which the comparison is performed.\n",
    "   - Options:\n",
    "     - `0` or `'index'`: Compare along the index (rows).\n",
    "     - `1` or `'columns'`: Compare along the columns (default).\n",
    "   - If `other` is a Series, the alignment is performed based on the `axis`.\n",
    "\n",
    "3. **`level`**:\n",
    "   - Used when comparing with a MultiIndex DataFrame.\n",
    "   - Specifies the level of the MultiIndex to align the comparison.\n",
    "   - If `None`, the comparison is performed element-wise without considering the MultiIndex levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- A DataFrame of boolean values (`True` or `False`) indicating whether each element in the original DataFrame is **not equal** to the corresponding element in `other`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- Mismatched indices between the DataFrame and `other` will be unioned, and missing values will be filled with `NaN`.\n",
    "- `NaN` values are considered unequal (i.e., `NaN != NaN`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Comparison with a Scalar**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100], 'revenue': [100, 250, 300]}, index=['A', 'B', 'C'])\n",
    "\n",
    "# Compare if elements are not equal to 150\n",
    "result = df.ne(150)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False     True\n",
    "C   True     True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Comparison with a Series**\n",
    "\n",
    "```python\n",
    "# Compare with a Series (aligned by index)\n",
    "other = pd.Series([100, 250], index=['cost', 'revenue'])\n",
    "result = df.ne(other, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Comparison with a DataFrame**\n",
    "\n",
    "```python\n",
    "# Compare with another DataFrame\n",
    "other_df = pd.DataFrame({'cost': [200, 150, 50], 'revenue': [50, 300, 350]}, index=['A', 'B', 'C'])\n",
    "result = df.ne(other_df)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False     True\n",
    "C   True     True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Comparison with a MultiIndex DataFrame**\n",
    "\n",
    "```python\n",
    "# Create a MultiIndex DataFrame\n",
    "df_multiindex = pd.DataFrame(\n",
    "    {'cost': [250, 150, 100, 150, 300, 220], 'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "    index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'], ['A', 'B', 'C', 'A', 'B', 'C']]\n",
    ")\n",
    "\n",
    "# Compare with another DataFrame at a specific MultiIndex level\n",
    "result = df.ne(df_multiindex, level=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        cost  revenue\n",
    "Q1 A  False    False\n",
    "   B  False    False\n",
    "   C  False    False\n",
    "Q2 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "- `DataFrame.eq`: Equality comparison.\n",
    "- `DataFrame.le`: Less than or equal to comparison.\n",
    "- `DataFrame.lt`: Less than comparison.\n",
    "- `DataFrame.ge`: Greater than or equal to comparison.\n",
    "- `DataFrame.gt`: Greater than comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "\n",
    "- Use `axis` to control the alignment of the comparison (rows or columns).\n",
    "- Use `level` for MultiIndex DataFrames to specify the level of alignment.\n",
    "- The result is a boolean DataFrame indicating the comparison result.\n",
    "\n",
    "This method is particularly useful for filtering or conditional operations in data analysis. For example, you can use it to identify mismatched values between two datasets or filter out rows/columns that do not meet certain conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.eq\n",
    "DataFrame.eq(other, axis='columns', level=None)[source]\n",
    "Get Equal to of dataframe and other, element-wise (binary operator eq).\n",
    "\n",
    "Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison operators.\n",
    "\n",
    "Equivalent to ==, !=, <=, <, >=, > with support to choose axis (rows or columns) and level for comparison.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "scalar, sequence, Series, or DataFrame\n",
    "Any single or multiple element data structure, or list-like object.\n",
    "\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default ‘columns’\n",
    "Whether to compare by the index (0 or ‘index’) or columns (1 or ‘columns’).\n",
    "\n",
    "level\n",
    "int or label\n",
    "Broadcast across a level, matching Index values on the passed MultiIndex level.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame of bool\n",
    "Result of the comparison.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.eq\n",
    "Compare DataFrames for equality elementwise.\n",
    "\n",
    "DataFrame.ne\n",
    "Compare DataFrames for inequality elementwise.\n",
    "\n",
    "DataFrame.le\n",
    "Compare DataFrames for less than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.lt\n",
    "Compare DataFrames for strictly less than inequality elementwise.\n",
    "\n",
    "DataFrame.ge\n",
    "Compare DataFrames for greater than inequality or equality elementwise.\n",
    "\n",
    "DataFrame.gt\n",
    "Compare DataFrames for strictly greater than inequality elementwise.\n",
    "\n",
    "Notes\n",
    "\n",
    "Mismatched indices will be unioned together. NaN values are considered different (i.e. NaN != NaN).\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100],\n",
    "                   'revenue': [100, 250, 300]},\n",
    "                  index=['A', 'B', 'C'])\n",
    "df\n",
    "   cost  revenue\n",
    "A   250      100\n",
    "B   150      250\n",
    "C   100      300\n",
    "Comparison with a scalar, using either the operator or method:\n",
    "\n",
    "df == 100\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "df.eq(100)\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "When other is a Series, the columns of a DataFrame are aligned with the index of other and broadcast:\n",
    "\n",
    "df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "Use the method to control the broadcast axis:\n",
    "\n",
    "df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
    "   cost  revenue\n",
    "A  True    False\n",
    "B  True     True\n",
    "C  True     True\n",
    "D  True     True\n",
    "When comparing to an arbitrary sequence, the number of columns must match the number elements in other:\n",
    "\n",
    "df == [250, 100]\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False    False\n",
    "C  False    False\n",
    "Use the method to control the axis:\n",
    "\n",
    "df.eq([250, 250, 100], axis='index')\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C   True    False\n",
    "Compare to a DataFrame of different shape.\n",
    "\n",
    "other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
    "                     index=['A', 'B', 'C', 'D'])\n",
    "other\n",
    "   revenue\n",
    "A      300\n",
    "B      250\n",
    "C      100\n",
    "D      150\n",
    "df.gt(other)\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False    False\n",
    "C  False     True\n",
    "D  False    False\n",
    "Compare to a MultiIndex by level.\n",
    "\n",
    "df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
    "                             'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "                            index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
    "                                   ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "df_multindex\n",
    "      cost  revenue\n",
    "Q1 A   250      100\n",
    "   B   150      250\n",
    "   C   100      300\n",
    "Q2 A   150      200\n",
    "   B   300      175\n",
    "   C   220      225\n",
    "df.le(df_multindex, level=1)\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.eq` method is used to perform element-wise **equality comparison** between a DataFrame and another object (scalar, sequence, Series, or DataFrame). It checks if the elements in the DataFrame are **equal** to the corresponding elements in the other object. The method returns a DataFrame of boolean values (`True` or `False`) indicating the result of the comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.eq(other, axis='columns', level=None)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`other`**:\n",
    "\n",
    "   - The object to compare with the DataFrame.\n",
    "   - Can be a scalar, sequence, Series, or DataFrame.\n",
    "   - If `other` is a DataFrame, it must have the same shape as the original DataFrame unless alignment is performed using `axis` or `level`.\n",
    "\n",
    "2. **`axis`**:\n",
    "\n",
    "   - Determines the axis along which the comparison is performed.\n",
    "   - Options:\n",
    "     - `0` or `'index'`: Compare along the index (rows).\n",
    "     - `1` or `'columns'`: Compare along the columns (default).\n",
    "   - If `other` is a Series, the alignment is performed based on the `axis`.\n",
    "\n",
    "3. **`level`**:\n",
    "   - Used when comparing with a MultiIndex DataFrame.\n",
    "   - Specifies the level of the MultiIndex to align the comparison.\n",
    "   - If `None`, the comparison is performed element-wise without considering the MultiIndex levels.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- A DataFrame of boolean values (`True` or `False`) indicating whether each element in the original DataFrame is **equal** to the corresponding element in `other`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Notes**\n",
    "\n",
    "- Mismatched indices between the DataFrame and `other` will be unioned, and missing values will be filled with `NaN`.\n",
    "- `NaN` values are considered unequal (i.e., `NaN != NaN`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Comparison with a Scalar**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'cost': [250, 150, 100], 'revenue': [100, 250, 300]}, index=['A', 'B', 'C'])\n",
    "\n",
    "# Compare if elements are equal to 100\n",
    "result = df.eq(100)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Comparison with a Series**\n",
    "\n",
    "```python\n",
    "# Compare with a Series (aligned by index)\n",
    "other = pd.Series([100, 250], index=['cost', 'revenue'])\n",
    "result = df.eq(other, axis='columns')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False     True\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Comparison with a DataFrame**\n",
    "\n",
    "```python\n",
    "# Compare with another DataFrame\n",
    "other_df = pd.DataFrame({'cost': [250, 150, 50], 'revenue': [100, 250, 350]}, index=['A', 'B', 'C'])\n",
    "result = df.eq(other_df)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True     True\n",
    "C  False    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Comparison with a MultiIndex DataFrame**\n",
    "\n",
    "```python\n",
    "# Create a MultiIndex DataFrame\n",
    "df_multiindex = pd.DataFrame(\n",
    "    {'cost': [250, 150, 100, 150, 300, 220], 'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "    index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'], ['A', 'B', 'C', 'A', 'B', 'C']]\n",
    ")\n",
    "\n",
    "# Compare with another DataFrame at a specific MultiIndex level\n",
    "result = df.eq(df_multiindex, level=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "        cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False    False\n",
    "   B  False    False\n",
    "   C  False    False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "- `DataFrame.ne`: Inequality comparison.\n",
    "- `DataFrame.le`: Less than or equal to comparison.\n",
    "- `DataFrame.lt`: Less than comparison.\n",
    "- `DataFrame.ge`: Greater than or equal to comparison.\n",
    "- `DataFrame.gt`: Greater than comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "\n",
    "- Use `axis` to control the alignment of the comparison (rows or columns).\n",
    "- Use `level` for MultiIndex DataFrames to specify the level of alignment.\n",
    "- The result is a boolean DataFrame indicating the comparison result.\n",
    "\n",
    "This method is particularly useful for filtering or conditional operations in data analysis. For example, you can use it to identify matching values between two datasets or filter rows/columns that meet specific conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.combine\n",
    "DataFrame.combine(other, func, fill_value=None, overwrite=True)[source]\n",
    "Perform column-wise combine with another DataFrame.\n",
    "\n",
    "Combines a DataFrame with other DataFrame using func to element-wise combine columns. The row and column indexes of the resulting DataFrame will be the union of the two.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "DataFrame\n",
    "The DataFrame to merge column-wise.\n",
    "\n",
    "func\n",
    "function\n",
    "Function that takes two series as inputs and return a Series or a scalar. Used to merge the two dataframes column by columns.\n",
    "\n",
    "fill_value\n",
    "scalar value, default None\n",
    "The value to fill NaNs with prior to passing any column to the merge func.\n",
    "\n",
    "overwrite\n",
    "bool, default True\n",
    "If True, columns in self that do not exist in other will be overwritten with NaNs.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Combination of the provided DataFrames.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.combine_first\n",
    "Combine two DataFrame objects and default to non-null values in frame calling the method.\n",
    "\n",
    "Examples\n",
    "\n",
    "Combine using a simple function that chooses the smaller column.\n",
    "\n",
    "df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
    "df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
    "take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
    "df1.combine(df2, take_smaller)\n",
    "   A  B\n",
    "0  0  3\n",
    "1  0  3\n",
    "Example using a true element-wise combine function.\n",
    "\n",
    "df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n",
    "df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
    "df1.combine(df2, np.minimum)\n",
    "   A  B\n",
    "0  1  2\n",
    "1  0  3\n",
    "Using fill_value fills Nones prior to passing the column to the merge function.\n",
    "\n",
    "df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
    "df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
    "df1.combine(df2, take_smaller, fill_value=-5)\n",
    "   A    B\n",
    "0  0 -5.0\n",
    "1  0  4.0\n",
    "However, if the same element in both dataframes is None, that None is preserved\n",
    "\n",
    "df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
    "df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n",
    "df1.combine(df2, take_smaller, fill_value=-5)\n",
    "    A    B\n",
    "0  0 -5.0\n",
    "1  0  3.0\n",
    "Example that demonstrates the use of overwrite and behavior when the axis differ between the dataframes.\n",
    "\n",
    "df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
    "df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n",
    "df1.combine(df2, take_smaller)\n",
    "     A    B     C\n",
    "0  NaN  NaN   NaN\n",
    "1  NaN  3.0 -10.0\n",
    "2  NaN  3.0   1.0\n",
    "df1.combine(df2, take_smaller, overwrite=False)\n",
    "     A    B     C\n",
    "0  0.0  NaN   NaN\n",
    "1  0.0  3.0 -10.0\n",
    "2  NaN  3.0   1.0\n",
    "Demonstrating the preference of the passed in dataframe.\n",
    "\n",
    "df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n",
    "df2.combine(df1, take_smaller)\n",
    "   A    B   C\n",
    "0  0.0  NaN NaN\n",
    "1  0.0  3.0 NaN\n",
    "2  NaN  3.0 NaN\n",
    "df2.combine(df1, take_smaller, overwrite=False)\n",
    "     A    B   C\n",
    "0  0.0  NaN NaN\n",
    "1  0.0  3.0 1.0\n",
    "2  NaN  3.0 1.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas.DataFrame.eq()**  \n",
    "The `eq()` method performs **element-wise equality comparison** between a DataFrame and another object (scalar, sequence, Series, or DataFrame). It is equivalent to the `==` operator but provides additional flexibility, such as specifying the axis or level for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "`DataFrame.eq(other, axis='columns', level=None)`\n",
    "\n",
    "**Parameters**:\n",
    "\n",
    "- `other`: Scalar, sequence, Series, or DataFrame to compare with.\n",
    "- `axis`: `{0 or 'index', 1 or 'columns'}`, default `'columns'`.\n",
    "  - `0` or `'index'`: Compare rows.\n",
    "  - `1` or `'columns'`: Compare columns.\n",
    "- `level`: `int` or `label`.\n",
    "  - Used with MultiIndex to specify the level for comparison.\n",
    "\n",
    "**Returns**:\n",
    "\n",
    "- A DataFrame of **boolean values** (`True`/`False`) indicating the result of the comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Behaviors**\n",
    "\n",
    "1. **Element-wise Comparison**:\n",
    "\n",
    "   - Compares each element of the DataFrame with the corresponding element in `other`.\n",
    "   - If `other` is a scalar, it compares all elements in the DataFrame to that scalar.\n",
    "\n",
    "2. **Alignment**:\n",
    "\n",
    "   - If `other` is a Series or DataFrame, the indices/columns are aligned before comparison.\n",
    "   - Mismatched indices/columns are **unioned**, and missing values result in `False`.\n",
    "\n",
    "3. **NaN Handling**:\n",
    "\n",
    "   - `NaN` values are considered **not equal** to any value, including other `NaN` values.\n",
    "\n",
    "4. **Flexibility**:\n",
    "   - Can compare along rows (`axis=0`) or columns (`axis=1`).\n",
    "   - Supports MultiIndex comparisons using the `level` parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **Example 1**: Comparison with a Scalar\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'cost': [250, 150, 100], 'revenue': [100, 250, 300]}, index=['A', 'B', 'C'])\n",
    "df.eq(100)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "- Compares each element in `df` to the scalar `100`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 2**: Comparison with a Series\n",
    "\n",
    "```python\n",
    "df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "```\n",
    "\n",
    "- The Series is aligned with the columns of `df`.\n",
    "- Each column is compared to the corresponding value in the Series.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 3**: Comparison with a Sequence\n",
    "\n",
    "```python\n",
    "df.eq([250, 250, 100], axis='index')\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True    False\n",
    "B  False     True\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "- The sequence `[250, 250, 100]` is compared row-wise (`axis='index'`).\n",
    "- Each row is compared to the corresponding value in the sequence.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 4**: Comparison with a DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({'revenue': [300, 250, 100, 150]}, index=['A', 'B', 'C', 'D'])\n",
    "df.gt(other)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False    False\n",
    "C  False     True\n",
    "D  False    False\n",
    "```\n",
    "\n",
    "- Compares `df` with `other` element-wise.\n",
    "- Missing indices/columns result in `False`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 5**: MultiIndex Comparison\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame(\n",
    "    {'cost': [250, 150, 100, 150, 300, 220], 'revenue': [100, 250, 300, 200, 175, 225]},\n",
    "    index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'], ['A', 'B', 'C', 'A', 'B', 'C']]\n",
    ")\n",
    "df.le(df_multindex, level=1)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True    False\n",
    "```\n",
    "\n",
    "- Compares `df` with `df_multindex` at `level=1` of the MultiIndex.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison with Other Methods**\n",
    "\n",
    "| Method | Description                      |\n",
    "| ------ | -------------------------------- |\n",
    "| `eq()` | Equal to (`==`).                 |\n",
    "| `ne()` | Not equal to (`!=`).             |\n",
    "| `le()` | Less than or equal to (`<=`).    |\n",
    "| `lt()` | Less than (`<`).                 |\n",
    "| `ge()` | Greater than or equal to (`>=`). |\n",
    "| `gt()` | Greater than (`>`).              |\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use**\n",
    "\n",
    "- Perform **element-wise comparisons** with flexibility in axis/level.\n",
    "- Compare DataFrames with mismatched indices/columns.\n",
    "- Handle MultiIndex comparisons.\n",
    "- Replace the `==` operator when additional control is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.combine_first\n",
    "DataFrame.combine_first(other)[source]\n",
    "Update null elements with value in the same location in other.\n",
    "\n",
    "Combine two DataFrame objects by filling null values in one DataFrame with non-null values from other DataFrame. The row and column indexes of the resulting DataFrame will be the union of the two. The resulting dataframe contains the ‘first’ dataframe values and overrides the second one values where both first.loc[index, col] and second.loc[index, col] are not missing values, upon calling first.combine_first(second).\n",
    "\n",
    "Parameters\n",
    ":\n",
    "other\n",
    "DataFrame\n",
    "Provided DataFrame to use to fill null values.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "The result of combining the provided DataFrame with the other object.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.combine\n",
    "Perform series-wise operation on two DataFrames using a given function.\n",
    "\n",
    "Examples\n",
    "\n",
    "df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
    "df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
    "df1.combine_first(df2)\n",
    "     A    B\n",
    "0  1.0  3.0\n",
    "1  0.0  4.0\n",
    "Null values still persist if the location of that null value does not exist in other\n",
    "\n",
    "df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
    "df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
    "df1.combine_first(df2)\n",
    "     A    B    C\n",
    "0  NaN  4.0  NaN\n",
    "1  0.0  3.0  1.0\n",
    "2  NaN  3.0  1.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `combine_first()` method in `pandas` is a powerful function used to handle null values in a DataFrame by filling them with corresponding values from another DataFrame. Here’s a detailed breakdown of how `DataFrame.combine_first()` works, along with its syntax, parameters, return values, examples, and some potential use cases.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.combine_first(other)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **other**: `DataFrame`\n",
    "  - This is the provided DataFrame used to fill null values in the calling DataFrame. The operation compares the indices and columns of both DataFrames to combine them.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrame**\n",
    "  - The result is a new DataFrame containing values from the calling DataFrame (`self`) and filling in its null values with corresponding non-null values from the `other` DataFrame.\n",
    "\n",
    "### Working Principle\n",
    "\n",
    "- The method aligns the two DataFrames by their indices and columns. Wherever a null value exists in the calling DataFrame, it will be filled with the value from the same location in `other` if it’s non-null.\n",
    "- If both DataFrames have a non-null value at the same index and column, the value from the calling DataFrame takes precedence.\n",
    "- The resulting DataFrame will have a union of all indices and columns from both DataFrames.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
    "df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
    "\n",
    "result = df1.combine_first(df2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  1.0  3.0\n",
    "1  0.0  4.0\n",
    "```\n",
    "\n",
    "#### Example 2: Handling Non-Overlapping Indices\n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
    "df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
    "\n",
    "result = df1.combine_first(df2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "0  NaN  4.0  NaN\n",
    "1  0.0  3.0  1.0\n",
    "2  NaN  3.0  1.0\n",
    "```\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "- **Nulls Persist**: In the second example, row 0 in `df1` has null values that are not filled because the index of `df2` does not correspond.\n",
    "- **Union of Indexes/Columns**: The output DataFrame includes rows and columns from both `df1` and `df2`.\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "1. **Data Cleaning**: Quickly fill missing values in a DataFrame when you have another DataFrame with potentially relevant data.\n",
    "\n",
    "2. **Merging Datasets**: Combine datasets from different sources where one might hold partial information, allowing you to consolidate data effectively.\n",
    "\n",
    "3. **Time Series Alignment**: When working with time series data, you can fill missing timestamps in one DataFrame with values from another aligned DataFrame.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **DataFrame.combine()**: This function applies a function element-wise between two DataFrames instead of just filling in missing values. It allows for custom operations rather than simple filling.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `DataFrame.combine_first()` method is a convenient way to manage missing data by leveraging another DataFrame to fill gaps. Its ability to handle different shapes and indices makes it versatile for various data manipulation tasks in `pandas`. If you have any specific scenarios you'd like to address or further questions about this function, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.eq()` method is a powerful and versatile function used for element-wise comparison of values within a DataFrame against another entity (which can be a scalar, Series, another DataFrame, or a list-like object). This comparison returns a DataFrame of boolean values indicating whether each element meets the equality condition.\n",
    "\n",
    "Here's a comprehensive breakdown of the `DataFrame.eq()` functionality:\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.eq(other, axis='columns', level=None)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **other**: `scalar`, `sequence`, `Series`, or `DataFrame`\n",
    "\n",
    "  - The element(s) to compare against the DataFrame. This can be any value or structure such as a scalar, Series, or another DataFrame.\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default is `'columns'`\n",
    "\n",
    "  - Determines the axis to compare along. Use:\n",
    "    - `0` or `'index'` to compare by rows.\n",
    "    - `1` or `'columns'` to compare by columns.\n",
    "\n",
    "- **level**: `int` or `label`, optional\n",
    "  - For DataFrames with a MultiIndex, this indicates which level of the index to use for the comparison.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrame of bool**\n",
    "  - The result is a new DataFrame containing boolean values. Each value is `True` if the corresponding element in the original DataFrame is equal to the value in `other`, and `False` otherwise.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- When comparing different DataFrames, if their indices or columns do not match, they are unioned together.\n",
    "- NaN values are treated as different; thus, comparisons with NaN will yield `False`.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **DataFrame.ne()**: Checks for inequality (element-wise `!=`).\n",
    "- **DataFrame.le()**: Checks for less than or equal to (element-wise `<=`).\n",
    "- **DataFrame.lt()**: Checks for strictly less than (element-wise `<`).\n",
    "- **DataFrame.ge()**: Checks for greater than or equal to (element-wise `>=`).\n",
    "- **DataFrame.gt()**: Checks for strictly greater than (element-wise `>`).\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Scalar Comparison\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'cost': [250, 150, 100],\n",
    "    'revenue': [100, 250, 300]\n",
    "}, index=['A', 'B', 'C'])\n",
    "\n",
    "# Using eq method\n",
    "result = df.eq(100)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False     True\n",
    "B  False    False\n",
    "C   True    False\n",
    "```\n",
    "\n",
    "#### Example 2: Comparison with a Series\n",
    "\n",
    "```python\n",
    "result = df.ne(pd.Series([100, 250], index=[\"cost\", \"revenue\"]))\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B   True    False\n",
    "C  False     True\n",
    "```\n",
    "\n",
    "#### Example 3: Specifying the Axis\n",
    "\n",
    "```python\n",
    "result = df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   cost  revenue\n",
    "A  True    False\n",
    "B  True     True\n",
    "C  True     True\n",
    "D  True     True\n",
    "```\n",
    "\n",
    "#### Example 4: Comparison with a List\n",
    "\n",
    "```python\n",
    "result = df.eq([250, 100], axis='index')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A   True     True\n",
    "B  False    False\n",
    "C  False    False\n",
    "```\n",
    "\n",
    "#### Example 5: Comparing with another DataFrame\n",
    "\n",
    "```python\n",
    "other = pd.DataFrame({\n",
    "    'revenue': [300, 250, 100, 150]\n",
    "}, index=['A', 'B', 'C', 'D'])\n",
    "\n",
    "result = df.gt(other)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    cost  revenue\n",
    "A  False    False\n",
    "B  False    False\n",
    "C  False     True\n",
    "D  False    False\n",
    "```\n",
    "\n",
    "#### Example 6: MultiIndex DataFrame Comparison\n",
    "\n",
    "```python\n",
    "df_multindex = pd.DataFrame({\n",
    "    'cost': [250, 150, 100, 150, 300, 220],\n",
    "    'revenue': [100, 250, 300, 200, 175, 225]\n",
    "}, index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'], ['A', 'B', 'C', 'A', 'B', 'C']])\n",
    "\n",
    "result = df.le(df_multindex, level=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "       cost  revenue\n",
    "Q1 A   True     True\n",
    "   B   True     True\n",
    "   C   True     True\n",
    "Q2 A  False     True\n",
    "   B   True    False\n",
    "   C   True     True\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `DataFrame.eq()` method is an essential tool in the `pandas` library for performing element-wise equality checks. Its flexibility in handling different types of inputs and alignment makes it particularly useful for data analysis and manipulation.\n",
    "\n",
    "If you have any specific scenarios you want to implement or further questions about this method, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas.DataFrame.combine_first()**  \n",
    "This method merges two DataFrames by filling **null (NaN)** values in the first DataFrame with corresponding non-null values from the second. The result combines the indices and columns of both DataFrames, prioritizing non-null values from the first DataFrame where overlaps occur.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "`DataFrame.combine_first(other)`\n",
    "\n",
    "**Parameters**:\n",
    "\n",
    "- `other`: The second DataFrame used to fill null values in the first.\n",
    "\n",
    "**Returns**:\n",
    "\n",
    "- A new DataFrame with merged data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Behaviors**\n",
    "\n",
    "1. **Union of Indices/Columns**:\n",
    "\n",
    "   - The resulting DataFrame includes **all rows** (union of indices) and **all columns** (union of columns) from both DataFrames.\n",
    "   - Missing indices/columns in one DataFrame are added from the other.\n",
    "\n",
    "2. **Priority Rules**:\n",
    "\n",
    "   - If a cell in the **first DataFrame** is **not null**, it is retained.\n",
    "   - If a cell in the first DataFrame is **null**, it is filled with the corresponding value from `other` (if non-null).\n",
    "   - If both DataFrames have **null** in the same cell, the result remains **null**.\n",
    "\n",
    "3. **Non-Overlapping Data**:\n",
    "   - Rows/columns present in `other` but not in the first DataFrame are added to the result.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **Example 1**: Basic Usage\n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
    "df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
    "result = df1.combine_first(df2)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  1.0  3.0\n",
    "1  0.0  4.0\n",
    "```\n",
    "\n",
    "- `df1`’s nulls (row 0) are filled with `df2`’s values.\n",
    "- Non-null values in `df1` (row 1) override `df2`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 2**: Non-Overlapping Indices/Columns\n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
    "df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
    "result = df1.combine_first(df2)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "0  NaN  4.0  NaN\n",
    "1  0.0  3.0  1.0\n",
    "2  NaN  3.0  1.0\n",
    "```\n",
    "\n",
    "- **Row 0**: Only exists in `df1` → `A` remains `NaN`, `B=4.0` (from `df1`).\n",
    "- **Row 1**: `df1.A=0.0` is kept; `df1.B` is `NaN` → filled with `df2.B=3.0`. Column `C` is added from `df2`.\n",
    "- **Row 2**: Exists only in `df2` → `B=3.0` and `C=1.0` are retained; `A` is `NaN` (not present in `df2`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison with Similar Methods**\n",
    "\n",
    "- **`fillna()`**: Requires matching indices/columns. Does not merge new indices/columns.\n",
    "- **`update()`**: Modifies the first DataFrame in-place and does not add new indices/columns.\n",
    "- **`combine()`**: Uses a custom function to resolve overlaps (e.g., `max`, `min`).\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use**\n",
    "\n",
    "- Merge two DataFrames with **partial overlaps** (indices/columns).\n",
    "- Prioritize non-null values from the first DataFrame while filling gaps with the second.\n",
    "- Example use cases: Merging sensor data from overlapping time periods, combining partial datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.apply\n",
    "DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), by_row='compat', engine='python', engine_kwargs=None, **kwargs)[source]\n",
    "Apply a function along an axis of the DataFrame.\n",
    "\n",
    "Objects passed to the function are Series objects whose index is either the DataFrame’s index (axis=0) or the DataFrame’s columns (axis=1). By default (result_type=None), the final return type is inferred from the return type of the applied function. Otherwise, it depends on the result_type argument.\n",
    "\n",
    "Parameters:\n",
    "funcfunction\n",
    "Function to apply to each column or row.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Axis along which the function is applied:\n",
    "\n",
    "0 or ‘index’: apply function to each column.\n",
    "\n",
    "1 or ‘columns’: apply function to each row.\n",
    "\n",
    "rawbool, default False\n",
    "Determines if row or column is passed as a Series or ndarray object:\n",
    "\n",
    "False : passes each row or column as a Series to the function.\n",
    "\n",
    "True : the passed function will receive ndarray objects instead. If you are just applying a NumPy reduction function this will achieve much better performance.\n",
    "\n",
    "result_type{‘expand’, ‘reduce’, ‘broadcast’, None}, default None\n",
    "These only act when axis=1 (columns):\n",
    "\n",
    "‘expand’ : list-like results will be turned into columns.\n",
    "\n",
    "‘reduce’ : returns a Series if possible rather than expanding list-like results. This is the opposite of ‘expand’.\n",
    "\n",
    "‘broadcast’ : results will be broadcast to the original shape of the DataFrame, the original index and columns will be retained.\n",
    "\n",
    "The default behaviour (None) depends on the return value of the applied function: list-like results will be returned as a Series of those. However if the apply function returns a Series these are expanded to columns.\n",
    "\n",
    "argstuple\n",
    "Positional arguments to pass to func in addition to the array/series.\n",
    "\n",
    "by_rowFalse or “compat”, default “compat”\n",
    "Only has an effect when func is a listlike or dictlike of funcs and the func isn’t a string. If “compat”, will if possible first translate the func into pandas methods (e.g. Series().apply(np.sum) will be translated to Series().sum()). If that doesn’t work, will try call to apply again with by_row=True and if that fails, will call apply again with by_row=False (backward compatible). If False, the funcs will be passed the whole Series at once.\n",
    "\n",
    "Added in version 2.1.0.\n",
    "\n",
    "engine{‘python’, ‘numba’}, default ‘python’\n",
    "Choose between the python (default) engine or the numba engine in apply.\n",
    "\n",
    "The numba engine will attempt to JIT compile the passed function, which may result in speedups for large DataFrames. It also supports the following engine_kwargs :\n",
    "\n",
    "nopython (compile the function in nopython mode)\n",
    "\n",
    "nogil (release the GIL inside the JIT compiled function)\n",
    "\n",
    "parallel (try to apply the function in parallel over the DataFrame)\n",
    "\n",
    "Note: Due to limitations within numba/how pandas interfaces with numba, you should only use this if raw=True\n",
    "\n",
    "Note: The numba compiler only supports a subset of valid Python/numpy operations.\n",
    "\n",
    "Please read more about the supported python features and supported numpy features in numba to learn what you can or cannot use in the passed function.\n",
    "\n",
    "Added in version 2.2.0.\n",
    "\n",
    "engine_kwargsdict\n",
    "Pass keyword arguments to the engine. This is currently only used by the numba engine, see the documentation for the engine argument for more information.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to pass as keywords arguments to func.\n",
    "\n",
    "Returns:\n",
    "Series or DataFrame\n",
    "Result of applying func along the given axis of the DataFrame.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.map\n",
    "For elementwise operations.\n",
    "\n",
    "DataFrame.aggregate\n",
    "Only perform aggregating type operations.\n",
    "\n",
    "DataFrame.transform\n",
    "Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "\n",
    "Functions that mutate the passed object can produce unexpected behavior or errors and are not supported. See Mutating with User Defined Function (UDF) methods for more details.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    "df\n",
    "   A  B\n",
    "0  4  9\n",
    "1  4  9\n",
    "2  4  9\n",
    "Using a numpy universal function (in this case the same as np.sqrt(df)):\n",
    "\n",
    "df.apply(np.sqrt)\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "Using a reducing function on either axis\n",
    "\n",
    "df.apply(np.sum, axis=0)\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "df.apply(np.sum, axis=1)\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "Returning a list-like will result in a Series\n",
    "\n",
    "df.apply(lambda x: [1, 2], axis=1)\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "Passing result_type='expand' will expand list-like results to columns of a Dataframe\n",
    "\n",
    "df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "Returning a Series inside the function is similar to passing result_type='expand'. The resulting column names will be the Series index.\n",
    "\n",
    "df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
    "   foo  bar\n",
    "0    1    2\n",
    "1    1    2\n",
    "2    1    2\n",
    "Passing result_type='broadcast' will ensure the same shape result, whether list-like or scalar is returned by the function, and broadcast it along the axis. The resulting column names will be the originals.\n",
    "\n",
    "df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.apply()` method is a versatile function that allows you to apply a specified function along a particular axis of a DataFrame. This can be useful for performing operations on rows or columns, transforming data, or aggregating results. Below is a detailed overview of the method, including its syntax, parameters, return values, and examples.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), by_row='compat', engine='python', engine_kwargs=None, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **func**: `function`\n",
    "\n",
    "  - This is the function to apply to each column or row of the DataFrame.\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default is `0`\n",
    "\n",
    "  - Determines the axis along which the function is applied:\n",
    "    - `0` or `'index'`: apply function to each column.\n",
    "    - `1` or `'columns'`: apply function to each row.\n",
    "\n",
    "- **raw**: `bool`, default is `False`\n",
    "\n",
    "  - If `False`, each row or column is passed as a Series to the function. If `True`, the function receives ndarray objects instead, which can improve performance for NumPy operations.\n",
    "\n",
    "- **result_type**: `{‘expand’, ‘reduce’, ‘broadcast’, None}`, default is `None`\n",
    "\n",
    "  - This parameter only affects the output when `axis=1` (columns):\n",
    "    - `'expand'`: list-like results will be turned into columns.\n",
    "    - `'reduce'`: attempts to return a Series if possible rather than expanding list-like results.\n",
    "    - `'broadcast'`: results will be broadcast to the original shape of the DataFrame.\n",
    "\n",
    "- **args**: `tuple`\n",
    "\n",
    "  - Positional arguments to pass to `func` in addition to the array/Series.\n",
    "\n",
    "- **by_row**: `False` or `\"compat\"`, default is `\"compat\"`\n",
    "\n",
    "  - Affects behavior when `func` is a list-like or dict-like of functions. If `\"compat\"`, it will attempt to translate the function into pandas methods first.\n",
    "\n",
    "- **engine**: `{‘python’, ‘numba’}`, default is `'python'`\n",
    "\n",
    "  - Specifies the engine to use for applying the function. The `numba` engine can provide speedups for large DataFrames when `raw=True`.\n",
    "\n",
    "- **engine_kwargs**: `dict`\n",
    "\n",
    "  - Keyword arguments for the engine, primarily used with the `numba` engine.\n",
    "\n",
    "- **kwargs**: additional keyword arguments\n",
    "  - Additional keyword arguments to pass to `func`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series or DataFrame**\n",
    "  - The result of applying `func` along the specified axis of the DataFrame.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    "print(df)\n",
    "\n",
    "# Applying a NumPy function\n",
    "result = df.apply(np.sqrt)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "```\n",
    "\n",
    "#### Example 2: Reducing Function on Columns\n",
    "\n",
    "```python\n",
    "# Sum of each column\n",
    "column_sum = df.apply(np.sum, axis=0)\n",
    "print(column_sum)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 3: Reducing Function on Rows\n",
    "\n",
    "```python\n",
    "# Sum of each row\n",
    "row_sum = df.apply(np.sum, axis=1)\n",
    "print(row_sum)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 4: Returning List-like Results\n",
    "\n",
    "```python\n",
    "# Returning a list-like result\n",
    "result = df.apply(lambda x: [1, 2], axis=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "#### Example 5: Expanding List-like Results\n",
    "\n",
    "```python\n",
    "# Expanding list-like results into columns\n",
    "result_expand = df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "print(result_expand)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "```\n",
    "\n",
    "#### Example 6: Returning a Series\n",
    "\n",
    "```python\n",
    "# Returning a Series inside the function\n",
    "result_series = df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
    "print(result_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   foo  bar\n",
    "0    1    2\n",
    "1    1    2\n",
    "2    1    2\n",
    "```\n",
    "\n",
    "#### Example 7: Broadcasting Results\n",
    "\n",
    "```python\n",
    "# Broadcasting results to the original shape\n",
    "result_broadcast = df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "print(result_broadcast)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `DataFrame.apply()` method is a powerful tool in `pandas` for applying custom functions to rows or columns of a DataFrame. Its flexibility allows for a wide range of operations, from simple transformations to complex aggregations. If you have specific use cases or further questions about this method, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas.DataFrame.apply()**  \n",
    "The `apply()` method applies a function along an axis (rows or columns) of a DataFrame. It is highly flexible and can be used for transformations, aggregations, or custom operations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "`DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), by_row='compat', engine='python', engine_kwargs=None, **kwargs)`\n",
    "\n",
    "**Parameters**:\n",
    "\n",
    "- `func`: The function to apply. Can be a Python function, lambda, or string (for built-in methods).\n",
    "- `axis`: `{0 or 'index', 1 or 'columns'}`, default `0`.\n",
    "  - `0` or `'index'`: Apply the function to each **column**.\n",
    "  - `1` or `'columns'`: Apply the function to each **row**.\n",
    "- `raw`: `bool`, default `False`.\n",
    "  - `False`: Pass each row/column as a **Series**.\n",
    "  - `True`: Pass each row/column as a **NumPy ndarray** (for better performance with NumPy functions).\n",
    "- `result_type`: `{'expand', 'reduce', 'broadcast', None}`, default `None`.\n",
    "  - `'expand'`: List-like results are turned into **columns**.\n",
    "  - `'reduce'`: Returns a **Series** if possible (opposite of `'expand'`).\n",
    "  - `'broadcast'`: Results are broadcast to the **original shape** of the DataFrame.\n",
    "  - `None`: Infer the return type based on the function's output.\n",
    "- `args`: `tuple`, default `()`.\n",
    "  - Additional positional arguments to pass to `func`.\n",
    "- `by_row`: `False` or `\"compat\"`, default `\"compat\"`.\n",
    "  - Only applies when `func` is a list-like or dict-like of functions.\n",
    "  - `\"compat\"`: Tries to translate `func` into pandas methods first.\n",
    "  - `False`: Passes the whole Series at once.\n",
    "- `engine`: `{'python', 'numba'}`, default `'python'`.\n",
    "  - `'python'`: Uses the standard Python engine.\n",
    "  - `'numba'`: Uses the Numba engine for JIT compilation (requires `raw=True`).\n",
    "- `engine_kwargs`: `dict`, default `None`.\n",
    "  - Keyword arguments for the engine (e.g., `nopython`, `nogil`, `parallel` for Numba).\n",
    "- `**kwargs`: Additional keyword arguments to pass to `func`.\n",
    "\n",
    "**Returns**:\n",
    "\n",
    "- A **Series** or **DataFrame** depending on the function's output and `result_type`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Behaviors**\n",
    "\n",
    "1. **Flexible Function Application**:\n",
    "\n",
    "   - Can apply any function to rows or columns.\n",
    "   - Supports lambda functions, custom functions, and built-in methods.\n",
    "\n",
    "2. **Alignment**:\n",
    "\n",
    "   - If `func` returns a Series or list-like object, the result can be expanded into columns or broadcast to match the original shape.\n",
    "\n",
    "3. **Performance**:\n",
    "\n",
    "   - Using `raw=True` with NumPy functions can improve performance.\n",
    "   - The Numba engine (`engine='numba'`) can further optimize performance for large DataFrames.\n",
    "\n",
    "4. **Result Type Control**:\n",
    "   - Use `result_type` to control how list-like results are handled (`'expand'`, `'reduce'`, `'broadcast'`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **Example 1**: Apply a NumPy Function\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    "df.apply(np.sqrt)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "```\n",
    "\n",
    "- Applies `np.sqrt` element-wise to the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 2**: Apply a Reducing Function\n",
    "\n",
    "```python\n",
    "df.apply(np.sum, axis=0)  # Sum columns\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "```python\n",
    "df.apply(np.sum, axis=1)  # Sum rows\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Applies `np.sum` along the specified axis.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 3**: Return List-like Results\n",
    "\n",
    "```python\n",
    "df.apply(lambda x: [1, 2], axis=1)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "- Returns a Series of lists.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 4**: Expand List-like Results into Columns\n",
    "\n",
    "```python\n",
    "df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "```\n",
    "\n",
    "- Expands the list-like results into separate columns.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 5**: Broadcast Results to Original Shape\n",
    "\n",
    "```python\n",
    "df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "```\n",
    "\n",
    "- Broadcasts the results to match the original DataFrame shape.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example 6**: Use Numba Engine for Performance\n",
    "\n",
    "```python\n",
    "df.apply(np.sum, axis=0, engine='numba', raw=True)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "- Uses the Numba engine for JIT compilation (requires `raw=True`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison with Similar Methods**\n",
    "\n",
    "| Method        | Description                                 |\n",
    "| ------------- | ------------------------------------------- |\n",
    "| `apply()`     | General-purpose function application.       |\n",
    "| `map()`       | Element-wise operations (for Series only).  |\n",
    "| `applymap()`  | Element-wise operations (for DataFrames).   |\n",
    "| `agg()`       | Aggregation operations.                     |\n",
    "| `transform()` | Transformations that return the same shape. |\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use**\n",
    "\n",
    "- Perform **custom transformations** or **aggregations** on rows/columns.\n",
    "- Handle **list-like results** and control their output format.\n",
    "- Optimize performance with `raw=True` or the Numba engine.\n",
    "- Replace loops with vectorized operations for better efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.map\n",
    "DataFrame.map(func, na_action=None, **kwargs)[source]\n",
    "Apply a function to a Dataframe elementwise.\n",
    "\n",
    "Added in version 2.1.0: DataFrame.applymap was deprecated and renamed to DataFrame.map.\n",
    "\n",
    "This method applies a function that accepts and returns a scalar to every element of a DataFrame.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "func\n",
    "callable\n",
    "Python function, returns a single value from a single value.\n",
    "\n",
    "na_action\n",
    "{None, ‘ignore’}, default None\n",
    "If ‘ignore’, propagate NaN values, without passing them to func.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to pass as keywords arguments to func.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Transformed DataFrame.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.apply\n",
    "Apply a function along input axis of DataFrame.\n",
    "\n",
    "DataFrame.replace\n",
    "Replace values given in to_replace with value.\n",
    "\n",
    "Series.map\n",
    "Apply a function elementwise on a Series.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
    "df\n",
    "       0      1\n",
    "0  1.000  2.120\n",
    "1  3.356  4.567\n",
    "df.map(lambda x: len(str(x)))\n",
    "   0  1\n",
    "0  3  4\n",
    "1  5  5\n",
    "Like Series.map, NA values can be ignored:\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_copy.iloc[0, 0] = pd.NA\n",
    "df_copy.map(lambda x: len(str(x)), na_action='ignore')\n",
    "     0  1\n",
    "0  NaN  4\n",
    "1  5.0  5\n",
    "It is also possible to use map with functions that are not lambda functions:\n",
    "\n",
    "df.map(round, ndigits=1)\n",
    "     0    1\n",
    "0  1.0  2.1\n",
    "1  3.4  4.6\n",
    "Note that a vectorized version of func often exists, which will be much faster. You could square each number elementwise.\n",
    "\n",
    "df.map(lambda x: x**2)\n",
    "           0          1\n",
    "0   1.000000   4.494400\n",
    "1  11.262736  20.857489\n",
    "But it’s better to avoid map in that case.\n",
    "\n",
    "df ** 2\n",
    "           0          1\n",
    "0   1.000000   4.494400\n",
    "1  11.262736  20.857489 \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.map()` method is used to apply a specified function element-wise across a DataFrame. It was introduced as a replacement for the deprecated `DataFrame.applymap()` method, allowing for more intuitive and flexible operations on DataFrame cells. Here’s a complete overview of the method, including its syntax, parameters, return values, and examples.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.map(func, na_action=None, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **func**: `callable`\n",
    "\n",
    "  - This is the function that will be applied to each element of the DataFrame. The function must accept a single value and return a single value.\n",
    "\n",
    "- **na_action**: `{None, 'ignore'}`, default is `None`\n",
    "\n",
    "  - If set to `'ignore'`, NaN values will be propagated, meaning they will not be passed to the `func`. Instead, they will be left as NaN in the resulting DataFrame.\n",
    "\n",
    "- **kwargs**: additional keyword arguments\n",
    "  - Additional arguments to pass to `func`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrame**\n",
    "  - A new DataFrame containing the transformed values after applying the function to each element.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Apply a function to count the length of elements when converted to strings\n",
    "result = df.map(lambda x: len(str(x)))\n",
    "print(\"\\nMapped DataFrame:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "       0      1\n",
    "0  1.000  2.120\n",
    "1  3.356  4.567\n",
    "\n",
    "Mapped DataFrame:\n",
    "   0  1\n",
    "0  3  4\n",
    "1  5  5\n",
    "```\n",
    "\n",
    "#### Example 2: Handling NA Values\n",
    "\n",
    "```python\n",
    "# Create a new DataFrame with an NA value\n",
    "df_copy = df.copy()\n",
    "df_copy.iloc[0, 0] = pd.NA\n",
    "print(\"\\nDataFrame with NA value:\")\n",
    "print(df_copy)\n",
    "\n",
    "# Apply function while ignoring NA values\n",
    "result_na_ignore = df_copy.map(lambda x: len(str(x)), na_action='ignore')\n",
    "print(\"\\nMapped DataFrame with NA ignored:\")\n",
    "print(result_na_ignore)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "DataFrame with NA value:\n",
    "       0      1\n",
    "0  <NA>   2.120\n",
    "1  3.356  4.567\n",
    "\n",
    "Mapped DataFrame with NA ignored:\n",
    "     0  1\n",
    "0  NaN  4\n",
    "1  5.0  5\n",
    "```\n",
    "\n",
    "#### Example 3: Using Built-in Functions\n",
    "\n",
    "```python\n",
    "# Using a built-in function to round the values\n",
    "result_round = df.map(round, ndigits=1)\n",
    "print(\"\\nRounded DataFrame:\")\n",
    "print(result_round)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Rounded DataFrame:\n",
    "     0    1\n",
    "0  1.0  2.1\n",
    "1  3.4  4.6\n",
    "```\n",
    "\n",
    "#### Example 4: Squaring Each Element\n",
    "\n",
    "```python\n",
    "# Squaring each number in the DataFrame\n",
    "result_squared = df.map(lambda x: x ** 2)\n",
    "print(\"\\nSquared DataFrame:\")\n",
    "print(result_squared)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Squared DataFrame:\n",
    "           0          1\n",
    "0   1.000000   4.494400\n",
    "1  11.262736  20.857489\n",
    "```\n",
    "\n",
    "#### Example 5: Using Vectorized Operations\n",
    "\n",
    "```python\n",
    "# Alternative way using vectorized operation\n",
    "result_squared_vectorized = df ** 2\n",
    "print(\"\\nSquared DataFrame using vectorized operation:\")\n",
    "print(result_squared_vectorized)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Squared DataFrame using vectorized operation:\n",
    "           0          1\n",
    "0   1.000000   4.494400\n",
    "1  11.262736  20.857489\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `DataFrame.map()` method is a convenient way to transform DataFrame elements using scalar functions. It allows for greater flexibility, especially with respect to handling NaNs. It’s worth noting that for operations that can be vectorized (i.e., applied to an entire DataFrame without looping), it's often more efficient to use vectorized methods or operations directly rather than `map`.\n",
    "\n",
    "If you have any specific questions about using `DataFrame.map()` or need further examples, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.applymap\n",
    "DataFrame.applymap(func, na_action=None, **kwargs)[source]\n",
    "Apply a function to a Dataframe elementwise.\n",
    "\n",
    "Deprecated since version 2.1.0: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
    "\n",
    "This method applies a function that accepts and returns a scalar to every element of a DataFrame.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "func\n",
    "callable\n",
    "Python function, returns a single value from a single value.\n",
    "\n",
    "na_action\n",
    "{None, ‘ignore’}, default None\n",
    "If ‘ignore’, propagate NaN values, without passing them to func.\n",
    "\n",
    "**kwargs\n",
    "Additional keyword arguments to pass as keywords arguments to func.\n",
    "\n",
    "Returns\n",
    ":\n",
    "DataFrame\n",
    "Transformed DataFrame.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.apply\n",
    "Apply a function along input axis of DataFrame.\n",
    "\n",
    "DataFrame.map\n",
    "Apply a function along input axis of DataFrame.\n",
    "\n",
    "DataFrame.replace\n",
    "Replace values given in to_replace with value.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
    "df\n",
    "       0      1\n",
    "0  1.000  2.120\n",
    "1  3.356  4.567\n",
    "df.map(lambda x: len(str(x)))\n",
    "   0  1\n",
    "0  3  4\n",
    "1  5  5 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.applymap()` method was traditionally used to apply a function element-wise to every cell in a DataFrame. However, this method has been deprecated since version 2.1.0, and you should now use `DataFrame.map()` for similar functionality. Here's a comprehensive overview of what `applymap()` was, its parameters, usage, and examples for your understanding.\n",
    "\n",
    "### Overview of `DataFrame.applymap()`\n",
    "\n",
    "**Deprecated Notice:**\n",
    "\n",
    "- Since version 2.1.0, `DataFrame.applymap()` has been deprecated. Instead, you should use `DataFrame.map()`.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.applymap(func, na_action=None, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **func**: `callable`\n",
    "\n",
    "  - A Python function that takes a single value as input and returns a single value as output.\n",
    "\n",
    "- **na_action**: `{None, 'ignore'}`, default is `None`\n",
    "\n",
    "  - If set to `'ignore'`, the method will propagate NaN values, meaning they will not be passed to the function. Instead, they will be preserved in the resulting DataFrame.\n",
    "\n",
    "- **kwargs**: additional keyword arguments\n",
    "  - Additional arguments that can be passed to `func`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrame**\n",
    "  - A new DataFrame with transformed values after applying the specified function element-wise.\n",
    "\n",
    "### Example of `DataFrame.applymap()`\n",
    "\n",
    "Here’s how you would have used `applymap()` before its deprecation:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Applying a function to count the length of elements when converted to strings\n",
    "result = df.applymap(lambda x: len(str(x)))\n",
    "print(\"\\nMapped DataFrame using applymap:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "       0      1\n",
    "0  1.000  2.120\n",
    "1  3.356  4.567\n",
    "\n",
    "Mapped DataFrame using applymap:\n",
    "   0  1\n",
    "0  3  4\n",
    "1  5  5\n",
    "```\n",
    "\n",
    "### Transition to `DataFrame.map()`\n",
    "\n",
    "Since `applymap()` has been deprecated, you should use `map()` for similar functionality:\n",
    "\n",
    "#### Example Using `DataFrame.map()`\n",
    "\n",
    "```python\n",
    "# Using DataFrame.map instead of deprecated applymap\n",
    "result_map = df.map(lambda x: len(str(x)))\n",
    "print(\"\\nMapped DataFrame using map:\")\n",
    "print(result_map)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Mapped DataFrame using map:\n",
    "   0  1\n",
    "0  3  4\n",
    "1  5  5\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "While `DataFrame.applymap()` was once the go-to method for applying functions element-wise across a DataFrame, you should now utilize `DataFrame.map()` to achieve the same effect. Both methods allowed for the transformation of DataFrame elements, but `map()` is now the recommended approach moving forward.\n",
    "\n",
    "If you have any further questions about `DataFrame.map()` or how to handle specific transformations, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.map` method is used to apply a function **element-wise** to every element in a DataFrame. It is a versatile method that allows you to transform each element of the DataFrame using a custom function. This method was introduced in **pandas 2.1.0** as a replacement for the deprecated `DataFrame.applymap`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.map(func, na_action=None, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "1. **`func`**:\n",
    "\n",
    "   - A Python function (or callable) that takes a single value as input and returns a single value.\n",
    "   - This function is applied to each element of the DataFrame.\n",
    "\n",
    "2. **`na_action`**:\n",
    "\n",
    "   - Controls how `NaN` values are handled.\n",
    "   - Options:\n",
    "     - `None` (default): `NaN` values are passed to the function.\n",
    "     - `'ignore'`: `NaN` values are propagated without being passed to the function.\n",
    "\n",
    "3. **`**kwargs`\\*\\*:\n",
    "   - Additional keyword arguments to pass to the function `func`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- A **DataFrame** with the same shape as the original, where each element is the result of applying the function `func`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "\n",
    "- The `map` method is **element-wise**, meaning the function is applied to each individual element of the DataFrame.\n",
    "- It is similar to `Series.map` but works on entire DataFrames.\n",
    "- For operations that can be vectorized (e.g., mathematical operations), avoid using `map` and use direct DataFrame operations instead, as they are faster.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Basic Usage with a Lambda Function**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Input DataFrame:**\n",
    "\n",
    "```\n",
    "       0      1\n",
    "0  1.000  2.120\n",
    "1  3.356  4.567\n",
    "```\n",
    "\n",
    "```python\n",
    "# Apply a lambda function to calculate the length of the string representation of each element\n",
    "result = df.map(lambda x: len(str(x)))\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   0  1\n",
    "0  3  4\n",
    "1  5  5\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Handling NaN Values with `na_action='ignore'`**\n",
    "\n",
    "```python\n",
    "# Create a copy of the DataFrame and introduce a NaN value\n",
    "df_copy = df.copy()\n",
    "df_copy.iloc[0, 0] = pd.NA\n",
    "\n",
    "# Apply the same lambda function but ignore NaN values\n",
    "result = df_copy.map(lambda x: len(str(x)), na_action='ignore')\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     0  1\n",
    "0  NaN  4\n",
    "1  5.0  5\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Using a Built-in Function with Additional Arguments**\n",
    "\n",
    "```python\n",
    "# Use the `round` function to round each element to 1 decimal place\n",
    "result = df.map(round, ndigits=1)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     0    1\n",
    "0  1.0  2.1\n",
    "1  3.4  4.6\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Avoiding `map` for Vectorized Operations**\n",
    "\n",
    "```python\n",
    "# Square each element using a lambda function\n",
    "result = df.map(lambda x: x**2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           0          1\n",
    "0   1.000000   4.494400\n",
    "1  11.262736  20.857489\n",
    "```\n",
    "\n",
    "However, for such operations, it is better to use direct DataFrame operations for better performance:\n",
    "\n",
    "```python\n",
    "# Vectorized operation (faster and more efficient)\n",
    "result = df ** 2\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           0          1\n",
    "0   1.000000   4.494400\n",
    "1  11.262736  20.857489\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `DataFrame.map`**\n",
    "\n",
    "- Use `map` when you need to apply a **custom function** to each element of the DataFrame.\n",
    "- Use it for **non-vectorizable operations** (e.g., string manipulations, custom logic).\n",
    "- Avoid using `map` for **vectorizable operations** (e.g., mathematical operations) and instead use direct DataFrame operations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Methods**\n",
    "\n",
    "- `DataFrame.apply`: Apply a function along the rows or columns of a DataFrame.\n",
    "- `DataFrame.replace`: Replace values in a DataFrame.\n",
    "- `Series.map`: Apply a function element-wise on a Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- `DataFrame.map` is a powerful tool for **element-wise transformations** in a DataFrame.\n",
    "- It is flexible and supports custom functions, handling of `NaN` values, and additional arguments.\n",
    "- For performance-critical operations, prefer **vectorized operations** over `map`.\n",
    "\n",
    "This method is particularly useful for data cleaning, transformation, and custom calculations in data analysis workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "pandas.DataFrame.pipe\n",
    "DataFrame.pipe(func, *args, **kwargs)[source]\n",
    "Apply chainable functions that expect Series or DataFrames.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "func\n",
    "function\n",
    "Function to apply to the Series/DataFrame. args, and kwargs are passed into func. Alternatively a (callable, data_keyword) tuple where data_keyword is a string indicating the keyword of callable that expects the Series/DataFrame.\n",
    "\n",
    "*args\n",
    "iterable, optional\n",
    "Positional arguments passed into func.\n",
    "\n",
    "**kwargs\n",
    "mapping, optional\n",
    "A dictionary of keyword arguments passed into func.\n",
    "\n",
    "Returns\n",
    ":\n",
    "the return type of\n",
    "func\n",
    ".\n",
    "See also\n",
    "\n",
    "DataFrame.apply\n",
    "Apply a function along input axis of DataFrame.\n",
    "\n",
    "DataFrame.map\n",
    "Apply a function elementwise on a whole DataFrame.\n",
    "\n",
    "Series.map\n",
    "Apply a mapping correspondence on a Series.\n",
    "\n",
    "Notes\n",
    "\n",
    "Use .pipe when chaining together functions that expect Series, DataFrames or GroupBy objects.\n",
    "\n",
    "Examples\n",
    "\n",
    "Constructing a income DataFrame from a dictionary.\n",
    "\n",
    "data = [[8000, 1000], [9500, np.nan], [5000, 2000]]\n",
    "df = pd.DataFrame(data, columns=['Salary', 'Others'])\n",
    "df\n",
    "   Salary  Others\n",
    "0    8000  1000.0\n",
    "1    9500     NaN\n",
    "2    5000  2000.0\n",
    "Functions that perform tax reductions on an income DataFrame.\n",
    "\n",
    "def subtract_federal_tax(df):\n",
    "    return df * 0.9\n",
    "def subtract_state_tax(df, rate):\n",
    "    return df * (1 - rate)\n",
    "def subtract_national_insurance(df, rate, rate_increase):\n",
    "    new_rate = rate + rate_increase\n",
    "    return df * (1 - new_rate)\n",
    "Instead of writing\n",
    "\n",
    "subtract_national_insurance(\n",
    "    subtract_state_tax(subtract_federal_tax(df), rate=0.12),\n",
    "    rate=0.05,\n",
    "    rate_increase=0.02)  \n",
    "You can write\n",
    "\n",
    "(\n",
    "    df.pipe(subtract_federal_tax)\n",
    "    .pipe(subtract_state_tax, rate=0.12)\n",
    "    .pipe(subtract_national_insurance, rate=0.05, rate_increase=0.02)\n",
    ")\n",
    "    Salary   Others\n",
    "0  5892.48   736.56\n",
    "1  6997.32      NaN\n",
    "2  3682.80  1473.12\n",
    "If you have a function that takes the data as (say) the second argument, pass a tuple indicating which keyword expects the data. For example, suppose national_insurance takes its data as df in the second argument:\n",
    "\n",
    "def subtract_national_insurance(rate, df, rate_increase):\n",
    "    new_rate = rate + rate_increase\n",
    "    return df * (1 - new_rate)\n",
    "(\n",
    "    df.pipe(subtract_federal_tax)\n",
    "    .pipe(subtract_state_tax, rate=0.12)\n",
    "    .pipe(\n",
    "        (subtract_national_insurance, 'df'),\n",
    "        rate=0.05,\n",
    "        rate_increase=0.02\n",
    "    )\n",
    ")\n",
    "    Salary   Others\n",
    "0  5892.48   736.56\n",
    "1  6997.32      NaN\n",
    "2  3682.80  1473.12 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.pipe()` method is a powerful utility that allows you to apply a series of chainable functions to a DataFrame or Series. This method enhances code readability and makes it easier to apply multiple transformations in a clear and organized manner.\n",
    "\n",
    "### Overview of `DataFrame.pipe()`\n",
    "\n",
    "The `pipe()` method provides a way to apply functions that expect a DataFrame or Series as their first argument, while also allowing for additional positional and keyword arguments.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.pipe(func, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **func**: `function`\n",
    "\n",
    "  - The function to apply to the DataFrame. Alternatively, a tuple of the form `(callable, data_keyword)` can be provided where `data_keyword` is a string indicating the keyword of a callable that accepts the Series/DataFrame.\n",
    "\n",
    "- **args**: `iterable, optional`\n",
    "\n",
    "  - Positional arguments passed to `func`.\n",
    "\n",
    "- **kwargs**: `mapping, optional`\n",
    "  - A dictionary of keyword arguments passed to `func`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- The return type of `func`.\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- Use `pipe()` when chaining together multiple functions that require Series, DataFrames, or GroupBy objects. It creates a more readable flow as compared to nested function calls.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Constructing an income DataFrame from a dictionary\n",
    "data = [[8000, 1000], [9500, np.nan], [5000, 2000]]\n",
    "df = pd.DataFrame(data, columns=['Salary', 'Others'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "   Salary  Others\n",
    "0    8000  1000.0\n",
    "1    9500     NaN\n",
    "2    5000  2000.0\n",
    "```\n",
    "\n",
    "#### Example 2: Chaining Functions\n",
    "\n",
    "Here we’ll define several functions to perform tax deductions:\n",
    "\n",
    "```python\n",
    "def subtract_federal_tax(df):\n",
    "    return df * 0.9\n",
    "\n",
    "def subtract_state_tax(df, rate):\n",
    "    return df * (1 - rate)\n",
    "\n",
    "def subtract_national_insurance(df, rate, rate_increase):\n",
    "    new_rate = rate + rate_increase\n",
    "    return df * (1 - new_rate)\n",
    "\n",
    "# Applying multiple deductions using pipe\n",
    "result = (\n",
    "    df.pipe(subtract_federal_tax)\n",
    "    .pipe(subtract_state_tax, rate=0.12)\n",
    "    .pipe(subtract_national_insurance, rate=0.05, rate_increase=0.02)\n",
    ")\n",
    "\n",
    "print(\"\\nDataFrame after applying tax deductions:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     Salary   Others\n",
    "0  5892.48   736.56\n",
    "1  6997.32      NaN\n",
    "2  3682.80  1473.12\n",
    "```\n",
    "\n",
    "#### Example 3: Using a Function with Data as Second Argument\n",
    "\n",
    "If you have a function that needs the DataFrame as a second argument, you can pass it in a tuple. For example:\n",
    "\n",
    "```python\n",
    "def subtract_national_insurance(rate, df, rate_increase):\n",
    "    new_rate = rate + rate_increase\n",
    "    return df * (1 - new_rate)\n",
    "\n",
    "# Applying tax deductions again, but with the national insurance function taking df as second argument\n",
    "result_with_second_arg = (\n",
    "    df.pipe(subtract_federal_tax)\n",
    "    .pipe(subtract_state_tax, rate=0.12)\n",
    "    .pipe(\n",
    "        (subtract_national_insurance, 'df'),  # Tuple indicating that 'df' is the keyword\n",
    "        rate=0.05,\n",
    "        rate_increase=0.02\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nDataFrame after applying deductions with second argument:\")\n",
    "print(result_with_second_arg)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     Salary   Others\n",
    "0  5892.48   736.56\n",
    "1  6997.32      NaN\n",
    "2  3682.80  1473.12\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `DataFrame.pipe()` method is a convenient way to improve the clarity of your code by enabling a functional programming style. It's particularly useful for applying multiple transformations in a readable manner, avoiding the complexity associated with deeply nested function calls.\n",
    "\n",
    "If you have any further questions about using `pipe()` or need more examples, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.agg\n",
    "DataFrame.agg(func=None, axis=0, *args, **kwargs)[source]\n",
    "Aggregate using one or more operations over the specified axis.\n",
    "\n",
    "Parameters:\n",
    "funcfunction, str, list or dict\n",
    "Function to use for aggregating the data. If a function, must either work when passed a DataFrame or when passed to DataFrame.apply.\n",
    "\n",
    "Accepted combinations are:\n",
    "\n",
    "function\n",
    "\n",
    "string function name\n",
    "\n",
    "list of functions and/or function names, e.g. [np.sum, 'mean']\n",
    "\n",
    "dict of axis labels -> functions, function names or list of such.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "If 0 or ‘index’: apply function to each column. If 1 or ‘columns’: apply function to each row.\n",
    "\n",
    "*args\n",
    "Positional arguments to pass to func.\n",
    "\n",
    "**kwargs\n",
    "Keyword arguments to pass to func.\n",
    "\n",
    "Returns:\n",
    "scalar, Series or DataFrame\n",
    "The return can be:\n",
    "\n",
    "scalar : when Series.agg is called with single function\n",
    "\n",
    "Series : when DataFrame.agg is called with a single function\n",
    "\n",
    "DataFrame : when DataFrame.agg is called with several functions\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.apply\n",
    "Perform any type of operations.\n",
    "\n",
    "DataFrame.transform\n",
    "Perform transformation type operations.\n",
    "\n",
    "pandas.DataFrame.groupby\n",
    "Perform operations over groups.\n",
    "\n",
    "pandas.DataFrame.resample\n",
    "Perform operations over resampled bins.\n",
    "\n",
    "pandas.DataFrame.rolling\n",
    "Perform operations over rolling window.\n",
    "\n",
    "pandas.DataFrame.expanding\n",
    "Perform operations over expanding window.\n",
    "\n",
    "pandas.core.window.ewm.ExponentialMovingWindow\n",
    "Perform operation over exponential weighted window.\n",
    "\n",
    "Notes\n",
    "\n",
    "The aggregation operations are always performed over an axis, either the index (default) or the column axis. This behavior is different from numpy aggregation functions (mean, median, prod, sum, std, var), where the default is to compute the aggregation of the flattened array, e.g., numpy.mean(arr_2d) as opposed to numpy.mean(arr_2d, axis=0).\n",
    "\n",
    "agg is an alias for aggregate. Use the alias.\n",
    "\n",
    "Functions that mutate the passed object can produce unexpected behavior or errors and are not supported. See Mutating with User Defined Function (UDF) methods for more details.\n",
    "\n",
    "A passed user-defined-function will be passed a Series for evaluation.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9],\n",
    "                   [np.nan, np.nan, np.nan]],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "Aggregate these functions over the rows.\n",
    "\n",
    "df.agg(['sum', 'min'])\n",
    "        A     B     C\n",
    "sum  12.0  15.0  18.0\n",
    "min   1.0   2.0   3.0\n",
    "Different aggregations per column.\n",
    "\n",
    "df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
    "        A    B\n",
    "sum  12.0  NaN\n",
    "min   1.0  2.0\n",
    "max   NaN  8.0\n",
    "Aggregate different functions over the columns and rename the index of the resulting DataFrame.\n",
    "\n",
    "df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\n",
    "     A    B    C\n",
    "x  7.0  NaN  NaN\n",
    "y  NaN  2.0  NaN\n",
    "z  NaN  NaN  6.0\n",
    "Aggregate over the columns.\n",
    "\n",
    "df.agg(\"mean\", axis=\"columns\")\n",
    "0    2.0\n",
    "1    5.0\n",
    "2    8.0\n",
    "3    NaN\n",
    "dtype: float64 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.agg()` method is used for aggregating data in a DataFrame using one or more operations along a specified axis (either rows or columns). It allows you to apply various aggregation functions conveniently and flexibly.\n",
    "\n",
    "### Overview of `DataFrame.agg()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.agg(func=None, axis=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **func**: `function`, `str`, `list`, or `dict`\n",
    "\n",
    "  - Function to use for aggregating the data. Can be:\n",
    "    - A single function (e.g., `np.sum`).\n",
    "    - A string function name (e.g., `'mean'`).\n",
    "    - A list of functions or function names (e.g., `[np.sum, 'mean']`).\n",
    "    - A dictionary mapping DataFrame columns to functions.\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default is `0`\n",
    "\n",
    "  - If `0` or `'index'`: apply the function to each column.\n",
    "  - If `1` or `'columns'`: apply the function to each row.\n",
    "\n",
    "- **args**: `iterable, optional`\n",
    "\n",
    "  - Positional arguments to pass to the function.\n",
    "\n",
    "- **kwargs**: `mapping, optional`\n",
    "  - Keyword arguments to pass to the function.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **scalar**, **Series**, or **DataFrame**\n",
    "  - The return type varies depending on how the method is called:\n",
    "    - A scalar when called on a Series with a single function.\n",
    "    - A Series when called on a DataFrame with a single function.\n",
    "    - A DataFrame when called with several functions.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Aggregations are performed over a specified axis, which differs from NumPy's functions that flatten the array by default.\n",
    "- User-defined functions that mutate the passed object may produce unexpected behavior or errors; it's advisable to avoid them.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Aggregation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9],\n",
    "                   [np.nan, np.nan, np.nan]],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "\n",
    "# Aggregate functions over the rows\n",
    "result = df.agg(['sum', 'min'])\n",
    "print(\"Aggregate sum and min over rows:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           A     B     C\n",
    "sum     12.0  15.0  18.0\n",
    "min      1.0   2.0   3.0\n",
    "```\n",
    "\n",
    "#### Example 2: Different Aggregations per Column\n",
    "\n",
    "```python\n",
    "# Aggregate different functions for specific columns\n",
    "result_col_specific = df.agg({'A': ['sum', 'min'], 'B': ['min', 'max']})\n",
    "print(\"\\nDifferent aggregations per column:\")\n",
    "print(result_col_specific)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           A    B\n",
    "sum     12.0  NaN\n",
    "min      1.0  2.0\n",
    "max      NaN  8.0\n",
    "```\n",
    "\n",
    "#### Example 3: Renaming Output with Column Aggregations\n",
    "\n",
    "```python\n",
    "# Aggregate different functions and rename the index\n",
    "result_rename = df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\n",
    "print(\"\\nAggregate with renaming indexes:\")\n",
    "print(result_rename)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "x  7.0  NaN  NaN\n",
    "y  NaN  2.0  NaN\n",
    "z  NaN  NaN  6.0\n",
    "```\n",
    "\n",
    "#### Example 4: Aggregating Over Columns\n",
    "\n",
    "```python\n",
    "# Aggregate using mean over the columns\n",
    "result_mean = df.agg(\"mean\", axis=\"columns\")\n",
    "print(\"\\nMean aggregated over columns:\")\n",
    "print(result_mean)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    5.0\n",
    "2    8.0\n",
    "3    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `DataFrame.agg()` method is a versatile function that allows you to apply various aggregation functions along different axes of a DataFrame. By utilizing it effectively, you can achieve complex summaries of your data with simple and readable code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a concise and organized explanation of `pandas.DataFrame.agg()`:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.agg()`**\n",
    "\n",
    "Aggregates data using one or more operations over rows or columns.\n",
    "\n",
    "#### **Parameters**\n",
    "\n",
    "- **`func`**: Function(s) to apply. Can be:\n",
    "  - Single function (e.g., `np.sum`, `'mean'`).\n",
    "  - List of functions (e.g., `['sum', 'min']`).\n",
    "  - Dict mapping columns to specific functions (e.g., `{'A': 'max', 'B': ['min', 'mean']}`).\n",
    "- **`axis`**: `0` or `'index'` (column-wise, default) / `1` or `'columns'` (row-wise).\n",
    "- **`*args`**/**`**kwargs`**: Additional arguments for `func`.\n",
    "\n",
    "#### **Returns**\n",
    "\n",
    "- **Scalar**: If a single function is applied to a `Series`.\n",
    "- **Series**: If a single function is applied to a `DataFrame`.\n",
    "- **DataFrame**: If multiple functions are applied.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Axis Behavior**:\n",
    "\n",
    "   - `axis=0` (default): Apply to each **column**.\n",
    "   - `axis=1`: Apply to each **row**.\n",
    "   - Differs from NumPy’s default (aggregates over flattened array).\n",
    "\n",
    "2. **Flexibility**:\n",
    "\n",
    "   - Use **strings** (e.g., `'sum'`), **built-in functions**, or **custom functions**.\n",
    "   - Rename results using keyword syntax (e.g., `x=('A', 'max')`).\n",
    "\n",
    "3. **Handling NaNs**:\n",
    "   - Functions like `sum` ignore NaN, while `mean` returns NaN if all values are NaN.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Basic Aggregation**\n",
    "\n",
    "```python\n",
    "df.agg(['sum', 'min'])\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     A     B     C\n",
    "sum 12.0  15.0  18.0\n",
    "min  1.0   2.0   3.0\n",
    "```\n",
    "\n",
    "Applies `sum` and `min` to every column.\n",
    "\n",
    "#### 2. **Column-Specific Aggregation**\n",
    "\n",
    "```python\n",
    "df.agg({'A': ['sum', 'min'], 'B': ['min', 'max']})\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "        A    B\n",
    "sum  12.0  NaN\n",
    "min   1.0  2.0\n",
    "max   NaN  8.0\n",
    "```\n",
    "\n",
    "Only specified columns (`A`, `B`) are included.\n",
    "\n",
    "#### 3. **Row-Wise Aggregation**\n",
    "\n",
    "```python\n",
    "df.agg(\"mean\", axis=\"columns\")\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0    2.0  # (1+2+3)/3\n",
    "1    5.0  # (4+5+6)/3\n",
    "2    8.0  # (7+8+9)/3\n",
    "3    NaN  # All NaNs\n",
    "```\n",
    "\n",
    "#### 4. **Renaming Results**\n",
    "\n",
    "```python\n",
    "df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "x  7.0  NaN  NaN  # Max of A\n",
    "y  NaN  2.0  NaN  # Min of B\n",
    "z  NaN  NaN  6.0  # Mean of C\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- `apply()`: General-purpose operations.\n",
    "- `transform()`: Broadcast results to original shape.\n",
    "- `groupby()`: Group-based aggregation.\n",
    "\n",
    "### **Alias**\n",
    "\n",
    "`agg()` is interchangeable with `aggregate()`.\n",
    "\n",
    "---\n",
    "\n",
    "This method is ideal for summarizing data, computing statistics, and preparing reports. Use it to streamline data analysis workflows!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.aggregate\n",
    "DataFrame.aggregate(func=None, axis=0, *args, **kwargs)[source]\n",
    "Aggregate using one or more operations over the specified axis.\n",
    "\n",
    "Parameters:\n",
    "funcfunction, str, list or dict\n",
    "Function to use for aggregating the data. If a function, must either work when passed a DataFrame or when passed to DataFrame.apply.\n",
    "\n",
    "Accepted combinations are:\n",
    "\n",
    "function\n",
    "\n",
    "string function name\n",
    "\n",
    "list of functions and/or function names, e.g. [np.sum, 'mean']\n",
    "\n",
    "dict of axis labels -> functions, function names or list of such.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "If 0 or ‘index’: apply function to each column. If 1 or ‘columns’: apply function to each row.\n",
    "\n",
    "*args\n",
    "Positional arguments to pass to func.\n",
    "\n",
    "**kwargs\n",
    "Keyword arguments to pass to func.\n",
    "\n",
    "Returns:\n",
    "scalar, Series or DataFrame\n",
    "The return can be:\n",
    "\n",
    "scalar : when Series.agg is called with single function\n",
    "\n",
    "Series : when DataFrame.agg is called with a single function\n",
    "\n",
    "DataFrame : when DataFrame.agg is called with several functions\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.apply\n",
    "Perform any type of operations.\n",
    "\n",
    "DataFrame.transform\n",
    "Perform transformation type operations.\n",
    "\n",
    "pandas.DataFrame.groupby\n",
    "Perform operations over groups.\n",
    "\n",
    "pandas.DataFrame.resample\n",
    "Perform operations over resampled bins.\n",
    "\n",
    "pandas.DataFrame.rolling\n",
    "Perform operations over rolling window.\n",
    "\n",
    "pandas.DataFrame.expanding\n",
    "Perform operations over expanding window.\n",
    "\n",
    "pandas.core.window.ewm.ExponentialMovingWindow\n",
    "Perform operation over exponential weighted window.\n",
    "\n",
    "Notes\n",
    "\n",
    "The aggregation operations are always performed over an axis, either the index (default) or the column axis. This behavior is different from numpy aggregation functions (mean, median, prod, sum, std, var), where the default is to compute the aggregation of the flattened array, e.g., numpy.mean(arr_2d) as opposed to numpy.mean(arr_2d, axis=0).\n",
    "\n",
    "agg is an alias for aggregate. Use the alias.\n",
    "\n",
    "Functions that mutate the passed object can produce unexpected behavior or errors and are not supported. See Mutating with User Defined Function (UDF) methods for more details.\n",
    "\n",
    "A passed user-defined-function will be passed a Series for evaluation.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9],\n",
    "                   [np.nan, np.nan, np.nan]],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "Aggregate these functions over the rows.\n",
    "\n",
    "df.agg(['sum', 'min'])\n",
    "        A     B     C\n",
    "sum  12.0  15.0  18.0\n",
    "min   1.0   2.0   3.0\n",
    "Different aggregations per column.\n",
    "\n",
    "df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
    "        A    B\n",
    "sum  12.0  NaN\n",
    "min   1.0  2.0\n",
    "max   NaN  8.0\n",
    "Aggregate different functions over the columns and rename the index of the resulting DataFrame.\n",
    "\n",
    "df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\n",
    "     A    B    C\n",
    "x  7.0  NaN  NaN\n",
    "y  NaN  2.0  NaN\n",
    "z  NaN  NaN  6.0\n",
    "Aggregate over the columns.\n",
    "\n",
    "df.agg(\"mean\", axis=\"columns\")\n",
    "0    2.0\n",
    "1    5.0\n",
    "2    8.0\n",
    "3    NaN\n",
    "dtype: float64 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.aggregate()` method (often abbreviated as `agg()`) is a versatile function used to apply one or more aggregation operations across specified axes of a DataFrame. This functionality is particularly useful for summarizing data in a concise manner.\n",
    "\n",
    "### Overview of `DataFrame.aggregate()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.aggregate(func=None, axis=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **func**: `function`, `str`, `list`, or `dict`\n",
    "\n",
    "  - Specifies the function(s) to use for aggregation:\n",
    "    - **function**: A single callable that is applicable to the DataFrame.\n",
    "    - **string function name**: A string representing a built-in function (e.g., `'mean'`).\n",
    "    - **list of functions**: A list containing one or more functions or function names (e.g., `[np.sum, 'mean']`).\n",
    "    - **dict**: A mapping of column labels to functions, function names, or lists of such (e.g., `{'A': ['sum', 'min'], 'B': 'max'}`).\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default is `0`\n",
    "\n",
    "  - Determines whether to apply the function to rows or columns:\n",
    "    - `0` or `'index'`: Apply function to each column.\n",
    "    - `1` or `'columns'`: Apply function to each row.\n",
    "\n",
    "- **args**: `iterable, optional`\n",
    "\n",
    "  - Positional arguments to pass to the aggregation function.\n",
    "\n",
    "- **kwargs**: `mapping, optional`\n",
    "  - Keyword arguments to pass to the aggregation function.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **scalar**, **Series**, or **DataFrame**\n",
    "  - The return type varies depending on how the method is called:\n",
    "    - A scalar when `Series.aggregate` is called with a single function.\n",
    "    - A Series when `DataFrame.aggregate` is called with a single function.\n",
    "    - A DataFrame when multiple functions are specified.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The operations are performed over a specified axis but differ from NumPy's aggregation functions, which perform aggregation over the flattened array by default.\n",
    "- `agg()` is an alias for `aggregate()`, and both can be used interchangeably.\n",
    "- Be cautious with user-defined functions; those that mutate objects can lead to unexpected behaviors and errors.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Aggregation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9],\n",
    "                   [np.nan, np.nan, np.nan]],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "\n",
    "# Aggregate functions over the rows\n",
    "result = df.aggregate(['sum', 'min'])\n",
    "print(\"Aggregate sum and min over rows:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           A     B     C\n",
    "sum     12.0  15.0  18.0\n",
    "min      1.0   2.0   3.0\n",
    "```\n",
    "\n",
    "#### Example 2: Different Aggregations Per Column\n",
    "\n",
    "```python\n",
    "# Aggregate different functions for specific columns\n",
    "result_col_specific = df.aggregate({'A': ['sum', 'min'], 'B': ['min', 'max']})\n",
    "print(\"\\nDifferent aggregations per column:\")\n",
    "print(result_col_specific)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "           A    B\n",
    "sum     12.0  NaN\n",
    "min      1.0  2.0\n",
    "max      NaN  8.0\n",
    "```\n",
    "\n",
    "#### Example 3: Renaming Output with Column Aggregations\n",
    "\n",
    "```python\n",
    "# Aggregate different functions and rename the index\n",
    "result_rename = df.aggregate(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\n",
    "print(\"\\nAggregate with renaming indexes:\")\n",
    "print(result_rename)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "     A    B    C\n",
    "x  7.0  NaN  NaN\n",
    "y  NaN  2.0  NaN\n",
    "z  NaN  NaN  6.0\n",
    "```\n",
    "\n",
    "#### Example 4: Aggregating Over Columns\n",
    "\n",
    "```python\n",
    "# Aggregate using mean over the columns\n",
    "result_mean = df.aggregate(\"mean\", axis=\"columns\")\n",
    "print(\"\\nMean aggregated over columns:\")\n",
    "print(result_mean)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    2.0\n",
    "1    5.0\n",
    "2    8.0\n",
    "3    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `DataFrame.aggregate()` method is an essential tool for performing aggregation operations over DataFrames in a flexible way. By utilizing various aggregation functions and specifying whether to aggregate along rows or columns, you can easily summarize and analyze your data.\n",
    "\n",
    "If you have more questions or need further examples on how to use `aggregate()`, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.transform\n",
    "DataFrame.transform(func, axis=0, *args, **kwargs)[source]\n",
    "Call func on self producing a DataFrame with the same axis shape as self.\n",
    "\n",
    "Parameters:\n",
    "funcfunction, str, list-like or dict-like\n",
    "Function to use for transforming the data. If a function, must either work when passed a DataFrame or when passed to DataFrame.apply. If func is both list-like and dict-like, dict-like behavior takes precedence.\n",
    "\n",
    "Accepted combinations are:\n",
    "\n",
    "function\n",
    "\n",
    "string function name\n",
    "\n",
    "list-like of functions and/or function names, e.g. [np.exp, 'sqrt']\n",
    "\n",
    "dict-like of axis labels -> functions, function names or list-like of such.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "If 0 or ‘index’: apply function to each column. If 1 or ‘columns’: apply function to each row.\n",
    "\n",
    "*args\n",
    "Positional arguments to pass to func.\n",
    "\n",
    "**kwargs\n",
    "Keyword arguments to pass to func.\n",
    "\n",
    "Returns:\n",
    "DataFrame\n",
    "A DataFrame that must have the same length as self.\n",
    "\n",
    "Raises:\n",
    "ValueError\n",
    "If the returned DataFrame has a different length than self.\n",
    "See also\n",
    "\n",
    "DataFrame.agg\n",
    "Only perform aggregating type operations.\n",
    "\n",
    "DataFrame.apply\n",
    "Invoke function on a DataFrame.\n",
    "\n",
    "Notes\n",
    "\n",
    "Functions that mutate the passed object can produce unexpected behavior or errors and are not supported. See Mutating with User Defined Function (UDF) methods for more details.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
    "df\n",
    "   A  B\n",
    "0  0  1\n",
    "1  1  2\n",
    "2  2  3\n",
    "df.transform(lambda x: x + 1)\n",
    "   A  B\n",
    "0  1  2\n",
    "1  2  3\n",
    "2  3  4\n",
    "Even though the resulting DataFrame must have the same length as the input DataFrame, it is possible to provide several input functions:\n",
    "\n",
    "s = pd.Series(range(3))\n",
    "s\n",
    "0    0\n",
    "1    1\n",
    "2    2\n",
    "dtype: int64\n",
    "s.transform([np.sqrt, np.exp])\n",
    "       sqrt        exp\n",
    "0  0.000000   1.000000\n",
    "1  1.000000   2.718282\n",
    "2  1.414214   7.389056\n",
    "You can call transform on a GroupBy object:\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Date\": [\n",
    "        \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
    "        \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
    "    \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
    "})\n",
    "df\n",
    "         Date  Data\n",
    "0  2015-05-08     5\n",
    "1  2015-05-07     8\n",
    "2  2015-05-06     6\n",
    "3  2015-05-05     1\n",
    "4  2015-05-08    50\n",
    "5  2015-05-07   100\n",
    "6  2015-05-06    60\n",
    "7  2015-05-05   120\n",
    "df.groupby('Date')['Data'].transform('sum')\n",
    "0     55\n",
    "1    108\n",
    "2     66\n",
    "3    121\n",
    "4     55\n",
    "5    108\n",
    "6     66\n",
    "7    121\n",
    "Name: Data, dtype: int64\n",
    "df = pd.DataFrame({\n",
    "    \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
    "    \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
    "})\n",
    "df\n",
    "   c type\n",
    "0  1    m\n",
    "1  1    n\n",
    "2  1    o\n",
    "3  2    m\n",
    "4  2    m\n",
    "5  2    n\n",
    "6  2    n\n",
    "df['size'] = df.groupby('c')['type'].transform(len)\n",
    "df\n",
    "   c type size\n",
    "0  1    m    3\n",
    "1  1    n    3\n",
    "2  1    o    3\n",
    "3  2    m    4\n",
    "4  2    m    4\n",
    "5  2    n    4\n",
    "6  2    n    4 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.transform()` method allows you to apply a function to each element in the DataFrame (or to each group) and return a DataFrame that retains the same shape as the input. This makes it particularly useful for element-wise transformations without changing the structure of the original data.\n",
    "\n",
    "### Overview of `DataFrame.transform()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.transform(func, axis=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **func**: `function`, `str`, `list-like`, or `dict-like`\n",
    "\n",
    "  - Indicates the function(s) to use for transformation:\n",
    "    - **function**: A single callable that can be applied to the DataFrame.\n",
    "    - **string function name**: A built-in function name as a string (e.g., `'sqrt'`).\n",
    "    - **list-like of functions**: A list containing one or more functions (e.g., `[np.exp, 'log']`).\n",
    "    - **dict-like**: A mapping of column labels to functions, function names, or lists of functions.\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default is `0`\n",
    "\n",
    "  - Specifies whether to apply the function to columns or rows:\n",
    "    - `0` or `'index'`: Apply function to each column.\n",
    "    - `1` or `'columns'`: Apply function to each row.\n",
    "\n",
    "- **args**: `iterable, optional`\n",
    "\n",
    "  - Positional arguments to pass to the function.\n",
    "\n",
    "- **kwargs**: `mapping, optional`\n",
    "  - Keyword arguments to pass to the function.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrame**\n",
    "  - Returns a DataFrame with the same shape as the input DataFrame.\n",
    "\n",
    "### Raises\n",
    "\n",
    "- **ValueError**\n",
    "  - Raised if the returned DataFrame has a different length or shape than the original.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Functions that mutate the passed object can produce unexpected behavior. It's advisable to avoid using mutable functions in this context.\n",
    "- You can call `transform` on GroupBy objects, allowing for more complex operations based on grouping.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Transformation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Apply a transformation\n",
    "transformed_df = df.transform(lambda x: x + 1)\n",
    "print(\"\\nTransformed DataFrame:\")\n",
    "print(transformed_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "   A  B\n",
    "0  0  1\n",
    "1  1  2\n",
    "2  2  3\n",
    "\n",
    "Transformed DataFrame:\n",
    "   A  B\n",
    "0  1  2\n",
    "1  2  3\n",
    "2  3  4\n",
    "```\n",
    "\n",
    "#### Example 2: Using Multiple Functions\n",
    "\n",
    "```python\n",
    "# Transforming a Series with multiple functions\n",
    "s = pd.Series(range(3))\n",
    "print(\"\\nOriginal Series:\")\n",
    "print(s)\n",
    "\n",
    "transformed_series = s.transform([np.sqrt, np.exp])\n",
    "print(\"\\nTransformed Series with multiple functions:\")\n",
    "print(transformed_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original Series:\n",
    "0    0\n",
    "1    1\n",
    "2    2\n",
    "dtype: int64\n",
    "\n",
    "Transformed Series with multiple functions:\n",
    "       sqrt        exp\n",
    "0  0.000000   1.000000\n",
    "1  1.000000   2.718282\n",
    "2  1.414214   7.389056\n",
    "```\n",
    "\n",
    "#### Example 3: Transformation with GroupBy\n",
    "\n",
    "```python\n",
    "# Creating a DataFrame for group operations\n",
    "df = pd.DataFrame({\n",
    "    \"Date\": [\n",
    "        \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
    "        \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
    "    \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
    "})\n",
    "print(\"\\nDataFrame with Date and Data:\")\n",
    "print(df)\n",
    "\n",
    "# Total sum for each date\n",
    "grouped_sum = df.groupby('Date')['Data'].transform('sum')\n",
    "print(\"\\nGrouped sum of Data by Date:\")\n",
    "print(grouped_sum)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "DataFrame with Date and Data:\n",
    "         Date  Data\n",
    "0  2015-05-08     5\n",
    "1  2015-05-07     8\n",
    "2  2015-05-06     6\n",
    "3  2015-05-05     1\n",
    "4  2015-05-08    50\n",
    "5  2015-05-07   100\n",
    "6  2015-05-06    60\n",
    "7  2015-05-05   120\n",
    "\n",
    "Grouped sum of Data by Date:\n",
    "0     55\n",
    "1    108\n",
    "2     66\n",
    "3    121\n",
    "4     55\n",
    "5    108\n",
    "6     66\n",
    "7    121\n",
    "Name: Data, dtype: int64\n",
    "```\n",
    "\n",
    "#### Example 4: Adding Column to DataFrame\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
    "    \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
    "})\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Adding a column for the size of groups\n",
    "df['size'] = df.groupby('c')['type'].transform(len)\n",
    "print(\"\\nDataFrame with size of each group:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "   c type\n",
    "0  1    m\n",
    "1  1    n\n",
    "2  1    o\n",
    "3  2    m\n",
    "4  2    m\n",
    "5  2    n\n",
    "6  2    n\n",
    "\n",
    "DataFrame with size of each group:\n",
    "   c type  size\n",
    "0  1    m     3\n",
    "1  1    n     3\n",
    "2  1    o     3\n",
    "3  2    m     4\n",
    "4  2    m     4\n",
    "5  2    n     4\n",
    "6  2    n     4\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `DataFrame.transform()` method is ideal for when you want to apply a function to each element while maintaining the original DataFrame structure. It can be applied to both DataFrames and Series, and also works seamlessly with GroupBy objects for grouped transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, categorical data and more) in columns. It is similar to a spreadsheet, a SQL table or the data.frame in R.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "     {\n",
    "        \"Name\": [\n",
    "           \"Braund, Mr. Owen Harris\",\n",
    "             \"Allen, Mr. William Henry\",\n",
    "            \"Bonnell, Miss. Elizabeth\",\n",
    "        ],\n",
    "         \"Age\": [22, 35, 58],\n",
    "         \"Sex\": [\"male\", \"male\", \"female\"],\n",
    "     }\n",
    ")\n",
    " \n",
    "\n",
    "df\n",
    "df[\"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A pandas Series has no column labels, as it is just a single column of a DataFrame. A Series does have row labels.\n",
    "\n",
    "ages = pd.Series([22, 35, 58], name=\"Age\")\n",
    "ages\n",
    "df[\"Age\"].max() #Make sure to always have a check on the data after reading in the data. When displaying a DataFrame, the first and last 5 rows will be shown by default:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.groupby\n",
    "DataFrame.groupby(by=None, axis=<no_default>, level=None, as_index=True, sort=True, group_keys=True, observed=<no_default>, dropna=True)[source]\n",
    "Group DataFrame using a mapper or by a Series of columns.\n",
    "\n",
    "A groupby operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups.\n",
    "\n",
    "Parameters:\n",
    "bymapping, function, label, pd.Grouper or list of such\n",
    "Used to determine the groups for the groupby. If by is a function, it’s called on each value of the object’s index. If a dict or Series is passed, the Series or dict VALUES will be used to determine the groups (the Series’ values are first aligned; see .align() method). If a list or ndarray of length equal to the selected axis is passed (see the groupby user guide), the values are used as-is to determine the groups. A label or list of labels may be passed to group by the columns in self. Notice that a tuple is interpreted as a (single) key.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "Split along rows (0) or columns (1). For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Deprecated since version 2.1.0: Will be removed and behave like axis=0 in a future version. For axis=1, do frame.T.groupby(...) instead.\n",
    "\n",
    "levelint, level name, or sequence of such, default None\n",
    "If the axis is a MultiIndex (hierarchical), group by a particular level or levels. Do not specify both by and level.\n",
    "\n",
    "as_indexbool, default True\n",
    "Return object with group labels as the index. Only relevant for DataFrame input. as_index=False is effectively “SQL-style” grouped output. This argument has no effect on filtrations (see the filtrations in the user guide), such as head(), tail(), nth() and in transformations (see the transformations in the user guide).\n",
    "\n",
    "sortbool, default True\n",
    "Sort group keys. Get better performance by turning this off. Note this does not influence the order of observations within each group. Groupby preserves the order of rows within each group. If False, the groups will appear in the same order as they did in the original DataFrame. This argument has no effect on filtrations (see the filtrations in the user guide), such as head(), tail(), nth() and in transformations (see the transformations in the user guide).\n",
    "\n",
    "Changed in version 2.0.0: Specifying sort=False with an ordered categorical grouper will no longer sort the values.\n",
    "\n",
    "group_keysbool, default True\n",
    "When calling apply and the by argument produces a like-indexed (i.e. a transform) result, add group keys to index to identify pieces. By default group keys are not included when the result’s index (and column) labels match the inputs, and are included otherwise.\n",
    "\n",
    "Changed in version 1.5.0: Warns that group_keys will no longer be ignored when the result from apply is a like-indexed Series or DataFrame. Specify group_keys explicitly to include the group keys or not.\n",
    "\n",
    "Changed in version 2.0.0: group_keys now defaults to True.\n",
    "\n",
    "observedbool, default False\n",
    "This only applies if any of the groupers are Categoricals. If True: only show observed values for categorical groupers. If False: show all values for categorical groupers.\n",
    "\n",
    "Deprecated since version 2.1.0: The default value will change to True in a future version of pandas.\n",
    "\n",
    "dropnabool, default True\n",
    "If True, and if group keys contain NA values, NA values together with row/column will be dropped. If False, NA values will also be treated as the key in groups.\n",
    "\n",
    "Returns:\n",
    "pandas.api.typing.DataFrameGroupBy\n",
    "Returns a groupby object that contains information about the groups.\n",
    "\n",
    "See also\n",
    "\n",
    "resample\n",
    "Convenience method for frequency conversion and resampling of time series.\n",
    "\n",
    "Notes\n",
    "\n",
    "See the user guide for more detailed usage and examples, including splitting an object into groups, iterating through groups, selecting a group, aggregation, and more.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
    "                              'Parrot', 'Parrot'],\n",
    "                   'Max Speed': [380., 370., 24., 26.]})\n",
    "df\n",
    "   Animal  Max Speed\n",
    "0  Falcon      380.0\n",
    "1  Falcon      370.0\n",
    "2  Parrot       24.0\n",
    "3  Parrot       26.0\n",
    "df.groupby(['Animal']).mean()\n",
    "        Max Speed\n",
    "Animal\n",
    "Falcon      375.0\n",
    "Parrot       25.0\n",
    "Hierarchical Indexes\n",
    "\n",
    "We can groupby different levels of a hierarchical index using the level parameter:\n",
    "\n",
    "arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "          ['Captive', 'Wild', 'Captive', 'Wild']]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
    "df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
    "                  index=index)\n",
    "df\n",
    "                Max Speed\n",
    "Animal Type\n",
    "Falcon Captive      390.0\n",
    "       Wild         350.0\n",
    "Parrot Captive       30.0\n",
    "       Wild          20.0\n",
    "df.groupby(level=0).mean()\n",
    "        Max Speed\n",
    "Animal\n",
    "Falcon      370.0\n",
    "Parrot       25.0\n",
    "df.groupby(level=\"Type\").mean()\n",
    "         Max Speed\n",
    "Type\n",
    "Captive      210.0\n",
    "Wild         185.0\n",
    "We can also choose to include NA in group keys or not by setting dropna parameter, the default setting is True.\n",
    "\n",
    "l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
    "df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
    "df.groupby(by=[\"b\"]).sum()\n",
    "    a   c\n",
    "b\n",
    "1.0 2   3\n",
    "2.0 2   5\n",
    "df.groupby(by=[\"b\"], dropna=False).sum()\n",
    "    a   c\n",
    "b\n",
    "1.0 2   3\n",
    "2.0 2   5\n",
    "NaN 1   4\n",
    "l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
    "df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
    "df.groupby(by=\"a\").sum()\n",
    "    b     c\n",
    "a\n",
    "a   13.0   13.0\n",
    "b   12.3  123.0\n",
    "df.groupby(by=\"a\", dropna=False).sum()\n",
    "    b     c\n",
    "a\n",
    "a   13.0   13.0\n",
    "b   12.3  123.0\n",
    "NaN 12.3   33.0\n",
    "When using .apply(), use group_keys to include or exclude the group keys. The group_keys argument defaults to True (include).\n",
    "\n",
    "df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
    "                              'Parrot', 'Parrot'],\n",
    "                   'Max Speed': [380., 370., 24., 26.]})\n",
    "df.groupby(\"Animal\", group_keys=True)[['Max Speed']].apply(lambda x: x)\n",
    "          Max Speed\n",
    "Animal\n",
    "Falcon 0      380.0\n",
    "       1      370.0\n",
    "Parrot 2       24.0\n",
    "       3       26.0\n",
    "df.groupby(\"Animal\", group_keys=False)[['Max Speed']].apply(lambda x: x)\n",
    "   Max Speed\n",
    "0      380.0\n",
    "1      370.0\n",
    "2       24.0\n",
    "3       26.0\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.groupby()` method is a powerful tool for grouping data in a DataFrame. It allows you to split your data into groups based on certain criteria, apply functions to these groups, and combine the results back into a DataFrame. This method is essential for data analysis, enabling operations like aggregation, transformation, and filtering.\n",
    "\n",
    "### Overview of `DataFrame.groupby()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, observed=False, dropna=True)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **by**: `mapping`, `function`, `label`, `pd.Grouper`, or list of such\n",
    "\n",
    "  - Determines the groups for the groupby operation. It can be a function called on each value of the object's index, a dict or Series to determine groups based on values, or a list of labels for grouping by columns.\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default is `0`\n",
    "\n",
    "  - Specifies whether to group along rows (0) or columns (1). Note that for Series, this parameter is ignored.\n",
    "\n",
    "- **level**: `int`, `level name`, or sequence of such, default is `None`\n",
    "\n",
    "  - For MultiIndex DataFrames, specifies the level(s) to group by.\n",
    "\n",
    "- **as_index**: `bool`, default is `True`\n",
    "\n",
    "  - If `True`, group labels are returned as the index. If `False`, it behaves like SQL-style grouped output.\n",
    "\n",
    "- **sort**: `bool`, default is `True`\n",
    "\n",
    "  - If `True`, group keys are sorted. Setting this to `False` can improve performance but does not affect the order of observations within each group.\n",
    "\n",
    "- **group_keys**: `bool`, default is `True`\n",
    "\n",
    "  - If `True`, adds group keys to the index when calling `apply`.\n",
    "\n",
    "- **observed**: `bool`, default is `False`\n",
    "\n",
    "  - Only relevant for categorical groupers. If `True`, only shows observed values.\n",
    "\n",
    "- **dropna**: `bool`, default is `True`\n",
    "  - If `True`, NA values are dropped from the group keys. If `False`, NA values are treated as a key in groups.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrameGroupBy**\n",
    "  - Returns a groupby object containing information about the groups.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The `groupby` operation involves splitting the DataFrame, applying a function, and combining the results.\n",
    "- It can be used in conjunction with aggregation functions like `sum()`, `mean()`, etc.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Grouping\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({'Animal': ['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "                   'Max Speed': [380., 370., 24., 26.]})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Group by 'Animal' and calculate the mean Max Speed\n",
    "mean_speed = df.groupby(['Animal']).mean()\n",
    "print(\"\\nMean Max Speed by Animal:\")\n",
    "print(mean_speed)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "   Animal  Max Speed\n",
    "0  Falcon      380.0\n",
    "1  Falcon      370.0\n",
    "2  Parrot       24.0\n",
    "3  Parrot       26.0\n",
    "\n",
    "Mean Max Speed by Animal:\n",
    "        Max Speed\n",
    "Animal\n",
    "Falcon      375.0\n",
    "Parrot       25.0\n",
    "```\n",
    "\n",
    "#### Example 2: Grouping with Hierarchical Indexes\n",
    "\n",
    "```python\n",
    "# Creating a MultiIndex DataFrame\n",
    "arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "          ['Captive', 'Wild', 'Captive', 'Wild']]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
    "df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]}, index=index)\n",
    "\n",
    "print(\"\\nMultiIndex DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Group by the first level of the index\n",
    "mean_by_animal = df.groupby(level=0).mean()\n",
    "print(\"\\nMean Max Speed by Animal:\")\n",
    "print(mean_by_animal)\n",
    "\n",
    "# Group by the second level of the index\n",
    "mean_by_type = df.groupby(level=\"Type\").mean()\n",
    "print(\"\\nMean Max Speed by Type:\")\n",
    "print(mean_by_type)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "MultiIndex DataFrame:\n",
    "                Max Speed\n",
    "Animal Type\n",
    "Falcon Captive      390.0\n",
    "       Wild         350.0\n",
    "Parrot Captive       30.0\n",
    "       Wild          20.0\n",
    "\n",
    "Mean Max Speed by Animal:\n",
    "        Max Speed\n",
    "Animal\n",
    "Falcon      370.0\n",
    "Parrot       25.0\n",
    "\n",
    "Mean Max Speed by Type:\n",
    "         Max Speed\n",
    "Type\n",
    "Captive      210.0\n",
    "Wild         185.0\n",
    "```\n",
    "\n",
    "#### Example 3: Handling NA Values in Grouping\n",
    "\n",
    "```python\n",
    "# Creating a DataFrame with NA values\n",
    "l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
    "df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "print(\"\\nDataFrame with NA values:\")\n",
    "print(df)\n",
    "\n",
    "# Group by column 'b' and sum the values\n",
    "grouped_sum = df.groupby(by=[\"b\"]).sum()\n",
    "print(\"\\nGrouped sum by column 'b' (dropping NA):\")\n",
    "print(grouped_sum)\n",
    "\n",
    "# Group by column 'b' without dropping NA\n",
    "grouped_sum_with_na = df.groupby(by=[\"b\"], dropna=False).sum()\n",
    "print(\"\\nGrouped sum by column 'b' (including NA):\")\n",
    "print(grouped_sum_with_na)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "DataFrame with NA values:\n",
    "   a    b  c\n",
    "0  1  2.0  3\n",
    "1  1  NaN  4\n",
    "2  2  1.0  3\n",
    "3  1  2.0  2\n",
    "\n",
    "Grouped sum by column 'b' (dropping NA):\n",
    "    a   c\n",
    "b\n",
    "1.0 2   3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.groupby()`**, covering its syntax, parameters, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.groupby()`**\n",
    "\n",
    "Groups a DataFrame using a mapper (e.g., column names, functions, or arrays) and allows you to perform operations (e.g., aggregation, transformation, filtration) on these groups.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, observed=False, dropna=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "| Parameter | Description                              |\n",
    "| --------- | ---------------------------------------- |\n",
    "| **`by`**  | Specifies how to group the data. Can be: |\n",
    "\n",
    "- A **column name** or **list of column names**.\n",
    "- A **function** applied to the index.\n",
    "- A **dict** or **Series** mapping values to groups.\n",
    "- A **list of arrays** of the same length as the axis.  \n",
    "  | **`axis`** | Axis to group along:\n",
    "- `0` or `'index'`: Group by rows (default).\n",
    "- `1` or `'columns'`: Group by columns.  \n",
    "  | **`level`** | For MultiIndex DataFrames, specifies the level(s) to group by. |  \n",
    "  | **`as_index`** | If `True`, group labels become the index of the result. If `False`, group labels are returned as columns (SQL-style). |  \n",
    "  | **`sort`** | If `True`, sort group keys. Disable for better performance. |  \n",
    "  | **`group_keys`** | If `True`, include group keys in the index when using `apply`. |  \n",
    "  | **`observed`** | If `True`, only show observed values for categorical groupers. If `False`, show all categories. |  \n",
    "  | **`dropna`** | If `True`, exclude NA values in group keys. If `False`, include NA as a group. |\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **`DataFrameGroupBy`**: A groupby object containing information about the groups.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Grouping Process**:\n",
    "\n",
    "   - **Split**: Splits the DataFrame into groups based on the `by` parameter.\n",
    "   - **Apply**: Applies a function (e.g., aggregation, transformation) to each group.\n",
    "   - **Combine**: Combines the results into a new DataFrame or Series.\n",
    "\n",
    "2. **Common Use Cases**:\n",
    "\n",
    "   - **Aggregation**: Compute summary statistics (e.g., `mean`, `sum`, `count`).\n",
    "   - **Transformation**: Perform group-wise operations while preserving the original shape.\n",
    "   - **Filtration**: Filter groups based on a condition.\n",
    "\n",
    "3. **Flexibility**:\n",
    "   - Group by **single or multiple columns**.\n",
    "   - Use **custom functions** or **built-in methods**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Basic Grouping and Aggregation**\n",
    "\n",
    "Group by a single column and compute the mean:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Animal': ['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "    'Max Speed': [380., 370., 24., 26.]\n",
    "})\n",
    "\n",
    "df.groupby('Animal').mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "        Max Speed\n",
    "Animal\n",
    "Falcon      375.0\n",
    "Parrot       25.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Grouping by Multiple Columns**\n",
    "\n",
    "Group by multiple columns and compute the sum:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Animal': ['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "    'Type': ['Wild', 'Captive', 'Wild', 'Captive'],\n",
    "    'Max Speed': [350., 370., 20., 26.]\n",
    "})\n",
    "\n",
    "df.groupby(['Animal', 'Type']).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "                Max Speed\n",
    "Animal Type\n",
    "Falcon Captive      370.0\n",
    "       Wild         350.0\n",
    "Parrot Captive       26.0\n",
    "       Wild          20.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Grouping with Hierarchical Index**\n",
    "\n",
    "Group by a level in a MultiIndex DataFrame:\n",
    "\n",
    "```python\n",
    "arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "          ['Captive', 'Wild', 'Captive', 'Wild']]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
    "df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]}, index=index)\n",
    "\n",
    "df.groupby(level=0).mean()  # Group by the first level of the index\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "        Max Speed\n",
    "Animal\n",
    "Falcon      370.0\n",
    "Parrot       25.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Handling NA Values**\n",
    "\n",
    "Include or exclude NA values in group keys:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'a': [1, 1, 2, 1],\n",
    "    'b': [2, None, 1, 2],\n",
    "    'c': [3, 4, 3, 2]\n",
    "})\n",
    "\n",
    "# Exclude NA (default)\n",
    "df.groupby('b').sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     a  c\n",
    "b\n",
    "1.0  2  3\n",
    "2.0  2  5\n",
    "```\n",
    "\n",
    "```python\n",
    "# Include NA\n",
    "df.groupby('b', dropna=False).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     a  c\n",
    "b\n",
    "1.0  2  3\n",
    "2.0  2  5\n",
    "NaN  1  4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Using `apply` with Group Keys**\n",
    "\n",
    "Include or exclude group keys in the result:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Animal': ['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "    'Max Speed': [380., 370., 24., 26.]\n",
    "})\n",
    "\n",
    "# Include group keys (default)\n",
    "df.groupby('Animal', group_keys=True).apply(lambda x: x)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          Max Speed\n",
    "Animal\n",
    "Falcon 0      380.0\n",
    "       1      370.0\n",
    "Parrot 2       24.0\n",
    "       3       26.0\n",
    "```\n",
    "\n",
    "```python\n",
    "# Exclude group keys\n",
    "df.groupby('Animal', group_keys=False).apply(lambda x: x)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   Max Speed\n",
    "0      380.0\n",
    "1      370.0\n",
    "2       24.0\n",
    "3       26.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`agg()`**: Aggregate groups using one or more operations.\n",
    "- **`transform()`**: Perform group-wise transformations while preserving the shape.\n",
    "- **`filter()`**: Filter groups based on a condition.\n",
    "- **`resample()`**: Group time-series data by frequency.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `groupby()`**\n",
    "\n",
    "- To **split data into groups** based on a condition.\n",
    "- To **compute group-wise statistics** (e.g., mean, sum, count).\n",
    "- To **transform data** within groups (e.g., normalize, rank).\n",
    "- To **filter groups** based on aggregate conditions.\n",
    "\n",
    "This method is essential for data analysis and manipulation in pandas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.rolling\n",
    "DataFrame.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=<no_default>, closed=None, step=None, method='single')[source]\n",
    "Provide rolling window calculations.\n",
    "\n",
    "Parameters:\n",
    "windowint, timedelta, str, offset, or BaseIndexer subclass\n",
    "Size of the moving window.\n",
    "\n",
    "If an integer, the fixed number of observations used for each window.\n",
    "\n",
    "If a timedelta, str, or offset, the time period of each window. Each window will be a variable sized based on the observations included in the time-period. This is only valid for datetimelike indexes. To learn more about the offsets & frequency strings, please see this link.\n",
    "\n",
    "If a BaseIndexer subclass, the window boundaries based on the defined get_window_bounds method. Additional rolling keyword arguments, namely min_periods, center, closed and step will be passed to get_window_bounds.\n",
    "\n",
    "min_periodsint, default None\n",
    "Minimum number of observations in window required to have a value; otherwise, result is np.nan.\n",
    "\n",
    "For a window that is specified by an offset, min_periods will default to 1.\n",
    "\n",
    "For a window that is specified by an integer, min_periods will default to the size of the window.\n",
    "\n",
    "centerbool, default False\n",
    "If False, set the window labels as the right edge of the window index.\n",
    "\n",
    "If True, set the window labels as the center of the window index.\n",
    "\n",
    "win_typestr, default None\n",
    "If None, all points are evenly weighted.\n",
    "\n",
    "If a string, it must be a valid scipy.signal window function.\n",
    "\n",
    "Certain Scipy window types require additional parameters to be passed in the aggregation function. The additional parameters must match the keywords specified in the Scipy window type method signature.\n",
    "\n",
    "onstr, optional\n",
    "For a DataFrame, a column label or Index level on which to calculate the rolling window, rather than the DataFrame’s index.\n",
    "\n",
    "Provided integer column is ignored and excluded from result since an integer index is not used to calculate the rolling window.\n",
    "\n",
    "axisint or str, default 0\n",
    "If 0 or 'index', roll across the rows.\n",
    "\n",
    "If 1 or 'columns', roll across the columns.\n",
    "\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "Deprecated since version 2.1.0: The axis keyword is deprecated. For axis=1, transpose the DataFrame first instead.\n",
    "\n",
    "closedstr, default None\n",
    "If 'right', the first point in the window is excluded from calculations.\n",
    "\n",
    "If 'left', the last point in the window is excluded from calculations.\n",
    "\n",
    "If 'both', the no points in the window are excluded from calculations.\n",
    "\n",
    "If 'neither', the first and last points in the window are excluded from calculations.\n",
    "\n",
    "Default None ('right').\n",
    "\n",
    "stepint, default None\n",
    "Added in version 1.5.0.\n",
    "\n",
    "Evaluate the window at every step result, equivalent to slicing as [::step]. window must be an integer. Using a step argument other than None or 1 will produce a result with a different shape than the input.\n",
    "\n",
    "methodstr {‘single’, ‘table’}, default ‘single’\n",
    "Added in version 1.3.0.\n",
    "\n",
    "Execute the rolling operation per single column or row ('single') or over the entire object ('table').\n",
    "\n",
    "This argument is only implemented when specifying engine='numba' in the method call.\n",
    "\n",
    "Returns:\n",
    "pandas.api.typing.Window or pandas.api.typing.Rolling\n",
    "An instance of Window is returned if win_type is passed. Otherwise, an instance of Rolling is returned.\n",
    "\n",
    "See also\n",
    "\n",
    "expanding\n",
    "Provides expanding transformations.\n",
    "\n",
    "ewm\n",
    "Provides exponential weighted functions.\n",
    "\n",
    "Notes\n",
    "\n",
    "See Windowing Operations for further usage details and examples.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "df\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  2.0\n",
    "3  NaN\n",
    "4  4.0\n",
    "window\n",
    "\n",
    "Rolling sum with a window length of 2 observations.\n",
    "\n",
    "df.rolling(2).sum()\n",
    "     B\n",
    "0  NaN\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  NaN\n",
    "4  NaN\n",
    "Rolling sum with a window span of 2 seconds.\n",
    "\n",
    "df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
    "                       index=[pd.Timestamp('20130101 09:00:00'),\n",
    "                              pd.Timestamp('20130101 09:00:02'),\n",
    "                              pd.Timestamp('20130101 09:00:03'),\n",
    "                              pd.Timestamp('20130101 09:00:05'),\n",
    "                              pd.Timestamp('20130101 09:00:06')])\n",
    "df_time\n",
    "                       B\n",
    "2013-01-01 09:00:00  0.0\n",
    "2013-01-01 09:00:02  1.0\n",
    "2013-01-01 09:00:03  2.0\n",
    "2013-01-01 09:00:05  NaN\n",
    "2013-01-01 09:00:06  4.0\n",
    "df_time.rolling('2s').sum()\n",
    "                       B\n",
    "2013-01-01 09:00:00  0.0\n",
    "2013-01-01 09:00:02  1.0\n",
    "2013-01-01 09:00:03  3.0\n",
    "2013-01-01 09:00:05  NaN\n",
    "2013-01-01 09:00:06  4.0\n",
    "Rolling sum with forward looking windows with 2 observations.\n",
    "\n",
    "indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
    "df.rolling(window=indexer, min_periods=1).sum()\n",
    "     B\n",
    "0  1.0\n",
    "1  3.0\n",
    "2  2.0\n",
    "3  4.0\n",
    "4  4.0\n",
    "min_periods\n",
    "\n",
    "Rolling sum with a window length of 2 observations, but only needs a minimum of 1 observation to calculate a value.\n",
    "\n",
    "df.rolling(2, min_periods=1).sum()\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  2.0\n",
    "4  4.0\n",
    "center\n",
    "\n",
    "Rolling sum with the result assigned to the center of the window index.\n",
    "\n",
    "df.rolling(3, min_periods=1, center=True).sum()\n",
    "     B\n",
    "0  1.0\n",
    "1  3.0\n",
    "2  3.0\n",
    "3  6.0\n",
    "4  4.0\n",
    "df.rolling(3, min_periods=1, center=False).sum()\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  3.0\n",
    "4  6.0\n",
    "step\n",
    "\n",
    "Rolling sum with a window length of 2 observations, minimum of 1 observation to calculate a value, and a step of 2.\n",
    "\n",
    "df.rolling(2, min_periods=1, step=2).sum()\n",
    "     B\n",
    "0  0.0\n",
    "2  3.0\n",
    "4  4.0\n",
    "win_type\n",
    "\n",
    "Rolling sum with a window length of 2, using the Scipy 'gaussian' window type. std is required in the aggregation function.\n",
    "\n",
    "df.rolling(2, win_type='gaussian').sum(std=3)\n",
    "          B\n",
    "0       NaN\n",
    "1  0.986207\n",
    "2  2.958621\n",
    "3       NaN\n",
    "4       NaN\n",
    "on\n",
    "\n",
    "Rolling sum with a window length of 2 days.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [pd.to_datetime('2020-01-01'),\n",
    "          pd.to_datetime('2020-01-01'),\n",
    "          pd.to_datetime('2020-01-02'),],\n",
    "    'B': [1, 2, 3], },\n",
    "    index=pd.date_range('2020', periods=3))\n",
    "df\n",
    "                    A  B\n",
    "2020-01-01 2020-01-01  1\n",
    "2020-01-02 2020-01-01  2\n",
    "2020-01-03 2020-01-02  3\n",
    "df.rolling('2D', on='A').sum()\n",
    "                    A    B\n",
    "2020-01-01 2020-01-01  1.0\n",
    "2020-01-02 2020-01-01  3.0\n",
    "2020-01-03 2020-01-02  6.0 all syntaxes all about  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.rolling()`**, covering its syntax, parameters, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.rolling()`**\n",
    "\n",
    "Provides rolling window calculations, which are useful for time-series or sequential data analysis. It allows you to compute metrics (e.g., mean, sum, standard deviation) over a sliding window of observations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None, step=None, method='single')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "| Parameter    | Description                        |\n",
    "| ------------ | ---------------------------------- |\n",
    "| **`window`** | Size of the moving window. Can be: |\n",
    "\n",
    "- **Integer**: Fixed number of observations.\n",
    "- **Timedelta/str/offset**: Variable-sized window for datetime-like indexes.\n",
    "- **BaseIndexer subclass**: Custom window boundaries. |  \n",
    "  | **`min_periods`** | Minimum number of observations in a window to compute a result. Defaults to `window` size for integer windows, or `1` for offset-based windows. |  \n",
    "  | **`center`** | If `True`, label the window by its center. If `False`, label by the right edge. |  \n",
    "  | **`win_type`** | Type of window weighting (e.g., `'gaussian'`, `'triang'`). Requires additional parameters for some types. |  \n",
    "  | **`on`** | Column or index level to use for rolling calculations (instead of the DataFrame index). |  \n",
    "  | **`axis`** | Axis to roll along: `0` (rows) or `1` (columns). Default is `0`. |  \n",
    "  | **`closed`** | Specifies which end of the window is inclusive:\n",
    "- `'right'`: Exclude the first point (default).\n",
    "- `'left'`: Exclude the last point.\n",
    "- `'both'`: Include both ends.\n",
    "- `'neither'`: Exclude both ends. |  \n",
    "  | **`step`** | Evaluate the window at every `step` result (e.g., `step=2` skips every other window). |  \n",
    "  | **`method`** | Execution method: `'single'` (per column/row) or `'table'` (entire object). Only works with `engine='numba'`. |\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **`Rolling` object**: If `win_type` is not specified.\n",
    "- **`Window` object**: If `win_type` is specified.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Window Types**:\n",
    "\n",
    "   - **Fixed windows**: Use an integer for a fixed number of observations.\n",
    "   - **Variable windows**: Use a timedelta or offset for time-based windows.\n",
    "   - **Custom windows**: Use a `BaseIndexer` subclass for custom logic.\n",
    "\n",
    "2. **Common Use Cases**:\n",
    "\n",
    "   - **Moving averages**: Smooth time-series data.\n",
    "   - **Cumulative metrics**: Compute rolling sums, standard deviations, etc.\n",
    "   - **Weighted calculations**: Apply window functions (e.g., Gaussian, exponential).\n",
    "\n",
    "3. **Handling Missing Data**:\n",
    "   - Use `min_periods` to control how many observations are required for a valid result.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Basic Rolling Sum**\n",
    "\n",
    "Compute a rolling sum with a window of 2 observations:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "df.rolling(2).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     B\n",
    "0  NaN\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  NaN\n",
    "4  NaN\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Time-Based Rolling Window**\n",
    "\n",
    "Compute a rolling sum with a 2-second window:\n",
    "\n",
    "```python\n",
    "df_time = pd.DataFrame(\n",
    "    {'B': [0, 1, 2, np.nan, 4]},\n",
    "    index=pd.to_datetime([\n",
    "        '2013-01-01 09:00:00',\n",
    "        '2013-01-01 09:00:02',\n",
    "        '2013-01-01 09:00:03',\n",
    "        '2013-01-01 09:00:05',\n",
    "        '2013-01-01 09:00:06'\n",
    "    ])\n",
    ")\n",
    "\n",
    "df_time.rolling('2s').sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "                       B\n",
    "2013-01-01 09:00:00  0.0\n",
    "2013-01-01 09:00:02  1.0\n",
    "2013-01-01 09:00:03  3.0\n",
    "2013-01-01 09:00:05  NaN\n",
    "2013-01-01 09:00:06  4.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Custom Window with `min_periods`**\n",
    "\n",
    "Compute a rolling sum with a window of 2 observations, requiring at least 1 observation:\n",
    "\n",
    "```python\n",
    "df.rolling(2, min_periods=1).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  2.0\n",
    "4  4.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Centered Rolling Window**\n",
    "\n",
    "Compute a rolling sum with the result centered in the window:\n",
    "\n",
    "```python\n",
    "df.rolling(3, min_periods=1, center=True).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     B\n",
    "0  1.0\n",
    "1  3.0\n",
    "2  3.0\n",
    "3  6.0\n",
    "4  4.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Step-Based Rolling Window**\n",
    "\n",
    "Compute a rolling sum with a step of 2:\n",
    "\n",
    "```python\n",
    "df.rolling(2, min_periods=1, step=2).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     B\n",
    "0  0.0\n",
    "2  3.0\n",
    "4  4.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **Weighted Rolling Window**\n",
    "\n",
    "Compute a rolling sum using a Gaussian window:\n",
    "\n",
    "```python\n",
    "df.rolling(2, win_type='gaussian').sum(std=3)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          B\n",
    "0       NaN\n",
    "1  0.986207\n",
    "2  2.958621\n",
    "3       NaN\n",
    "4       NaN\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. **Rolling on a Specific Column**\n",
    "\n",
    "Compute a rolling sum on a specific column:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': pd.to_datetime(['2020-01-01', '2020-01-01', '2020-01-02']),\n",
    "    'B': [1, 2, 3]\n",
    "}, index=pd.date_range('2020', periods=3))\n",
    "\n",
    "df.rolling('2D', on='A').sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "                    A    B\n",
    "2020-01-01 2020-01-01  1.0\n",
    "2020-01-02 2020-01-01  3.0\n",
    "2020-01-03 2020-01-02  6.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`expanding()`**: Cumulative window calculations.\n",
    "- **`ewm()`**: Exponential weighted moving calculations.\n",
    "- **`groupby()`**: Group-wise operations.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `rolling()`**\n",
    "\n",
    "- For **time-series analysis** (e.g., moving averages, trends).\n",
    "- For **smoothing noisy data**.\n",
    "- For **sequential data calculations** (e.g., rolling sums, standard deviations).\n",
    "\n",
    "This method is essential for time-series and sequential data analysis in pandas!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.rolling()` method provides rolling window calculations, which are useful for time series analysis and smoothing data. This method allows you to perform calculations over a specified window of data points, making it easier to analyze trends and patterns.\n",
    "\n",
    "### Overview of `DataFrame.rolling()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.rolling(window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None, step=None, method='single')\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **window**: `int`, `timedelta`, `str`, `offset`, or `BaseIndexer subclass`\n",
    "\n",
    "  - Defines the size of the moving window. It can be:\n",
    "    - An integer for a fixed number of observations.\n",
    "    - A timedelta, string, or offset for time-based windows (only valid for datetime-like indexes).\n",
    "\n",
    "- **min_periods**: `int`, default is `None`\n",
    "\n",
    "  - Minimum number of observations in the window required to have a value; otherwise, the result is `np.nan`. Defaults to the window size if an integer is specified.\n",
    "\n",
    "- **center**: `bool`, default is `False`\n",
    "\n",
    "  - If `True`, the window labels are set to the center of the window. If `False`, the labels are set to the right edge.\n",
    "\n",
    "- **win_type**: `str`, default is `None`\n",
    "\n",
    "  - If specified, it must be a valid SciPy window function (e.g., 'hamming', 'blackman'). If `None`, all points are evenly weighted.\n",
    "\n",
    "- **on**: `str`, optional\n",
    "\n",
    "  - For a DataFrame, specifies a column label or index level on which to calculate the rolling window.\n",
    "\n",
    "- **axis**: `int` or `str`, default is `0`\n",
    "\n",
    "  - Specifies whether to roll across rows (0) or columns (1). This parameter is ignored for Series.\n",
    "\n",
    "- **closed**: `str`, default is `None`\n",
    "\n",
    "  - Defines which endpoints are included in the window:\n",
    "    - 'right': include the right endpoint (default).\n",
    "    - 'left': include the left endpoint.\n",
    "    - 'both': include both endpoints.\n",
    "    - 'neither': exclude both endpoints.\n",
    "\n",
    "- **step**: `int`, default is `None`\n",
    "\n",
    "  - Added in version 1.5.0. Evaluates the window at every specified step. Must be an integer.\n",
    "\n",
    "- **method**: `str`, default is `'single'`\n",
    "  - Specifies how to execute the rolling operation. 'single' rolls per column/row, while 'table' rolls over the entire object (only available with `engine='numba'`).\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Window or Rolling**\n",
    "  - Returns a `Window` instance if `win_type` is specified; otherwise, it returns a `Rolling` instance.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Rolling Calculation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Rolling sum with a window length of 2 observations\n",
    "rolling_sum = df.rolling(2).sum()\n",
    "print(\"\\nRolling sum with a window length of 2:\")\n",
    "print(rolling_sum)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  2.0\n",
    "3  NaN\n",
    "4  4.0\n",
    "\n",
    "Rolling sum with a window length of 2:\n",
    "     B\n",
    "0  NaN\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  NaN\n",
    "4  NaN\n",
    "```\n",
    "\n",
    "#### Example 2: Rolling with Time-Based Index\n",
    "\n",
    "```python\n",
    "# Creating a DataFrame with a datetime index\n",
    "df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
    "                       index=[pd.Timestamp('20130101 09:00:00'),\n",
    "                              pd.Timestamp('20130101 09:00:02'),\n",
    "                              pd.Timestamp('20130101 09:00:03'),\n",
    "                              pd.Timestamp('20130101 09:00:05'),\n",
    "                              pd.Timestamp('20130101 09:00:06')])\n",
    "\n",
    "print(\"\\nTime-based DataFrame:\")\n",
    "print(df_time)\n",
    "\n",
    "# Rolling sum with a window span of 2 seconds\n",
    "rolling_time_sum = df_time.rolling('2s').sum()\n",
    "print(\"\\nRolling sum with a window span of 2 seconds:\")\n",
    "print(rolling_time_sum)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Time-based DataFrame:\n",
    "                       B\n",
    "2013-01-01 09:00:00  0.0\n",
    "2013-01-01 09:00:02  1.0\n",
    "2013-01-01 09:00:03  2.0\n",
    "2013-01-01 09:00:05  NaN\n",
    "2013-01-01 09:00:06  4.0\n",
    "\n",
    "Rolling sum with a window span of 2 seconds:\n",
    "                       B\n",
    "2013-01-01 09:00:00  0.0\n",
    "2013-01-01 09:00:02  1.0\n",
    "2013-01-01 09:00:03  3.0\n",
    "2013-01-01 09:00:05  NaN\n",
    "2013-01-01 09:00:06  4.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.expanding\n",
    "DataFrame.expanding(min_periods=1, axis=<no_default>, method='single')[source]\n",
    "Provide expanding window calculations.\n",
    "\n",
    "Parameters:\n",
    "min_periodsint, default 1\n",
    "Minimum number of observations in window required to have a value; otherwise, result is np.nan.\n",
    "\n",
    "axisint or str, default 0\n",
    "If 0 or 'index', roll across the rows.\n",
    "\n",
    "If 1 or 'columns', roll across the columns.\n",
    "\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "methodstr {‘single’, ‘table’}, default ‘single’\n",
    "Execute the rolling operation per single column or row ('single') or over the entire object ('table').\n",
    "\n",
    "This argument is only implemented when specifying engine='numba' in the method call.\n",
    "\n",
    "Added in version 1.3.0.\n",
    "\n",
    "Returns:\n",
    "pandas.api.typing.Expanding\n",
    "See also\n",
    "\n",
    "rolling\n",
    "Provides rolling window calculations.\n",
    "\n",
    "ewm\n",
    "Provides exponential weighted functions.\n",
    "\n",
    "Notes\n",
    "\n",
    "See Windowing Operations for further usage details and examples.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
    "df\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  2.0\n",
    "3  NaN\n",
    "4  4.0\n",
    "min_periods\n",
    "\n",
    "Expanding sum with 1 vs 3 observations needed to calculate a value.\n",
    "\n",
    "df.expanding(1).sum()\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  3.0\n",
    "4  7.0\n",
    "df.expanding(3).sum()\n",
    "     B\n",
    "0  NaN\n",
    "1  NaN\n",
    "2  3.0\n",
    "3  3.0\n",
    "4  7.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.expanding()` method provides expanding window calculations, which allow you to compute statistics over an expanding window of observations in your DataFrame. This method is particularly useful for cumulative calculations, where each result includes all previous data points up to the current observation.\n",
    "\n",
    "### Overview of `DataFrame.expanding()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.expanding(min_periods=1, axis=0, method='single')\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **min_periods**: `int`, default is `1`\n",
    "\n",
    "  - The minimum number of observations in the window required to have a value; otherwise, the result is `np.nan`.\n",
    "\n",
    "- **axis**: `int` or `str`, default is `0`\n",
    "\n",
    "  - If `0` or `'index'`, the operation rolls across the rows. If `1` or `'columns'`, it rolls across the columns.\n",
    "\n",
    "- **method**: `str`, {‘single’, ‘table’}, default is `'single'`\n",
    "  - Specifies whether to execute the expanding operation per column or row ('single') or over the entire object ('table'). This argument is only relevant when using `engine='numba'`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Expanding**\n",
    "  - An instance of the `Expanding` object is returned, which provides methods for calculating various statistics over the expanding window.\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "The expanding window is particularly useful for cumulative sums, means, or any other statistics that aggregate data from the beginning of a dataset up to the current observation.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Expanding Calculation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Expanding sum with a minimum of 1 observation needed to calculate a value\n",
    "expanding_sum_1 = df.expanding(1).sum()\n",
    "print(\"\\nExpanding sum with min_periods=1:\")\n",
    "print(expanding_sum_1)\n",
    "\n",
    "# Expanding sum with a minimum of 3 observations needed to calculate a value\n",
    "expanding_sum_3 = df.expanding(3).sum()\n",
    "print(\"\\nExpanding sum with min_periods=3:\")\n",
    "print(expanding_sum_3)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  2.0\n",
    "3  NaN\n",
    "4  4.0\n",
    "\n",
    "Expanding sum with min_periods=1:\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  3.0\n",
    "4  7.0\n",
    "\n",
    "Expanding sum with min_periods=3:\n",
    "     B\n",
    "0  NaN\n",
    "1  NaN\n",
    "2  3.0\n",
    "3  3.0\n",
    "4  7.0\n",
    "```\n",
    "\n",
    "In this example:\n",
    "\n",
    "- The first expanding sum with `min_periods=1` gives cumulative sums starting from the first row, so each row's value reflects the sum of all previous rows including itself.\n",
    "- The second expanding sum with `min_periods=3` requires at least 3 observations, so the first two rows return `NaN`.\n",
    "\n",
    "#### Example 2: Expanding Mean Calculation\n",
    "\n",
    "```python\n",
    "# Expanding mean with a minimum of 1 observation needed\n",
    "expanding_mean = df.expanding().mean()\n",
    "print(\"\\nExpanding mean with min_periods=1:\")\n",
    "print(expanding_mean)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Expanding mean with min_periods=1:\n",
    "     B\n",
    "0  0.0\n",
    "1  0.5\n",
    "2  1.0\n",
    "3  1.0\n",
    "4  1.75\n",
    "```\n",
    "\n",
    "This calculation shows the average of all previous values (including the current value) for each row.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The `pandas.DataFrame.expanding()` method is a powerful tool for conducting cumulative analyses on DataFrames. It allows for the calculation of various statistical measures while accommodating different minimum observation requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.expanding()`**, covering its syntax, parameters, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.expanding()`**\n",
    "\n",
    "Provides expanding window calculations, which are cumulative and grow over time. It is useful for computing cumulative metrics (e.g., cumulative sum, mean, or standard deviation) over a dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.expanding(min_periods=1, axis=0, method='single')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "| Parameter         | Description                                                                                |\n",
    "| ----------------- | ------------------------------------------------------------------------------------------ |\n",
    "| **`min_periods`** | Minimum number of observations in the window required to compute a result. Default is `1`. |\n",
    "| **`axis`**        | Axis to apply the expanding window:                                                        |\n",
    "\n",
    "- `0` or `'index'`: Apply to rows (default).\n",
    "- `1` or `'columns'`: Apply to columns. |  \n",
    "  | **`method`** | Execution method:\n",
    "- `'single'`: Perform calculations per column/row (default).\n",
    "- `'table'`: Perform calculations over the entire object (requires `engine='numba'`). |\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **`Expanding` object**: Used to compute cumulative metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Expanding Window**:\n",
    "\n",
    "   - The window starts at the first observation and grows to include all previous observations.\n",
    "   - Useful for cumulative calculations (e.g., cumulative sum, cumulative average).\n",
    "\n",
    "2. **Handling Missing Data**:\n",
    "\n",
    "   - Use `min_periods` to control how many observations are required for a valid result.\n",
    "\n",
    "3. **Common Use Cases**:\n",
    "   - Cumulative sums, averages, or other metrics.\n",
    "   - Analyzing trends over time.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Basic Expanding Sum**\n",
    "\n",
    "Compute the cumulative sum with a minimum of 1 observation:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
    "df.expanding(1).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  3.0\n",
    "3  3.0\n",
    "4  7.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Expanding Sum with `min_periods`**\n",
    "\n",
    "Compute the cumulative sum with a minimum of 3 observations:\n",
    "\n",
    "```python\n",
    "df.expanding(3).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     B\n",
    "0  NaN\n",
    "1  NaN\n",
    "2  3.0\n",
    "3  3.0\n",
    "4  7.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Expanding Mean**\n",
    "\n",
    "Compute the cumulative mean:\n",
    "\n",
    "```python\n",
    "df.expanding().mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     B\n",
    "0  0.0\n",
    "1  0.5\n",
    "2  1.0\n",
    "3  1.0\n",
    "4  1.75\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Expanding Standard Deviation**\n",
    "\n",
    "Compute the cumulative standard deviation:\n",
    "\n",
    "```python\n",
    "df.expanding().std()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "     B\n",
    "0  NaN\n",
    "1  0.707107\n",
    "2  1.000000\n",
    "3  1.000000\n",
    "4  1.707825\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Expanding on Columns**\n",
    "\n",
    "Compute the cumulative sum across columns:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
    "df.expanding(axis=1).sum()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   A   B\n",
    "0  1   5\n",
    "1  2   7\n",
    "2  3   9\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`rolling()`**: Rolling window calculations.\n",
    "- **`ewm()`**: Exponential weighted moving calculations.\n",
    "- **`cumsum()`**: Cumulative sum (simpler alternative for specific cases).\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `expanding()`**\n",
    "\n",
    "- For **cumulative calculations** (e.g., cumulative sums, averages).\n",
    "- For **trend analysis** over time.\n",
    "- When you need **growing window metrics** instead of fixed-size windows.\n",
    "\n",
    "This method is essential for cumulative data analysis in pandas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.ewm\n",
    "DataFrame.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=<no_default>, times=None, method='single')[source]\n",
    "Provide exponentially weighted (EW) calculations.\n",
    "\n",
    "Exactly one of com, span, halflife, or alpha must be provided if times is not provided. If times is provided, halflife and one of com, span or alpha may be provided.\n",
    "\n",
    "Parameters:\n",
    "comfloat, optional\n",
    "Specify decay in terms of center of mass\n",
    "\n",
    ", for \n",
    ".\n",
    "\n",
    "spanfloat, optional\n",
    "Specify decay in terms of span\n",
    "\n",
    ", for \n",
    ".\n",
    "\n",
    "halflifefloat, str, timedelta, optional\n",
    "Specify decay in terms of half-life\n",
    "\n",
    ", for \n",
    ".\n",
    "\n",
    "If times is specified, a timedelta convertible unit over which an observation decays to half its value. Only applicable to mean(), and halflife value will not apply to the other functions.\n",
    "\n",
    "alphafloat, optional\n",
    "Specify smoothing factor \n",
    " directly\n",
    "\n",
    ".\n",
    "\n",
    "min_periodsint, default 0\n",
    "Minimum number of observations in window required to have a value; otherwise, result is np.nan.\n",
    "\n",
    "adjustbool, default True\n",
    "Divide by decaying adjustment factor in beginning periods to account for imbalance in relative weightings (viewing EWMA as a moving average).\n",
    "\n",
    "When adjust=True (default), the EW function is calculated using weights \n",
    ". For example, the EW moving average of the series [\n",
    "] would be:\n",
    "\n",
    " \n",
    "When adjust=False, the exponentially weighted function is calculated recursively:\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "ignore_nabool, default False\n",
    "Ignore missing values when calculating weights.\n",
    "\n",
    "When ignore_na=False (default), weights are based on absolute positions. For example, the weights of \n",
    " and \n",
    " used in calculating the final weighted average of [\n",
    ", None, \n",
    "] are \n",
    " and \n",
    " if adjust=True, and \n",
    " and \n",
    " if adjust=False.\n",
    "\n",
    "When ignore_na=True, weights are based on relative positions. For example, the weights of \n",
    " and \n",
    " used in calculating the final weighted average of [\n",
    ", None, \n",
    "] are \n",
    " and \n",
    " if adjust=True, and \n",
    " and \n",
    " if adjust=False.\n",
    "\n",
    "axis{0, 1}, default 0\n",
    "If 0 or 'index', calculate across the rows.\n",
    "\n",
    "If 1 or 'columns', calculate across the columns.\n",
    "\n",
    "For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "timesnp.ndarray, Series, default None\n",
    "Only applicable to mean().\n",
    "\n",
    "Times corresponding to the observations. Must be monotonically increasing and datetime64[ns] dtype.\n",
    "\n",
    "If 1-D array like, a sequence with the same shape as the observations.\n",
    "\n",
    "methodstr {‘single’, ‘table’}, default ‘single’\n",
    "Added in version 1.4.0.\n",
    "\n",
    "Execute the rolling operation per single column or row ('single') or over the entire object ('table').\n",
    "\n",
    "This argument is only implemented when specifying engine='numba' in the method call.\n",
    "\n",
    "Only applicable to mean()\n",
    "\n",
    "Returns:\n",
    "pandas.api.typing.ExponentialMovingWindow\n",
    "See also\n",
    "\n",
    "rolling\n",
    "Provides rolling window calculations.\n",
    "\n",
    "expanding\n",
    "Provides expanding transformations.\n",
    "\n",
    "Notes\n",
    "\n",
    "See Windowing Operations for further usage details and examples.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "df\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  2.0\n",
    "3  NaN\n",
    "4  4.0\n",
    "df.ewm(com=0.5).mean()\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "df.ewm(alpha=2 / 3).mean()\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "adjust\n",
    "\n",
    "df.ewm(com=0.5, adjust=True).mean()\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "df.ewm(com=0.5, adjust=False).mean()\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.666667\n",
    "2  1.555556\n",
    "3  1.555556\n",
    "4  3.650794\n",
    "ignore_na\n",
    "\n",
    "df.ewm(com=0.5, ignore_na=True).mean()\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.225000\n",
    "df.ewm(com=0.5, ignore_na=False).mean()\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "times\n",
    "\n",
    "Exponentially weighted mean with weights calculated with a timedelta halflife relative to times.\n",
    "\n",
    "times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
    "df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.585786\n",
    "2  1.523889\n",
    "3  1.523889\n",
    "4  3.233686 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.ewm()` method provides exponentially weighted calculations, which are useful for smoothing time series data by giving more weight to recent observations. This method can be used to compute various statistics such as the exponentially weighted mean, variance, and standard deviation.\n",
    "\n",
    "### Overview of `DataFrame.ewm()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0, times=None, method='single')\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **com**: `float`, optional\n",
    "\n",
    "  - Specifies decay in terms of center of mass. The relationship is given by:\n",
    "    $$ \\alpha = \\frac{1}{1 + com} $$\n",
    "\n",
    "- **span**: `float`, optional\n",
    "\n",
    "  - Specifies decay in terms of span. The relationship is:\n",
    "    $$ \\alpha = \\frac{2}{span + 1} $$\n",
    "\n",
    "- **halflife**: `float`, `str`, or `timedelta`, optional\n",
    "\n",
    "  - Specifies decay in terms of half-life. The relationship is:\n",
    "    $$ \\alpha = 1 - \\exp\\left(-\\frac{\\ln(2)}{halflife}\\right) $$\n",
    "\n",
    "- **alpha**: `float`, optional\n",
    "\n",
    "  - Specifies the smoothing factor directly, where $$ 0 < \\alpha \\leq 1 $$.\n",
    "\n",
    "- **min_periods**: `int`, default is `0`\n",
    "\n",
    "  - Minimum number of observations in the window required to have a value; otherwise, the result is `np.nan`.\n",
    "\n",
    "- **adjust**: `bool`, default is `True`\n",
    "\n",
    "  - If `True`, the function divides by a decaying adjustment factor in beginning periods to account for imbalance in relative weightings.\n",
    "\n",
    "- **ignore_na**: `bool`, default is `False`\n",
    "\n",
    "  - If `True`, missing values are ignored when calculating weights.\n",
    "\n",
    "- **axis**: `int` or `str`, default is `0`\n",
    "\n",
    "  - If `0` or `'index'`, calculates across the rows; if `1` or `'columns'`, calculates across the columns.\n",
    "\n",
    "- **times**: `np.ndarray` or `Series`, default is `None`\n",
    "\n",
    "  - Only applicable to the `mean()` function. Specifies times corresponding to observations, which must be monotonically increasing and of `datetime64[ns]` dtype.\n",
    "\n",
    "- **method**: `str`, {‘single’, ‘table’}, default is `'single'`\n",
    "  - Specifies whether to execute the operation per single column or row ('single') or over the entire object ('table'). This is implemented when using `engine='numba'`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **ExponentialMovingWindow**\n",
    "  - Returns an instance of the `ExponentialMovingWindow` object, which provides methods for calculating exponentially weighted statistics.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Exponentially Weighted Mean\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Exponentially weighted mean with center of mass\n",
    "ewm_mean_com = df.ewm(com=0.5).mean()\n",
    "print(\"\\nExponentially weighted mean (com=0.5):\")\n",
    "print(ewm_mean_com)\n",
    "\n",
    "# Exponentially weighted mean with alpha\n",
    "ewm_mean_alpha = df.ewm(alpha=2/3).mean()\n",
    "print(\"\\nExponentially weighted mean (alpha=2/3):\")\n",
    "print(ewm_mean_alpha)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "     B\n",
    "0  0.0\n",
    "1  1.0\n",
    "2  2.0\n",
    "3  NaN\n",
    "4  4.0\n",
    "\n",
    "Exponentially weighted mean (com=0.5):\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "\n",
    "Exponentially weighted mean (alpha=2/3):\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "```\n",
    "\n",
    "#### Example 2: Adjusting for Missing Values\n",
    "\n",
    "```python\n",
    "# Exponentially weighted mean with adjust=True\n",
    "ewm_adjust_true = df.ewm(com=0.5, adjust=True).mean()\n",
    "print(\"\\nExponentially weighted mean with adjust=True:\")\n",
    "print(ewm_adjust_true)\n",
    "\n",
    "# Exponentially weighted mean with adjust=False\n",
    "ewm_adjust_false = df.ewm\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.ewm()`**, covering its syntax, parameters, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.ewm()`**\n",
    "\n",
    "Provides exponentially weighted (EW) calculations, which are useful for smoothing time-series data or computing weighted metrics. It assigns exponentially decreasing weights to older observations, giving more importance to recent data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.ewm(com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0, times=None, method='single')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "| Parameter         | Description                                                                                            |\n",
    "| ----------------- | ------------------------------------------------------------------------------------------------------ |\n",
    "| **`com`**         | Specify decay in terms of **center of mass** (e.g., `com=0.5`).                                        |\n",
    "| **`span`**        | Specify decay in terms of **span** (e.g., `span=10`).                                                  |\n",
    "| **`halflife`**    | Specify decay in terms of **half-life** (e.g., `halflife=5`). Can be a float, string, or timedelta.    |\n",
    "| **`alpha`**       | Specify **smoothing factor** directly (e.g., `alpha=0.5`).                                             |\n",
    "| **`min_periods`** | Minimum number of observations required to compute a result. Default is `0`.                           |\n",
    "| **`adjust`**      | If `True`, adjust weights to account for imbalance in early periods. Default is `True`.                |\n",
    "| **`ignore_na`**   | If `True`, ignore missing values when calculating weights. Default is `False`.                         |\n",
    "| **`axis`**        | Axis to apply the calculation: `0` (rows) or `1` (columns). Default is `0`.                            |\n",
    "| **`times`**       | Times corresponding to observations (for time-based decay). Must be monotonically increasing.          |\n",
    "| **`method`**      | Execution method: `'single'` (per column/row) or `'table'` (entire object). Requires `engine='numba'`. |\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **`ExponentialMovingWindow` object**: Used to compute exponentially weighted metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Decay Parameters**:\n",
    "\n",
    "   - Exactly one of `com`, `span`, `halflife`, or `alpha` must be provided (unless `times` is specified).\n",
    "   - These parameters control how quickly weights decay:\n",
    "     - `com`: Center of mass.\n",
    "     - `span`: Span of the window.\n",
    "     - `halflife`: Half-life of the decay.\n",
    "     - `alpha`: Smoothing factor directly.\n",
    "\n",
    "2. **Adjustment**:\n",
    "\n",
    "   - If `adjust=True`, weights are adjusted to account for imbalance in early periods.\n",
    "   - If `adjust=False`, weights are calculated recursively.\n",
    "\n",
    "3. **Handling Missing Data**:\n",
    "\n",
    "   - If `ignore_na=True`, missing values are ignored when calculating weights.\n",
    "   - If `ignore_na=False`, missing values are treated as part of the sequence.\n",
    "\n",
    "4. **Common Use Cases**:\n",
    "   - Smoothing time-series data.\n",
    "   - Computing exponentially weighted moving averages (EWMA).\n",
    "   - Analyzing trends with more weight on recent observations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Basic Exponentially Weighted Mean**\n",
    "\n",
    "Compute the exponentially weighted mean using `com`:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
    "df.ewm(com=0.5).mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Exponentially Weighted Mean with `alpha`**\n",
    "\n",
    "Compute the exponentially weighted mean using `alpha`:\n",
    "\n",
    "```python\n",
    "df.ewm(alpha=2/3).mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Adjustment (`adjust` Parameter)**\n",
    "\n",
    "Compare `adjust=True` (default) and `adjust=False`:\n",
    "\n",
    "```python\n",
    "# With adjust=True (default)\n",
    "df.ewm(com=0.5, adjust=True).mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "```\n",
    "\n",
    "```python\n",
    "# With adjust=False\n",
    "df.ewm(com=0.5, adjust=False).mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.666667\n",
    "2  1.555556\n",
    "3  1.555556\n",
    "4  3.650794\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Handling Missing Data (`ignore_na` Parameter)**\n",
    "\n",
    "Compare `ignore_na=True` and `ignore_na=False`:\n",
    "\n",
    "```python\n",
    "# With ignore_na=True\n",
    "df.ewm(com=0.5, ignore_na=True).mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.225000\n",
    "```\n",
    "\n",
    "```python\n",
    "# With ignore_na=False (default)\n",
    "df.ewm(com=0.5, ignore_na=False).mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.750000\n",
    "2  1.615385\n",
    "3  1.615385\n",
    "4  3.670213\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Time-Based Decay (`times` Parameter)**\n",
    "\n",
    "Compute the exponentially weighted mean with time-based decay:\n",
    "\n",
    "```python\n",
    "times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
    "df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "          B\n",
    "0  0.000000\n",
    "1  0.585786\n",
    "2  1.523889\n",
    "3  1.523889\n",
    "4  3.233686\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`rolling()`**: Rolling window calculations.\n",
    "- **`expanding()`**: Cumulative window calculations.\n",
    "- **`cumsum()`**: Cumulative sum (simpler alternative for specific cases).\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `ewm()`**\n",
    "\n",
    "- For **smoothing time-series data** with more weight on recent observations.\n",
    "- For **trend analysis** with exponential decay.\n",
    "- When you need **weighted metrics** that prioritize recent data.\n",
    "\n",
    "This method is essential for time-series analysis and smoothing in pandas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.abs\n",
    "DataFrame.abs()[source]\n",
    "Return a Series/DataFrame with absolute numeric value of each element.\n",
    "\n",
    "This function only applies to elements that are all numeric.\n",
    "\n",
    "Returns\n",
    ":\n",
    "abs\n",
    "Series/DataFrame containing the absolute value of each element.\n",
    "\n",
    "See also\n",
    "\n",
    "numpy.absolute\n",
    "Calculate the absolute value element-wise.\n",
    "\n",
    "Notes\n",
    "\n",
    "For complex inputs, 1.2 + 1j, the absolute value is \n",
    ".\n",
    "\n",
    "Examples\n",
    "\n",
    "Absolute numeric values in a Series.\n",
    "\n",
    "s = pd.Series([-1.10, 2, -3.33, 4])\n",
    "s.abs()\n",
    "0    1.10\n",
    "1    2.00\n",
    "2    3.33\n",
    "3    4.00\n",
    "dtype: float64\n",
    "Absolute numeric values in a Series with complex numbers.\n",
    "\n",
    "s = pd.Series([1.2 + 1j])\n",
    "s.abs()\n",
    "0    1.56205\n",
    "dtype: float64\n",
    "Absolute numeric values in a Series with a Timedelta element.\n",
    "\n",
    "s = pd.Series([pd.Timedelta('1 days')])\n",
    "s.abs()\n",
    "0   1 days\n",
    "dtype: timedelta64[ns]\n",
    "Select rows with data closest to certain value using argsort (from StackOverflow).\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 6, 7],\n",
    "    'b': [10, 20, 30, 40],\n",
    "    'c': [100, 50, -30, -50]\n",
    "})\n",
    "df\n",
    "     a    b    c\n",
    "0    4   10  100\n",
    "1    5   20   50\n",
    "2    6   30  -30\n",
    "3    7   40  -50\n",
    "df.loc[(df.c - 43).abs().argsort()]\n",
    "     a    b    c\n",
    "1    5   20   50\n",
    "0    4   10  100\n",
    "2    6   30  -30\n",
    "3    7   40  -50 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.abs()` method is used to compute the absolute numeric values of each element in a DataFrame or Series. This function is particularly useful when you want to ignore the sign of the numeric values, returning only their magnitudes.\n",
    "\n",
    "### Overview of `DataFrame.abs()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.abs()\n",
    "```\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **abs**: `Series` or `DataFrame`\n",
    "  - A Series or DataFrame containing the absolute value of each element. This function only applies to numeric elements.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The `abs()` method is similar to `numpy.absolute()`, which also calculates the absolute value element-wise.\n",
    "- For complex numbers, the absolute value is calculated as the magnitude of the complex number, given by the formula:\n",
    "  $$ |z| = \\sqrt{a^2 + b^2} $$\n",
    "  where \\( z = a + bi \\).\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Absolute Numeric Values in a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a Series with negative and positive values\n",
    "s = pd.Series([-1.10, 2, -3.33, 4])\n",
    "print(\"Absolute values in Series:\")\n",
    "print(s.abs())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1.10\n",
    "1    2.00\n",
    "2    3.33\n",
    "3    4.00\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 2: Absolute Numeric Values in a Series with Complex Numbers\n",
    "\n",
    "```python\n",
    "# Creating a Series with a complex number\n",
    "s_complex = pd.Series([1.2 + 1j])\n",
    "print(\"\\nAbsolute values in Series with complex numbers:\")\n",
    "print(s_complex.abs())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    1.56205\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 3: Absolute Numeric Values in a Series with Timedelta\n",
    "\n",
    "```python\n",
    "# Creating a Series with a Timedelta element\n",
    "s_timedelta = pd.Series([pd.Timedelta('1 days')])\n",
    "print(\"\\nAbsolute values in Series with Timedelta:\")\n",
    "print(s_timedelta.abs())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0   1 days\n",
    "dtype: timedelta64[ns]\n",
    "```\n",
    "\n",
    "#### Example 4: Selecting Rows Based on Closest Values Using Absolute Difference\n",
    "\n",
    "You can also use the `abs()` method to select rows with data closest to a certain value. Here’s how to do it using `argsort()`:\n",
    "\n",
    "```python\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 6, 7],\n",
    "    'b': [10, 20, 30, 40],\n",
    "    'c': [100, 50, -30, -50]\n",
    "})\n",
    "\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Selecting rows where column 'c' is closest to 43\n",
    "closest_rows = df.loc[(df.c - 43).abs().argsort()]\n",
    "print(\"\\nRows with 'c' closest to 43:\")\n",
    "print(closest_rows)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "   a   b    c\n",
    "0  4  10  100\n",
    "1  5  20   50\n",
    "2  6  30  -30\n",
    "3  7  40  -50\n",
    "\n",
    "Rows with 'c' closest to 43:\n",
    "   a   b   c\n",
    "1  5  20  50\n",
    "0  4  10 100\n",
    "2  6  30 -30\n",
    "3  7  40 -50\n",
    "```\n",
    "\n",
    "In this example, we calculate the absolute difference between the values in column `c` and the target value (43), then use `argsort()` to sort the indices based on the smallest differences, allowing us to retrieve the rows in order of proximity to the target value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.abs()`**, covering its syntax, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.abs()`**\n",
    "\n",
    "Returns a DataFrame or Series where each element is replaced by its **absolute value**. This function is applicable only to numeric data (integers, floats, and complex numbers).\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.abs()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame/Series**: A new DataFrame or Series with the absolute value of each element.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Applicability**:\n",
    "\n",
    "   - Works only on numeric data (integers, floats, complex numbers).\n",
    "   - For complex numbers, the absolute value is calculated as the magnitude:  \n",
    "     \\[\n",
    "     \\text{abs}(a + bj) = \\sqrt{a^2 + b^2}\n",
    "     \\]\n",
    "   - For timedelta objects, the absolute value is the same as the original value (since timedeltas are always non-negative).\n",
    "\n",
    "2. **Non-Numeric Data**:\n",
    "\n",
    "   - If the DataFrame or Series contains non-numeric data, it will be ignored, and the function will only apply to numeric columns.\n",
    "\n",
    "3. **Common Use Cases**:\n",
    "   - Converting negative values to positive.\n",
    "   - Calculating distances or deviations from a reference value.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Absolute Values in a Series**\n",
    "\n",
    "Compute the absolute values of a Series:\n",
    "\n",
    "```python\n",
    "s = pd.Series([-1.10, 2, -3.33, 4])\n",
    "s.abs()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0    1.10\n",
    "1    2.00\n",
    "2    3.33\n",
    "3    4.00\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Absolute Values in a Series with Complex Numbers**\n",
    "\n",
    "Compute the absolute values of a Series containing complex numbers:\n",
    "\n",
    "```python\n",
    "s = pd.Series([1.2 + 1j])\n",
    "s.abs()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0    1.56205\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Explanation:  \n",
    "\\[\n",
    "\\text{abs}(1.2 + 1j) = \\sqrt{1.2^2 + 1^2} = 1.56205\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Absolute Values in a DataFrame**\n",
    "\n",
    "Compute the absolute values of all numeric columns in a DataFrame:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 6, 7],\n",
    "    'b': [10, 20, 30, 40],\n",
    "    'c': [100, 50, -30, -50]\n",
    "})\n",
    "\n",
    "df.abs()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   a   b    c\n",
    "0  4  10  100\n",
    "1  5  20   50\n",
    "2  6  30   30\n",
    "3  7  40   50\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Absolute Values with Timedelta**\n",
    "\n",
    "Compute the absolute values of a Series containing timedelta objects:\n",
    "\n",
    "```python\n",
    "s = pd.Series([pd.Timedelta('1 days')])\n",
    "s.abs()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0   1 days\n",
    "dtype: timedelta64[ns]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Select Rows Closest to a Value Using `abs()`**\n",
    "\n",
    "Use `abs()` to find rows with values closest to a specific number:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 6, 7],\n",
    "    'b': [10, 20, 30, 40],\n",
    "    'c': [100, 50, -30, -50]\n",
    "})\n",
    "\n",
    "# Find rows where column 'c' is closest to 43\n",
    "df.loc[(df['c'] - 43).abs().argsort()]\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   a   b    c\n",
    "1  5  20   50\n",
    "0  4  10  100\n",
    "2  6  30  -30\n",
    "3  7  40  -50\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- `(df['c'] - 43).abs()` computes the absolute deviation from 43.\n",
    "- `argsort()` sorts the deviations in ascending order.\n",
    "- `df.loc[]` selects rows based on the sorted order.\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`numpy.absolute`**: Similar functionality in NumPy.\n",
    "- **`pandas.Series.abs()`**: Absolute values for a Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `abs()`**\n",
    "\n",
    "- To convert negative values to positive.\n",
    "- To calculate distances, deviations, or magnitudes.\n",
    "- For preprocessing data (e.g., removing negative values).\n",
    "\n",
    "This method is simple yet powerful for numeric data manipulation in pandas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.all\n",
    "DataFrame.all(axis=0, bool_only=False, skipna=True, **kwargs)[source]\n",
    "Return whether all elements are True, potentially over an axis.\n",
    "\n",
    "Returns True unless there at least one element within a series or along a Dataframe axis that is False or equivalent (e.g. zero or empty).\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
    "Indicate which axis or axes should be reduced. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "0 / ‘index’ : reduce the index, return a Series whose index is the original column labels.\n",
    "\n",
    "1 / ‘columns’ : reduce the columns, return a Series whose index is the original index.\n",
    "\n",
    "None : reduce all axes, return a scalar.\n",
    "\n",
    "bool_only\n",
    "bool, default False\n",
    "Include only boolean columns. Not implemented for Series.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If the entire row/column is NA and skipna is True, then the result will be True, as for an empty row/column. If skipna is False, then NA are treated as True, because these are not equal to zero.\n",
    "\n",
    "**kwargs\n",
    "any, default None\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "If level is specified, then, DataFrame is returned; otherwise, Series is returned.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.all\n",
    "Return True if all elements are True.\n",
    "\n",
    "DataFrame.any\n",
    "Return True if one (or more) elements are True.\n",
    "\n",
    "Examples\n",
    "\n",
    "Series\n",
    "\n",
    "pd.Series([True, True]).all()\n",
    "True\n",
    "pd.Series([True, False]).all()\n",
    "False\n",
    "pd.Series([], dtype=\"float64\").all()\n",
    "True\n",
    "pd.Series([np.nan]).all()\n",
    "True\n",
    "pd.Series([np.nan]).all(skipna=False)\n",
    "True\n",
    "DataFrames\n",
    "\n",
    "Create a dataframe from a dictionary.\n",
    "\n",
    "df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
    "df\n",
    "   col1   col2\n",
    "0  True   True\n",
    "1  True  False\n",
    "Default behaviour checks if values in each column all return True.\n",
    "\n",
    "df.all()\n",
    "col1     True\n",
    "col2    False\n",
    "dtype: bool\n",
    "Specify axis='columns' to check if values in each row all return True.\n",
    "\n",
    "df.all(axis='columns')\n",
    "0     True\n",
    "1    False\n",
    "dtype: bool\n",
    "Or axis=None for whether every value is True.\n",
    "\n",
    "df.all(axis=None)\n",
    "False \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.all()` method is used to determine whether all elements in a DataFrame (or Series) evaluate to `True` along a specified axis. It returns a boolean result indicating if every element is `True`, with options to customize its behavior regarding how it handles null values and which axes to check.\n",
    "\n",
    "### Overview of `DataFrame.all()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.all(axis=0, bool_only=False, skipna=True, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns', None}`, default `0`\n",
    "  - Determines which axis to reduce:\n",
    "    - `0` or `'index'` - Reduce the index (check each column).\n",
    "    - `1` or `'columns'` - Reduce the columns (check each row).\n",
    "    - `None` - Reduce all axes (check the entire DataFrame).\n",
    "- **bool_only**: `bool`, default `False`\n",
    "\n",
    "  - If `True`, includes only boolean columns. Note: This parameter is not implemented for Series.\n",
    "\n",
    "- **skipna**: `bool`, default `True`\n",
    "\n",
    "  - If `True`, excludes NA/null values. If an entire row or column is NA, the result will be `True` (for that row/column).\n",
    "  - If `False`, NAs are treated as `True` (i.e., they contribute to a True outcome).\n",
    "\n",
    "- **kwargs**: Additional keyword arguments (not used).\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series or DataFrame**\n",
    "  - Returns a Series if checking along one axis, or a scalar if reducing all axes.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **pandas.Series.all()**: Checks if all elements in a Series are `True`.\n",
    "- **DataFrame.any()**: Returns `True` if any element is `True`.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Using `all()` with a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Series examples\n",
    "print(pd.Series([True, True]).all())          # True\n",
    "print(pd.Series([True, False]).all())         # False\n",
    "print(pd.Series([], dtype=\"float64\").all())  # True (empty Series)\n",
    "print(pd.Series([np.nan]).all())              # True (NA ignored)\n",
    "print(pd.Series([np.nan]).all(skipna=False)) # True (NA treated as True)\n",
    "```\n",
    "\n",
    "#### Example 2: Using `all()` with a DataFrame\n",
    "\n",
    "```python\n",
    "# Creating a DataFrame from a dictionary\n",
    "df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Default behavior: Check if all values in each column are True\n",
    "print(\"\\nCheck all values in each column:\")\n",
    "print(df.all())  # Check along index (columns)\n",
    "\n",
    "# Specify axis='columns' to check if all values in each row are True\n",
    "print(\"\\nCheck all values in each row:\")\n",
    "print(df.all(axis='columns'))  # Check along columns (rows)\n",
    "\n",
    "# Check if all values in the entire DataFrame are True\n",
    "print(\"\\nCheck all values in the entire DataFrame:\")\n",
    "print(df.all(axis=None))  # Check all elements\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "   col1   col2\n",
    "0  True   True\n",
    "1  True  False\n",
    "\n",
    "Check all values in each column:\n",
    "col1     True\n",
    "col2    False\n",
    "dtype: bool\n",
    "\n",
    "Check all values in each row:\n",
    "0     True\n",
    "1    False\n",
    "dtype: bool\n",
    "\n",
    "Check all values in the entire DataFrame:\n",
    "False\n",
    "```\n",
    "\n",
    "### Explanation of the Output\n",
    "\n",
    "1. **Default Behavior**: When calling `df.all()` without parameters, it checks each column to see if all values in that column evaluate to `True`. Here, `col1` returns `True` because all values are `True`, while `col2` returns `False` because one value is `False`.\n",
    "\n",
    "2. **Axis Specified**: When using `df.all(axis='columns')`, it checks each row independently. The first row returns `True` (both values are `True`), while the second row returns `False` (because of the `False` in `col2`).\n",
    "\n",
    "3. **Checking Entire DataFrame**: Calling `df.all(axis=None)` checks all elements in the DataFrame. Since not all values are `True`, it returns `False`.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `DataFrame.all()` method is a powerful way to evaluate conditions across columns or rows in a DataFrame, making it useful for data validation, conditional checks, and any scenario where the truthiness of entire datasets is important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.all()`**, covering its syntax, parameters, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.all()`**\n",
    "\n",
    "Returns `True` if **all elements** in a DataFrame or Series are `True` (or equivalent, like non-zero numbers or non-empty strings). Otherwise, it returns `False`. This function can operate row-wise, column-wise, or across the entire DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.all(axis=0, bool_only=False, skipna=True, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "| Parameter  | Description     |\n",
    "| ---------- | --------------- |\n",
    "| **`axis`** | Axis to reduce: |\n",
    "\n",
    "- `0` or `'index'`: Check if all elements in each **column** are `True` (default).\n",
    "- `1` or `'columns'`: Check if all elements in each **row** are `True`.\n",
    "- `None`: Check if **all elements** in the entire DataFrame are `True`. |  \n",
    "  | **`bool_only`** | If `True`, include only boolean columns. Default is `False`. |  \n",
    "  | **`skipna`** | If `True`, exclude `NaN`/`None` values. If `False`, treat `NaN`/`None` as `True`. Default is `True`. |  \n",
    "  | **`**kwargs`\\*\\* | Additional arguments for compatibility (no effect). |\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: If `axis=0` or `axis=1`, returns a Series with boolean values.\n",
    "- **Scalar**: If `axis=None`, returns a single boolean value.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Behavior with `NaN`/`None`**:\n",
    "\n",
    "   - If `skipna=True` (default), `NaN`/`None` values are ignored.\n",
    "   - If `skipna=False`, `NaN`/`None` values are treated as `True`.\n",
    "\n",
    "2. **Behavior with Empty Data**:\n",
    "\n",
    "   - For an empty Series or DataFrame, `all()` returns `True`.\n",
    "\n",
    "3. **Common Use Cases**:\n",
    "   - Check if all values in a column/row meet a condition.\n",
    "   - Validate data integrity (e.g., ensure no `False` or zero values).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Series Examples**\n",
    "\n",
    "Check if all elements in a Series are `True`:\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, True])\n",
    "s.all()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Check with a `False` value:\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False])\n",
    "s.all()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Check with an empty Series:\n",
    "\n",
    "```python\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "s.all()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Check with `NaN` values:\n",
    "\n",
    "```python\n",
    "s = pd.Series([np.nan])\n",
    "s.all()  # skipna=True by default\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "```python\n",
    "s.all(skipna=False)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **DataFrame Examples**\n",
    "\n",
    "Check if all elements in each column are `True`:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
    "df.all()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "col1     True\n",
    "col2    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "Check if all elements in each row are `True`:\n",
    "\n",
    "```python\n",
    "df.all(axis='columns')\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0     True\n",
    "1    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "Check if all elements in the entire DataFrame are `True`:\n",
    "\n",
    "```python\n",
    "df.all(axis=None)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Handling `NaN` Values**\n",
    "\n",
    "Check with `NaN` values in a DataFrame:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'col1': [True, np.nan], 'col2': [True, False]})\n",
    "\n",
    "# Default behavior (skipna=True)\n",
    "df.all()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "col1     True\n",
    "col2    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "```python\n",
    "# Treat NaN as True (skipna=False)\n",
    "df.all(skipna=False)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "col1     True\n",
    "col2    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Using `bool_only`**\n",
    "\n",
    "Check only boolean columns:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'col1': [True, True], 'col2': [1, 0]})\n",
    "\n",
    "# Include only boolean columns\n",
    "df.all(bool_only=True)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "col1    True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`DataFrame.any()`**: Returns `True` if **any** element is `True`.\n",
    "- **`Series.all()`**: Similar functionality for Series.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `all()`**\n",
    "\n",
    "- To validate if **all values** in a dataset meet a condition.\n",
    "- To check for the absence of `False`, `0`, or empty values.\n",
    "- For data integrity checks in preprocessing pipelines.\n",
    "\n",
    "This method is simple yet powerful for boolean evaluations in pandas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.any\n",
    "DataFrame.any(*, axis=0, bool_only=False, skipna=True, **kwargs)[source]\n",
    "Return whether any element is True, potentially over an axis.\n",
    "\n",
    "Returns False unless there is at least one element within a series or along a Dataframe axis that is True or equivalent (e.g. non-zero or non-empty).\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
    "Indicate which axis or axes should be reduced. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "0 / ‘index’ : reduce the index, return a Series whose index is the original column labels.\n",
    "\n",
    "1 / ‘columns’ : reduce the columns, return a Series whose index is the original index.\n",
    "\n",
    "None : reduce all axes, return a scalar.\n",
    "\n",
    "bool_only\n",
    "bool, default False\n",
    "Include only boolean columns. Not implemented for Series.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If the entire row/column is NA and skipna is True, then the result will be False, as for an empty row/column. If skipna is False, then NA are treated as True, because these are not equal to zero.\n",
    "\n",
    "**kwargs\n",
    "any, default None\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "If level is specified, then, DataFrame is returned; otherwise, Series is returned.\n",
    "\n",
    "See also\n",
    "\n",
    "numpy.any\n",
    "Numpy version of this method.\n",
    "\n",
    "Series.any\n",
    "Return whether any element is True.\n",
    "\n",
    "Series.all\n",
    "Return whether all elements are True.\n",
    "\n",
    "DataFrame.any\n",
    "Return whether any element is True over requested axis.\n",
    "\n",
    "DataFrame.all\n",
    "Return whether all elements are True over requested axis.\n",
    "\n",
    "Examples\n",
    "\n",
    "Series\n",
    "\n",
    "For Series input, the output is a scalar indicating whether any element is True.\n",
    "\n",
    "pd.Series([False, False]).any()\n",
    "False\n",
    "pd.Series([True, False]).any()\n",
    "True\n",
    "pd.Series([], dtype=\"float64\").any()\n",
    "False\n",
    "pd.Series([np.nan]).any()\n",
    "False\n",
    "pd.Series([np.nan]).any(skipna=False)\n",
    "True\n",
    "DataFrame\n",
    "\n",
    "Whether each column contains at least one True element (the default).\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
    "df\n",
    "   A  B  C\n",
    "0  1  0  0\n",
    "1  2  2  0\n",
    "df.any()\n",
    "A     True\n",
    "B     True\n",
    "C    False\n",
    "dtype: bool\n",
    "Aggregating over the columns.\n",
    "\n",
    "df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
    "df\n",
    "       A  B\n",
    "0   True  1\n",
    "1  False  2\n",
    "df.any(axis='columns')\n",
    "0    True\n",
    "1    True\n",
    "dtype: bool\n",
    "df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
    "df\n",
    "       A  B\n",
    "0   True  1\n",
    "1  False  0\n",
    "df.any(axis='columns')\n",
    "0    True\n",
    "1    False\n",
    "dtype: bool\n",
    "Aggregating over the entire DataFrame with axis=None.\n",
    "\n",
    "df.any(axis=None)\n",
    "True\n",
    "any for an empty DataFrame is an empty Series.\n",
    "\n",
    "pd.DataFrame([]).any()\n",
    "Series([], dtype: bool) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.any()` method is a powerful tool used to determine whether any elements within a DataFrame (or Series) evaluate to `True`. This function is particularly useful for checking if at least one value meets a certain condition along specified axes.\n",
    "\n",
    "### Overview of `DataFrame.any()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.any(axis=0, bool_only=False, skipna=True, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns', None}`, default `0`\n",
    "\n",
    "  - Defines the axis to evaluate:\n",
    "    - `0` or `'index'`: Reduce across the index (check each column).\n",
    "    - `1` or `'columns'`: Reduce across the columns (check each row).\n",
    "    - `None`: Reduce over all axes, returning a scalar result.\n",
    "\n",
    "- **bool_only**: `bool`, default `False`\n",
    "\n",
    "  - When set to `True`, it only includes columns that are of boolean type. Not applicable for Series.\n",
    "\n",
    "- **skipna**: `bool`, default `True`\n",
    "  - If `True`, NA/null values are excluded from the evaluation. If the entire row or column is NA, the result will be `False`.\n",
    "  - If `False`, NA values are treated as `True`, influencing the outcome.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series or scalar**\n",
    "  - A Series is returned when checking one axis, or a scalar Boolean value when reducing across all axes.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **numpy.any**: Similar function in NumPy for evaluating boolean conditions.\n",
    "- **Series.any**: For evaluating whether any element in a Series is `True`.\n",
    "- **DataFrame.all**: Checks if all elements are `True` across specified axes.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Using `any()` with a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Series examples\n",
    "print(pd.Series([False, False]).any())           # False\n",
    "print(pd.Series([True, False]).any())            # True\n",
    "print(pd.Series([], dtype=\"float64\").any())     # False (empty Series)\n",
    "print(pd.Series([np.nan]).any())                 # False (NA ignored)\n",
    "print(pd.Series([np.nan]).any(skipna=False))    # True (NA treated as True when skipna=False)\n",
    "```\n",
    "\n",
    "#### Example 2: Using `any()` with a DataFrame\n",
    "\n",
    "```python\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Check if any values in each column are True (non-zero)\n",
    "print(\"\\nCheck if any values in each column are True:\")\n",
    "print(df.any())  # Default behavior\n",
    "\n",
    "# Aggregating over rows (checking if any value in each row is True)\n",
    "print(\"\\nCheck if any values in each row are True:\")\n",
    "print(df.any(axis='columns'))\n",
    "\n",
    "# DataFrame with mixed boolean and numerical values\n",
    "df_mixed = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
    "print(\"\\nDataFrame with mixed types:\")\n",
    "print(df_mixed)\n",
    "\n",
    "# Check if any value in each row is True\n",
    "print(\"\\nCheck if any values in each row are True:\")\n",
    "print(df_mixed.any(axis='columns'))\n",
    "\n",
    "# Aggregating over the entire DataFrame with axis=None\n",
    "print(\"\\nCheck whether any value in the entire DataFrame is True:\")\n",
    "print(df.any(axis=None))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "   A  B  C\n",
    "0  1  0  0\n",
    "1  2  2  0\n",
    "\n",
    "Check if any values in each column are True:\n",
    "A     True\n",
    "B     True\n",
    "C    False\n",
    "dtype: bool\n",
    "\n",
    "Check if any values in each row are True:\n",
    "0    True\n",
    "1    True\n",
    "dtype: bool\n",
    "\n",
    "DataFrame with mixed types:\n",
    "       A  B\n",
    "0   True  1\n",
    "1  False  2\n",
    "\n",
    "Check if any values in each row are True:\n",
    "0    True\n",
    "1    True\n",
    "dtype: bool\n",
    "\n",
    "Check whether any value in the entire DataFrame is True:\n",
    "True\n",
    "```\n",
    "\n",
    "### Explanation of the Output\n",
    "\n",
    "1. **Column Checks**: The `df.any()` call evaluates each column for any non-zero values. In the first DataFrame, columns `A` and `B` return `True`, indicating they contain at least one non-zero value, while column `C` returns `False`.\n",
    "\n",
    "2. **Row Checks**: When using `any(axis='columns')`, it evaluates whether each row contains at least one non-zero value, returning `True` for all rows since both rows have at least one non-zero entry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.any()` method is used to evaluate whether any elements within a DataFrame (or Series) are `True` along a specified axis. This method returns a boolean value indicating if at least one element meets the condition, and it provides options for handling missing values and choosing the axis over which to aggregate.\n",
    "\n",
    "### Overview of `DataFrame.any()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.any(*, axis=0, bool_only=False, skipna=True, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns', None}`, default `0`\n",
    "\n",
    "  - Specifies which axis to reduce:\n",
    "    - `0` or `'index'` - Aggregates across the index (checks each column).\n",
    "    - `1` or `'columns'` - Aggregates across the columns (checks each row).\n",
    "    - `None` - Reduces across all axes (checks the entire DataFrame).\n",
    "\n",
    "- **bool_only**: `bool`, default `False`\n",
    "\n",
    "  - If `True`, includes only boolean columns. This parameter is not applicable to Series.\n",
    "\n",
    "- **skipna**: `bool`, default `True`\n",
    "\n",
    "  - If `True`, NA/null values are excluded. If an entire row or column is NA and `skipna` is `True`, the result will be `False`.\n",
    "  - If `False`, NAs are treated as `True`, meaning they will not affect the aggregate result as they are not zero or empty.\n",
    "\n",
    "- **kwargs**: Additional keyword arguments that are not used but can be included for compatibility with NumPy.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - A Series is returned if checking along one axis; if all axes are checked, a scalar is returned.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **numpy.any**: The NumPy version of this method.\n",
    "- **Series.any()**: Returns `True` if any element in a Series is `True`.\n",
    "- **Series.all()**: Returns `True` if all elements in a Series are `True`.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Using `any()` with a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Series examples\n",
    "print(pd.Series([False, False]).any())          # False\n",
    "print(pd.Series([True, False]).any())           # True\n",
    "print(pd.Series([], dtype=\"float64\").any())    # False (empty Series)\n",
    "print(pd.Series([np.nan]).any())                 # False (NaN ignored)\n",
    "print(pd.Series([np.nan]).any(skipna=False))    # True (NaN is treated as True)\n",
    "```\n",
    "\n",
    "#### Example 2: Using `any()` with a DataFrame\n",
    "\n",
    "```python\n",
    "# Creating a DataFrame with values\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
    "print(\"\\nOriginal DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Default behavior: Check if any value in each column is True (non-zero)\n",
    "print(\"\\nCheck any value in each column:\")\n",
    "print(df.any())  # Checks along index (columns)\n",
    "\n",
    "# Specifying axis='columns' to check if any value in each row is True\n",
    "df2 = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
    "print(\"\\nDataFrame for row-wise check:\")\n",
    "print(df2)\n",
    "print(\"\\nCheck any value in each row:\")\n",
    "print(df2.any(axis='columns'))  # Checks along columns (rows)\n",
    "\n",
    "# Another example with different values\n",
    "df3 = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
    "print(\"\\nDataFrame with mixed values:\")\n",
    "print(df3)\n",
    "print(\"\\nCheck any value in each row:\")\n",
    "print(df3.any(axis='columns'))  # Checks along columns (rows)\n",
    "\n",
    "# Check if any value in the entire DataFrame is True\n",
    "print(\"\\nCheck any value in the entire DataFrame:\")\n",
    "print(df.any(axis=None))  # Checks all elements\n",
    "\n",
    "# Check for an empty DataFrame\n",
    "print(\"\\nAny for an empty DataFrame:\")\n",
    "print(pd.DataFrame([]).any())  # Should return an empty Series\n",
    "```\n",
    "\n",
    "### Explanation of the Output\n",
    "\n",
    "1. **Series Checks**: The output from the Series checks validates if any elements are `True`. For example, an empty Series returns `False`.\n",
    "\n",
    "2. **Column Checks**: The DataFrame `df` checks if any values in each column are non-zero (which evaluates to `True`). Columns A and B return `True`, while column C returns `False` since all its values are zero.\n",
    "\n",
    "3. **Row Checks**: For DataFrame `df2`, the method checks each row for any `True` values. The output indicates every row contains at least\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.any()`**, covering its syntax, parameters, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.any()`**\n",
    "\n",
    "Returns `True` if **any element** in a DataFrame or Series is `True` (or equivalent, like non-zero numbers or non-empty strings). Otherwise, it returns `False`. This function can operate row-wise, column-wise, or across the entire DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.any(*, axis=0, bool_only=False, skipna=True, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "| Parameter  | Description     |\n",
    "| ---------- | --------------- |\n",
    "| **`axis`** | Axis to reduce: |\n",
    "\n",
    "- `0` or `'index'`: Check if any element in each **column** is `True` (default).\n",
    "- `1` or `'columns'`: Check if any element in each **row** is `True`.\n",
    "- `None`: Check if **any element** in the entire DataFrame is `True`. |  \n",
    "  | **`bool_only`** | If `True`, include only boolean columns. Default is `False`. |  \n",
    "  | **`skipna`** | If `True`, exclude `NaN`/`None` values. If `False`, treat `NaN`/`None` as `True`. Default is `True`. |  \n",
    "  | **`**kwargs`\\*\\* | Additional arguments for compatibility (no effect). |\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: If `axis=0` or `axis=1`, returns a Series with boolean values.\n",
    "- **Scalar**: If `axis=None`, returns a single boolean value.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Behavior with `NaN`/`None`**:\n",
    "\n",
    "   - If `skipna=True` (default), `NaN`/`None` values are ignored.\n",
    "   - If `skipna=False`, `NaN`/`None` values are treated as `True`.\n",
    "\n",
    "2. **Behavior with Empty Data**:\n",
    "\n",
    "   - For an empty Series or DataFrame, `any()` returns `False`.\n",
    "\n",
    "3. **Common Use Cases**:\n",
    "   - Check if **any value** in a column/row meets a condition.\n",
    "   - Validate data integrity (e.g., ensure at least one `True` or non-zero value).\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Series Examples**\n",
    "\n",
    "Check if any element in a Series is `True`:\n",
    "\n",
    "```python\n",
    "s = pd.Series([False, False])\n",
    "s.any()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Check with a `True` value:\n",
    "\n",
    "```python\n",
    "s = pd.Series([True, False])\n",
    "s.any()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "Check with an empty Series:\n",
    "\n",
    "```python\n",
    "s = pd.Series([], dtype=\"float64\")\n",
    "s.any()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Check with `NaN` values:\n",
    "\n",
    "```python\n",
    "s = pd.Series([np.nan])\n",
    "s.any()  # skipna=True by default\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "```python\n",
    "s.any(skipna=False)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **DataFrame Examples**\n",
    "\n",
    "Check if any element in each column is `True`:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, 0], 'B': [0, 0], 'C': [0, 2]})\n",
    "df.any()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "A     True\n",
    "B    False\n",
    "C     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "Check if any element in each row is `True`:\n",
    "\n",
    "```python\n",
    "df.any(axis='columns')\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0     True\n",
    "1     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "Check if any element in the entire DataFrame is `True`:\n",
    "\n",
    "```python\n",
    "df.any(axis=None)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Handling `NaN` Values**\n",
    "\n",
    "Check with `NaN` values in a DataFrame:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [True, np.nan], 'B': [False, False]})\n",
    "\n",
    "# Default behavior (skipna=True)\n",
    "df.any()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "A     True\n",
    "B    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "```python\n",
    "# Treat NaN as True (skipna=False)\n",
    "df.any(skipna=False)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "A     True\n",
    "B    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Using `bool_only`**\n",
    "\n",
    "Check only boolean columns:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [True, False], 'B': [1, 0]})\n",
    "\n",
    "# Include only boolean columns\n",
    "df.any(bool_only=True)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "A     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`DataFrame.all()`**: Returns `True` if **all elements** are `True`.\n",
    "- **`Series.any()`**: Similar functionality for Series.\n",
    "- **`numpy.any()`**: NumPy version of this method.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `any()`**\n",
    "\n",
    "- To validate if **any value** in a dataset meets a condition.\n",
    "- To check for the presence of `True`, non-zero, or non-empty values.\n",
    "- For data integrity checks in preprocessing pipelines.\n",
    "\n",
    "This method is simple yet powerful for boolean evaluations in pandas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.clip\n",
    "DataFrame.clip(lower=None, upper=None, *, axis=None, inplace=False, **kwargs)[source]\n",
    "Trim values at input threshold(s).\n",
    "\n",
    "Assigns values outside boundary to boundary values. Thresholds can be singular values or array like, and in the latter case the clipping is performed element-wise in the specified axis.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "lower\n",
    "float or array-like, default None\n",
    "Minimum threshold value. All values below this threshold will be set to it. A missing threshold (e.g NA) will not clip the value.\n",
    "\n",
    "upper\n",
    "float or array-like, default None\n",
    "Maximum threshold value. All values above this threshold will be set to it. A missing threshold (e.g NA) will not clip the value.\n",
    "\n",
    "axis\n",
    "{{0 or ‘index’, 1 or ‘columns’, None}}, default None\n",
    "Align object with lower and upper along the given axis. For Series this parameter is unused and defaults to None.\n",
    "\n",
    "inplace\n",
    "bool, default False\n",
    "Whether to perform the operation in place on the data.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional keywords have no effect but might be accepted for compatibility with numpy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame or None\n",
    "Same type as calling object with the values outside the clip boundaries replaced or None if inplace=True.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.clip\n",
    "Trim values at input threshold in series.\n",
    "\n",
    "DataFrame.clip\n",
    "Trim values at input threshold in dataframe.\n",
    "\n",
    "numpy.clip\n",
    "Clip (limit) the values in an array.\n",
    "\n",
    "Examples\n",
    "\n",
    "data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "   col_0  col_1\n",
    "0      9     -2\n",
    "1     -3     -7\n",
    "2      0      6\n",
    "3     -1      8\n",
    "4      5     -5\n",
    "Clips per column using lower and upper thresholds:\n",
    "\n",
    "df.clip(-4, 6)\n",
    "   col_0  col_1\n",
    "0      6     -2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3     -1      6\n",
    "4      5     -4\n",
    "Clips using specific lower and upper thresholds per column:\n",
    "\n",
    "df.clip([-2, -1], [4, 5])\n",
    "    col_0  col_1\n",
    "0      4     -1\n",
    "1     -2     -1\n",
    "2      0      5\n",
    "3     -1      5\n",
    "4      4     -1\n",
    "Clips using specific lower and upper thresholds per column element:\n",
    "\n",
    "t = pd.Series([2, -4, -1, 6, 3])\n",
    "t\n",
    "0    2\n",
    "1   -4\n",
    "2   -1\n",
    "3    6\n",
    "4    3\n",
    "dtype: int64\n",
    "df.clip(t, t + 4, axis=0)\n",
    "   col_0  col_1\n",
    "0      6      2\n",
    "1     -3     -4\n",
    "2      0      3\n",
    "3      6      8\n",
    "4      5      3\n",
    "Clips using specific lower threshold per column element, with missing values:\n",
    "\n",
    "t = pd.Series([2, -4, np.nan, 6, 3])\n",
    "t\n",
    "0    2.0\n",
    "1   -4.0\n",
    "2    NaN\n",
    "3    6.0\n",
    "4    3.0\n",
    "dtype: float64\n",
    "df.clip(t, axis=0)\n",
    "col_0  col_1\n",
    "0      9      2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3      6      8\n",
    "4      5      3 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.clip()` method is used to trim values in a DataFrame to specified thresholds. Any values below the `lower` threshold are set to that threshold, and any values above the `upper` threshold are set to that upper limit. This method can be particularly useful for data normalization and outlier removal.\n",
    "\n",
    "### Overview of `DataFrame.clip()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.clip(lower=None, upper=None, *, axis=None, inplace=False, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **lower**: `float` or `array-like`, default `None`\n",
    "\n",
    "  - The minimum threshold value. Values below this threshold will be set to the threshold. If not provided, there is no lower limit.\n",
    "\n",
    "- **upper**: `float` or `array-like`, default `None`\n",
    "\n",
    "  - The maximum threshold value. Values above this threshold will be set to the threshold. If not provided, there is no upper limit.\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns', None}`, default `None`\n",
    "\n",
    "  - Aligns the DataFrame with `lower` and `upper` along the specified axis for element-wise clipping.\n",
    "\n",
    "- **inplace**: `bool`, default `False`\n",
    "\n",
    "  - If `True`, modifies the DataFrame in place; if `False`, returns a new DataFrame with clipped values.\n",
    "\n",
    "- **kwargs**: Additional keyword arguments that are ignored but may be accepted for compatibility with NumPy.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series or DataFrame or None**:\n",
    "  - Returns a DataFrame with values clipped to the thresholds. If `inplace=True`, it returns `None`.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **Series.clip()**: Similar method for Series objects.\n",
    "- **numpy.clip()**: For clipping values in NumPy arrays.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Clipping\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with sample data\n",
    "data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Clip values using a lower and upper threshold\n",
    "clipped_df = df.clip(lower=-4, upper=6)\n",
    "print(\"\\nClipped DataFrame with thresholds (-4, 6):\")\n",
    "print(clipped_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original DataFrame:\n",
    "   col_0  col_1\n",
    "0      9     -2\n",
    "1     -3     -7\n",
    "2      0      6\n",
    "3     -1      8\n",
    "4      5     -5\n",
    "\n",
    "Clipped DataFrame with thresholds (-4, 6):\n",
    "   col_0  col_1\n",
    "0      6     -2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3     -1      6\n",
    "4      5     -4\n",
    "```\n",
    "\n",
    "#### Example 2: Specifying Thresholds Per Column\n",
    "\n",
    "```python\n",
    "# Clip using specific lower and upper thresholds for each column\n",
    "clipped_df_columns = df.clip(lower=[-2, -1], upper=[4, 5])\n",
    "print(\"\\nClipped DataFrame with specific thresholds per column:\")\n",
    "print(clipped_df_columns)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Clipped DataFrame with specific thresholds per column:\n",
    "   col_0  col_1\n",
    "0      4     -1\n",
    "1     -2     -1\n",
    "2      0      5\n",
    "3     -1      5\n",
    "4      4     -1\n",
    "```\n",
    "\n",
    "#### Example 3: Clipping Using a Series\n",
    "\n",
    "```python\n",
    "# Clipping using a Series for thresholds\n",
    "t = pd.Series([2, -4, -1, 6, 3])\n",
    "print(\"\\nSeries used for clipping:\")\n",
    "print(t)\n",
    "\n",
    "clipped_with_series = df.clip(lower=t, upper=t + 4, axis=0)\n",
    "print(\"\\nClipped DataFrame using Series for thresholds:\")\n",
    "print(clipped_with_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Series used for clipping:\n",
    "0    2\n",
    "1   -4\n",
    "2   -1\n",
    "3    6\n",
    "4    3\n",
    "dtype: int64\n",
    "\n",
    "Clipped DataFrame using Series for thresholds:\n",
    "   col_0  col_1\n",
    "0      6      2\n",
    "1     -3     -4\n",
    "2      0      3\n",
    "3      6      8\n",
    "4      5      3\n",
    "```\n",
    "\n",
    "#### Example 4: Clipping with Missing Values\n",
    "\n",
    "```python\n",
    "# Clipping with a Series containing NaN values\n",
    "t_nan = pd.Series([2, -4, np.nan, 6, 3])\n",
    "print(\"\\nSeries with missing values:\")\n",
    "print(t_nan)\n",
    "\n",
    "clipped_with_nan = df.clip(lower=t_nan, axis=0)\n",
    "print(\"\\nClipped DataFrame with Series containing NaN:\")\n",
    "print(clipped_with_nan)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Series with missing values:\n",
    "0    2.0\n",
    "1   -4.0\n",
    "2    NaN\n",
    "3    6.0\n",
    "4    3.0\n",
    "dtype: float64\n",
    "\n",
    "Clipped DataFrame with Series containing NaN:\n",
    "   col_0  col_1\n",
    "0      9      2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3      6      8\n",
    "4      5      3\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `DataFrame.clip()` method provides an effective way to manage extreme values in your DataFrame by trimming them to specific ranges. This is useful for data preprocessing and ensuring that your dataset adheres to certain limits for analysis or modeling purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.clip()`**, covering its syntax, parameters, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.clip()`**\n",
    "\n",
    "Trims values at specified thresholds. Values below the `lower` threshold are set to the `lower` value, and values above the `upper` threshold are set to the `upper` value. This function can be applied element-wise, column-wise, or row-wise.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.clip(lower=None, upper=None, axis=None, inplace=False, **kwargs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "| Parameter   | Description                                                                                       |\n",
    "| ----------- | ------------------------------------------------------------------------------------------------- |\n",
    "| **`lower`** | Minimum threshold value. All values below this are set to `lower`. Can be a scalar or array-like. |\n",
    "| **`upper`** | Maximum threshold value. All values above this are set to `upper`. Can be a scalar or array-like. |\n",
    "| **`axis`**  | Axis to align `lower` and `upper` thresholds:                                                     |\n",
    "\n",
    "- `0` or `'index'`: Align with rows.\n",
    "- `1` or `'columns'`: Align with columns.\n",
    "- `None`: Align with both rows and columns (default). |  \n",
    "  | **`inplace`** | If `True`, performs the operation in place and returns `None`. Default is `False`. |  \n",
    "  | **`**kwargs`\\*\\* | Additional arguments for compatibility (no effect). |\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **DataFrame/Series**: A new DataFrame or Series with clipped values.\n",
    "- **None**: If `inplace=True`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **Thresholds**:\n",
    "\n",
    "   - If `lower` or `upper` is `None`, no clipping is performed for that bound.\n",
    "   - If `lower` or `upper` is array-like, it must match the shape of the DataFrame or Series along the specified axis.\n",
    "\n",
    "2. **Behavior with `NaN`**:\n",
    "\n",
    "   - If `lower` or `upper` contains `NaN`, those values are ignored (no clipping occurs for those elements).\n",
    "\n",
    "3. **Common Use Cases**:\n",
    "   - Limit values to a specific range (e.g., for normalization or outlier handling).\n",
    "   - Apply element-wise or column-wise clipping.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Basic Clipping**\n",
    "\n",
    "Clip all values in a DataFrame to a range:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]})\n",
    "df.clip(-4, 6)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   col_0  col_1\n",
    "0      6     -2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3     -1      6\n",
    "4      5     -4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Column-Wise Clipping**\n",
    "\n",
    "Clip each column with different thresholds:\n",
    "\n",
    "```python\n",
    "df.clip(lower=[-2, -1], upper=[4, 5])\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   col_0  col_1\n",
    "0      4     -1\n",
    "1     -2     -1\n",
    "2      0      5\n",
    "3     -1      5\n",
    "4      4     -1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Row-Wise Clipping**\n",
    "\n",
    "Clip each row with different thresholds:\n",
    "\n",
    "```python\n",
    "t = pd.Series([2, -4, -1, 6, 3])\n",
    "df.clip(lower=t, upper=t + 4, axis=0)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   col_0  col_1\n",
    "0      6      2\n",
    "1     -3     -4\n",
    "2      0      3\n",
    "3      6      8\n",
    "4      5      3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Handling `NaN` in Thresholds**\n",
    "\n",
    "Clip with `NaN` in thresholds (ignores `NaN` values):\n",
    "\n",
    "```python\n",
    "t = pd.Series([2, -4, np.nan, 6, 3])\n",
    "df.clip(lower=t, axis=0)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   col_0  col_1\n",
    "0      9      2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3      6      8\n",
    "4      5      3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **In-Place Clipping**\n",
    "\n",
    "Clip values in place (modifies the original DataFrame):\n",
    "\n",
    "```python\n",
    "df.clip(-4, 6, inplace=True)\n",
    "df\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "   col_0  col_1\n",
    "0      6     -2\n",
    "1     -3     -4\n",
    "2      0      6\n",
    "3     -1      6\n",
    "4      5     -4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`Series.clip()`**: Clip values in a Series.\n",
    "- **`numpy.clip()`**: Clip values in a NumPy array.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `clip()`**\n",
    "\n",
    "- To limit values to a specific range (e.g., for normalization).\n",
    "- To handle outliers by capping extreme values.\n",
    "- For element-wise or column-wise data manipulation.\n",
    "\n",
    "This method is powerful for data preprocessing and cleaning in pandas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "pandas.DataFrame.corr\n",
    "\n",
    "DataFrame.corr(method='pearson', min_periods=1, numeric_only=False)\n",
    "\n",
    "Compute pairwise correlation of columns, excluding NA/null values.\n",
    "\n",
    "Parameters:\n",
    "method{‘pearson’, ‘kendall’, ‘spearman’} or callable\n",
    "Method of correlation:\n",
    "\n",
    "pearson : standard correlation coefficient\n",
    "\n",
    "kendall : Kendall Tau correlation coefficient\n",
    "\n",
    "spearman : Spearman rank correlation\n",
    "\n",
    "callable: callable with input two 1d ndarrays\n",
    "and returning a float. Note that the returned matrix from corr will have 1 along the diagonals and will be symmetric regardless of the callable’s behavior.\n",
    "\n",
    "min_periodsint, optional\n",
    "Minimum number of observations required per pair of columns to have a valid result. Currently only available for Pearson and Spearman correlation.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int or boolean data.\n",
    "\n",
    "Added in version 1.5.0.\n",
    "\n",
    "Changed in version 2.0.0: The default value of numeric_only is now False.\n",
    "\n",
    "Returns:\n",
    "DataFrame\n",
    "Correlation matrix.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.corrwith\n",
    "Compute pairwise correlation with another DataFrame or Series.\n",
    "\n",
    "Series.corr\n",
    "Compute the correlation between two Series.\n",
    "\n",
    "Notes\n",
    "\n",
    "Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\n",
    "\n",
    "Pearson correlation coefficient\n",
    "\n",
    "Kendall rank correlation coefficient\n",
    "\n",
    "Spearman’s rank correlation coefficient\n",
    "\n",
    "Examples\n",
    "\n",
    "def histogram_intersection(a, b):\n",
    "    v = np.minimum(a, b).sum().round(decimals=1)\n",
    "    return v\n",
    "df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
    "                  columns=['dogs', 'cats'])\n",
    "df.corr(method=histogram_intersection)\n",
    "      dogs  cats\n",
    "dogs   1.0   0.3\n",
    "cats   0.3   1.0\n",
    "df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\n",
    "                  columns=['dogs', 'cats'])\n",
    "df.corr(min_periods=3)\n",
    "      dogs  cats\n",
    "dogs   1.0   NaN\n",
    "cats   NaN   1.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.corr` method is used to compute pairwise correlation of columns in a DataFrame, excluding NA/null values. Below is a comprehensive overview of the syntax, parameters, and usage examples:\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.corr(method='pearson', min_periods=1, numeric_only=False)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "1. **method** : `{'pearson', 'kendall', 'spearman'}` or callable, default 'pearson'\n",
    "\n",
    "   - Method of correlation:\n",
    "     - **pearson** : Standard correlation coefficient.\n",
    "     - **kendall** : Kendall Tau correlation coefficient.\n",
    "     - **spearman** : Spearman rank correlation.\n",
    "     - **callable** : A callable function that takes two 1d ndarrays as input and returns a float. The returned matrix will have 1 along the diagonals and will be symmetric.\n",
    "\n",
    "2. **min_periods** : int, optional\n",
    "\n",
    "   - Minimum number of observations required per pair of columns to have a valid result. Currently, this is only available for Pearson and Spearman correlation.\n",
    "\n",
    "3. **numeric_only** : bool, default False\n",
    "   - If True, includes only float, int, or boolean data in the correlation computation. This parameter was added in version 1.5.0, and its default value changed to False in version 2.0.0.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrame** : Correlation matrix.\n",
    "\n",
    "### See Also\n",
    "\n",
    "- **DataFrame.corrwith** : Compute pairwise correlation with another DataFrame or Series.\n",
    "- **Series.corr** : Compute the correlation between two Series.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Pearson, Kendall, and Spearman correlations are computed using pairwise complete observations.\n",
    "- The Pearson correlation coefficient measures linear correlation.\n",
    "- The Kendall rank correlation coefficient measures ordinal association.\n",
    "- Spearman’s rank correlation coefficient assesses how well the relationship between two variables can be described using a monotonic function.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Using Pearson Correlation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [4, 3, 2, 1],\n",
    "    'C': [1, 3, 2, 4]\n",
    "})\n",
    "\n",
    "# Compute Pearson correlation\n",
    "corr_matrix = df.corr(method='pearson')\n",
    "print(corr_matrix)\n",
    "```\n",
    "\n",
    "#### Example 2: Using Spearman Correlation\n",
    "\n",
    "```python\n",
    "# Compute Spearman correlation\n",
    "corr_matrix = df.corr(method='spearman')\n",
    "print(corr_matrix)\n",
    "```\n",
    "\n",
    "#### Example 3: Using a Custom Callable Function\n",
    "\n",
    "```python\n",
    "def histogram_intersection(a, b):\n",
    "    v = np.minimum(a, b).sum().round(decimals=1)\n",
    "    return v\n",
    "\n",
    "df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
    "                  columns=['dogs', 'cats'])\n",
    "\n",
    "# Compute correlation using custom function\n",
    "corr_matrix = df.corr(method=histogram_intersection)\n",
    "print(corr_matrix)\n",
    "```\n",
    "\n",
    "#### Example 4: Handling Missing Values with `min_periods`\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\n",
    "                  columns=['dogs', 'cats'])\n",
    "\n",
    "# Compute correlation with minimum periods\n",
    "corr_matrix = df.corr(min_periods=3)\n",
    "print(corr_matrix)\n",
    "```\n",
    "\n",
    "### Output Examples\n",
    "\n",
    "#### Example 1 Output:\n",
    "\n",
    "```python\n",
    "     A    B    C\n",
    "A  1.0 -1.0  0.8\n",
    "B -1.0  1.0 -0.8\n",
    "C  0.8 -0.8  1.0\n",
    "```\n",
    "\n",
    "#### Example 2 Output:\n",
    "\n",
    "```python\n",
    "     A    B    C\n",
    "A  1.0 -1.0  0.8\n",
    "B -1.0  1.0 -0.8\n",
    "C  0.8 -0.8  1.0\n",
    "```\n",
    "\n",
    "#### Example 3 Output:\n",
    "\n",
    "```python\n",
    "      dogs  cats\n",
    "dogs   1.0   0.3\n",
    "cats   0.3   1.0\n",
    "```\n",
    "\n",
    "#### Example 4 Output:\n",
    "\n",
    "```python\n",
    "      dogs  cats\n",
    "dogs   1.0   NaN\n",
    "cats   NaN   1.0\n",
    "```\n",
    "\n",
    "### Additional Notes\n",
    "\n",
    "- The correlation matrix will always have 1s on the diagonal, representing the correlation of each column with itself.\n",
    "- If there are insufficient valid pairs of observations (less than `min_periods`), the result will be `NaN` for those pairs.\n",
    "- The `numeric_only` parameter ensures that only numeric columns are included in the correlation computation, which can be useful when dealing with mixed data types.\n",
    "\n",
    "This method is highly versatile and can be adapted to various correlation computation needs, whether using built-in methods or custom functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.corr()` method is used to compute pairwise correlation between the columns of a DataFrame, excluding any NA/null values. This can be particularly useful for understanding relationships between different variables in your dataset.\n",
    "\n",
    "### Overview of `DataFrame.corr()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.corr(method='pearson', min_periods=1, numeric_only=False)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **method**: `{‘pearson’, ‘kendall’, ‘spearman’}` or callable, default `'pearson'`\n",
    "\n",
    "  - Specifies the method to use for correlation:\n",
    "    - `'pearson'`: Standard correlation coefficient.\n",
    "    - `'kendall'`: Kendall Tau correlation coefficient.\n",
    "    - `'spearman'`: Spearman rank correlation.\n",
    "    - `callable`: A user-defined function that takes two 1D arrays as input and returns a float.\n",
    "\n",
    "- **min_periods**: `int`, optional, default `1`\n",
    "\n",
    "  - Minimum number of observations required per pair of columns to have a valid result. This parameter is currently only applicable for Pearson and Spearman correlation.\n",
    "\n",
    "- **numeric_only**: `bool`, default `False`\n",
    "  - If `True`, only includes float, int, or boolean data in the correlation calculation.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A correlation matrix showing the correlation coefficients between the columns.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **DataFrame.corrwith()**: Computes pairwise correlation with another DataFrame or Series.\n",
    "- **Series.corr()**: Computes the correlation between two Series.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The Pearson, Kendall, and Spearman correlations are computed using pairwise complete observations, meaning that only the rows with non-null values in both columns are considered.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Correlation Calculation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with sample data\n",
    "df = pd.DataFrame({\n",
    "    'dogs': [0.2, 0.0, 0.6, 0.2],\n",
    "    'cats': [0.3, 0.6, 0.0, 0.1]\n",
    "})\n",
    "\n",
    "# Calculate the Pearson correlation (default)\n",
    "correlation_matrix = df.corr()\n",
    "print(\"Correlation matrix (Pearson):\")\n",
    "print(correlation_matrix)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Correlation matrix (Pearson):\n",
    "       dogs      cats\n",
    "dogs    1.0  0.309999\n",
    "cats    0.31  1.0\n",
    "```\n",
    "\n",
    "#### Example 2: Using Different Correlation Methods\n",
    "\n",
    "```python\n",
    "# Calculate the Kendall correlation\n",
    "kendall_corr = df.corr(method='kendall')\n",
    "print(\"\\nCorrelation matrix (Kendall):\")\n",
    "print(kendall_corr)\n",
    "\n",
    "# Calculate the Spearman correlation\n",
    "spearman_corr = df.corr(method='spearman')\n",
    "print(\"\\nCorrelation matrix (Spearman):\")\n",
    "print(spearman_corr)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Correlation matrix (Kendall):\n",
    "       dogs      cats\n",
    "dogs    1.0  0.333333\n",
    "cats    0.33  1.0\n",
    "\n",
    "Correlation matrix (Spearman):\n",
    "       dogs      cats\n",
    "dogs    1.0  0.333333\n",
    "cats    0.33  1.0\n",
    "```\n",
    "\n",
    "#### Example 3: Using a Callable for Custom Correlation\n",
    "\n",
    "```python\n",
    "def histogram_intersection(a, b):\n",
    "    v = np.minimum(a, b).sum().round(decimals=1)\n",
    "    return v\n",
    "\n",
    "# Calculate correlation using a custom function\n",
    "custom_corr = df.corr(method=histogram_intersection)\n",
    "print(\"\\nCorrelation matrix using custom method:\")\n",
    "print(custom_corr)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Correlation matrix using custom method:\n",
    "       dogs  cats\n",
    "dogs   1.0  0.3\n",
    "cats   0.3  1.0\n",
    "```\n",
    "\n",
    "#### Example 4: Handling Missing Values with `min_periods`\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with some missing values\n",
    "df_nan = pd.DataFrame({\n",
    "    'dogs': [1, 2, np.nan, 4],\n",
    "    'cats': [1, np.nan, 3, 4]\n",
    "})\n",
    "\n",
    "# Calculate correlation with a minimum number of periods\n",
    "nan_corr = df_nan.corr(min_periods=3)\n",
    "print(\"\\nCorrelation matrix with min_periods=3:\")\n",
    "print(nan_corr)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Correlation matrix with min_periods=3:\n",
    "       dogs  cats\n",
    "dogs   1.0   NaN\n",
    "cats   NaN   1.0\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `DataFrame.corr()` method is a powerful tool for assessing the relationships between different columns in a DataFrame. By offering multiple correlation methods and the ability to handle missing data, it provides flexibility for various analytical needs. Whether you're exploring data relationships or preparing for predictive modeling, understanding these correlations can be crucial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.corrwith\n",
    "DataFrame.corrwith(other, axis=0, drop=False, method='pearson', numeric_only=False)[source]\n",
    "Compute pairwise correlation.\n",
    "\n",
    "Pairwise correlation is computed between rows or columns of DataFrame with rows or columns of Series or DataFrame. DataFrames are first aligned along both axes before computing the correlations.\n",
    "\n",
    "Parameters:\n",
    "otherDataFrame, Series\n",
    "Object with which to compute correlations.\n",
    "\n",
    "axis{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "The axis to use. 0 or ‘index’ to compute row-wise, 1 or ‘columns’ for column-wise.\n",
    "\n",
    "dropbool, default False\n",
    "Drop missing indices from result.\n",
    "\n",
    "method{‘pearson’, ‘kendall’, ‘spearman’} or callable\n",
    "Method of correlation:\n",
    "\n",
    "pearson : standard correlation coefficient\n",
    "\n",
    "kendall : Kendall Tau correlation coefficient\n",
    "\n",
    "spearman : Spearman rank correlation\n",
    "\n",
    "callable: callable with input two 1d ndarrays\n",
    "and returning a float.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int or boolean data.\n",
    "\n",
    "Added in version 1.5.0.\n",
    "\n",
    "Changed in version 2.0.0: The default value of numeric_only is now False.\n",
    "\n",
    "Returns:\n",
    "Series\n",
    "Pairwise correlations.\n",
    "\n",
    "See also\n",
    "\n",
    "DataFrame.corr\n",
    "Compute pairwise correlation of columns.\n",
    "\n",
    "Examples\n",
    "\n",
    "index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "columns = [\"one\", \"two\", \"three\", \"four\"]\n",
    "df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
    "df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
    "df1.corrwith(df2)\n",
    "one      1.0\n",
    "two      1.0\n",
    "three    1.0\n",
    "four     1.0\n",
    "dtype: float64\n",
    "df2.corrwith(df1, axis=1)\n",
    "a    1.0\n",
    "b    1.0\n",
    "c    1.0\n",
    "d    1.0\n",
    "e    NaN\n",
    "dtype: float64 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.corrwith()` method computes pairwise correlation between the rows or columns of a DataFrame with those of another DataFrame or Series. This method is especially useful for exploring relationships between datasets or verifying similar patterns among different groups of observations.\n",
    "\n",
    "### Overview of `DataFrame.corrwith()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.corrwith(other, axis=0, drop=False, method='pearson', numeric_only=False)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **other**: `DataFrame`, `Series`\n",
    "\n",
    "  - The object with which to compute correlations.\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "  - The axis to compute over. Use `0` or `'index'` for row-wise correlation, or `1` or `'columns'` for column-wise correlation.\n",
    "\n",
    "- **drop**: `bool`, default `False`\n",
    "\n",
    "  - Whether to drop indices that are missing in the result.\n",
    "\n",
    "- **method**: `{‘pearson’, ‘kendall’, ‘spearman’}` or callable\n",
    "\n",
    "  - Method of correlation to use:\n",
    "    - `'pearson'`: Standard correlation coefficient.\n",
    "    - `'kendall'`: Kendall Tau correlation coefficient.\n",
    "    - `'spearman'`: Spearman rank correlation.\n",
    "    - `callable`: A user-defined function that accepts two 1D arrays and returns a float.\n",
    "\n",
    "- **numeric_only**: `bool`, default `False`\n",
    "  - If `True`, only consider float, int, or boolean data when computing the correlations.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series**:\n",
    "  - A Series containing the pairwise correlations.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **DataFrame.corr()**: Compute pairwise correlation of the entire DataFrame.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Correlation Calculation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create two DataFrames with sample data\n",
    "index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "columns = [\"one\", \"two\", \"three\", \"four\"]\n",
    "df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
    "df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
    "\n",
    "# Compute pairwise correlation (df1 against df2)\n",
    "correlation_result = df1.corrwith(df2)\n",
    "print(\"Pairwise correlation (df1 with df2):\")\n",
    "print(correlation_result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Pairwise correlation (df1 with df2):\n",
    "one      1.0\n",
    "two      1.0\n",
    "three    1.0\n",
    "four     1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 2: Correlation with Row-wise Calculation\n",
    "\n",
    "```python\n",
    "# Compute pairwise correlation (df2 against df1, row-wise)\n",
    "row_correlation = df2.corrwith(df1, axis=1)\n",
    "print(\"\\nRow-wise correlation (df2 with df1):\")\n",
    "print(row_correlation)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Row-wise correlation (df2 with df1):\n",
    "a    1.0\n",
    "b    1.0\n",
    "c    1.0\n",
    "d    1.0\n",
    "e    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 3: Using Different Correlation Methods\n",
    "\n",
    "```python\n",
    "# Create another DataFrame with different data\n",
    "df3 = pd.DataFrame({\n",
    "    'one': [1, 2, 3],\n",
    "    'two': [4, 5, 6],\n",
    "    'three': [7, 8, 9]\n",
    "}, index=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "# Calculate correlation using the Kendall method\n",
    "kendall_correlation = df3.corrwith(df1)\n",
    "print(\"\\nKendall correlation (df3 with df1):\")\n",
    "print(kendall_correlation)\n",
    "\n",
    "# Calculate correlation using the Spearman method\n",
    "spearman_correlation = df3.corrwith(df1, method='spearman')\n",
    "print(\"\\nSpearman correlation (df3 with df1):\")\n",
    "print(spearman_correlation)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Kendall correlation (df3 with df1):\n",
    "one      1.0\n",
    "two      1.0\n",
    "three    1.0\n",
    "dtype: float64\n",
    "\n",
    "Spearman correlation (df3 with df1):\n",
    "one      1.0\n",
    "two      1.0\n",
    "three    1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `DataFrame.corrwith()` method is a straightforward way to compute the correlation between two datasets, allowing for either row-wise or column-wise analysis. It supports multiple correlation methods, giving flexibility to analyze relationships based on different statistical approaches. This can be especially useful in exploratory data analysis or when comparing different datasets for similarities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.corrwith` method is used to compute pairwise correlations between rows or columns of a DataFrame and another DataFrame or Series. Below is a detailed explanation of the syntax, parameters, and usage examples:\n",
    "\n",
    "---\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.corrwith(other, axis=0, drop=False, method='pearson', numeric_only=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Parameters\n",
    "\n",
    "1. **other** : DataFrame or Series\n",
    "\n",
    "   - The object (DataFrame or Series) with which to compute correlations.\n",
    "\n",
    "2. **axis** : `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "   - The axis to use for computation:\n",
    "     - `0` or `'index'` : Compute correlation row-wise (between rows of the DataFrame and rows of `other`).\n",
    "     - `1` or `'columns'` : Compute correlation column-wise (between columns of the DataFrame and columns of `other`).\n",
    "\n",
    "3. **drop** : bool, default `False`\n",
    "\n",
    "   - If `True`, drop missing indices from the result. If `False`, include missing indices with `NaN` values.\n",
    "\n",
    "4. **method** : `{'pearson', 'kendall', 'spearman'}` or callable, default `'pearson'`\n",
    "\n",
    "   - Method of correlation:\n",
    "     - **pearson** : Standard correlation coefficient.\n",
    "     - **kendall** : Kendall Tau correlation coefficient.\n",
    "     - **spearman** : Spearman rank correlation.\n",
    "     - **callable** : A custom function that takes two 1d ndarrays as input and returns a float.\n",
    "\n",
    "5. **numeric_only** : bool, default `False`\n",
    "   - If `True`, include only float, int, or boolean data in the computation. This parameter was added in version 1.5.0, and its default value changed to `False` in version 2.0.0.\n",
    "\n",
    "---\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series** : Pairwise correlations between the DataFrame and `other`.\n",
    "\n",
    "---\n",
    "\n",
    "### See Also\n",
    "\n",
    "- **DataFrame.corr** : Compute pairwise correlation of columns within a DataFrame.\n",
    "- **Series.corr** : Compute the correlation between two Series.\n",
    "\n",
    "---\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The DataFrames are aligned along both axes before computing correlations.\n",
    "- Missing values (`NaN`) are excluded from the computation.\n",
    "- If `drop=False`, missing indices in the result will be filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Column-wise Correlation Between Two DataFrames\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create two DataFrames\n",
    "index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "columns = [\"one\", \"two\", \"three\", \"four\"]\n",
    "df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
    "df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
    "\n",
    "# Compute column-wise correlation\n",
    "corr_series = df1.corrwith(df2)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "one      1.0\n",
    "two      1.0\n",
    "three    1.0\n",
    "four     1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Row-wise Correlation Between Two DataFrames\n",
    "\n",
    "```python\n",
    "# Compute row-wise correlation\n",
    "corr_series = df2.corrwith(df1, axis=1)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1.0\n",
    "b    1.0\n",
    "c    1.0\n",
    "d    1.0\n",
    "e    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Correlation with a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "series = pd.Series([1, 2, 3, 4], index=columns)\n",
    "\n",
    "# Compute correlation with the Series\n",
    "corr_series = df1.corrwith(series)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "one      1.0\n",
    "two      1.0\n",
    "three    1.0\n",
    "four     1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Using a Custom Correlation Method\n",
    "\n",
    "```python\n",
    "# Define a custom correlation function\n",
    "def custom_corr(a, b):\n",
    "    return np.sum(a * b) / (np.sqrt(np.sum(a**2)) * np.sqrt(np.sum(b**2)))\n",
    "\n",
    "# Compute correlation using the custom function\n",
    "corr_series = df1.corrwith(df2, method=custom_corr)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Handling Missing Values with `drop`\n",
    "\n",
    "```python\n",
    "# Introduce missing values\n",
    "df2.loc['a', 'one'] = np.nan\n",
    "\n",
    "# Compute correlation with missing values\n",
    "corr_series = df1.corrwith(df2, drop=False)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "one      NaN\n",
    "two      1.0\n",
    "three    1.0\n",
    "four     1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- `corrwith` is useful for computing correlations between two DataFrames or a DataFrame and a Series.\n",
    "- The `axis` parameter determines whether correlations are computed row-wise or column-wise.\n",
    "- Missing values are automatically excluded from the computation, but you can control whether to drop or keep missing indices in the result using the `drop` parameter.\n",
    "- Custom correlation methods can be used by passing a callable function to the `method` parameter.\n",
    "\n",
    "This method is particularly useful when comparing the relationships between two datasets or aligning correlations along specific axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.count\n",
    "DataFrame.count(axis=0, numeric_only=False)[source]\n",
    "Count non-NA cells for each column or row.\n",
    "\n",
    "The values None, NaN, NaT, pandas.NA are considered NA.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "If 0 or ‘index’ counts are generated for each column. If 1 or ‘columns’ counts are generated for each row.\n",
    "\n",
    "numeric_only\n",
    "bool, default False\n",
    "Include only float, int or boolean data.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series\n",
    "For each column/row the number of non-NA/null entries.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.count\n",
    "Number of non-NA elements in a Series.\n",
    "\n",
    "DataFrame.value_counts\n",
    "Count unique combinations of columns.\n",
    "\n",
    "DataFrame.shape\n",
    "Number of DataFrame rows and columns (including NA elements).\n",
    "\n",
    "DataFrame.isna\n",
    "Boolean same-sized DataFrame showing places of NA elements.\n",
    "\n",
    "Examples\n",
    "\n",
    "Constructing DataFrame from a dictionary:\n",
    "\n",
    "df = pd.DataFrame({\"Person\":\n",
    "                   [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
    "                   \"Age\": [24., np.nan, 21., 33, 26],\n",
    "                   \"Single\": [False, True, True, True, False]})\n",
    "df\n",
    "   Person   Age  Single\n",
    "0    John  24.0   False\n",
    "1    Myla   NaN    True\n",
    "2   Lewis  21.0    True\n",
    "3    John  33.0    True\n",
    "4    Myla  26.0   False\n",
    "Notice the uncounted NA values:\n",
    "\n",
    "df.count()\n",
    "Person    5\n",
    "Age       4\n",
    "Single    5\n",
    "dtype: int64\n",
    "Counts for each row:\n",
    "\n",
    "df.count(axis='columns')\n",
    "0    3\n",
    "1    2\n",
    "2    3\n",
    "3    3\n",
    "4    3\n",
    "dtype: int64 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.corrwith` method is used to compute pairwise correlations between rows or columns of a DataFrame and another DataFrame or Series. Below is a detailed explanation of the syntax, parameters, and usage examples:\n",
    "\n",
    "---\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.corrwith(other, axis=0, drop=False, method='pearson', numeric_only=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Parameters\n",
    "\n",
    "1. **other** : DataFrame or Series\n",
    "\n",
    "   - The object (DataFrame or Series) with which to compute correlations.\n",
    "\n",
    "2. **axis** : `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "   - The axis to use for computation:\n",
    "     - `0` or `'index'` : Compute correlation row-wise (between rows of the DataFrame and rows of `other`).\n",
    "     - `1` or `'columns'` : Compute correlation column-wise (between columns of the DataFrame and columns of `other`).\n",
    "\n",
    "3. **drop** : bool, default `False`\n",
    "\n",
    "   - If `True`, drop missing indices from the result. If `False`, include missing indices with `NaN` values.\n",
    "\n",
    "4. **method** : `{'pearson', 'kendall', 'spearman'}` or callable, default `'pearson'`\n",
    "\n",
    "   - Method of correlation:\n",
    "     - **pearson** : Standard correlation coefficient.\n",
    "     - **kendall** : Kendall Tau correlation coefficient.\n",
    "     - **spearman** : Spearman rank correlation.\n",
    "     - **callable** : A custom function that takes two 1d ndarrays as input and returns a float.\n",
    "\n",
    "5. **numeric_only** : bool, default `False`\n",
    "   - If `True`, include only float, int, or boolean data in the computation. This parameter was added in version 1.5.0, and its default value changed to `False` in version 2.0.0.\n",
    "\n",
    "---\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series** : Pairwise correlations between the DataFrame and `other`.\n",
    "\n",
    "---\n",
    "\n",
    "### See Also\n",
    "\n",
    "- **DataFrame.corr** : Compute pairwise correlation of columns within a DataFrame.\n",
    "- **Series.corr** : Compute the correlation between two Series.\n",
    "\n",
    "---\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The DataFrames are aligned along both axes before computing correlations.\n",
    "- Missing values (`NaN`) are excluded from the computation.\n",
    "- If `drop=False`, missing indices in the result will be filled with `NaN`.\n",
    "\n",
    "---\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Column-wise Correlation Between Two DataFrames\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create two DataFrames\n",
    "index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "columns = [\"one\", \"two\", \"three\", \"four\"]\n",
    "df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
    "df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
    "\n",
    "# Compute column-wise correlation\n",
    "corr_series = df1.corrwith(df2)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "one      1.0\n",
    "two      1.0\n",
    "three    1.0\n",
    "four     1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Row-wise Correlation Between Two DataFrames\n",
    "\n",
    "```python\n",
    "# Compute row-wise correlation\n",
    "corr_series = df2.corrwith(df1, axis=1)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "a    1.0\n",
    "b    1.0\n",
    "c    1.0\n",
    "d    1.0\n",
    "e    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Correlation with a Series\n",
    "\n",
    "```python\n",
    "# Create a Series\n",
    "series = pd.Series([1, 2, 3, 4], index=columns)\n",
    "\n",
    "# Compute correlation with the Series\n",
    "corr_series = df1.corrwith(series)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "one      1.0\n",
    "two      1.0\n",
    "three    1.0\n",
    "four     1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Using a Custom Correlation Method\n",
    "\n",
    "```python\n",
    "# Define a custom correlation function\n",
    "def custom_corr(a, b):\n",
    "    return np.sum(a * b) / (np.sqrt(np.sum(a**2)) * np.sqrt(np.sum(b**2)))\n",
    "\n",
    "# Compute correlation using the custom function\n",
    "corr_series = df1.corrwith(df2, method=custom_corr)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Handling Missing Values with `drop`\n",
    "\n",
    "```python\n",
    "# Introduce missing values\n",
    "df2.loc['a', 'one'] = np.nan\n",
    "\n",
    "# Compute correlation with missing values\n",
    "corr_series = df1.corrwith(df2, drop=False)\n",
    "print(corr_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "one      NaN\n",
    "two      1.0\n",
    "three    1.0\n",
    "four     1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- `corrwith` is useful for computing correlations between two DataFrames or a DataFrame and a Series.\n",
    "- The `axis` parameter determines whether correlations are computed row-wise or column-wise.\n",
    "- Missing values are automatically excluded from the computation, but you can control whether to drop or keep missing indices in the result using the `drop` parameter.\n",
    "- Custom correlation methods can be used by passing a callable function to the `method` parameter.\n",
    "\n",
    "This method is particularly useful when comparing the relationships between two datasets or aligning correlations along specific axes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comprehensive explanation of **`pandas.DataFrame.count()`**, covering its syntax, parameters, behavior, and examples:\n",
    "\n",
    "---\n",
    "\n",
    "### **`pandas.DataFrame.count()`**\n",
    "\n",
    "Counts the number of **non-NA/null** values for each column or row in a DataFrame. This function is useful for understanding the completeness of your data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.count(axis=0, numeric_only=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Parameters**\n",
    "\n",
    "| Parameter  | Description          |\n",
    "| ---------- | -------------------- |\n",
    "| **`axis`** | Axis to count along: |\n",
    "\n",
    "- `0` or `'index'`: Count non-NA values for each **column** (default).\n",
    "- `1` or `'columns'`: Count non-NA values for each **row**. |  \n",
    "  | **`numeric_only`** | If `True`, include only numeric columns (float, int, or boolean). Default is `False`. |\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**\n",
    "\n",
    "- **Series**: A Series containing the count of non-NA values for each column or row.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes**\n",
    "\n",
    "1. **NA Values**:\n",
    "\n",
    "   - The following are considered NA: `None`, `NaN`, `NaT`, and `pandas.NA`.\n",
    "   - These values are excluded from the count.\n",
    "\n",
    "2. **Behavior with Empty Data**:\n",
    "\n",
    "   - If a column or row contains only NA values, the count will be `0`.\n",
    "\n",
    "3. **Common Use Cases**:\n",
    "   - Check for missing data in columns or rows.\n",
    "   - Assess data completeness before analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### 1. **Count Non-NA Values in Columns**\n",
    "\n",
    "Count non-NA values for each column:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    \"Person\": [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
    "    \"Age\": [24., np.nan, 21., 33, 26],\n",
    "    \"Single\": [False, True, True, True, False]\n",
    "})\n",
    "\n",
    "df.count()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Person    5\n",
    "Age       4\n",
    "Single    5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Count Non-NA Values in Rows**\n",
    "\n",
    "Count non-NA values for each row:\n",
    "\n",
    "```python\n",
    "df.count(axis='columns')\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "0    3\n",
    "1    2\n",
    "2    3\n",
    "3    3\n",
    "4    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Count Only Numeric Columns**\n",
    "\n",
    "Count non-NA values for numeric columns only:\n",
    "\n",
    "```python\n",
    "df.count(numeric_only=True)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Age       4\n",
    "Single    5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Handling All-NA Columns**\n",
    "\n",
    "Count non-NA values in a DataFrame with an all-NA column:\n",
    "\n",
    "```python\n",
    "df['New_Column'] = np.nan\n",
    "df.count()\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Person        5\n",
    "Age           4\n",
    "Single        5\n",
    "New_Column    0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Related Functions**\n",
    "\n",
    "- **`Series.count()`**: Count non-NA values in a Series.\n",
    "- **`DataFrame.value_counts()`**: Count unique combinations of columns.\n",
    "- **`DataFrame.shape`**: Get the number of rows and columns (including NA values).\n",
    "- **`DataFrame.isna()`**: Identify NA values in a DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `count()`**\n",
    "\n",
    "- To assess the completeness of your data.\n",
    "- To identify columns or rows with missing values.\n",
    "- For data cleaning and preprocessing.\n",
    "\n",
    "This method is essential for understanding the structure and quality of your data in pandas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.cov\n",
    "DataFrame.cov(min_periods=None, ddof=1, numeric_only=False)[source]\n",
    "Compute pairwise covariance of columns, excluding NA/null values.\n",
    "\n",
    "Compute the pairwise covariance among the series of a DataFrame. The returned data frame is the covariance matrix of the columns of the DataFrame.\n",
    "\n",
    "Both NA and null values are automatically excluded from the calculation. (See the note below about bias from missing values.) A threshold can be set for the minimum number of observations for each value created. Comparisons with observations below this threshold will be returned as NaN.\n",
    "\n",
    "This method is generally used for the analysis of time series data to understand the relationship between different measures across time.\n",
    "\n",
    "Parameters:\n",
    "min_periodsint, optional\n",
    "Minimum number of observations required per pair of columns to have a valid result.\n",
    "\n",
    "ddofint, default 1\n",
    "Delta degrees of freedom. The divisor used in calculations is N - ddof, where N represents the number of elements. This argument is applicable only when no nan is in the dataframe.\n",
    "\n",
    "numeric_onlybool, default False\n",
    "Include only float, int or boolean data.\n",
    "\n",
    "Added in version 1.5.0.\n",
    "\n",
    "Changed in version 2.0.0: The default value of numeric_only is now False.\n",
    "\n",
    "Returns:\n",
    "DataFrame\n",
    "The covariance matrix of the series of the DataFrame.\n",
    "\n",
    "See also\n",
    "\n",
    "Series.cov\n",
    "Compute covariance with another Series.\n",
    "\n",
    "core.window.ewm.ExponentialMovingWindow.cov\n",
    "Exponential weighted sample covariance.\n",
    "\n",
    "core.window.expanding.Expanding.cov\n",
    "Expanding sample covariance.\n",
    "\n",
    "core.window.rolling.Rolling.cov\n",
    "Rolling sample covariance.\n",
    "\n",
    "Notes\n",
    "\n",
    "Returns the covariance matrix of the DataFrame’s time series. The covariance is normalized by N-ddof.\n",
    "\n",
    "For DataFrames that have Series that are missing data (assuming that data is missing at random) the returned covariance matrix will be an unbiased estimate of the variance and covariance between the member Series.\n",
    "\n",
    "However, for many applications this estimate may not be acceptable because the estimate covariance matrix is not guaranteed to be positive semi-definite. This could lead to estimate correlations having absolute values which are greater than one, and/or a non-invertible covariance matrix. See Estimation of covariance matrices for more details.\n",
    "\n",
    "Examples\n",
    "\n",
    "df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
    "                  columns=['dogs', 'cats'])\n",
    "df.cov()\n",
    "          dogs      cats\n",
    "dogs  0.666667 -1.000000\n",
    "cats -1.000000  1.666667\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.randn(1000, 5),\n",
    "                  columns=['a', 'b', 'c', 'd', 'e'])\n",
    "df.cov()\n",
    "          a         b         c         d         e\n",
    "a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
    "b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
    "c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
    "d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
    "e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
    "Minimum number of periods\n",
    "\n",
    "This method also supports an optional min_periods keyword that specifies the required minimum number of non-NA observations for each column pair in order to have a valid result:\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.randn(20, 3),\n",
    "                  columns=['a', 'b', 'c'])\n",
    "df.loc[df.index[:5], 'a'] = np.nan\n",
    "df.loc[df.index[5:10], 'b'] = np.nan\n",
    "df.cov(min_periods=12)\n",
    "          a         b         c\n",
    "a  0.316741       NaN -0.150812\n",
    "b       NaN  1.248003  0.191417\n",
    "c -0.150812  0.191417  0.895202 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.cov()` method computes the pairwise covariance of the columns in a DataFrame, excluding any NA (Not Available) or null values. This method is particularly useful in statistical analysis to understand the relationships between different variables.\n",
    "\n",
    "### Overview of `DataFrame.cov()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.cov(min_periods=None, ddof=1, numeric_only=False)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **min_periods**: `int`, optional\n",
    "\n",
    "  - Minimum number of observations required per pair of columns to have a valid result. If the number of non-NA observations is less than this, the result will be `NaN`.\n",
    "\n",
    "- **ddof**: `int`, default `1`\n",
    "\n",
    "  - Delta degrees of freedom. The divisor used in calculations is \\(N - \\text{ddof}\\), where \\(N\\) is the number of non-NA elements. This parameter is applicable only when there are no NA values in the DataFrame.\n",
    "\n",
    "- **numeric_only**: `bool`, default `False`\n",
    "  - If `True`, only considers float, int, or boolean data for the calculation.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **DataFrame**:\n",
    "  - A covariance matrix representing the covariance between the columns of the DataFrame.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **Series.cov()**: Computes covariance with another Series.\n",
    "- **core.window.ewm.ExponentialMovingWindow.cov**: Computes exponential weighted sample covariance.\n",
    "- **core.window.expanding.Expanding.cov**: Computes expanding sample covariance.\n",
    "- **core.window.rolling.Rolling.cov**: Computes rolling sample covariance.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The covariance matrix provides insights into how two variables change together. A positive covariance indicates that as one variable increases, the other tends to increase, while a negative covariance indicates the opposite.\n",
    "- The covariance matrix may not be guaranteed to be positive semi-definite, which can lead to issues in certain applications.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Basic Covariance Calculation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
    "                  columns=['dogs', 'cats'])\n",
    "\n",
    "# Compute the covariance matrix\n",
    "cov_matrix = df.cov()\n",
    "print(\"Covariance matrix:\")\n",
    "print(cov_matrix)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Covariance matrix:\n",
    "          dogs      cats\n",
    "dogs  0.666667 -1.000000\n",
    "cats -1.000000  1.666667\n",
    "```\n",
    "\n",
    "#### Example 2: Covariance with Random Data\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a DataFrame with random numbers\n",
    "df_random = pd.DataFrame(np.random.randn(1000, 5),\n",
    "                         columns=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "# Compute the covariance matrix\n",
    "cov_random = df_random.cov()\n",
    "print(\"\\nCovariance matrix of random data:\")\n",
    "print(cov_random)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Covariance matrix of random data:\n",
    "          a         b         c         d         e\n",
    "a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
    "b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
    "c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
    "d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
    "e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
    "```\n",
    "\n",
    "#### Example 3: Covariance with Minimum Periods\n",
    "\n",
    "```python\n",
    "# Create a DataFrame with missing values\n",
    "np.random.seed(42)\n",
    "df_nan = pd.DataFrame(np.random.randn(20, 3),\n",
    "                      columns=['a', 'b', 'c'])\n",
    "\n",
    "# Introduce NaN values\n",
    "df_nan.loc[df_nan.index[:5], 'a'] = np.nan\n",
    "df_nan.loc[df_nan.index[5:10], 'b'] = np.nan\n",
    "\n",
    "# Compute the covariance matrix with a minimum number of periods\n",
    "cov_min_periods = df_nan.cov(min_periods=12)\n",
    "print(\"\\nCovariance matrix with min_periods=12:\")\n",
    "print(cov_min_periods)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Covariance matrix with min_periods=12:\n",
    "          a         b         c\n",
    "a  0.316741       NaN -0.150812\n",
    "b       NaN  1.248003  0.191417\n",
    "c -0.150812  0.191417  0.895202\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `DataFrame.cov()` method is a powerful tool for calculating the covariance matrix of a DataFrame, allowing analysts to understand the relationships between different variables. By excluding NA values and providing options for minimum observation thresholds, it offers flexibility for various statistical analyses, particularly in time series data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.count` method is used to count the number of non-NA (non-missing) cells for each column or row in a DataFrame. Below is a detailed explanation of the syntax, parameters, and usage examples:\n",
    "\n",
    "---\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.count(axis=0, numeric_only=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Parameters\n",
    "\n",
    "1. **axis** : `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "   - The axis along which to count non-NA cells:\n",
    "     - `0` or `'index'` : Count non-NA cells for each **column**.\n",
    "     - `1` or `'columns'` : Count non-NA cells for each **row**.\n",
    "\n",
    "2. **numeric_only** : bool, default `False`\n",
    "   - If `True`, include only float, int, or boolean data in the count. If `False`, include all data types.\n",
    "\n",
    "---\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series** : A Series containing the count of non-NA/null entries for each column or row.\n",
    "\n",
    "---\n",
    "\n",
    "### See Also\n",
    "\n",
    "- **Series.count** : Number of non-NA elements in a Series.\n",
    "- **DataFrame.value_counts** : Count unique combinations of columns.\n",
    "- **DataFrame.shape** : Number of DataFrame rows and columns (including NA elements).\n",
    "- **DataFrame.isna** : Boolean DataFrame showing the locations of NA elements.\n",
    "\n",
    "---\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The following values are considered NA (missing):\n",
    "  - `None`\n",
    "  - `NaN` (Not a Number)\n",
    "  - `NaT` (Not a Time)\n",
    "  - `pandas.NA` (pandas' missing value indicator).\n",
    "- If `numeric_only=True`, only numeric columns (float, int, boolean) are included in the count.\n",
    "\n",
    "---\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Counting Non-NA Cells in Columns\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Person\": [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
    "    \"Age\": [24., np.nan, 21., 33, 26],\n",
    "    \"Single\": [False, True, True, True, False]\n",
    "})\n",
    "\n",
    "# Count non-NA cells for each column\n",
    "count_series = df.count()\n",
    "print(count_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Person    5\n",
    "Age       4\n",
    "Single    5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Counting Non-NA Cells in Rows\n",
    "\n",
    "```python\n",
    "# Count non-NA cells for each row\n",
    "count_series = df.count(axis='columns')\n",
    "print(count_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    3\n",
    "1    2\n",
    "2    3\n",
    "3    3\n",
    "4    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Counting Only Numeric Columns\n",
    "\n",
    "```python\n",
    "# Count non-NA cells for numeric columns only\n",
    "count_series = df.count(numeric_only=True)\n",
    "print(count_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Age       4\n",
    "Single    5\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 4: Handling Missing Values\n",
    "\n",
    "```python\n",
    "# Introduce more missing values\n",
    "df.loc[2, 'Person'] = np.nan\n",
    "df.loc[3, 'Single'] = np.nan\n",
    "\n",
    "# Count non-NA cells for each column\n",
    "count_series = df.count()\n",
    "print(count_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Person    4\n",
    "Age       4\n",
    "Single    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 5: Counting Non-NA Cells in Rows with Missing Values\n",
    "\n",
    "```python\n",
    "# Count non-NA cells for each row\n",
    "count_series = df.count(axis=1)\n",
    "print(count_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "0    3\n",
    "1    2\n",
    "2    2\n",
    "3    2\n",
    "4    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- The `count` method is useful for identifying the number of valid (non-missing) entries in a DataFrame.\n",
    "- By default, it counts non-NA cells for each column (`axis=0`). Use `axis=1` to count non-NA cells for each row.\n",
    "- The `numeric_only` parameter allows you to restrict the count to numeric columns (float, int, boolean).\n",
    "- Missing values (`None`, `NaN`, `NaT`, `pandas.NA`) are excluded from the count.\n",
    "\n",
    "This method is particularly helpful for data cleaning and understanding the completeness of your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.cummax\n",
    "DataFrame.cummax(axis=None, skipna=True, *args, **kwargs)[source]\n",
    "Return cumulative maximum over a DataFrame or Series axis.\n",
    "\n",
    "Returns a DataFrame or Series of the same size containing the cumulative maximum.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "The index or the name of the axis. 0 is equivalent to None or ‘index’. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "Return cumulative maximum of Series or DataFrame.\n",
    "\n",
    "See also\n",
    "\n",
    "core.window.expanding.Expanding.max\n",
    "Similar functionality but ignores NaN values.\n",
    "\n",
    "DataFrame.max\n",
    "Return the maximum over DataFrame axis.\n",
    "\n",
    "DataFrame.cummax\n",
    "Return cumulative maximum over DataFrame axis.\n",
    "\n",
    "DataFrame.cummin\n",
    "Return cumulative minimum over DataFrame axis.\n",
    "\n",
    "DataFrame.cumsum\n",
    "Return cumulative sum over DataFrame axis.\n",
    "\n",
    "DataFrame.cumprod\n",
    "Return cumulative product over DataFrame axis.\n",
    "\n",
    "Examples\n",
    "\n",
    "Series\n",
    "\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "s\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    5.0\n",
    "3   -1.0\n",
    "4    0.0\n",
    "dtype: float64\n",
    "By default, NA values are ignored.\n",
    "\n",
    "s.cummax()\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    5.0\n",
    "3    5.0\n",
    "4    5.0\n",
    "dtype: float64\n",
    "To include NA values in the operation, use skipna=False\n",
    "\n",
    "s.cummax(skipna=False)\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "DataFrame\n",
    "\n",
    "df = pd.DataFrame([[2.0, 1.0],\n",
    "                   [3.0, np.nan],\n",
    "                   [1.0, 0.0]],\n",
    "                  columns=list('AB'))\n",
    "df\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  3.0  NaN\n",
    "2  1.0  0.0\n",
    "By default, iterates over rows and finds the maximum in each column. This is equivalent to axis=None or axis='index'.\n",
    "\n",
    "df.cummax()\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  3.0  NaN\n",
    "2  3.0  1.0\n",
    "To iterate over columns and find the maximum in each row, use axis=1\n",
    "\n",
    "df.cummax(axis=1)\n",
    "     A    B\n",
    "0  2.0  2.0\n",
    "1  3.0  NaN\n",
    "2  1.0  1.0  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.cummax()` method calculates the cumulative maximum value along a specified axis of a DataFrame or Series. This function is useful for analyzing time series data or any sequential data where you want to track the highest value seen so far.\n",
    "\n",
    "### Overview of `DataFrame.cummax()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.cummax(axis=None, skipna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "  - Determines the axis for the operation:\n",
    "    - `0` or `'index'`: Cumulative maximum is computed column-wise.\n",
    "    - `1` or `'columns'`: Cumulative maximum is computed row-wise.\n",
    "\n",
    "- **skipna**: `bool`, default `True`\n",
    "  - Excludes NA/null values from the calculation. If an entire row or column is NA, the result will be NA.\n",
    "- **args, kwargs**:\n",
    "  - Additional arguments are accepted for compatibility with NumPy but have no effect on this method.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - Returns a Series or DataFrame containing the cumulative maximum values along the specified axis.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **DataFrame.max()**: Returns the maximum value over the specified DataFrame axis.\n",
    "- **DataFrame.cummin()**: Returns cumulative minimum over DataFrame axis.\n",
    "- **DataFrame.cumsum()**: Returns cumulative sum over DataFrame.\n",
    "- **DataFrame.cumprod()**: Returns cumulative product over DataFrame.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Cumulative Maximum on a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "print(\"Series:\")\n",
    "print(s)\n",
    "\n",
    "# Compute cumulative maximum\n",
    "cummax_series = s.cummax()\n",
    "print(\"\\nCumulative maximum:\")\n",
    "print(cummax_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Series:\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    5.0\n",
    "3   -1.0\n",
    "4    0.0\n",
    "dtype: float64\n",
    "\n",
    "Cumulative maximum:\n",
    "0    2.0\n",
    "1    2.0\n",
    "2    5.0\n",
    "3    5.0\n",
    "4    5.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 2: Including NA Values in Cumulative Maximum\n",
    "\n",
    "```python\n",
    "# Cumulative maximum with skipna=False\n",
    "cummax_series_na = s.cummax(skipna=False)\n",
    "print(\"\\nCumulative maximum including NA values:\")\n",
    "print(cummax_series_na)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cumulative maximum including NA values:\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 3: Cumulative Maximum on a DataFrame\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame([[2.0, 1.0],\n",
    "                   [3.0, np.nan],\n",
    "                   [1.0, 0.0]],\n",
    "                  columns=list('AB'))\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Cumulative maximum column-wise (default behavior)\n",
    "cummax_df = df.cummax()\n",
    "print(\"\\nCumulative maximum (column-wise):\")\n",
    "print(cummax_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cumulative maximum (column-wise):\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  3.0  1.0\n",
    "2  3.0  1.0\n",
    "```\n",
    "\n",
    "#### Example 4: Cumulative Maximum Row-wise\n",
    "\n",
    "```python\n",
    "# Cumulative maximum row-wise\n",
    "cummax_df_row = df.cummax(axis=1)\n",
    "print(\"\\nCumulative maximum (row-wise):\")\n",
    "print(cummax_df_row)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cumulative maximum (row-wise):\n",
    "     A    B\n",
    "0  2.0  2.0\n",
    "1  3.0  3.0\n",
    "2  1.0  1.0\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `DataFrame.cummax()` method is a powerful tool in pandas for calculating the cumulative maximum values across a DataFrame or Series. It's particularly useful when tracking the highest values seen up to each point in time or observations. By allowing the option to skip NA values, it provides flexibility for various data types and scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.cummin\n",
    "DataFrame.cummin(axis=None, skipna=True, *args, **kwargs)[source]\n",
    "Return cumulative minimum over a DataFrame or Series axis.\n",
    "\n",
    "Returns a DataFrame or Series of the same size containing the cumulative minimum.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "axis\n",
    "{0 or ‘index’, 1 or ‘columns’}, default 0\n",
    "The index or the name of the axis. 0 is equivalent to None or ‘index’. For Series this parameter is unused and defaults to 0.\n",
    "\n",
    "skipna\n",
    "bool, default True\n",
    "Exclude NA/null values. If an entire row/column is NA, the result will be NA.\n",
    "\n",
    "*args, **kwargs\n",
    "Additional keywords have no effect but might be accepted for compatibility with NumPy.\n",
    "\n",
    "Returns\n",
    ":\n",
    "Series or DataFrame\n",
    "Return cumulative minimum of Series or DataFrame.\n",
    "\n",
    "See also\n",
    "\n",
    "core.window.expanding.Expanding.min\n",
    "Similar functionality but ignores NaN values.\n",
    "\n",
    "DataFrame.min\n",
    "Return the minimum over DataFrame axis.\n",
    "\n",
    "DataFrame.cummax\n",
    "Return cumulative maximum over DataFrame axis.\n",
    "\n",
    "DataFrame.cummin\n",
    "Return cumulative minimum over DataFrame axis.\n",
    "\n",
    "DataFrame.cumsum\n",
    "Return cumulative sum over DataFrame axis.\n",
    "\n",
    "DataFrame.cumprod\n",
    "Return cumulative product over DataFrame axis.\n",
    "\n",
    "Examples\n",
    "\n",
    "Series\n",
    "\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "s\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    5.0\n",
    "3   -1.0\n",
    "4    0.0\n",
    "dtype: float64\n",
    "By default, NA values are ignored.\n",
    "\n",
    "s.cummin()\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    2.0\n",
    "3   -1.0\n",
    "4   -1.0\n",
    "dtype: float64\n",
    "To include NA values in the operation, use skipna=False\n",
    "\n",
    "s.cummin(skipna=False)\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "DataFrame\n",
    "\n",
    "df = pd.DataFrame([[2.0, 1.0],\n",
    "                   [3.0, np.nan],\n",
    "                   [1.0, 0.0]],\n",
    "                  columns=list('AB'))\n",
    "df\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  3.0  NaN\n",
    "2  1.0  0.0\n",
    "By default, iterates over rows and finds the minimum in each column. This is equivalent to axis=None or axis='index'.\n",
    "\n",
    "df.cummin()\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  2.0  NaN\n",
    "2  1.0  0.0\n",
    "To iterate over columns and find the minimum in each row, use axis=1\n",
    "\n",
    "df.cummin(axis=1)\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  3.0  NaN\n",
    "2  1.0  0.0 \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.cummin()` method calculates the cumulative minimum value along a specified axis of a DataFrame or Series. This function is useful in scenarios where you need to track the lowest value encountered up to each point in your data.\n",
    "\n",
    "### Overview of `DataFrame.cummin()`\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.cummin(axis=None, skipna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- **axis**: `{0 or 'index', 1 or 'columns'}`, default `0`\n",
    "\n",
    "  - Defines the axis for the operation:\n",
    "    - `0` or `'index'`: Cumulative minimum is computed column-wise (along each column).\n",
    "    - `1` or `'columns'`: Cumulative minimum is computed row-wise (along each row).\n",
    "\n",
    "- **skipna**: `bool`, default `True`\n",
    "\n",
    "  - Excludes NA/null values from the calculation. If an entire row or column is NA, the result will be NA.\n",
    "\n",
    "- **args, kwargs**:\n",
    "  - Additional arguments are accepted for compatibility with NumPy but have no effect on this method.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **Series or DataFrame**:\n",
    "  - Returns a Series or DataFrame with the cumulative minimum values along the specified axis.\n",
    "\n",
    "### Related Functions\n",
    "\n",
    "- **DataFrame.min()**: Returns the minimum value over the specified DataFrame axis.\n",
    "- **DataFrame.cummax()**: Returns cumulative maximum over DataFrame axis.\n",
    "- **DataFrame.cumsum()**: Returns cumulative sum over DataFrame.\n",
    "- **DataFrame.cumprod()**: Returns cumulative product over DataFrame.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Cumulative Minimum on a Series\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([2, np.nan, 5, -1, 0])\n",
    "print(\"Series:\")\n",
    "print(s)\n",
    "\n",
    "# Compute cumulative minimum\n",
    "cummin_series = s.cummin()\n",
    "print(\"\\nCumulative minimum:\")\n",
    "print(cummin_series)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Series:\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    5.0\n",
    "3   -1.0\n",
    "4    0.0\n",
    "dtype: float64\n",
    "\n",
    "Cumulative minimum:\n",
    "0    2.0\n",
    "1    2.0\n",
    "2    2.0\n",
    "3   -1.0\n",
    "4   -1.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 2: Including NA Values in Cumulative Minimum\n",
    "\n",
    "```python\n",
    "# Cumulative minimum with skipna=False\n",
    "cummin_series_na = s.cummin(skipna=False)\n",
    "print(\"\\nCumulative minimum including NA values:\")\n",
    "print(cummin_series_na)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cumulative minimum including NA values:\n",
    "0    2.0\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "#### Example 3: Cumulative Minimum on a DataFrame\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame([[2.0, 1.0],\n",
    "                   [3.0, np.nan],\n",
    "                   [1.0, 0.0]],\n",
    "                  columns=list('AB'))\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Cumulative minimum column-wise (default behavior)\n",
    "cummin_df = df.cummin()\n",
    "print(\"\\nCumulative minimum (column-wise):\")\n",
    "print(cummin_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cumulative minimum (column-wise):\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  2.0  1.0\n",
    "2  1.0  0.0\n",
    "```\n",
    "\n",
    "#### Example 4: Cumulative Minimum Row-wise\n",
    "\n",
    "```python\n",
    "# Cumulative minimum row-wise\n",
    "cummin_df_row = df.cummin(axis=1)\n",
    "print(\"\\nCumulative minimum (row-wise):\")\n",
    "print(cummin_df_row)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Cumulative minimum (row-wise):\n",
    "     A    B\n",
    "0  2.0  1.0\n",
    "1  3.0  3.0\n",
    "2  1.0  0.0\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `DataFrame.cummin()` method is a valuable feature in pandas that allows for the calculation of cumulative minimum values across a DataFrame or Series. It efficiently tracks the lowest values seen so far while providing options to handle NA values based on user preference. This can be particularly useful in data analysis for monitoring trends or changes over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pandas.DataFrame.to_numpy\n",
    "DataFrame.to_numpy(dtype=None, copy=False, na_value=<no_default>)[source]\n",
    "Convert the DataFrame to a NumPy array.\n",
    "\n",
    "By default, the dtype of the returned array will be the common NumPy dtype of all types in the DataFrame. For example, if the dtypes are float16 and float32, the results dtype will be float32. This may require copying data and coercing values, which may be expensive.\n",
    "\n",
    "Parameters\n",
    ":\n",
    "dtype\n",
    "str or numpy.dtype, optional\n",
    "The dtype to pass to numpy.asarray().\n",
    "\n",
    "copy\n",
    "bool, default False\n",
    "Whether to ensure that the returned value is not a view on another array. Note that copy=False does not ensure that to_numpy() is no-copy. Rather, copy=True ensure that a copy is made, even if not strictly necessary.\n",
    "\n",
    "na_value\n",
    "Any, optional\n",
    "The value to use for missing values. The default value depends on dtype and the dtypes of the DataFrame columns.\n",
    "\n",
    "Returns\n",
    ":\n",
    "numpy.ndarray\n",
    "See also\n",
    "\n",
    "Series.to_numpy\n",
    "Similar method for Series.\n",
    "\n",
    "Examples\n",
    "\n",
    "pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n",
    "array([[1, 3],\n",
    "       [2, 4]])\n",
    "With heterogeneous data, the lowest common type will have to be used.\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
    "df.to_numpy()\n",
    "array([[1. , 3. ],\n",
    "       [2. , 4.5]])\n",
    "For a mix of numeric and non-numeric types, the output array will have object dtype.\n",
    "\n",
    "df['C'] = pd.date_range('2000', periods=2)\n",
    "df.to_numpy()\n",
    "array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n",
    "       [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.to_numpy` method is a versatile function that converts a DataFrame into a NumPy array. Below, I'll provide a comprehensive overview of its syntax, parameters, return values, and examples to illustrate its usage.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.to_numpy(dtype=None, copy=False, na_value=<no_default>)\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "1. **dtype**: `str` or `numpy.dtype`, optional\n",
    "\n",
    "   - This parameter allows you to specify the desired data type for the output NumPy array. If not provided, the method will infer the common data type based on the DataFrame's columns.\n",
    "\n",
    "2. **copy**: `bool`, default `False`\n",
    "\n",
    "   - This parameter controls whether to ensure that the returned array is not a view on another array.\n",
    "   - If `copy=True`, a copy of the data will be made, even if it is not strictly necessary.\n",
    "   - If `copy=False`, the method may return a view of the data if possible, which can lead to performance benefits but may also mean changes to the original DataFrame affect the NumPy array.\n",
    "\n",
    "3. **na_value**: `Any`, optional\n",
    "   - This specifies the value to use for missing values (NaNs). The default behavior depends on the specified `dtype` and the dtypes of the DataFrame columns.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- **numpy.ndarray**: The method returns a NumPy array representation of the DataFrame.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Basic Example\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a simple DataFrame\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n",
    "\n",
    "# Converting to a NumPy array\n",
    "array_result = df.to_numpy()\n",
    "print(array_result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([[1, 3],\n",
    "       [2, 4]])\n",
    "```\n",
    "\n",
    "#### With Heterogeneous Data\n",
    "\n",
    "When the DataFrame contains mixed types, the output will use the lowest common type.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
    "array_result = df.to_numpy()\n",
    "print(array_result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([[1. , 3. ],\n",
    "       [2. , 4.5]])\n",
    "```\n",
    "\n",
    "#### Mixed Numeric and Non-Numeric Types\n",
    "\n",
    "If the DataFrame contains a mix of numeric and non-numeric types, the output array will have `object` dtype.\n",
    "\n",
    "```python\n",
    "df['C'] = pd.date_range('2000', periods=2)\n",
    "array_result = df.to_numpy()\n",
    "print(array_result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n",
    "       [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n",
    "```\n",
    "\n",
    "#### Specifying a Data Type\n",
    "\n",
    "You can specify a particular dtype for the output array.\n",
    "\n",
    "```python\n",
    "array_result = df.to_numpy(dtype='float32')\n",
    "print(array_result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "array([[1. , 3. , 0.],\n",
    "       [2. , 4.5, 0.]], dtype=float32)\n",
    "```\n",
    "\n",
    "#### Copy Parameter\n",
    "\n",
    "If you want to ensure that a copy is made regardless of whether a view could be returned, set `copy=True`.\n",
    "\n",
    "```python\n",
    "array_result = df.to_numpy(copy=True)\n",
    "print(array_result)\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The `to_numpy()` method is a powerful tool for converting a DataFrame to a NumPy array, allowing for flexible data type handling and control over whether a copy is made.\n",
    "- It is especially useful when integrating pandas with libraries that require NumPy arrays, such as machine learning libraries.\n",
    "\n",
    "This overview should provide you with a clear understanding of how to use `pandas.DataFrame.to_numpy` effectively. If you have any further questions or need clarification on specific aspects, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.DataFrame.to_numpy()` method is used to convert a **Pandas DataFrame** into a **NumPy array**. This is particularly useful when you need to perform numerical operations or use libraries that require NumPy arrays as input. Below is a comprehensive explanation of the method, including its parameters, return value, and examples.\n",
    "\n",
    "---\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "```python\n",
    "DataFrame.to_numpy(dtype=None, copy=False, na_value=<no_default>)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Parameters**\n",
    "\n",
    "| Parameter      | Description                                                                                                                                                           |\n",
    "| -------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **`dtype`**    | `str` or `numpy.dtype`, optional<br>The data type of the resulting NumPy array. If not specified, the common dtype of all columns will be used.                       |\n",
    "| **`copy`**     | `bool`, default `False`<br>If `True`, ensures that the returned array is a copy of the data. If `False`, the array may be a view on the original data.                |\n",
    "| **`na_value`** | Any, optional<br>The value to use for missing (`NaN`) values in the DataFrame. If not specified, the default depends on the `dtype` and the DataFrame's column types. |\n",
    "\n",
    "---\n",
    "\n",
    "## **Returns**\n",
    "\n",
    "- **`numpy.ndarray`**: A NumPy array representation of the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Points**\n",
    "\n",
    "1. **Dtype Inference**:\n",
    "\n",
    "   - If the DataFrame contains columns with different dtypes, the resulting array will have a **common dtype** that can accommodate all the data.\n",
    "   - For example:\n",
    "     - If the DataFrame has `float16` and `float32` columns, the resulting array will have `float32` dtype.\n",
    "     - If the DataFrame has a mix of numeric and non-numeric types, the resulting array will have `object` dtype.\n",
    "\n",
    "2. **Copy Behavior**:\n",
    "\n",
    "   - By default (`copy=False`), the method may return a **view** of the data, meaning changes to the array could affect the original DataFrame.\n",
    "   - If `copy=True`, a **copy** of the data is always returned, ensuring that changes to the array do not affect the DataFrame.\n",
    "\n",
    "3. **Handling Missing Values**:\n",
    "   - The `na_value` parameter allows you to specify a value to replace missing (`NaN`) values in the DataFrame.\n",
    "   - If not specified, the default behavior depends on the `dtype` of the resulting array.\n",
    "\n",
    "---\n",
    "\n",
    "## **Examples**\n",
    "\n",
    "### **Example 1: Basic Usage**\n",
    "\n",
    "Convert a DataFrame with homogeneous data (all integers) to a NumPy array.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n",
    "array = df.to_numpy()\n",
    "print(array)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "[[1 3]\n",
    " [2 4]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 2: Heterogeneous Data**\n",
    "\n",
    "Convert a DataFrame with mixed data types (integers and floats) to a NumPy array.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
    "array = df.to_numpy()\n",
    "print(array)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "[[1.  3. ]\n",
    " [2.  4.5]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 3: Mixed Numeric and Non-Numeric Data**\n",
    "\n",
    "Convert a DataFrame with numeric and non-numeric (e.g., datetime) columns to a NumPy array.\n",
    "\n",
    "```python\n",
    "df['C'] = pd.date_range('2000', periods=2)\n",
    "array = df.to_numpy()\n",
    "print(array)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "[[1 3.0 Timestamp('2000-01-01 00:00:00')]\n",
    " [2 4.5 Timestamp('2000-01-02 00:00:00')]]\n",
    "```\n",
    "\n",
    "- The resulting array has `dtype=object` because it contains mixed types.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 4: Specifying `dtype`**\n",
    "\n",
    "Convert a DataFrame to a NumPy array with a specific data type.\n",
    "\n",
    "```python\n",
    "array = df.to_numpy(dtype='float32')\n",
    "print(array)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "[[1.  3.  0. ]\n",
    " [2.  4.5 0. ]]\n",
    "```\n",
    "\n",
    "- Non-numeric columns (e.g., datetime) are coerced to `0.0` because they cannot be converted to `float32`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 5: Handling Missing Values**\n",
    "\n",
    "Convert a DataFrame with missing values to a NumPy array, replacing `NaN` with a specified value.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\"A\": [1, None], \"B\": [3.0, 4.5]})\n",
    "array = df.to_numpy(na_value=-1)\n",
    "print(array)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "```\n",
    "[[ 1.   3. ]\n",
    " [-1.   4.5]]\n",
    "```\n",
    "\n",
    "- The `NaN` value in column `A` is replaced with `-1`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example 6: Ensuring a Copy**\n",
    "\n",
    "Convert a DataFrame to a NumPy array and ensure the result is a copy.\n",
    "\n",
    "```python\n",
    "array = df.to_numpy(copy=True)\n",
    "```\n",
    "\n",
    "- This ensures that the returned array is a copy of the data, not a view.\n",
    "\n",
    "---\n",
    "\n",
    "## **When to Use `to_numpy()`**\n",
    "\n",
    "1. **Interoperability with NumPy**: Use `to_numpy()` when you need to pass DataFrame data to a NumPy-based library (e.g., SciPy, Scikit-learn).\n",
    "2. **Performance**: NumPy arrays are generally faster for numerical computations than Pandas DataFrames.\n",
    "3. **Memory Efficiency**: If you don't need the DataFrame's indexing or labeling, converting to a NumPy array can save memory.\n",
    "\n",
    "---\n",
    "\n",
    "## **See Also**\n",
    "\n",
    "- **`Series.to_numpy()`**: Similar method for converting a Pandas Series to a NumPy array.\n",
    "- **`numpy.asarray()`**: The underlying function used by `to_numpy()`.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
